A fast IP routing lookup scheme for gigabit switching routers. telecommunication network routing; transport protocols; table lookup; pipeline processing; SRAM chips; electronic switching systems; fast IP routing lookup; gigabit switching routers; IP packet; longest prefix matching; address lookup; SRAM; pipelined hardware; forwarding table; memory accesses; 450 to 470 kbyte; 10 ns; Routing; Random access memory; Packet switching; Hardware; Telecommunication traffic; Optical fiber cables; Internet; Databases; Computer science; Electronic mail. One of the key design issues for the new generation IP routers is the route lookup mechanism. For each incoming IP packet, the IP routing requires to perform a longest prefix matching on the address lookup in order to determine the packet's next hop. This paper presents a fast route lookup mechanism that only needs tiny SRAM and can be implemented in a pipelined skill in hardware. Based on the proposed scheme, the forwarding table is tiny enough to fit in SRAM with very low cost. For example, a large routing table with 40,000 routing entries can be compacted to a forwarding table of 450-470 Kbytes. In the worst case, the number of memory accesses for a lookup is three. When implemented in a pipeline skill in hardware, the proposed mechanism can achieve one routing lookup every memory access. With current 10 ns SRAM, this mechanism furnishes approximately 100 million routing lookups per second. This is much faster than any current commercially available routing lookup schemes.

Routing lookups in hardware at memory access speeds. telecommunication network routing; Internet; packet switching; transport protocols; table lookup; DRAM chips; pipeline processing; memory access speeds; IP routing lookups; bandwidth; Internet; network routers; Gigabit Ethernet packets; longest-prefix-match address lookup; OC-192 line; router performance; datagram; pipelined hardware implementation; DRAM; routing update patterns; forwarding table updates; routing tables; central processor; 50 ns; Routing; Hardware; Random access memory; Costs; Spine; Laboratories; Bit rate; Internet; Ethernet networks; Uninterruptible power systems. The increased bandwidth in the Internet puts great demands on network routers; for example, to route minimum sized Gigabit Ethernet packets, an IP router must process about 1.5/spl times/10/sup 6/ packets per second per port. Using the "rule-of-thumb" that it takes roughly 1000 packets per second for every 10/sup 6/ bits per second of line rate, an OC-192 line requires 10/spl times/10/sup 6/ routing lookups per second; well above current router capabilities. One limitation of router performance is the route lookup mechanism. IP routing requires that a router perform a longest-prefix-match address lookup for each incoming datagram in order to determine the datagram's next hop. We present a route lookup mechanism that when implemented in a pipelined fashion in hardware, can achieve one route lookup every memory access. With current 50 ns DRAM, this corresponds to approximately 20/spl times/10/sup 6/ packets per second; much faster than current commercially available routing lookup schemes. We also present novel schemes for performing quick updates to the forwarding table in hardware. We demonstrate using real routing update patterns that the routing tables can be updated with negligible overhead to the central processor.

CutSplit: A Decision-Tree Combining Cutting and Splitting for Scalable Packet Classification. computational complexity; decision trees; inference mechanisms; Internet; pattern classification; software defined networking; CutSplit; scalable packet classification; efficient algorithmic solutions; multifield packet classification; Software Defined Network; SDN; flow tables; increasing complexities; central role; forwarding plane; in-depth reasoning; scalable algorithmic solutions; practical framework; splitting techniques; central problem; uncontrollable rule replications; algorithmic packet classification; hardware-based solutions; low pre-processing time; rule updates; decision-tree; ClassBench; memory reduction; Classification algorithms; Memory management; Decision trees; Optimization; IP networks; Conferences; Software defined networking; Packet Classification; OpenFlow; Decision Tree; Algorithm; Firewall. Efficient algorithmic solutions for multi-field packet classification have been a challenging problem for many years. This problem is becoming even worse in the era of Software Defined Network (SDN), where flow tables with increasing complexities are playing a central role in the forwarding plane of SDN. In this paper, we first conduct an unprecedented in-depth reasoning on issues that led to the unsuccess of the major quests for scalable algorithmic solutions. With the insights obtained, we propose a practical framework called CutSplit, which can exploit the benefits of cutting and splitting techniques adaptively. By addressing the central problem caused by uncontrollable rule replications suffered by the major efforts, CutSplit not only pushes the performance of algorithmic packet classification more closely to hardware-based solutions, but also reduces the memory consumption to a practical level. Moreover, our work achieves low pre-processing time for rule updates, a problem that has long been ignored by previous decision-trees, but is becoming more relevant in the context of SDN due to frequent updates of rules. Experimental results show that using ClassBench, CutSplit achieves a memory reduction over 10 times, as well as 3x improvement on performance in terms of the number of memory access on average.

CutSplit: A Decision-Tree Combining Cutting and Splitting for Scalable Packet Classification. computational complexity; decision trees; inference mechanisms; Internet; pattern classification; software defined networking; CutSplit; scalable packet classification; efficient algorithmic solutions; multifield packet classification; Software Defined Network; SDN; flow tables; increasing complexities; central role; forwarding plane; in-depth reasoning; scalable algorithmic solutions; practical framework; splitting techniques; central problem; uncontrollable rule replications; algorithmic packet classification; hardware-based solutions; low pre-processing time; rule updates; decision-tree; ClassBench; memory reduction; Classification algorithms; Memory management; Decision trees; Optimization; IP networks; Conferences; Software defined networking; Packet Classification; OpenFlow; Decision Tree; Algorithm; Firewall. Efficient algorithmic solutions for multi-field packet classification have been a challenging problem for many years. This problem is becoming even worse in the era of Software Defined Network (SDN), where flow tables with increasing complexities are playing a central role in the forwarding plane of SDN. In this paper, we first conduct an unprecedented in-depth reasoning on issues that led to the unsuccess of the major quests for scalable algorithmic solutions. With the insights obtained, we propose a practical framework called CutSplit, which can exploit the benefits of cutting and splitting techniques adaptively. By addressing the central problem caused by uncontrollable rule replications suffered by the major efforts, CutSplit not only pushes the performance of algorithmic packet classification more closely to hardware-based solutions, but also reduces the memory consumption to a practical level. Moreover, our work achieves low pre-processing time for rule updates, a problem that has long been ignored by previous decision-trees, but is becoming more relevant in the context of SDN due to frequent updates of rules. Experimental results show that using ClassBench, CutSplit achieves a memory reduction over 10 times, as well as 3x improvement on performance in terms of the number of memory access on average.

ByteCuts: Fast Packet Classification by Interior Bit Extraction. firewalls; pattern classification; telecommunication network routing; telecommunication traffic; trees (mathematics); ByteCuts; fast packet classification; interior bit extraction; networking devices; routing tables; network traffic; tree-based packet classifiers; cutting method; firewalls; rule list; rule replication reduction; Vegetation; Decision trees; Memory management; Conferences; Real-time systems; Measurement; Indexes. Many networking devices, such as firewalls and routing tables, rely upon packet classifiers to define their behavior for various kinds of network traffic. Since these devices have real-time constraints, it is important for packet classification to be as fast as possible. We present a new method, ByteCuts, which includes two major improvements over existing tree-based packet classifiers. First, it introduces a new cutting method that is more efficient than existing methods. Second, ByteCuts intelligently partitions the rule list into multiple trees in a way that supports the cutting method and reduces rule replication. We compare ByteCuts to several existing methods such as HyperCuts, HyperSplit, and SmartSplit. We find that ByteCuts outperforms SmartSplit, the previous fastest classifier, in every metric; specifically, ByteCuts is able to classify packets 58% faster, can be constructed in seconds rather than minutes, and uses orders of magnitude less memory.

ByteCuts: Fast Packet Classification by Interior Bit Extraction. firewalls; pattern classification; telecommunication network routing; telecommunication traffic; trees (mathematics); ByteCuts; fast packet classification; interior bit extraction; networking devices; routing tables; network traffic; tree-based packet classifiers; cutting method; firewalls; rule list; rule replication reduction; Vegetation; Decision trees; Memory management; Conferences; Real-time systems; Measurement; Indexes. Many networking devices, such as firewalls and routing tables, rely upon packet classifiers to define their behavior for various kinds of network traffic. Since these devices have real-time constraints, it is important for packet classification to be as fast as possible. We present a new method, ByteCuts, which includes two major improvements over existing tree-based packet classifiers. First, it introduces a new cutting method that is more efficient than existing methods. Second, ByteCuts intelligently partitions the rule list into multiple trees in a way that supports the cutting method and reduces rule replication. We compare ByteCuts to several existing methods such as HyperCuts, HyperSplit, and SmartSplit. We find that ByteCuts outperforms SmartSplit, the previous fastest classifier, in every metric; specifically, ByteCuts is able to classify packets 58% faster, can be constructed in seconds rather than minutes, and uses orders of magnitude less memory.

Fast OpenFlow Table Lookup with Fast Update. Internet; IP networks; pipeline processing; protocols; software defined networking; table lookup; network architecture; software-defined networking; fast Openflow table lookup; Future Internet; communication protocol; longest prefix matching; multifield matching; packet classification; exact matching; IP lookup; fast OpenFlow table lookup; 5-stage pipeline architecture; long-pipeline architecture; lookup pipeline architecture; multiple OpenFlow tables; OpenFlow switches; data plane; control plane; Computer architecture; IP networks; Pipelines; Pipeline processing; Classification algorithms; Conferences; Protocols. Software-Defined Networking (SDN), which separates the control plane and data plane, is a promising new network architecture for the Future Internet. OpenFlow is the de facto standard which defines the communication protocol between the controller and switches. The most challenging issue in OpenFlow switches is the lookup of multiple OpenFlow tables. The lookup of OpenFlow tables is so complicated that the state-of-the-art research are still focusing on the design of lookup pipeline architecture, and there is no specific algorithm for the lookup of OpenFlow tables. In this paper, we revise the long-pipeline architecture of OpenFlow 1.4 to a 5-stage pipeline architecture to make a trade-off between flexibility and implementability, and decompose the lookup of OpenFlow tables into three kinds of lookup: longest prefix matching (IP lookup), multi-field matching (packet classification), and exact matching. Then we design new algorithms for packet classification, because the state-of-the-art solutions for them seldom support fast update which is highly demanding for OpenFlow. The other two kinds of lookups can be well handled by state-of-the-art. Experimental results show that our proposed algorithms work excellently, and outperform state-of-the-art solutions.

Fast incremental updates for pipelined forwarding engines. application specific integrated circuits; telecommunication equipment; pipeline processing; IP networks; telecommunication network routing; data structures; minimisation; fast incremental update; pipelined forwarding engine; application-specific integrated circuit; pipelined ASIC architecture; high speed IP router; optimization issues; memory-efficient data structure design; memory utilization balances; disruption minimization; core routing table; multiple pipeline stage; update overhead reduction; Engines; Routing; Pipeline processing; Application specific integrated circuits; Hardware; Random access memory; Data structures; Filtering; Costs; Design optimization. Pipelined ASIC architectures are increasingly being used in forwarding engines for high speed IP routers. We explore optimization issues in the design of memory-efficient data structures that support fast incremental updates in such forwarding engines. Our solution aims to balance the memory utilization across the multiple pipeline stages. We also propose a series of optimizations that minimize the disruption to the forwarding process caused by route updates. These optimizations reduce the update overheads by a factor of 2-5 for a variety of different core routing tables and update traces.

Mailbox switch: a scalable two-stage switch architecture for conflict resolution of ordered packets. packet switching; queueing theory; scheduling; mailbox switch; two-stage switch architecture; packet conflict resolution; input-buffered switch; virtual output queue; information matching; communication overhead; computation overhead; symmetric connection pattern; feedback path; packet departure time; packet scheduling; switch fabric; Birkhoff-von Neumann switch; Switches; Packet switching; Communication switching; Impedance matching; Computer architecture; Throughput; Fabrics; Concurrent computing; Pattern matching; Feedback. Traditionally, conflict resolution in an input-buffered switch is solved by finding a matching between inputs and outputs per time slot. To do this, a switch not only needs to gather the information of the virtual output queues at the inputs, hut also uses the gathered information to compute a matching. As such, both the communication overhead and the computation overhead make it difficult to scale. Recent works on the two-stage switch architecture in (6|, [7], [12], (8| showed that conflict resolution can be easily solved over time and space without communication and computation overhead. However, the main problem of such a two-stage switch architecture is that packets might be out of sequence. The main objective of this paper is to propose a scalable solution, called the mailbox switch, that solves the out-of-sequence problem in the two-stage switch architecture. The key idea of the mailbox switch is to use a set of symmetric connection patterns to create a feedback path for packet departure times. With the information of packet departure times, the mailbox switch can schedule packets so that they depart in the order of their arrivals. Despite the simplicity of the mailbox switch, we show via both the theoretical models and simulations that the throughput of the mailbox switch can be as high as 75%. With limited resequencing delay, a modified version of the mailbox switch achieves 95% throughput. We also propose a recursive way to construct the switch fabrics for the set of symmetric connection patterns. If the number of inputs, N, is a power of 2, we show that the switch fabric for the mailbox switch can be built with N/2 log<sub>2 </sub> N 2times2 switches

High-performance longest prefix matching supporting high-speed incremental updates and guaranteed compression. IP networks; Internet; tree data structures; storage management; telecommunication network routing; high-performance longest prefix matching; high-speed incremental updates; guaranteed compression; IP forwarding; Internet; direct indexing; tree structure; forwarding table; memory management technique; fast variable size allocation; IPv4 forwarding table data structure; SRAM; routing table; Routing; Data structures; Hardware; Wire; Internet; Robustness; Pathology; Indexing; Tree data structures; Memory management. Longest prefix matching is frequently used for IP forwarding in the Internet. Data structures used must be not only efficient, hut also robust against pathological entries caused by an adversary or misconfiguration. In this paper, we attack the longest prefix matching problem by presenting a new algorithm supporting high lookup performance, fast incremental updates and guaranteed compression ratio. High lookup performance is achieved by using only four memory accesses. Guaranteed compression ratio is achieved by combining direct indexing with an implicit tree structure and carefully choosing which construct to use when updating the forwarding table. Fast incremental updates are achieved by a new memory management technique featuring fast variable size allocation and deallocation while maintaining zero fragmentation. An IPv4 forwarding table data structure can be implemented in software or hardware within 2.7 Mb of memory to represent 2/sup 18/ routing entries. Incremental updates require only 752 memory accesses in worst case for the current guaranteed compression ratio. For a hardware implementation, we can use 300 MHz SRAM organized in four memory banks and four pipeline stages to achieve a guaranteed performance of 300 million lookups per second, corresponding to /spl sim/ 100 Gbit/s wire speed forwarding, and 400,000 incremental updates per second. In measurements performed on a 3.0 GHz Pentium 4 machine using a routing table with more than 2/sup 17/ entries, we can forward over 27 million IPv4 packets per second, which is equivalent to wire speeds exceeding 10 Gbit/s. On the same machine and with the same routing table, we can perform over 230,000 incremental updates/second.

