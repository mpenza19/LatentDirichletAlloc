{u'doi': u'10.1109/INFOCOM.2018.8485970', u'author': u'L. Wang and W. Wang and B. Li', u'title': u'Utopia: Near-optimal Coflow Scheduling with Isolation Guarantee', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Performance and service isolation come as two top objectives for coflow scheduling. However, the common wisdom is that these two objectives are often conflicting with each other and cannot be achieved simultaneously. Existing coflow scheduling frameworks either focus only on minimizing the average coflow completion time (CCT) (e.g., Varys), or providing optimal isolation between contending coflows by means of fair network sharing (e.g., HUG). In this paper, we make an attempt to achieve the best of both worlds through a novel coflow scheduler, Utopia, to attain near-optimal performance with provable isolation guarantee. This is particularly challenging given the correlation of bandwidth demands across multiple links from coflows. We show that Utopia is capable of reducing the average CCT dramatically, while still guaranteeing that no coflow will ever be delayed beyond a constant time than its CCT in a fair scheme. Both trace-driven simulation and EC2 deployment confirm that Utopia outperforms the fair sharing policy by 1.8 \xd7 in terms of average CCT, while producing no completion time delay for a single coflow. Even compared with performance-optimal Varys, Utopia speeds up average coflow completion by 9%.', u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'891-899', u'year': u'2018', u'keywords': u'delays;telecommunication scheduling;fair network;Utopia;near-optimal performance;provable isolation guarantee;average CCT;constant time;fair scheme;fair sharing policy;completion time delay;single coflow;performance-optimal Varys;near-optimal coflow scheduling;service isolation;common wisdom;coflow scheduling frameworks;average coflow completion time;optimal isolation;contending coflows;Bandwidth;Resource management;Fabrics;Delays;Conferences;Correlation;Production', 'ID': u'8485970', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2018.8485970', u'author': u'L. Wang and W. Wang and B. Li', u'title': u'Utopia: Near-optimal Coflow Scheduling with Isolation Guarantee', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Performance and service isolation come as two top objectives for coflow scheduling. However, the common wisdom is that these two objectives are often conflicting with each other and cannot be achieved simultaneously. Existing coflow scheduling frameworks either focus only on minimizing the average coflow completion time (CCT) (e.g., Varys), or providing optimal isolation between contending coflows by means of fair network sharing (e.g., HUG). In this paper, we make an attempt to achieve the best of both worlds through a novel coflow scheduler, Utopia, to attain near-optimal performance with provable isolation guarantee. This is particularly challenging given the correlation of bandwidth demands across multiple links from coflows. We show that Utopia is capable of reducing the average CCT dramatically, while still guaranteeing that no coflow will ever be delayed beyond a constant time than its CCT in a fair scheme. Both trace-driven simulation and EC2 deployment confirm that Utopia outperforms the fair sharing policy by 1.8 \xd7 in terms of average CCT, while producing no completion time delay for a single coflow. Even compared with performance-optimal Varys, Utopia speeds up average coflow completion by 9%.', u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'891-899', u'year': u'2018', u'keywords': u'delays;telecommunication scheduling;fair network;Utopia;near-optimal performance;provable isolation guarantee;average CCT;constant time;fair scheme;fair sharing policy;completion time delay;single coflow;performance-optimal Varys;near-optimal coflow scheduling;service isolation;common wisdom;coflow scheduling frameworks;average coflow completion time;optimal isolation;contending coflows;Bandwidth;Resource management;Fabrics;Delays;Conferences;Correlation;Production', 'ID': u'8485970', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057171', u'author': u'Q. Liang and E. Modiano', u'title': u'Coflow scheduling in input-queued switches: Optimal delay scaling and algorithms', 'ENTRYTYPE': u'inproceedings', u'abstract': u'A coflow is a collection of parallel flows belonging to the same job. It has the all-or-nothing property: a coflow is not complete until the completion of all its constituent flows. In this paper, we focus on optimizing coflow-level delay, i.e., the time to complete all the flows in a coflow, in the context of an N \xd7 N input-queued switch. In particular, we develop a throughput-optimal scheduling policy that achieves the best scaling of coflow-level delay as N \u2192 \u221e. We first derive lower bounds on the coflow-level delay that can be achieved by any scheduling policy. It is observed that these lower bounds critically depend on the variability of flow sizes. Then we analyze the coflow-level performance of some existing coflow-agnostic scheduling policies and show that none of them achieves provably optimal performance with respect to coflow-level delay. Finally, we propose the Coflow-Aware Batching (CAB) policy which achieves the optimal scaling of coflow-level delay under some mild assumptions.', u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'computer networks;delays;optimisation;queueing theory;scheduling;telecommunication scheduling;throughput-optimal scheduling policy;coflow-level delay;coflow-level performance;Coflow-Aware Batching policy;Optimal delay scaling;coflow-agnostic scheduling policies;CAB policy;Delays;Scheduling;Optimal scheduling;Processor scheduling;Ports (Computers)', 'ID': u'8057171', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057171', u'author': u'Q. Liang and E. Modiano', u'title': u'Coflow scheduling in input-queued switches: Optimal delay scaling and algorithms', 'ENTRYTYPE': u'inproceedings', u'abstract': u'A coflow is a collection of parallel flows belonging to the same job. It has the all-or-nothing property: a coflow is not complete until the completion of all its constituent flows. In this paper, we focus on optimizing coflow-level delay, i.e., the time to complete all the flows in a coflow, in the context of an N \xd7 N input-queued switch. In particular, we develop a throughput-optimal scheduling policy that achieves the best scaling of coflow-level delay as N \u2192 \u221e. We first derive lower bounds on the coflow-level delay that can be achieved by any scheduling policy. It is observed that these lower bounds critically depend on the variability of flow sizes. Then we analyze the coflow-level performance of some existing coflow-agnostic scheduling policies and show that none of them achieves provably optimal performance with respect to coflow-level delay. Finally, we propose the Coflow-Aware Batching (CAB) policy which achieves the optimal scaling of coflow-level delay under some mild assumptions.', u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'computer networks;delays;optimisation;queueing theory;scheduling;telecommunication scheduling;throughput-optimal scheduling policy;coflow-level delay;coflow-level performance;Coflow-Aware Batching policy;Optimal delay scaling;coflow-agnostic scheduling policies;CAB policy;Delays;Scheduling;Optimal scheduling;Processor scheduling;Ports (Computers)', 'ID': u'8057171', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057173', u'author': u'C. Wang and S. T. Maguluri and T. Javidi', u'title': u'Heavy traffic queue length behavior in switches with reconfiguration delay', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Optical switches have been drawing attention due to their large data bandwidth and low power consumption. However, scheduling policies need to account for the schedule reconfiguration delay of optical switches to achieve good performance. The Adaptive MaxWeight policy achieves optimal throughput for switches with nonzero reconfiguration delay, and has been shown in simulation to have good delay performance. In this paper, we analyze the queue length behavior of a switch with nonzero reconfiguration delay operating under the Adaptive MaxWeight. We first show that the Adaptive MaxWeight policy exhibits a weak state space collapse behavior in steady-state, which could be viewed as an inheritance of the MaxWeight policy in a switch with zero reconfiguration delay. We then use the weak state space collapse result to obtain a steady state delay bound under the Adaptive MaxWeight algorithm in heavy traffic by applying a recently developed drift technique. The resulting delay bound is dependent on the expected schedule duration. We then derive the relation between the expected schedule duration and the steady state queue length through drift analysis, and obtain asymptotically tight queue length bounds in the heavy traffic regime.', u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'delays;optical switches;queueing theory;telecommunication scheduling;telecommunication traffic;Adaptive MaxWeight policy;weak state space collapse behavior;drift analysis;schedule reconfiguration delay;scheduling policies;optical switches;heavy traffic regime;asymptotically tight queue length;steady state queue length;expected schedule duration;Adaptive MaxWeight algorithm;steady state delay;weak state space collapse result;nonzero reconfiguration delay;queue length behavior;Schedules;Delays;Optical switches;Steady-state;Throughput;Ports (Computers);Queueing analysis', 'ID': u'8057173', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057173', u'author': u'C. Wang and S. T. Maguluri and T. Javidi', u'title': u'Heavy traffic queue length behavior in switches with reconfiguration delay', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Optical switches have been drawing attention due to their large data bandwidth and low power consumption. However, scheduling policies need to account for the schedule reconfiguration delay of optical switches to achieve good performance. The Adaptive MaxWeight policy achieves optimal throughput for switches with nonzero reconfiguration delay, and has been shown in simulation to have good delay performance. In this paper, we analyze the queue length behavior of a switch with nonzero reconfiguration delay operating under the Adaptive MaxWeight. We first show that the Adaptive MaxWeight policy exhibits a weak state space collapse behavior in steady-state, which could be viewed as an inheritance of the MaxWeight policy in a switch with zero reconfiguration delay. We then use the weak state space collapse result to obtain a steady state delay bound under the Adaptive MaxWeight algorithm in heavy traffic by applying a recently developed drift technique. The resulting delay bound is dependent on the expected schedule duration. We then derive the relation between the expected schedule duration and the steady state queue length through drift analysis, and obtain asymptotically tight queue length bounds in the heavy traffic regime.', u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'delays;optical switches;queueing theory;telecommunication scheduling;telecommunication traffic;Adaptive MaxWeight policy;weak state space collapse behavior;drift analysis;schedule reconfiguration delay;scheduling policies;optical switches;heavy traffic regime;asymptotically tight queue length;steady state queue length;expected schedule duration;Adaptive MaxWeight algorithm;steady state delay;weak state space collapse result;nonzero reconfiguration delay;queue length behavior;Schedules;Delays;Optical switches;Steady-state;Throughput;Ports (Computers);Queueing analysis', 'ID': u'8057173', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2006.238', u'author': u'D. Shah and D. Wischik', u'title': u'Optimal Scheduling Algorithms for Input-Queued Switches', 'ENTRYTYPE': u'inproceedings', u'abstract': '', u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': '', u'pages': u'1-11', u'year': u'2006', u'keywords': u'Optimal scheduling;Scheduling algorithm;Switches;Impedance matching;Delay;Packet switching;Throughput;Fabrics;Internet;Algorithm design and analysis', 'ID': u'4146891', u'booktitle': u'Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2018.8486323', u'author': u'S. Im and M. Shadloo and Z. Zheng', u'title': u'Online Partial Throughput Maximization for Multidimensional Coflow', 'ENTRYTYPE': u'inproceedings', u'abstract': u"Coflow has recently been introduced to capture communication patterns that are widely observed in the cloud and massively parallel computing. Coflow consists of a number of flows that each represents data communication from one machine to another. A coflow is completed when all of its flows are completed. Due to its elegant abstraction of the complicated communication processes found in various parallel computing platforms, it has received significant attention. In this paper, we consider coflow for the objective of maximizing partial throughput. This objective seeks to measure the progress made for partially completed coflows before their deadline. Partially processed coflows still could be useful when their flows send out useful data that can be used for the next round computation. In our measure, a coflow is processed by a certain fraction when all of its flows are processed by the same fraction or more. We consider a natural class of greedy algorithms, which we call myopic concurrent. The algorithms seek to maximize the marginal increase of the partial throughput objective at each time. We analyze the performance of our algorithm against the optimal scheduler. In fact, our result is more general as a flow could be extended to demand various heterogeneous resources. Our experiment demonstrates our algorithm's superior performance.", u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'2042-2050', u'year': u'2018', u'keywords': u'data communication;parallel programming;scheduling;parallel computing platforms;partially completed coflows;partially processed coflows;partial throughput objective;online partial throughput maximization;multidimensional coflow;communication patterns;massively parallel computing;data communication;Task analysis;Throughput;Computational modeling;Schedules;Optimal scheduling;Cloud computing;Processor scheduling', 'ID': u'8486323', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2018.8486323', u'author': u'S. Im and M. Shadloo and Z. Zheng', u'title': u'Online Partial Throughput Maximization for Multidimensional Coflow', 'ENTRYTYPE': u'inproceedings', u'abstract': u"Coflow has recently been introduced to capture communication patterns that are widely observed in the cloud and massively parallel computing. Coflow consists of a number of flows that each represents data communication from one machine to another. A coflow is completed when all of its flows are completed. Due to its elegant abstraction of the complicated communication processes found in various parallel computing platforms, it has received significant attention. In this paper, we consider coflow for the objective of maximizing partial throughput. This objective seeks to measure the progress made for partially completed coflows before their deadline. Partially processed coflows still could be useful when their flows send out useful data that can be used for the next round computation. In our measure, a coflow is processed by a certain fraction when all of its flows are processed by the same fraction or more. We consider a natural class of greedy algorithms, which we call myopic concurrent. The algorithms seek to maximize the marginal increase of the partial throughput objective at each time. We analyze the performance of our algorithm against the optimal scheduler. In fact, our result is more general as a flow could be extended to demand various heterogeneous resources. Our experiment demonstrates our algorithm's superior performance.", u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'2042-2050', u'year': u'2018', u'keywords': u'data communication;parallel programming;scheduling;parallel computing platforms;partially completed coflows;partially processed coflows;partial throughput objective;online partial throughput maximization;multidimensional coflow;communication patterns;massively parallel computing;data communication;Task analysis;Throughput;Computational modeling;Schedules;Optimal scheduling;Cloud computing;Processor scheduling', 'ID': u'8486323', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057172', u'author': u'W. Wang and S. Ma and B. Li and B. Li', u'title': u'Coflex: Navigating the fairness-efficiency tradeoff for coflow scheduling', 'ENTRYTYPE': u'inproceedings', u'abstract': u"Fair and efficient coflow scheduling improves application-level networking performance in today's datacenters. Ideally, a coflow scheduler should provide isolation guarantees on the minimum coflow progress to achieve predictable networking performance. Network operators, on the other hand, strive to decrease the average coflow completion time (CCT). Unfortunately, optimal isolation guarantees and minimum average CCT are conflicting objectives and cannot be achieved at the same time. Existing coflow schedulers either optimize isolation guarantees at the expense of long CCTs (e.g., HUG [1]), or decrease the average CCT without performance isolation (e.g., Varys and Aalo [2], [3]). The lack of a smooth tradeoff in between poses a dilemma between low efficiency and no performance isolation. To bridge this gap, we develop a new coflow scheduler, Coflex, to navigate this tradeoff. Coflex allows network operators to specify the desired level of isolation guarantee using a tunable fairness knob, while at the same time decreasing the average CCT. Both our real-world deployments and trace-driven simulations have shown that Coflex offers a smooth tradeoff between fairness and efficiency. At an appropriate tradeoff level, Coflex outperforms fair schedulers by 2 \xd7 in minimizing the average CCT.", u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'computer centres;computer networks;telecommunication scheduling;Coflex;fairness-efficiency tradeoff;application-level networking performance;coflow scheduler;minimum coflow progress;predictable networking performance;network operators;average coflow completion time;optimal isolation guarantees;minimum average CCT;performance isolation;coflow scheduling;Bandwidth;Resource management;Fabrics;Navigation;Production;Silicon;Conferences', 'ID': u'8057172', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
