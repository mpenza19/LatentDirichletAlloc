Virtual Redundancy for Active-Standby Cloud Applications. cloud computing; resource allocation; scheduling; software reliability; virtual machines; active-active approaches; load balancing; autoscaling; active-standby approaches; cloud resources; large-scale cloud; resource utilization; virtual redundancy; active-standby cloud applications; VM redundancy; cloud-based solution; VM placement; redundancy-aware VM scheduler; Cloud computing; Servers; Ear; Redundancy; Resource management; Topology; Conferences. VM redundancy is the foundation of resilient cloud applications. While active-active approaches combined with load balancing and autoscaling are usually resource efficient, the stateful nature of many cloud applications often necessitates 1+1 (or 1+n) active-standby approaches. Keeping the standbys, however, could result in inefficient utilization of cloud resources. We explore an intriguing cloud-based solution, where standby VMs from active-standby applications are selectively overbooked to reduce resources reserved for failures. The approach requires careful VM placement to avoid a situation where multiple standby VMs activate simultaneously on the same host and thus cannot get the full resource entitlement. Indeed today's clouds do not have this visibility to the applications. We rectify this situation through ShadowBox, a novel redundancy-aware VM scheduler that optimizes the placement and activation of standby VMs, while assuring applications' resource entitlements. Evaluation on a large-scale cloud shows that ShadowBox can significantly improve resource utilization (i.e., more than 2.5 times than traditional approaches) while minimizing the impact on applications' entitlements.

Virtual Redundancy for Active-Standby Cloud Applications. cloud computing; resource allocation; scheduling; software reliability; virtual machines; active-active approaches; load balancing; autoscaling; active-standby approaches; cloud resources; large-scale cloud; resource utilization; virtual redundancy; active-standby cloud applications; VM redundancy; cloud-based solution; VM placement; redundancy-aware VM scheduler; Cloud computing; Servers; Ear; Redundancy; Resource management; Topology; Conferences. VM redundancy is the foundation of resilient cloud applications. While active-active approaches combined with load balancing and autoscaling are usually resource efficient, the stateful nature of many cloud applications often necessitates 1+1 (or 1+n) active-standby approaches. Keeping the standbys, however, could result in inefficient utilization of cloud resources. We explore an intriguing cloud-based solution, where standby VMs from active-standby applications are selectively overbooked to reduce resources reserved for failures. The approach requires careful VM placement to avoid a situation where multiple standby VMs activate simultaneously on the same host and thus cannot get the full resource entitlement. Indeed today's clouds do not have this visibility to the applications. We rectify this situation through ShadowBox, a novel redundancy-aware VM scheduler that optimizes the placement and activation of standby VMs, while assuring applications' resource entitlements. Evaluation on a large-scale cloud shows that ShadowBox can significantly improve resource utilization (i.e., more than 2.5 times than traditional approaches) while minimizing the impact on applications' entitlements.

Optimizing NFV Chain Deployment through Minimizing the Cost of Virtual Switching. computer networks; resource allocation; switching networks; telecommunication traffic; virtualisation; network traffic; high traffic throughput; theoretical placement functions; virtual switching resource utilization; network function virtualization; NFV chain deployment optimization; cloud infrastructure; physical resource allocation; VNF; virtual network functions; OpenStack-Nova method; Servers; Switches; Virtual machine monitors; Conferences; Virtualization; Cloud computing; Task analysis. Network Function Virtualization (NFV) is a novel paradigm that enables flexible and scalable implementation of network services on cloud infrastructure. A key factor in the success of NFV is the ability to dynamically allocate physical resources according to the demand. This is particularly important when dealing with the data plane since additional resources are required in order to support the virtual switching of the packets between the Virtual Network Functions (VNFs). The exact amount of these resources depends on the way service chains are deployed and the amount of network traffic being handled. Thus, orchestrating service chains that require high traffic throughput is a very complex task and most existing solutions either concentrate on handcrafted tuning of the servers to achieve the needed performance level, or present theoretical placement functions that assume that the switching cost is part of the input. In this work, we bridge this gap by presenting a deployment algorithm for service chains that optimizes performance by minimizing the actual cost of virtual switching. The results are based on extensive measurements of the actual switching cost and the performance of service chains in a realistic NFV environment. Our evaluation indicates that this new algorithm significantly reduces virtual switching resource utilization when compared to the de-facto standard placement in OpenStack/Nova - allowing a much higher acceptance ratio of network services.

Optimizing NFV Chain Deployment through Minimizing the Cost of Virtual Switching. computer networks; resource allocation; switching networks; telecommunication traffic; virtualisation; network traffic; high traffic throughput; theoretical placement functions; virtual switching resource utilization; network function virtualization; NFV chain deployment optimization; cloud infrastructure; physical resource allocation; VNF; virtual network functions; OpenStack-Nova method; Servers; Switches; Virtual machine monitors; Conferences; Virtualization; Cloud computing; Task analysis. Network Function Virtualization (NFV) is a novel paradigm that enables flexible and scalable implementation of network services on cloud infrastructure. A key factor in the success of NFV is the ability to dynamically allocate physical resources according to the demand. This is particularly important when dealing with the data plane since additional resources are required in order to support the virtual switching of the packets between the Virtual Network Functions (VNFs). The exact amount of these resources depends on the way service chains are deployed and the amount of network traffic being handled. Thus, orchestrating service chains that require high traffic throughput is a very complex task and most existing solutions either concentrate on handcrafted tuning of the servers to achieve the needed performance level, or present theoretical placement functions that assume that the switching cost is part of the input. In this work, we bridge this gap by presenting a deployment algorithm for service chains that optimizes performance by minimizing the actual cost of virtual switching. The results are based on extensive measurements of the actual switching cost and the performance of service chains in a realistic NFV environment. Our evaluation indicates that this new algorithm significantly reduces virtual switching resource utilization when compared to the de-facto standard placement in OpenStack/Nova - allowing a much higher acceptance ratio of network services.

Availability-aware mapping of service function chains. computer centres; computer network management; virtualisation; availability-aware SFC mapping problem; data centers; resource consumption; Service Function Chain mapping; Network Function Virtualization; service function chains; availability-aware mapping; SFC mapping request acceptance ratio; software-defined network functions; virtualized shared platforms; Redundancy; Delays; Computational modeling; Bandwidth; Conferences; Approximation algorithms. Network Function Virtualization (NFV) is a promising technique to greatly improve the effectiveness and flexibility of network services through a process named Service Function Chain (SFC) mapping, with which different network services are deployed over virtualized and shared platforms in data centers. However, such an evolution towards software-defined network functions introduces new challenges to network services which require high availability. One effective way of protecting the network services is to use sufficient redundancy. By doing so, however, the efficiency of physical resources may be greatly decreased. To address such an issue, this paper defines an optimal availability-aware SFC mapping problem and presents a novel online algorithm that can minimize the physical resources consumption while guaranteeing the required high availability within a polynomial time. Simulation results show that our proposed algorithm can significantly improve SFC mapping request acceptance ratio and reduce resource consumption.

Availability-aware mapping of service function chains. computer centres; computer network management; virtualisation; availability-aware SFC mapping problem; data centers; resource consumption; Service Function Chain mapping; Network Function Virtualization; service function chains; availability-aware mapping; SFC mapping request acceptance ratio; software-defined network functions; virtualized shared platforms; Redundancy; Delays; Computational modeling; Bandwidth; Conferences; Approximation algorithms. Network Function Virtualization (NFV) is a promising technique to greatly improve the effectiveness and flexibility of network services through a process named Service Function Chain (SFC) mapping, with which different network services are deployed over virtualized and shared platforms in data centers. However, such an evolution towards software-defined network functions introduces new challenges to network services which require high availability. One effective way of protecting the network services is to use sufficient redundancy. By doing so, however, the efficiency of physical resources may be greatly decreased. To address such an issue, this paper defines an optimal availability-aware SFC mapping problem and presents a novel online algorithm that can minimize the physical resources consumption while guaranteeing the required high availability within a polynomial time. Simulation results show that our proposed algorithm can significantly improve SFC mapping request acceptance ratio and reduce resource consumption.

Demystifying the Performance Interference of Co-Located Virtual Network Functions. computer networks; interference; virtual machines; virtualisation; performance interference demystifying; colocated VNF placement approaches; colocated virtual network functions; VM; network I-O bandwidth; hardware resource competition; scheduling; virtual machines; Interference; Servers; Bandwidth; Degradation; Hardware; Resource management; Throughput. Network function virtualization (NFV) decouples network functions from the dedicated hardware and enables them running on commodity servers, facilitating widespread deployment of virtualized network functions (VNFs). Network operators tend to deploy VNFs in virtual machines (VMs) due to VM's ease of duplication and migration, which enables flexible VNF placement and scheduling. Efforts have been paid to provide efficient VNF placement approaches, aiming at minimizing the resource cost of VNF deployment and reducing the latency of service chain. However, existing placement approaches may result in hardware resource competition of co-located VNFs, leading to performance degradation. In this paper, we present a measurement study on the performance interference among different types of co-located VNFs and analyze how VNFs' competitive hardware resources and the characteristics of packet affect the performance interference. We disclose that the performance interference between co-located VNFs is ubiquitous, which causes the performance degradation, in terms of VNFs' throughput, ranging from 12.36% to 50.3%, and the competition of network I/O bandwidth plays a key role in the performance interference. Based on our measurement results, we give some advices on how to design more efficient VNF placement approaches.

Demystifying the Performance Interference of Co-Located Virtual Network Functions. computer networks; interference; virtual machines; virtualisation; performance interference demystifying; colocated VNF placement approaches; colocated virtual network functions; VM; network I-O bandwidth; hardware resource competition; scheduling; virtual machines; Interference; Servers; Bandwidth; Degradation; Hardware; Resource management; Throughput. Network function virtualization (NFV) decouples network functions from the dedicated hardware and enables them running on commodity servers, facilitating widespread deployment of virtualized network functions (VNFs). Network operators tend to deploy VNFs in virtual machines (VMs) due to VM's ease of duplication and migration, which enables flexible VNF placement and scheduling. Efforts have been paid to provide efficient VNF placement approaches, aiming at minimizing the resource cost of VNF deployment and reducing the latency of service chain. However, existing placement approaches may result in hardware resource competition of co-located VNFs, leading to performance degradation. In this paper, we present a measurement study on the performance interference among different types of co-located VNFs and analyze how VNFs' competitive hardware resources and the characteristics of packet affect the performance interference. We disclose that the performance interference between co-located VNFs is ubiquitous, which causes the performance degradation, in terms of VNFs' throughput, ranging from 12.36% to 50.3%, and the competition of network I/O bandwidth plays a key role in the performance interference. Based on our measurement results, we give some advices on how to design more efficient VNF placement approaches.

Consolidating complementary VMs with spatial/temporal-awareness in cloud datacenters. cloud computing; computer centres; contracts; resource allocation; virtual machines; virtual machines; cloud datacenters; resource provisioning; service level agreement; SLA; physical resource allocation; VM allocation mechanism; VM resource utilization patterns; physical machine; PM; complementary VM consolidation; Resource management; Computers; Google; Conferences; Radio access networks; Virtual machining; Bandwidth. In cloud datacenters, effective resource provisioning is needed to maximize energy efficiency and utilization of cloud resources while guaranteeing the Service Level Agreement (SLA) for tenants. Previous resource provisioning strategies either allocate physical resources to virtual machines (VMs) based on static VM resource demands or dynamically handle the variations in VM resource requirements through live VM migrations. However, the former fail to maximize energy efficiency and resource utilization while the latter produce high migration overhead. To handle these problems, we propose an initial VM allocation mechanism that consolidates complementary VMs with spatial/temporal-awareness. Complementary VMs are the VMs whose total demand of each resource dimension (in the spatial space) nearly reaches their host's capacity during VM lifetime period (in the temporal space). Based on our observation of the existence of VM resource utilization patterns, the mechanism predicts the lifetime resource utilization patterns of short-term VMs or periodical resource utilization patterns of long-term VMs. Based on the predicted patterns, it coordinates the requirements of different resources and consolidates complementary VMs in the same physical machine (PM). This mechanism reduces the number of PMs needed to provide VM service hence increases energy efficiency and resource utilization and also reduces the number of VM migrations and SLA violations. Simulation based on two real traces and real-world testbed experiments show that our initial VM allocation mechanism significantly reduces the number of PMs used, SLA violations and VM migrations of the previous resource provisioning strategies.

The Impact of Virtualization on Network Performance of Amazon EC2 Data Center. computer centres; Internet; performance evaluation; virtual machines; network performance; cloud computing services; computing resources; cloud service providers; machine virtualization; networking performance; Amazon elastic cloud computing data center; processor sharing; packet delay; TCP/UDP throughput; packet loss; virtual machines; data center network; Virtual machining; Throughput; Large-scale systems; Resource virtualization; Computer networks; Cloud computing; Resource management; Loss measurement; Propagation delay; Communications Society. Cloud computing services allow users to lease computing resources from large scale data centers operated by service providers. Using cloud services, users can deploy a wide variety of applications dynamically and on-demand. Most cloud service providers use machine virtualization to provide flexible and cost-effective resource sharing. However, few studies have investigated the impact of machine virtualization in the cloud on networking performance. In this paper, we present a measurement study to characterize the impact of virtualization on the networking performance of the Amazon Elastic Cloud Computing (EC2) data center. We measure the processor sharing, packet delay, TCP/UDP throughput and packet loss among Amazon EC2 virtual machines. Our results show that even though the data center network is lightly utilized, virtualization can still cause significant throughput instability and abnormal delay variations. We discuss the implications of our findings on several classes of applications.

