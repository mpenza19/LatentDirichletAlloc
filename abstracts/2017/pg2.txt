@INPROCEEDINGS{8057041,
author={Y. Zhang and W. Wu and S. Banerjee and J. Kang and M. A. Sanchez},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={SLA-verifier: Stateful and quantitative verification for service chaining},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Network verification has been recently proposed to detect network misconfigurations. Existing work focuses on the reachability. This paper proposes a framework that verifies the Service Level Agreement (SLA) compliance of the network using static verification. This work proposes a quantitative model and a set of algorithms for verifying performance properties of a network with switches and middleboxes, i.e., service chains. We develop SLA-Verifier and evaluate its efficiency using simulation on real-world data and testbed experiments. To improve the SLA violation detection accuracy, our system uses verification results to optimize online monitoring.},
keywords={contracts;formal verification;quality of service;telecommunication network management;telecommunication services;SLA violation detection accuracy;SLA-Verifier;quantitative model;static verification;Service Level Agreement compliance;network misconfigurations;network verification;service chaining;quantitative verification;Stateful verification;SLA-verifier;Bandwidth;Middleboxes;Quality of service;Load modeling;Monitoring;Noise measurement},
doi={10.1109/INFOCOM.2017.8057041},
ISSN={},
month={May},}
@INPROCEEDINGS{8057042,
author={S. Ciavarella and N. Bartolini and H. Khamfroush and T. L. Porta},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Progressive damage assessment and network recovery after massive failures},
year={2017},
volume={},
number={},
pages={1-9},
abstract={After a massive scale failure, the assessment of damages to communication networks requires local interventions and remote monitoring. While previous works on network recovery require complete knowledge of damage extent, we address the problem of damage assessment and critical service restoration in a joint manner. We propose a polynomial algorithm called Centrality based Damage Assessment and Recovery (CeDAR) which performs a joint activity of failure monitoring and restoration of network components. CeDAR works under limited availability of recovery resources and optimizes service recovery over time. We modified two existing approaches to the problem of network recovery to make them also able to exploit incremental knowledge of the failure extent. Through simulations we show that CeDAR outperforms the previous approaches in terms of recovery resource utilization and accumulative flow over time of the critical services.},
keywords={condition monitoring;failure analysis;polynomials;telecommunication network management;telecommunication network reliability;progressive damage assessment;network recovery;massive scale failure;communication networks;remote monitoring;critical service restoration;Centrality based Damage Assessment;CeDAR;failure monitoring;recovery resource utilization;polynomial algorithm;Maintenance engineering;Monitoring;Schedules;Knowledge engineering;Inspection;Communication networks;Conferences},
doi={10.1109/INFOCOM.2017.8057042},
ISSN={},
month={May},}
@INPROCEEDINGS{8057043,
author={Y. Bejerano and C. Raman and C. Yu and V. Gupta and C. Gutterman and T. Young and H. Infante and Y. Abdelmalek and G. Zussman},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={DyMo: Dynamic monitoring of large scale LTE-Multicast systems},
year={2017},
volume={},
number={},
pages={1-9},
abstract={LTE evolved Multimedia Broadcast/Multicast Service (eMBMS) is an attractive solution for video delivery to very large groups in crowded venues. However, deployment and management of eMBMS systems is challenging, due to the lack of realtime feedback from the User Equipment (UEs). Therefore, we present the Dynamic Monitoring (DyMo) system for low-overhead feedback collection. DyMo leverages eMBMS for broadcasting Stochastic Group Instructions to all UEs. These instructions indicate the reporting rates as a function of the observed Quality of Service (QoS). This simple feedback mechanism collects very limited QoS reports from the UEs. The reports are used for network optimization, thereby ensuring high QoS to the UEs. We present the design aspects of DyMo and evaluate its performance analytically and via extensive simulations. Specifically, we show that DyMo infers the optimal eMBMS settings with extremely low overhead, while meeting strict QoS requirements under different UE mobility patterns and presence of network component failures. For instance, DyMo can detect the eMBMS Signal-to-Noise Ratio (SNR) experienced by the 0.1% percentile of the UEs with Root Mean Square Error (RMSE) of 0.05% with only 5 to 10 reports per second regardless of the number of UEs.},
keywords={broadcast communication;feedback;Long Term Evolution;mean square error methods;multicast communication;multimedia communication;quality of service;video delivery;eMBMS systems;realtime feedback;Dynamic Monitoring system;low-overhead feedback collection;DyMo leverages eMBMS;Stochastic Group Instructions;reporting rates;simple feedback mechanism;optimal eMBMS settings;extremely low overhead;strict QoS requirements;QoS;UE mobility patterns;large scale LTE-multicast systems;LTE evolved multimedia broadcast-multicast service;network optimization;root mean square error;RMSE;Signal to noise ratio;Quality of service;Estimation;Wireless fidelity;Long Term Evolution;Sociology;Statistics;Wireless Monitoring;LTE;eMBMS;Multi-cast;Feedback Mechanism},
doi={10.1109/INFOCOM.2017.8057043},
ISSN={},
month={May},}
@INPROCEEDINGS{8057044,
author={M. Zhang and L. Gao and J. Huang and M. Honig},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Cooperative and competitive operator pricing for mobile crowdsourced internet access},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Mobile Crowdsourced Access (MCA) enables mobile users (MUs) to share their Internet connections by serving as tethers to other MUs, hence can improve the quality of service of MUs as well as the overall utilization of network resources. However, MCA can also reduce the revenue-generating mobile traffic and increase the network congestion for mobile network operators (MNOs), and thus has been blocked by some MNOs in practice. In this work, we reconcile the conflicting objectives of MNOs and MUs by introducing a pricing framework for MCA, where the direct traffic and tethering traffic are charged independently according to a data price and a tethering price, respectively. We derive the optimal data and tethering prices systematically for MUs with the α-fair utility in two scenarios with cooperative and competitive MNOs, respectively. We show that the optimal tethering prices are zero and the optimal usage-based data prices are identical for all MUs, in both the cooperative and competitive scenarios. Such optimal pricing schemes will lead to mutually beneficial results for MNOs and MUs. Our simulation results show that the proposed pricing scheme approximately triples both the MNOs' profit and the MUs' payoff when the MNOs cooperate, comparing to the case where MCA is blocked. Moreover, competition among MNOs will decrease MNOs' profit and further increase the MUs' payoff.},
keywords={cooperative communication;Internet;mobile communication;mobile computing;optimisation;pricing;telecommunication services;telecommunication traffic;competitive operator pricing;mobile crowdsourced internet access;MCA;mobile users;network resources;revenue-generating mobile traffic;mobile network operators;pricing framework;direct traffic;tethering traffic;data price;tethering price;optimal tethering prices;optimal pricing schemes;cooperative operator pricing;competitive MNO;MNO profit;MU payoff;Pricing;Mobile communication;Mobile computing;Internet;Wireless fidelity;Downlink;Conferences},
doi={10.1109/INFOCOM.2017.8057044},
ISSN={},
month={May},}
@INPROCEEDINGS{8057045,
author={D. Bega and M. Gramaglia and A. Banchs and V. Sciancalepore and K. Samdanis and X. Costa-Perez},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Optimising 5G infrastructure markets: The business of network slicing},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In addition to providing substantial performance enhancements, future 5G networks will also change the mobile network ecosystem. Building on the network slicing concept, 5G allows to “slice” the network infrastructure into separate logical networks that may be operated independently and targeted at specific services. This opens the market to new players: the infrastructure provider, which is the owner of the infrastructure, and the tenants, which may acquire a network slice from the infrastructure provider to deliver a specific service to their customers. In this new context, we need new algorithms for the allocation of network resources that consider these new players. In this paper, we address this issue by designing an algorithm for the admission and allocation of network slices requests that (i) maximises the infrastructure provider's revenue and (ii) ensures that the service guarantees provided to tenants are satisfied. Our key contributions include: (i) an analytical model for the admissibility region of a network slicing-capable 5G Network, (ii) the analysis of the system (modelled as a Semi-Markov Decision Process) and the optimisation of the infrastructure provider's revenue, and (iii) the design of an adaptive algorithm (based on Q-learning) that achieves close to optimal performance.},
keywords={5G mobile communication;Markov processes;mobile computing;mobility management (mobile radio);substantial performance enhancements;future 5G networks;network slicing;logical networks;network slice requests;5G infrastructure market optimisation;semi-Markov decision process;Q-learning;infrastructure provider revenue optimisation;network resources;network infrastructure;mobile network ecosystem;Base stations;5G mobile communication;Algorithm design and analysis;Throughput;Ecosystems;Adaptation models;Mobile computing},
doi={10.1109/INFOCOM.2017.8057045},
ISSN={},
month={May},}
@INPROCEEDINGS{8057046,
author={P. Caballero and A. Banchs and G. de Veciana and X. Costa-Pérez},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Network slicing games: Enabling customization in multi-tenant networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Network slicing to enable resource sharing among multiple tenants-network operators and/or services-is considered a key functionality for next generation mobile networks. This paper provides an analysis of a well-known model for resource sharing, the `share-constrained proportional allocation' mechanism, to realize network slicing. This mechanism enables tenants to reap the performance benefits of sharing, while retaining the ability to customize their own users' allocation. This results in a network slicing game in which each tenant reacts to the user allocations of the other tenants so as to maximize its own utility. We show that, under appropriate conditions, the game associated with such strategic behavior converges to a Nash equilibrium. At the Nash equilibrium, a tenant always achieves the same, or better, performance than under a static partitioning of resources, hence providing the same level of protection as such static partitioning. We further analyze the efficiency and fairness of the resulting allocations, providing tight bounds for the price of anarchy and envy-freeness. Our analysis and extensive simulation results confirm that the mechanism provides a comprehensive practical solution to realize network slicing. Our theoretical results also fill a gap in the literature regarding the analysis of this resource allocation model under strategic players.},
keywords={game theory;mobile computing;next generation networks;program slicing;resource allocation;resource sharing;multiple tenants-network operators;network slicing game;user allocations;Nash equilibrium;static partitioning;resource allocation model;next generation mobile networks;share-constrained proportional allocation mechanism;multi-tenant networks;Resource management;Base stations;Mobile communication;Mobile computing;Analytical models;Nash equilibrium;Conferences},
doi={10.1109/INFOCOM.2017.8057046},
ISSN={},
month={May},}
@INPROCEEDINGS{8057047,
author={M. Zou and R. T. B. Ma and X. Wang and Y. Xu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={On optimal service differentiation in congested network markets},
year={2017},
volume={},
number={},
pages={1-9},
abstract={As Internet applications have become more diverse in recent years, users having heavy demand for online video services are more willing to pay higher prices for better services than light users that mainly use e-mails and instant messages. This encourages the Internet Service Providers (ISPs) to explore service differentiations so as to optimize their profits and allocation of network resources. Much prior work has focused on the viability of network service differentiation by comparing with the case of a single-class service. However, the optimal service differentiation for an ISP subject to resource constraints has remained unsolved. In this work, we establish an optimal control framework to derive the analytical solution to an ISP's optimal service differentiation, i.e., the optimal service qualities and associated prices. By analyzing the structures of the solution, we reveal how an ISP should adjust the service qualities and prices in order to meet varying capacity constraints and users' characteristics. We also obtain the conditions under which ISPs have strong incentives to implement service differentiation and whether regulators should encourage such practices.},
keywords={Internet;optimal control;pricing;quality of service;online video services;e-mails;instant messages;network resource allocation;optimal service differentiation;Internet applications;congested network markets;optimal service qualities;ISP's optimal service differentiation;optimal control framework;single-class service;network service differentiation;network resources;Internet Service Providers;Pricing;Capacity planning;Optimal control;Conferences;Regulators;Quality of service;Resource management},
doi={10.1109/INFOCOM.2017.8057047},
ISSN={},
month={May},}
@INPROCEEDINGS{8057048,
author={P. Nayak and M. Garetto and E. W. Knightly},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Multi-user downlink with single-user uplink can starve TCP},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In this paper we present the first cross-layer analysis of wireless LANs operating under downlink multi-user MIMO (MU-MIMO), considering the fundamental role played by closed-loop (TCP) traffic. In particular, we consider an 802.11ac scenario in which the access point transmits on the downlink via MU-MIMO, whereas stations must employ single-user transmissions on the uplink. With the help of analytical models built for the different regimes that can occur in the considered system, we identify and explain crucial performance anomalies that can result in very low throughput in some scenarios, completely offsetting the theoretical gains achievable by MU-MIMO. We discuss solutions to mitigate the risk of this performance degradation and alternative uplink strategies allowing WLANs to approach their maximum theoretical capacity under MU-MIMO.},
keywords={MIMO communication;multiuser detection;telecommunication traffic;transport protocols;wireless LAN;MU-MIMO;multiuser downlink;single-user uplink;wireless LAN;multiuser MIMO;closed-loop TCP traffic;Downlink;Uplink;Throughput;MIMO;Servers;Wireless LAN;Standards},
doi={10.1109/INFOCOM.2017.8057048},
ISSN={},
month={May},}
@INPROCEEDINGS{8057049,
author={D. Gunatilaka and M. Sha and C. Lu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Impacts of channel selection on industrial wireless sensor-actuator networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Industrial automation has emerged as an important application of wireless sensor-actuator networks (WSANs). To meet stringent reliability requirements of industrial applications, industrial standards such as WirelessHART adopt Time Slotted Channel Hopping (TSCH) as its MAC protocol. Since every link hops through all the channels used in TSCH, a straightforward policy to ensure reliability is to retain a link in the network topology only if it is reliable in all channels used. However, this policy has surprising side effects. While using more channels may enhance reliability due to channel diversity, more channels may also reduce the number of links and route diversity in the network topology. We empirically analyze the impact of channel selection on network topology, routing, and scheduling on a 52-node WSAN testbed. We observe inherent tradeoff between channel diversity and route diversity in channel selection, where using an excessive number of channels may negatively impact routing and scheduling. We propose novel channel and link selection strategies to improve route diversity and network schedulability. Experimental results on two different testbeds show that our algorithms can drastically improve routing and scheduling of industrial WSANs.},
keywords={access protocols;diversity reception;routing protocols;telecommunication network topology;telecommunication scheduling;wireless sensor networks;industrial wireless sensor-actuator networks;industrial automation;industrial standards;Time Slotted Channel Hopping;TSCH;network topology;route diversity;channel selection;channel diversity;network schedulability;industrial WSANs;WirelessHART;MAC protocol;Routing;Reliability;Network topology;Wireless sensor networks;Wireless communication;IEEE 802.15 Standard},
doi={10.1109/INFOCOM.2017.8057049},
ISSN={},
month={May},}
@INPROCEEDINGS{8057050,
author={A. Baiocchi and I. Tinnirello and D. Garlisi and A. L. Valvo},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Random access with repeated contentions for emerging wireless technologies},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In this paper we propose ReCo, a robust contention scheme for emerging wireless technologies, whose efficiency is not sensitive to the number of contending stations and to the settings of the contention parameters (such as the contention windows and retry limits). The idea is iterating a basic contention mechanism, devised to select a sub-set of stations among the contending ones, in consecutive elimination rounds, before performing a transmission attempt. Elimination rounds can be performed in the time or frequency domain, with different overheads, according to the physical capabilities of the nodes. Closed analytical formulas are given to dimension the number of contention rounds in order to achieve an arbitrary low collision probability. Simulation results and a real implementation for the time-domain solution demonstrate the effectiveness and robustness of this approach in comparison to IEEE 802.11 DCF.},
keywords={access protocols;probability;wireless LAN;contention parameters;contention windows;retry limits;frequency domain;closed analytical formulas;contention rounds;arbitrary low collision probability;time-domain solution;random access;wireless technologies;ReCo;robust contention scheme;Frequency-domain analysis;OFDM;Wireless communication;IEEE 802.11 Standard;Protocols;Multiaccess communication},
doi={10.1109/INFOCOM.2017.8057050},
ISSN={},
month={May},}
@INPROCEEDINGS{8057051,
author={C. Shih and R. Sivakumar},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Switch: Enabling transmitter and receiver participation in seamless lightweight control},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Lightweight control planes are techniques that create a control plane in WiFi networks without any additional spectrum requirements. Flash signals are an example of such control signals that exploit the link margin that typically exists in WiFi communication. In this paper we consider the problem of allowing transmitters and receivers of a transmission to exploit such control channels while the communication is ongoing. We present a mechanism called switch that facilitates switches in communication modes (Tx to Rx and vice-versa). We then use switch as the core building block to solve problems in WiFi networks such as starvation due to hidden terminals, early collision termination, and frequency backoffs. We rely on WARP radios to experimentally verify that switch is indeed possible, and use ns-3 simulations to study the impact of using switch to solve the aforementioned WiFi problems.},
keywords={access protocols;radio receivers;radio transmitters;telecommunication control;telecommunication switching;telecommunication traffic;wireless channels;wireless LAN;receiver participation;seamless lightweight control;WiFi networks;flash signals;control signals;link margin;WiFi communication;control channels;communication modes;collision termination;transmitter participation;Switches;Receivers;Wireless fidelity;Radio transmitters;Delays},
doi={10.1109/INFOCOM.2017.8057051},
ISSN={},
month={May},}
@INPROCEEDINGS{8057052,
author={W. Cheng and X. Zhang and H. Zhang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Pilot-based full-duplex spectrum-sensing and multichannel-MAC over non-time-slotted cognitive radio networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In the non-time-slotted cognitive radio networks (CRNs), the synchronization between PUs and secondary users (SUs) cannot be guaranteed, resulting in two challenging problems: the reactivation-failure of PUs and the frequently unexpected hand-offs among SUs. The reactivation-failure of PUs is the incident that the SUs cannot detect the PUs' reactivation when the SUs are occupying the channels to transmit their data in non-time-slotted CRNs. The frequently unexpected handoffs among SUs are the events that the SU cannot distinguish between the PUs' reactivation and the other SUs' contention, thus causing many unexpected hand-offs among SUs, which severely degrade the achieved throughput of SUs in non-time-slotted CRNs. Employing the energy-detection based wireless full-duplex spectrum sensing schemes, the PUs' reactivation-failure problem can be efficiently solved, thus guaranteeing the required throughput of PUs. However, the key of CRNs is not only the throughput-guarantees for PUs, but also the throughput-boosts for SUs. To optimize the throughput of SUs in multichannel non-time-slotted CRNs, in this paper we develop the pilot-based full-duplex spectrum sensing (PF-SS) scheme and the pilot-based medium access control (P-MAC) protocol to not only guarantee the required throughput of PUs, but also significantly increase the throughput of SUs in multichannel non-time-slotted CRNs. Using the PF-SS scheme, the SUs can identify whether the PUs' signal or the SUs' signal, thus significantly reducing the frequently unexpected hand-offs among SUs. Then, based on the PF-SS scheme, the P-MAC protocol can significantly increase the throughput of SUs. We conduct extensive numerical analyses to show that our developed PF-SS scheme and P-MAC protocol can significantly increase the throughput of SUs while guaranteeing the required throughput for PUs in multichannel non-time-slotted CRNs.},
keywords={access protocols;cognitive radio;mobility management (mobile radio);radio networks;radio spectrum management;signal detection;wireless channels;pilot-based medium access control protocol;P-MAC protocol;nontime-slotted cognitive radio networks;primary user;secondary users;multichannel-MAC;PUs reactivation;frequently unexpected handoffs;reactivation-failure;full-duplex spectrum-sensing;frequently unexpected hand-offs;SUs;CRNs;Throughput;Sensors;Wireless sensor networks;Protocols;Cognitive radio;Wireless networks;Non-time-slotted cognitive radio networks;hand-offs among secondary users;pilot-based full-duplex spectrum sensing;pilot-based medium access control protocol},
doi={10.1109/INFOCOM.2017.8057052},
ISSN={},
month={May},}
@INPROCEEDINGS{8057053,
author={X. Liu and J. Xie},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={A 2D heterogeneous rendezvous protocol for multi-wideband cognitive radio networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Ideally, users in cognitive radio networks (CRNs) are capable of sensing and exploiting any potential transmission opportunities in the available spectrum band ranging from 30 KHz to 300 GHz. With the multiple-diverse-band spectrum, the network can provide more radio resources and capacity to a large number of CR users. However, the multiband scenario (e.g., TV band + 2/3G band + 4/5G band) also introduces significant challenges in channel rendezvous, a fundamental operation for users in CRNs to set up their communication link on a common channel. Existing studies on channel rendezvous suffer from unacceptable long delay and high energy consumption when applied to such scenarios. In this paper, we propose a two-dimensional heterogeneous rendezvous (2D-HR) protocol which can support multi-wideband CRNs (MWB-CRNs) with a significantly reduced rendezvous delay and energy consumption for various rendezvous scenarios, such as the pair-wise rendezvous, any-wise rendezvous, and multi-wise rendezvous. The proposed design also performs better than existing efforts even when dealing with traditional single-band rendezvous. The merits of 2D-HR are proved theoretically and validated against extensive simulations. To the best of our knowledge, this is the first work that addresses heterogeneous rendezvous in MWB-CRNs.},
keywords={cognitive radio;protocols;radio links;radio spectrum management;wireless channels;MWB-CRN;multiwideband CRN;2D-HR protocol;energy consumption;any-wise rendezvous;pair-wise rendezvous;reduced rendezvous delay;two-dimensional heterogeneous rendezvous protocol;high energy consumption;channel rendezvous;TV band;multiband scenario;CR users;radio resources;multiple-diverse-band spectrum;multiwideband cognitive radio networks;multiwise rendezvous;frequency 30.0 kHz to 300.0 GHz;Delays;Algorithm design and analysis;Wideband;Energy consumption;Conferences;Protocols;Cognitive radio},
doi={10.1109/INFOCOM.2017.8057053},
ISSN={},
month={May},}
@INPROCEEDINGS{8057054,
author={C. Joo and N. B. Shroff},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={A novel coupled queueing model to control traffic via QoS-aware collision pricing in cognitive radio networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We consider a cognitive radio network, where primary users have priority over the spectrum resources, and secondary users can exploit the unused resources through channel sensing. Due to sensing inaccuracy, the secondary traffic may obstruct the primary traffic. A penalty for collision has been used to protect the primary traffic, which is often designed to provide a fixed per-collision compensation or to restrict the collision rate at an acceptable level. In this work, we develop a framework that can protect the primary traffic taking into account the Quality of Service of the primary traffic. In particular, we pay attention to the delay performance, which is determined not only by the collision rate but also by the amount of traffic in both networks. We design a novel model with coupled queues, and successfully incorporate dynamic interactions between the two systems through the standard optimization problem. We also consider the practical requirement of no direct sharing of the system information between the two networks, and develop a close-to-optimal solution of per-collision price and channel sensing under mild assumptions. We evaluate its performance through simulations.},
keywords={cognitive radio;multi-access systems;optimisation;quality of service;queueing theory;telecommunication congestion control;QoS-aware collision pricing;cognitive radio network;primary users;secondary users;channel sensing;secondary traffic;primary traffic;per-collision compensation;per-collision price;control traffic;coupled queueing model;spectrum resources;quality of service;Sensors;Quality of service;Cognitive radio;Signal to noise ratio;Interference;Throughput;Load management},
doi={10.1109/INFOCOM.2017.8057054},
ISSN={},
month={May},}
@INPROCEEDINGS{8057055,
author={A. Abdelfattah and N. Malouch},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Modeling and performance analysis of Wi-Fi networks coexisting with LTE-U},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In order to cope with the exponential growth of mobile traffic, mobile operators need to access more spectrum resources. LTE in unlicensed spectrum (LTE-U) has been proposed to extend the usual operation of LTE in licensed spectrum to cover also unlicensed spectrum. However, this extension poses significant challenges especially regarding the coexistence between LTE-U and legacy systems like Wi-Fi. In case of LTE-U adopts Time-Division Multiplexing (TDM) schemes to share the spectrum with Wi-Fi, we expect performance degradations of Wi-Fi networks. In this paper, we quantify the impact of TDM schemes on Wi-Fi performance in a coexistence scenario. We provide detailed analytical models using two different random walk approaches to compute the probability of collision faced by Wi-Fi stations and their throughput performance. Besides, we derive the performance results using an exponential approximation which shows its insufficiency to capture the exact behavior. We implement the coexistence in the NS3 simulator and we show that the models estimate accurately the collision probability and the throughput experienced by Wi-Fi. The models are then used to study and compare different coexistence schemes showing for instance that the Wi-Fi frame size has a non-negligible impact on the performance of Wi-Fi users.},
keywords={Long Term Evolution;probability;time division multiplexing;wireless LAN;Wi-Fi frame size;Wi-Fi users;Wi-Fi networks;LTE-U;mobile traffic;mobile operators;spectrum resources;unlicensed spectrum;licensed spectrum;Time-Division Multiplexing schemes;performance degradations;TDM schemes;Wi-Fi performance;Wi-Fi stations;NS3;U;Wireless fidelity;Analytical models;Long Term Evolution;Media Access Protocol;Throughput;Computational modeling;Markov processes;LTE-U;CSAT;Wi-Fi;5G;Mobile Communication;Collision Probability;Performance Evaluation;Simulation},
doi={10.1109/INFOCOM.2017.8057055},
ISSN={},
month={May},}
@INPROCEEDINGS{8057056,
author={Y. Qin and R. Jin and S. Hao and K. R. Pattipati and F. Qian and S. Sen and B. Wang and C. Yue},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={A control theoretic approach to ABR video streaming: A fresh look at PID-based rate adaptation},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Adaptive bitrate streaming (ABR) has become the de facto technique for video streaming over the Internet. Despite a flurry of techniques, achieving high quality ABR streaming over cellular networks remains a tremendous challenge. ABR streaming can be naturally modeled as a feedback control problem. There has been some initial work on using PID, a widely used feedback control technique, for ABR streaming. Existing studies, however, either use PID control directly without fully considering the special requirements of ABR streaming, leading to suboptimal results, or conclude that PID is not a suitable approach. In this paper, we take a fresh look at PID-based control for ABR streaming. We design a framework called PIA that strategically leverages PID control concepts and incorporates several novel strategies to account for the various requirements of ABR streaming. We evaluate PIA using simulation based on real LTE network traces, as well as using real DASH implementation. The results demonstrate that PIA outperforms state-of-the-art schemes in providing high average bitrate with significantly lower bitrate changes (reduction up to 40%) and stalls (reduction up to 85%), while incurring very small runtime overhead.},
keywords={cellular radio;feedback;Internet;Long Term Evolution;three-term control;video streaming;DASH implementation;LTE network traces;PID control concepts;Internet;de facto technique;adaptive bitrate streaming;PID-based rate adaptation;feedback control technique;ABR video streaming;control theoretic approach;feedback control problem;Streaming media;Bit rate;PI control;PD control;Bandwidth;Cellular networks},
doi={10.1109/INFOCOM.2017.8057056},
ISSN={},
month={May},}
@INPROCEEDINGS{8057057,
author={T. Zhang and F. Ren and W. Cheng and X. Luo and R. Shu and X. Liu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Modeling and analyzing the influence of chunk size variation on bitrate adaptation in DASH},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Recently, HTTP-based adaptive video streaming has been widely adopted in the Internet. Up to now, HTTP-based adaptive video streaming is standardized as Dynamic Adaptive Streaming over HTTP (DASH), where a client-side video player can dynamically pick the bitrate level according to the perceived network conditions. Actually, not only the available bandwidth is varying, but also the chunk sizes in the same bitrate level significantly fluctuate, which also influences the bitrate adaptation. However, existing bitrate adaptation algorithms do not accurately involve the chunk size variation, leading to performance losses. In this paper, we theoretically analyze the influence of chunk size variation on bitrate adaptation performance. Based on DASH system features, we build a general model describing the playback buffer evolution. Applying stochastic theories, we respectively analyze the influence of the chunk size variation on rebuffering probability and average bitrate level. Furthermore, based on theoretical insights, we provide several recommendations for algorithm designing and rate encoding, and also propose a simple bitrate adaptation algorithm. Extensive simulations verify our insights as well as the efficiency of the proposed recommendations and algorithm.},
keywords={hypermedia;Internet;probability;transport protocols;video streaming;chunk size variation;DASH;client-side video player;bitrate adaptation algorithms;bitrate adaptation performance;average bitrate level;simple bitrate adaptation algorithm;dynamic adaptive streaming over HTTP;HTTP-based adaptive video streaming;stochastic theory;Bit rate;Streaming media;Algorithm design and analysis;Bandwidth;Adaptation models;Encoding;Analytical models;Chunk Size;bitrate adaptation;rebuffering;average video rate;DASH},
doi={10.1109/INFOCOM.2017.8057057},
ISSN={},
month={May},}
@INPROCEEDINGS{8057058,
author={C. Zhang and Q. He and J. Liu and Z. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Beyond the touch: Interaction-aware mobile gamecasting with gazing pattern prediction},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Recent years have witnessed an explosion of gamecasting applications in the market, in which game players (or gamers in short) broadcast their game scenes in real-time. Such pioneer applications as YouTube Gaming, Twitch, and Mobcrush have attracted a massive number of online broadcasters, and each of them can attract hundreds or thousands of fellow viewers. The growing number however has created significant challenges to the network and end-devices, particularly considering bandwidth- and battery-limited smartphones or tablets are becoming dominating for both gamers and viewers. Yet the unique touch operations of the mobile interface offer opportunities, too. In this paper, our crowdsourced measurement reveals that strong associations exist between the gamers' touch interactions and the viewers' gazing patterns. Motivated by this, we present a novel interaction-aware optimization framework to improve the energy utilization and stream quality for mobile gamecasting (MGC). Our framework incorporates a touch-assisted prediction module to extract association rules for gazing pattern prediction and a tile-based optimization module to utilize energy on mobile devices efficiently. Trace-driven simulations illustrate the effectiveness of our framework in terms of energy consumption and streaming quality. Our user study experiments also demonstrate much improved (3%-13%) quality satisfaction than the state-of-the-art solution with similar network resources.},
keywords={computer games;data mining;mobile computing;smart phones;user interfaces;interaction-aware mobile gamecasting;game players;gamers;game scenes;online broadcasters;battery-limited smartphones;tablets;crowdsourced measurement;novel interaction-aware optimization framework;energy utilization;association rules;mobile devices;energy consumption;streaming quality;mobile interface;touch-assisted prediction module;gazing pattern prediction;touch interactions;tile-based optimization module;Games;Optimization;Land mobile radio;Smart phones;YouTube},
doi={10.1109/INFOCOM.2017.8057058},
ISSN={},
month={May},}
@INPROCEEDINGS{8057059,
author={K. Diab and M. Hefeeda},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={MASH: A rate adaptation algorithm for multiview video streaming over HTTP},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Multiview videos offer unprecedented experience by allowing users to explore scenes from different angles and perspectives. Thus, such videos have been gaining substantial interest from major content providers such as Google and Facebook. Adaptive streaming of multiview videos is, however, challenging because of the Internet dynamics and the diversity of user interests and network conditions. To address this challenge, we propose a novel rate adaptation algorithm for multiview videos (called MASH). Streaming multiview videos is more user centric than single-view videos, because it heavily depends on how users interact with the different views. To efficiently support this interactivity, MASH constructs probabilistic view switching models that capture the switching behavior of the user in the current session, as well as the aggregate switching behavior across all previous sessions of the same video. MASH then utilizes these models to dynamically assign relative importance to different views. Furthermore, MASH uses a new buffer-based approach to request video segments of various views at different qualities, such that the quality of the streamed videos is maximized while the network bandwidth is not wasted. We have implemented a multiview video player and integrated MASH in it. We compare MASH versus the state-of-the-art algorithm used by YouTube for streaming multiview videos. Our experimental results show that MASH can produce much higher and smoother quality than the algorithm used by YouTube, while it is more efficient in using the network bandwidth. In addition, we conduct large-scale experiments with up to 100 concurrent multiview streaming sessions, and we show that MASH maintains fairness across competing sessions, and it does not overload the streaming server.},
keywords={interactive video;Internet;social networking (online);video coding;video streaming;single-view videos;MASH constructs probabilistic view;video segments;streamed videos;multiview video player;multiview streaming sessions;Streaming media;Multi-stage noise shaping;Switches;Adaptation models;Computational modeling;Heuristic algorithms;YouTube},
doi={10.1109/INFOCOM.2017.8057059},
ISSN={},
month={May},}
@INPROCEEDINGS{8057060,
author={I. Markwood and Y. Liu and K. Kwiat and C. Kamhoua},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Electric grid power flow model camouflage against topology leaking attacks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The power flow model for DC power grids has been used theoretically to launch false data injection attacks (FDIAs) against state estimation. We recognize FDIAs are just one possible attack using the power flow model and that the grid topology information within the model implies its discovery may also facilitate topology-based attacks. We show attackers can derive the power flow model, and thus the topology also. Indeed, with incomplete data, attackers can accurately reconstruct regions of the model, or topology, all that is necessary to launch an attack. We also illustrate how to cause such attackers to derive instead a convincing fake model by camouflaging the real model. Consequently, no sensitive information will leak, so attacks based on this fake model will be ineffective, rather alerting grid administrators to the attacker's efforts. Using five test cases included in the MATLAB power flow analysis tool MATPOWER, ranging from 9 to 300 buses, an average 67.0% of the topology may be derived with a 69.1% model accuracy. Lastly, we find reconstructions of small portions of the model sufficient for performing FDIAs with 75% success, and that camouflage prevents 93% of them in all but the 9-bus case.},
keywords={DC power transmission;load flow control;power grids;power system simulation;power system state estimation;DC power grids;false data injection attacks;FDIAs;grid topology information;convincing fake model;MATLAB power flow analysis tool MATPOWER;electric grid power flow model camouflage;state estimation;MATPOWER;MATLAB power flow analysis tool;power flow model;topology leaking attacks;Mathematical model;Data models;Topology;Computational modeling;Meters;Admittance;Power grids},
doi={10.1109/INFOCOM.2017.8057060},
ISSN={},
month={May},}
@INPROCEEDINGS{8057061,
author={Z. Lu and M. Wei and X. Lu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={How they interact? Understanding cyber and physical interactions against fault propagation in smart grid},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In the smart grid, computer networks (i.e., the cyber domain) are built upon physical infrastructures (i.e., the physical domain) to facilitate advanced functionalities that were considered not possible in legacy systems. It is envisioned that such a cyber-physical paradigm enables intelligent, collaborative controls to prevent faults from propagating along large-scale infrastructures, which is a primary cause for massive blackouts (e.g., Northeast blackout of 2003). Despite this promising vision, how effective cyber and physical interactions are against fault propagation is not yet fully investigated. In this paper, we use analysis and system-level simulations to characterize such interactions during load shedding, which is a process to stop fault propagation by shedding a computed amount of loads based on collaborative communication. Specifically, we model faults happening in the physical domain as a counting process, with each count triggering a load shedding action on the fly in the cyber domain. We show that although global load shedding design is considered optimal by globally coordinating shedding actions in power engineering, its induced failure probability (defined as the one that at least a given number of power lines fail) is scalable to the delay performance and the system size in the cyber domain, thus less likely to stop fault propagation in large systems than local shedding design that sheds loads within a limited system scope. Our study demonstrates that a joint view on cyber and physical factors is essential for failure prevention design in the smart grid.},
keywords={load shedding;power system faults;probability;smart power grids;physical interactions;fault propagation;smart grid;cyber domain;physical infrastructures;physical domain;legacy systems;cyber-physical paradigm;system-level simulations;model faults;load shedding action;global load shedding design;shedding actions;local shedding design;physical factors;cyber interactions;Smart grids;Computational modeling;Load modeling;Power system faults;Power system protection;Analytical models;Smart grid;load shedding;fault propagation;cascading failure;failure prevention;modeling and simulations},
doi={10.1109/INFOCOM.2017.8057061},
ISSN={},
month={May},}
@INPROCEEDINGS{8057062,
author={X. Lou and R. Tan and D. K. Y. Yau and P. Cheng},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Cost of differential privacy in demand reporting for smart grid economic dispatch},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Increasing dynamics of electrical loads presents uncertainty and hence new challenges for power grid controls and optimization. In economic dispatch control (EDC) for minimizing generation cost, demand reporting by customers is a promising approach for managing the uncertainty, but it raises important privacy concerns. Adding random noise to aggregate queries of demand reports can provide differential privacy (DP) for the individual customers. But the noisy query results can adversely impact the EDC's optimality. In this paper, we analyze the privacy cost in demand reporting in terms of how DP-induced noise will increase the total generation cost. Our analysis shows that the noise amounts for different customers are intricately coupled with one another in determining the total cost. In view of the coupling, we apply the principle of Shapley value to attribute fair shares of the total cost to the power grid buses. For efficient sharing of the privacy cost, in a manner scalable to large power systems with many buses, we additionally propose heuristic algorithms to approximate the Shapley value. Trace-driven simulations based on a 5-bus power system model validate our analysis and illustrate the performance of the proposed cost sharing algorithms.},
keywords={data privacy;minimisation;power generation dispatch;power generation economics;power grids;smart power grids;differential privacy;demand reporting;smart grid economic dispatch;optimization;economic dispatch control;demand reports;privacy cost;DP-induced noise;power grid buses;cost sharing algorithms;electrical loads;power grid control;privacy concerns;EDC optimality;Shapley value;total generation cost minimisation;Privacy;Power grids;Aggregates;Uncertainty;Generators;Power system dynamics},
doi={10.1109/INFOCOM.2017.8057062},
ISSN={},
month={May},}
@INPROCEEDINGS{8057063,
author={A. Sehati and M. Ghaderi},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Energy-delay tradeoff for request bundling on smartphones},
year={2017},
volume={},
number={},
pages={1-9},
abstract={To reduce the energy consumption of a smartphone, multiple data transfer requests from applications can be bundled together and granted at once in order to reduce the time the radio interface is on. The side effect of bundling is the increased delay experienced by mobile applications. While several bundling algorithms have been proposed in the literature, a general and systematic solution to balance the energy-delay tradeoff is missing. In this paper, we formulate bundling as a cost minimization problem, in which the tradeoff between energy and delay is captured by a cost function. We then propose an online algorithm for minimizing the bundling cost and show that the algorithm is 4-competitive with respect to the optimal offline algorithm that knows the entire sequence of data transfer requests a priori. We evaluate the performance of the proposed algorithm and the accuracy of our results in a range of realistic scenarios using both model-driven simulations and real experiments on a smartphone. Our results show that depending on the delay tolerance level of a user, energy savings ranging from zero (delay intolerant) to about 100% (delay tolerant) can be achieved using our algorithm.},
keywords={costing;delays;minimisation;smart phones;telecommunication power management;energy-delay tradeoff;cost minimization problem;cost function;bundling cost;optimal offline algorithm;delay tolerance level;energy savings;request bundling;energy consumption;smartphone data transfer requests;multiple data transfer requests;mobile applications;bundling algorithms;radio interface;Delays;Algorithm design and analysis;Data transfer;Smart phones;Energy consumption;Mobile communication;Conferences},
doi={10.1109/INFOCOM.2017.8057063},
ISSN={},
month={May},}
@INPROCEEDINGS{8057064,
author={L. De Carli and R. Torres and G. Modelo-Howard and A. Tongaonkar and S. Jha},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Botnet protocol inference in the presence of encrypted traffic},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Network protocol reverse engineering of botnet command and control (C&C) is a challenging task, which requires various manual steps and a significant amount of domain knowledge. Furthermore, most of today's C&C protocols are encrypted, which prevents any analysis on the traffic without first discovering the encryption algorithm and key. To address these challenges, we present an end-to-end system for automatically discovering the encryption algorithm and keys, generating a protocol specification for the C&C traffic, and crafting effective network signatures. In order to infer the encryption algorithm and key, we enhance state-of-the-art techniques to extract this information using lightweight binary analysis. In order to generate protocol specifications we infer field types purely by analyzing network traffic. We evaluate our approach on three prominent malware families: Sality, ZeroAccess and Ramnit. Our results are encouraging: the approach decrypts all three protocols, detects 97% of fields whose semantics are supported, and infers specifications that correctly align with real protocol specifications.},
keywords={computer network security;cryptographic protocols;invasive software;reverse engineering;statistical analysis;telecommunication traffic;transport protocols;botnet protocol inference;encrypted traffic;network protocol reverse engineering;C&C protocols;network traffic;botnet botnet command and control protocols;lightweight binary analysis;network signatures;Sality malware;ZeroAccess malware;Ramnit malware;Encryption;Protocols;Malware;Ciphers;Payloads},
doi={10.1109/INFOCOM.2017.8057064},
ISSN={},
month={May},}
@INPROCEEDINGS{8057065,
author={A. A. Chariton and E. Degkleri and P. Papadopoulos and P. Ilia and E. P. Markatos},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={CCSP: A compressed certificate status protocol},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Trust in SSL-based communications is provided by Certificate Authorities (CAs) in the form of signed certificates. Checking the validity of a certificate involves three steps: (i) checking its expiration date, (ii) verifying its signature, and (iii) ensuring that it is not revoked. Currently, such certificate revocation checks are done either via Certificate Revocation Lists (CRLs) or Online Certificate Status Protocol (OCSP) servers. Unfortunately, despite the existence of these revocation checks, sophisticated cyber-attackers, may trick web browsers to trust a revoked certificate, believing that it is still valid. Consequently, the web browser will communicate (over TLS) with web servers controlled by cyber-attackers. Although frequently updated, nonced, and timestamped certificates may reduce the frequency and impact of such cyber-attacks, they impose a very large overhead to the CAs and OCSP servers, which now need to timestamp and sign on a regular basis all the responses, for every certificate they have issued, resulting in a very high overhead. To mitigate this overhead and provide a solution to the described cyber-attacks, we present CCSP: a new approach to provide timely information regarding the status of certificates, which capitalizes on a newly introduced notion called signed collections. In this paper, we present the design, preliminary implementation, and evaluation of CCSP in general, and signed collections in particular. Our preliminary results suggest that CCSP (i) reduces space requirements by more than an order of magnitude, (ii) lowers the number of signatures required by 6 orders of magnitude compared to OCSP-based methods, and (iii) adds only a few milliseconds of overhead in the overall user latency.},
keywords={certification;computer network security;Internet;protocols;public key cryptography;timestamped certificates;CAs;OCSP servers;CCSP;OCSP-based methods;compressed certificate status protocol;Certificate Authorities;signed certificates;certificate revocation checks;Certificate Revocation Lists;Online Certificate Status Protocol servers;sophisticated cyber-attackers;web browser;web servers;Browsers;Web servers;Protocols;Public key;Conferences;Receivers},
doi={10.1109/INFOCOM.2017.8057065},
ISSN={},
month={May},}
@INPROCEEDINGS{8057066,
author={B. Wang and L. Zhang and N. Z. Gong},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={SybilSCAR: Sybil detection in online social networks via local rule based propagation},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Detecting Sybils in online social networks (OSNs) is a fundamental security research problem as adversaries can leverage Sybils to perform various malicious activities. Structure-based methods have been shown to be promising at detecting Sybils. Existing structure-based methods can be classified into two categories: Random Walk (RW)-based methods and Loop Belief Propagation (LBP)-based methods. RW-based methods cannot leverage labeled Sybils and labeled benign users simultaneously, which limits their detection accuracy, and they are not robust to noisy labels. LBP-based methods are not scalable, and they cannot guarantee convergence. In this work, we propose SybilSCAR, a new structure-based method to perform Sybil detection in OSNs. SybilSCAR maintains the advantages of existing methods while overcoming their limitations. Specifically, SybilSCAR is Scalable, Convergent, Accurate, and Robust to label noises. We first propose a framework to unify RW-based and LBP-based methods. Under our framework, these methods can be viewed as iteratively applying a (different) local rule to every user, which propagates label information among a social graph. Second, we design a new local rule, which SybilSCAR iteratively applies to every user to detect Sybils. We compare SybilSCAR with a state-of-the-art RW-based method and a state-of-the-art LBP-based method, using both synthetic Sybils and large-scale social network datasets with real Sybils. Our results demonstrate that SybilSCAR is more accurate and more robust to label noise than the compared state-of-the-art RW-based method, and that SybilSCAR is orders of magnitude more scalable than the state-of-the-art LBP-based method and is guaranteed to converge. To facilitate research on Sybil detection, we have made our implementation of SybilSCAR publicly available on our webpages.},
keywords={graph theory;learning (artificial intelligence);security of data;social networking (online);Sybil detection;online social networks;RW-based methods;noisy labels;LBP-based methods;label information;synthetic Sybils;large-scale social network datasets;local rule based propagation;security research problem;SybilSCAR;OSN;Robustness;Image edge detection;Training;Belief propagation;Convergence;Twitter},
doi={10.1109/INFOCOM.2017.8057066},
ISSN={},
month={May},}
@INPROCEEDINGS{8057067,
author={S. Ji and S. Yang and A. Das and X. Hu and R. Beyah},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Password correlation: Quantification, evaluation and application},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In this paper, we study the correlation between passwords across different datasets which quantitatively explains the success of existing training-based password cracking techniques. We also study the correlation between a user's password and his/her social profile. This enabled us to develop the first social profile-aware password strength meter, namely SociaLShield. Our quantification techniques and SocialShield have meaningful implications to system administrators, users, and researchers, e.g., helping them quantitatively understand the threats posed by a password leakage incident, defending against emerging profile-based password attacks, and facilitating the research of countermeasures against existing and newly developed training-based password attacks. We validate our proposed quantification techniques and SocialShield through extensive experiments by leveraging real-world leaked passwords. Experimental results demonstrate that our quantification techniques are accurate in measuring correlation among different leaked datasets and that although SocialShield is light-weight, it is effective in defending against profile-based password attacks.},
keywords={authorisation;quantification techniques;SocialShield;password leakage incident;password correlation;password cracking techniques;social profile-aware password strength meter;SociaLShield;profile-based password attacks;training-based password attacks;leaked datasets;user passwork;user social profile;Correlation;Markov processes;Meters;Measurement;Security;Standards;LinkedIn},
doi={10.1109/INFOCOM.2017.8057067},
ISSN={},
month={May},}
@INPROCEEDINGS{8057068,
author={A. Kuhnle and T. Pan and M. A. Alim and M. T. Thai},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Scalable bicriteria algorithms for the threshold activation problem in online social networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We consider the Threshold Activation Problem (TAP): given social network G and positive threshold T, find a minimum-size seed set A that can trigger expected activation of at least T. We introduce the first scalable, parallelizable algorithm with performance guarantee for TAP suitable for datasets with millions of nodes and edges; we exploit the bicriteria nature of solutions to TAP to allow the user to control the running time versus accuracy of our algorithm through a parameter α ϵ (0, 1): given η > 0, with probability 1 - η our algorithm returns a solution A with expected activation greater than T - 2αT, and the size of the solution A is within factor 1-h 4α/T + log(T) of the optimal size. The algorithm runs in time O (α-2log (n/η) (n + m)|A|), where n, m, refer to the number of nodes, edges in the network. The performance guarantee holds for the general triggering model of internal influence and also incorporates external influence, provided a certain condition is met on the cost-effectivity of seed selection.},
keywords={computational complexity;directed graphs;network theory (graphs);parallel algorithms;probability;social networking (online);minimum-size seed set;expected activation;running time;positive threshold;TAP;scalable parallelizable algorithm;online social networks;threshold activation problem;scalable bicriteria algorithms;optimal size;Social network services;Integrated circuit modeling;Computational modeling;TV;Conferences;Context modeling},
doi={10.1109/INFOCOM.2017.8057068},
ISSN={},
month={May},}
@INPROCEEDINGS{8057069,
author={X. Li and J. D. Smith and T. N. Dinh and M. T. Thai},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Why approximate when you can get the exact? Optimal targeted viral marketing at scale},
year={2017},
volume={},
number={},
pages={1-9},
abstract={One of the most central problems in viral marketing is Influence Maximization (IM), which finds a set of k seed users who can influence the maximum number of users in online social networks. Unfortunately, all existing algorithms to IM, including the state of the art SSA and IMM, have an approximation ratio of (1 - 1/e - ϵ). Recently, a generalization of IM, Cost-aware Target Viral Marketing (CTVM), asks for the most cost-effective users to influence the most relevant users, has been introduced. The current best algorithm for CTVM has an approximation ratio of (1 - 1/√e - ϵ). In this paper, we study the CTVM problem, aiming to optimally solve the problem. We first highlight that using a traditional two stage stochastic programming to exactly solve CTVM is not possible because of scalability. We then propose an almost exact algorithm TIPTOP, which has an approximation ratio of (1 - ϵ). This result significantly improves the current best solutions to both IM and CTVM. At the heart of TIPTOP lies an innovative technique that reduces the number of samples as much as possible. This allows us to exactly solve CTVM on a much smaller space of generated samples using Integer Programming. While obtaining an almost exact solution, TIPTOP is very scalable, running on billion-scale networks such as Twitter under three hours. Furthermore, TIPTOP lends a tool for researchers to benchmark their solutions against the optimal one in large-scale networks, which is currently not available.},
keywords={approximation theory;graph theory;integer programming;marketing data processing;social networking (online);stochastic programming;IM;online social networks;approximation ratio;Cost-aware Target Viral Marketing;cost-effective users;CTVM problem;Influence Maximization;two stage stochastic programming;TIPTOP exact algorithm;Twitter;Approximation algorithms;Programming;Social network services;Integrated circuit modeling;Scalability;Conferences;Viral Marketing;Influence Maximization;Algorithms;Online Social Networks;Optimization},
doi={10.1109/INFOCOM.2017.8057069},
ISSN={},
month={May},}
@INPROCEEDINGS{8057070,
author={Z. Zhang and Y. Shi and J. Willson and D. Du and G. Tong},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Viral marketing with positive influence},
year={2017},
volume={},
number={},
pages={1-8},
abstract={One model for viral marketing is the positive influence. In this model, an inactive node is changed into active if and only if at least half of its neighbors are already in active state. The positive influence model can be viewed as a special case of a general threshold model, in which the threshold function at each node has value one if at least a certain fraction of neighbors are in active state, and value 0 otherwise. This function can be proved to be monotonically increasing and nonsubmodular for any predefined fraction. Therefore, given a seed set, the number of influenced nodes is not submodular with respect to the size of the seed set. This fact makes those optimization problems related with positive influence very hard, including the minimum partial positive influence seeding problem: Given a social network G = (V, E) and a number 0 <; p <; 1, find a minimum seed set S which can positively influence at least p|V| nodes. In this paper, we present an O ((log n)2H ([pn]))-approximation algorithm for the minimum partial positive influence seeding problem, where n is the number of nodes, and H(·) is the Harmonic number.},
keywords={computational complexity;marketing;network theory (graphs);optimisation;minimum partial positive influence seeding problem;viral marketing;positive influence model;threshold function;seed set;influenced nodes;social network;harmonic number;Approximation algorithms;Greedy algorithms;Conferences;Social network services;Computer science;Electronic mail;Computational modeling;viral marketing;partial positive-influence seeding problem;approximation algorithm},
doi={10.1109/INFOCOM.2017.8057070},
ISSN={},
month={May},}
@INPROCEEDINGS{8057071,
author={C. Lee and X. X. Do and Y. Eun},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={On the rao-blackwellization and its application for graph sampling via neighborhood exploration},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We study how the so-called Rao-Blackwellization, which is a variance reduction technique via “conditioning” for Monte Carlo methods, can be judiciously applied for graph sampling through neighborhood exploration. Despite its popularity for Monte Carlo methods, it is little known for Markov chain Monte Carlo methods and has never been discussed for random walk-based graph sampling. We first propose two forms of Rao-Blackwellization that can be used as a swap-in replacement for virtually all (reversible) random-walk graph sampling methods, and prove that the `Rao-Blackwellized' estimators reduce the (asymptotic) variances of their original estimators yet maintain their inherent unbiasedness. The variance reduction can translate into lowering the number of samples required to achieve a desired sampling accuracy. However, the sampling cost for neighborhood exploration, if required, may outweigh such improvement, even leading to higher total amortized cost. Considering this, we provide a generalization of Rao-Blackwellization, which allows one to choose a suitable extent of obtaining Rao-Blackwellized samples in order to achieve a right balance between sampling cost and accuracy. We finally provide simulation results via real-world datasets that confirm our theoretical findings.},
keywords={Bayes methods;graph theory;Markov processes;Monte Carlo methods;random processes;sampling methods;neighborhood exploration;graph sampling;Markov chain Monte Carlo methods;Rao-Blackwellized estimators;sampling cost;conditioning technique;asymptotic variance reduction;total amortized cost;virtually-all random-walk graph;Monte Carlo methods;Sampling methods;Markov processes;Conferences;Random variables;Simulation;Social network services},
doi={10.1109/INFOCOM.2017.8057071},
ISSN={},
month={May},}
@INPROCEEDINGS{8057072,
author={Y. Wu and B. Zhang and S. Yang and X. Yi and X. Yang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Energy-efficient joint communication-motion planning for relay-assisted wireless robot surveillance},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In this paper, we consider a surveillance scenario where a team of sensing robots survey a sensitive area and transmit the monitored data to a remote base station through a mobile relay. In this scenario, it is challenging to autonomously adjust the position of the mobile relay for the sake of minimizing the total communication-motion energy consumption of the system, while maintaining the communication quality of the mobile sensing robots. We first derive the asymptotically optimal transmit powers of the mobile relay and of the sensing robots according to the predefined end-to-end packet error rate (PER) requirement. Then, we propose a joint communication-motion planning (JCMP) method for minimizing the total communication-motion energy consumption in both: single- and multi-sensing-robot scenarios, where the trajectories of the sensing robots are rigorously defined. We further consider the scenario where the sensing robots' trajectories are not fixed but can be optimized in restrained areas. The effectiveness of the proposed JCMP is verified by analysis and numerical results for different system configurations, showing that a substantial energy-efficiency improvement may be achieved in comparison with the benchmark that only optimizes the communication energy consumption.},
keywords={energy conservation;energy consumption;error statistics;mobile robots;relay networks (telecommunication);telecommunication network planning;telecommunication power management;remote base station;mobile relay;total communication-motion energy consumption;communication quality;mobile sensing robots;asymptotically optimal transmit powers;predefined end-to-end packet error rate requirement;joint communication-motion planning method;multisensing-robot scenarios;energy-efficient joint communication-motion planning;wireless robot surveillance;surveillance scenario;energy-efficiency improvement;Robot sensing systems;Mobile communication;Relays;Energy consumption;Base stations;Joint communication-motion planning;energy-efficient relays;optimization methods;robots;surveillance},
doi={10.1109/INFOCOM.2017.8057072},
ISSN={},
month={May},}
@INPROCEEDINGS{8057073,
author={T. Shi and S. Cheng and J. Li and Z. Cai},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Constructing connected dominating sets in battery-free networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Currently, the limitation of battery has become a serious obstacle for the development of Internet of things (IoTs). Therefore, a new network architecture, named as battery-free network, were proposed. In a typical battery-free network, the battery-free nodes are equipped with any battery and can only gain energy from the environment. Such network extremely expands the scope of the IoT applications, however, it also brings many troubles for some network operations, e.g. data collection, since the energy of each node is quite small. Considering that the Connected Dominating Sets (CDSs) are commonly used to support data collection and network communication in wireless networks, and thus we will also investigate the CDS construction problem in battery-free networks. In this paper, the problem of constructing CDS in a battery-free network is formally defined, and we prove that it is NP-Complete. Thus, four approximation algorithms were proposed to deal with the snapshot, continuous and time-window based CDS construction requirements, respectively. Finally, the extensive experiments were carried out and the results verify that the proposed algorithms have high performance in term of accuracy and efficiency.},
keywords={approximation theory;Internet of Things;radio networks;set theory;connected dominating sets;network architecture;battery-free nodes;network operations;network communication;wireless networks;battery-free network;Internet of things;IoT;CDS;CDS construction problem;approximation algorithms;Sensors;Batteries;Wireless sensor networks;Bridges;Monitoring;Windows;Conferences},
doi={10.1109/INFOCOM.2017.8057073},
ISSN={},
month={May},}
@INPROCEEDINGS{8057074,
author={Y. Gao and W. Dong and X. Zhang and W. Wu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Universal path tracing for large-scale sensor networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Most sensor networks employ dynamic routing protocols so that the routing topology can be dynamically optimized with environmental changes. The routing behaviors can be quite complex with increasing network scale and environmental dynamics. Knowledge on the routing path of each packet is certainly a great help in understanding the complex routing behaviors, allowing effective performance diagnosis and efficient network management. We propose PAT, a universal sensornet path tracing approach. PAT includes an intelligent path encoding scheme that allows efficient decoding at the PC side. To make PAT more scalable, we propose techniques to accurately estimate the degree information by exploiting timing information, allowing more compact path encoding. Moreover, we employ subpath concatenation to infer excessively long paths with a high recovery probability. We carefully evaluate PAT's performance using testbed experiments and and extensive simulations with up to 4,000 nodes. Results show that PAT significantly outperforms existing approaches.},
keywords={decoding;encoding;probability;routing protocols;telecommunication network management;telecommunication network topology;wireless sensor networks;network management;decoding;performance diagnosis;PAT;complex routing behaviors;routing path;environmental dynamics;network scale;routing topology;dynamic routing protocols;large-scale sensor networks;compact path encoding;timing information;intelligent path encoding scheme;universal sensornet path tracing approach;Routing;Topology;Network topology;Wireless sensor networks;Robot sensing systems;Encoding;Monitoring},
doi={10.1109/INFOCOM.2017.8057074},
ISSN={},
month={May},}
@INPROCEEDINGS{8057075,
author={F. Guo and B. Zhou and M. C. Vuran},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={CFOSynt: Carrier frequency offset assisted clock syntonization for wireless sensor networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={System-level timing inconsistency and wireless communication delays are the main uncertainties of existing synchronization mechanisms for wireless sensor networks. Existing solutions mainly rely on timestamp exchanges to estimate clock offset and skew, which results in frequent synchronization, high overhead, and high energy consumption to maintain a well-synchronized network. This paper introduces a novel clock syntonization approach to estimate the differences between clock frequencies of network nodes without the need for timestamp exchanges. The carrier frequency offset (CFO) assisted syntonization (CFOSynt) utilizes the carrier information obtained from wireless packet transmission for clock skew compensation. The key idea of CFOSynt is that, in any wireless communication system, where carrier modulation is employed, carrier frequency delivers information about the transmitter RF clock. Consequently, clock frequency offset between a pair of sensor nodes will result in a carrier frequency offset detected by the receiver node. By leveraging the CFO information, CFOSynt can estimate the system clock skew based on digital counter theory. Extensive experiments and numerical analysis have been demonstrated to evaluate clock skew estimation.},
keywords={clocks;delays;modulation;synchronisation;wireless sensor networks;CFOSynt;wireless sensor networks;system-level timing inconsistency;wireless communication delays;synchronization mechanisms;timestamp exchanges;frequent synchronization;high energy consumption;well-synchronized network;novel clock syntonization approach;clock frequency;network nodes;carrier information;wireless packet transmission;clock skew compensation;wireless communication system;carrier modulation;transmitter RF clock;sensor nodes;system clock;clock skew estimation;carrier frequency offset;CFO assisted syntonization;Clocks;Synchronization;Wireless sensor networks;Estimation;Wireless communication;Radio frequency;Delays},
doi={10.1109/INFOCOM.2017.8057075},
ISSN={},
month={May},}
@INPROCEEDINGS{8057076,
author={X. Lin and S. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Efficient remote radio head switching scheme in cloud radio access network: A load balancing perspective},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Cloud radio access network (C-RAN) is deemed as a promising architecture to meet the exponentially increasing traffic demand in mobile networks, where baseband processing is separated from remote radio heads (RRHs) and performed in a centralized baseband unit (BBU) pool. However, the densely deployed RRHs, as well as the passive optical network which provides high capacity backhauls between the RRHs and the BBU pool, consume a large amount of energy. In this paper, we propose efficient RRH switching schemes to achieve a tradeoff between the system energy saving and the load balance among the RRHs in the C-RAN. We first develop an approximation algorithm to address the intractable user association problem for a given set of RRHs, based on which we introduce efficient local search algorithms to perform RRH selection procedure, which can reduce the load fairness index of the C-RAN by controlling the active/inactive state of each RRH. We also discuss the handover signalling overhead issue and introduce an adaptive trigger mechanism to avoid switching on/off too many RRHs simultaneously so as to keep the signalling overhead of the C-RAN below an acceptable level. Numerical results demonstrate that the proposed RRH switching schemes can improve the system performance of the C-RAN significantly. Moreover, our proposal sheds light on how to design effective and efficient handover schemes for next generation mobile networks.},
keywords={cellular radio;cloud computing;energy conservation;mobile radio;mobility management (mobile radio);radio access networks;resource allocation;search problems;telecommunication computing;telecommunication power management;telecommunication traffic;cloud radio access network;baseband processing;remote radio heads;centralized baseband unit pool;passive optical network;BBU pool;RRH selection procedure;load fairness index;RRH switching schemes;load balancing;traffic demand;local search algorithm;next generation mobile networks;remote radio head switching scheme;RRH efficiency;handover schemes;energy saving;Optical switches;Power demand;Interference;Indexes;Heuristic algorithms;Mobile communication},
doi={10.1109/INFOCOM.2017.8057076},
ISSN={},
month={May},}
@INPROCEEDINGS{8057077,
author={D. Griffith and A. Ben Mosbah and R. Rouil},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Group discovery time in device-to-device (D2D) proximity services (ProSe) networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Device-to-device (D2D) communications for Long Term Evolution (LTE) networks relies on a discovery process to enable User Equipment (UE) to determine which D2D applications and services are supported by neighboring UEs. This is especially important for groups of UEs that operate outside the coverage area of any base station. The amount of time required for discovery information to reach every UE in a group depends on the number of UEs in the group and the dimensions of the discovery resource pool associated with the Physical Sidelink Discovery Channel (PSDCH); an additional factor is the half-duplex property of current UEs. In this paper, we use a Markov chain to characterize the performance of Mode 2 direct discovery. The resulting analytical model gives the distribution of the time for a UE to discover all other UEs in its group. We validate the model using Monte Carlo and network simulations.},
keywords={Long Term Evolution;Monte Carlo methods;resource allocation;group discovery time;device-to-device proximity services;Device-to-device communications;Long Term Evolution networks;neighboring UEs;discovery information;discovery resource pool;Physical Sidelink Discovery Channel;Mode 2 direct discovery;LTE network;D2D communication;Monte Carlo;Device-to-device communication;Markov processes;Mathematical model;Superluminescent diodes;Analytical models;Indexes;Long Term Evolution},
doi={10.1109/INFOCOM.2017.8057077},
ISSN={},
month={May},}
@INPROCEEDINGS{8057078,
author={R. Calvo-Palomino and D. Giustiniano and V. Lenders and A. Fakhreddine},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Crowdsourcing spectrum data decoding},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Crowdsourced signal monitoring systems are gaining attention for capturing the wireless spectrum at large geographical scale. Yet, most of the current systems are still limited to simple power spectrum measurements reported by each sensor. Our objective is to enhance such systems with signal decoding capabilities performed in the backend while retaining the original vision of a low-cost and crowdsourced setup. We propose a distributed system architecture for collaborative radio signal monitoring and decoding that builds on $12 low-cost radio frequency (RF) frontends and embedded boards and that takes into consideration the limited network bandwidth from the sensors to the backend. We present a distributed time multiplexing mechanism to sample the spectrum in a coordinated fashion that exploits the similarity of the radio signal received by more than one RF frontend in the same radio coverage. We address the strict time synchronization required among sensors to reconstruct the signal from the samples they receive when in the same radio coverage. We study and implement techniques to identify and overcome errors in the timing information in the presence of noise sources and decode the data in the backend. We provide an evaluation based on simulations and on real signals transmitted by Long-Term Evolution (LTE) base stations. Our results show that we can reliably reconstruct and decode radio signals received by low-cost crowdsourced sensors.},
keywords={cognitive radio;crowdsourcing;decoding;radio receivers;synchronisation;radio coverage;backend;decode radio signals;spectrum data;crowdsourced signal monitoring systems;wireless spectrum;geographical scale;signal decoding capabilities;distributed system architecture;collaborative radio signal monitoring;consideration the limited network bandwidth;distributed time;time synchronization;crowdsourced sensors;Decoding;Radio frequency;Synchronization;Monitoring;Bandwidth;Internet;Economic indicators},
doi={10.1109/INFOCOM.2017.8057078},
ISSN={},
month={May},}
@INPROCEEDINGS{8057079,
author={Y. Zhang and L. Deng and M. Chen and P. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Joint bidding and geographical load balancing for datacenters: Is uncertainty a blessing or a curse?},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We consider the scenario where a cloud service provider (CSP) operates multiple geo-distributed datacenters to provide Internet-scale service. Our objective is to minimize the total electricity and bandwidth cost by jointly optimizing electricity procurement from wholesale markets and geographical load balancing (GLB), i.e., dynamically routing workloads to locations with cheaper electricity. Under the ideal setting where exact values of market prices and workloads are given, this problem reduces to a simple LP and is easy to solve. However, under the realistic setting where only distributions of these variables are available, the problem unfolds into a non-convex infinite-dimensional one and is challenging to solve. Our main contribution is to develop an algorithm that is proven to solve the challenging problem optimally and efficiently, by exploring the full design space of strategic bidding. Trace-driven evaluations corroborate our theoretical results, demonstrate fast convergence of our algorithm, and show that it can reduce the cost for the CSP by up to 20% as compared to baseline alternatives. Our study highlights the intriguing role of uncertainty. While variability in workloads deteriorates the cost-saving performance of joint electricity procurement and GLB, counter-intuitively, variability in market prices can be exploited to achieve a cost reduction even larger than the setting without price variability.},
keywords={cloud computing;computer centres;concave programming;convex programming;cost reduction;Internet;power aware computing;power markets;pricing;resource allocation;tendering;cloud service provider;CSP;Internet-scale service;joint bidding and geographical load balancing;multiple geo-distributed datacenters;joint electricity procurement optimisation;dynamic routing workloads;nonconvex infinite-dimensional problem;trace-driven evaluations;total electricity minimization;bandwidth cost minimization;price variability;cost reduction;cost-saving performance;strategic bidding;market prices;GLB;wholesale markets;Real-time systems;Procurement;Standards;Load management;Electricity supply industry;Conferences;Uncertainty},
doi={10.1109/INFOCOM.2017.8057079},
ISSN={},
month={May},}
@INPROCEEDINGS{8057080,
author={A. Kabbani and M. Sharif},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Flier: Flow-level congestion-aware routing for direct-connect data centers},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Various topologies have been proposed in the context of high-performance computing and data center networking. Direct-connect topologies generally offer large capacity with high path diversity and are highly cost effective for general data center traffic patterns. However, the lack of simple yet efficient load balancing techniques for direct-connect fabrics has hindered these networks from gaining traction in data centers. This paper presents the design, implementation, and evaluation of Flicr, a light-weight host-based load balancing mechanism for direct-connect data centers. Flicr dynamically reroutes traffic through minimal and non-minimal routes to avoid congesting the fabric. This enables Flicr to efficiently minimize networking resource consumption while exploiting high path diversity in direct-connect fabrics to balance the network and gracefully handle link failures. Flicr requires only a simple kernel modification and is readily deployable in commodity data centers today. Our evaluations show that Flicr consistently outperforms other state-of-the-art load balancing designs, achieving 25-60% lower average flow completion time compared to adaptive routing. Flicr is also more robust against link failures and has 5-8 χ better performance relative to other schemes in the presence of link failures.},
keywords={computer centres;computer networks;data communication;telecommunication network routing;telecommunication network topology;telecommunication traffic;Flow-level congestion-aware routing;high-performance computing;data center networking;high path diversity;general data center traffic patterns;Flicr;load balancing mechanism;commodity data centers today;fabrics;direct-connect topologies;networking resource consumption;Routing;Load management;Fabrics;Topology;Network topology;Robustness},
doi={10.1109/INFOCOM.2017.8057080},
ISSN={},
month={May},}
@INPROCEEDINGS{8057081,
author={R. Zhu and D. Niu and B. Li and Z. Li},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Optimal multicast in virtualized datacenter networks with software switches},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Virtualized datacenter networks have been deployed in production platforms, e.g., Amazon VPC and VMware's NVP, to offer the flexibility of network management to enterprise-level clients. A common characteristic of these platforms is that they adopt software switches, such as Open vSwitch (OvS), instead of hardware switches to transfer data between VMs. Although group communication is common in enterprise applications, the unique characteristics of software switches have posed new challenges to the design of multicast protocols. How logical multicast can be optimally performed with software switches is still not well understood. In this paper, we observe that unlike hardware switches, the per-stream output rate in a software switch critically depends on the packet processing overhead of flow cloning. We study the optimal OvS multicast topology with or without the help of additional dedicated software switches called service nodes, and formulate the throughput maximization as a new class of degree-supervised combinatorial graph problems due to the presence of flow cloning costs. We propose a lineartime optimal solution that translates into simple forwarding rules installed at each software switch. Through emulation-based OvS profiling and extensive simulation results, we demonstrate that our proposed logical multicast solutions can significantly improve session throughput with the ability to handle load balancing and latency issues, as compared to the state-of-the-art in the literature.},
keywords={computer centres;computer network management;graph theory;multicast protocols;telecommunication network topology;telecommunication switching;virtualisation;virtualized datacenter networks;hardware switches;software switches;network management;Open vSwitch;multicast protocols;OvS multicast topology;degree-supervised combinatorial graph problem;Software;Virtual machine monitors;Throughput;Topology;Hardware;Cloning;Network topology},
doi={10.1109/INFOCOM.2017.8057081},
ISSN={},
month={May},}
@INPROCEEDINGS{8057082,
author={Z. Li and W. Bai and K. Chen and D. Han and Y. Zhang and D. Li and H. Yu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Rate-aware flow scheduling for commodity data center networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Flow completion times (FCTs) are critical for many cloud applications. To minimize the average FCT, recent transport designs, such as pFabric, PASE, and PIAS, approximate the Shortest Remaining Time First (SRTF) scheduling. A common, implicit assumption of these solutions is that the remaining time is only determined by the remaining flow size. However, this assumption does not hold in many real-world scenarios where applications generate data at diverse rates that are smaller than the network capacity. In this paper, we look into this issue from system perspective and find that the operating system (OS) kernel can be exploited to better estimate the remaining time of a flow. In particular, we use the rate of copying data from user space to kernel space to measure the data generation rate. We design RAX, a rate aware flow scheduling method, that calculates the remaining time of a flow more accurately, based on not only the flow size but also the data generation rate. We have implemented a RAX prototype in Linux kernel and evaluated it through testbed experiments and ns-2 simulations. Our testbed results show that RAX reduces FCT by up to 14.9%/41.8% and 7.8%/22.9% over DCTCP and PIAS for all/medium flows respectively.},
keywords={computer centres;computer networks;Linux;telecommunication scheduling;transport protocols;network capacity;operating system kernel;data generation rate;rate aware flow scheduling method;commodity data center networks;flow completion times;cloud applications;diverse rates;FCT;shortest remaining time first schedulling approximation;SRTF scheduling;Linux kernel;RAX prototype;ns-2 simulations;Kernel;Servers;Schedules;Throughput;Conferences;Hard disks},
doi={10.1109/INFOCOM.2017.8057082},
ISSN={},
month={May},}
@INPROCEEDINGS{8057083,
author={Y. Li and W. Gao},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Interconnecting heterogeneous devices in the personal mobile cloud},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Recent diversification of mobile computing devices allows a mobile user to own multiple types of devices for different application scenarios, but also results in various restrictions on the performance and usability of these devices. A viable solution to such restriction is to incorporate and interconnect mobile devices towards a personal mobile cloud where these devices can complement each other via cooperative resource sharing, but is challenging due to the heterogeneity of mobile devices in both hardware and software aspects. In this paper, we propose a novel design of resource sharing framework to address these challenges and generically interconnect heterogeneous mobile devices. Our basic idea is to mask the hardware and software heterogeneity in mobile systems by exploiting the existing mobile OS services as the interface of resource sharing, and further develop the resource sharing framework as a middleware in the mobile OS. We have implemented our design over various mobile platforms with diverse characteristics and resource limits, and demonstrated that our design can efficiently support generic resource sharing among heterogeneous mobile devices without incurring significant system overhead or requiring individual system modification.},
keywords={cloud computing;middleware;mobile computing;operating systems (computers);resource allocation;heterogeneous devices;personal mobile cloud;mobile computing devices;mobile user;interconnect mobile devices;software aspects;generically interconnect heterogeneous mobile devices;software heterogeneity;mobile systems;resource sharing framework;mobile platforms;cooperative resource sharing;hardware heterogeneity;middleware;mobile OS;Mobile communication;Hardware;Resource management;Mobile handsets;Mobile applications;Androids;Humanoid robots},
doi={10.1109/INFOCOM.2017.8057083},
ISSN={},
month={May},}
@INPROCEEDINGS{8057084,
author={L. Chen and H. Shen},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Considering resource demand misalignments to reduce resource over-provisioning in cloud datacenters},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Previous resource provisioning strategies in cloud datacenters allocate physical resources to virtual machines (VMs) based on the predicted resource utilization pattern of VMs. The pattern for VMs of a job is usually derived from historical utilizations of multiple VMs of the job. We observed that these utilization curves are usually misaligned in time, which would lead to resource over-prediction and hence over-provisioning. Since this resource utilization misalignment problem has not been revealed and studied before, in this paper, we study the VM resource utilization from public datacenter traces to verify the existence of the utilization misalignments. Then, to reduce resource over-provisioning, we propose three VM resource utilization pattern refinement algorithms to improve the original generated pattern by lowering the cap of the pattern, reducing cap provision duration and varying the minimum value of the pattern. These algorithms can be used in any resource provisioning strategy that considers predicted resource utilizations of VMs of a job. We then adopt these refinement algorithms in an initial VM allocation mechanism and test them in trace-driven experiments and real-world cluster experiments. The experimental results show that each improved mechanism can increase resource efficiency up to 74%, and reduce the number of PMs needed to satisfy tenant requests up to 47% while conforming the SLO requirement.},
keywords={cloud computing;computer centres;resource allocation;virtual machines;resource demand misalignments;cloud datacenters;physical resources;predicted resource utilization pattern;historical utilizations;utilization curves;resource utilization misalignment problem;VM resource utilization;public datacenter;cap provision duration;resource provisioning strategy;resource utilizations;resource efficiency;resource over-provisioning reduction;VM allocation mechanism;SLO requirement;Resource management;Google;Correlation;Prediction algorithms;Clustering algorithms;Extraterrestrial measurements},
doi={10.1109/INFOCOM.2017.8057084},
ISSN={},
month={May},}
@INPROCEEDINGS{8057085,
author={J. P. Champati and B. Liang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Efficient minimization of sum and differential costs on machines with job placement constraints},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We revisit the problem of assigning n jobs to m machines/servers. We study this problem under more general settings, which capture important aspects of applications that arise in networking and information systems. In particular, we consider jobs that have placement constraints and machines that are heterogeneous. The cost incurred at a machine is given by any general convex function on the number of jobs assigned to it. We aim to minimize the sum cost and the maximum differential cost. Through a network-flow equivalence transformation, we observe how these two objectives are fundamentally related, showing that sum-cost minimization implies maximum-differential-cost minimization. We propose an efficient algorithm termed Maximum Edge-Cost Cycle Cancelling (MEC<sup>3</sup>) to solve the sum-cost minimization problem with O(n<sup>2</sup> m<sup>2</sup>) time complexity. Furthermore, for applications where only the maximum differential cost is of concern, we further improve the efficiency of MEC<sup>3</sup> by proposing an early stop condition. We implement MEC<sup>3</sup> and two other algorithms from the literature. Using benchmark input instances, we show that MEC<sup>3</sup> has substantially lower run time than the other algorithms.},
keywords={computational complexity;convex programming;graph theory;minimisation;scheduling;job placement constraints;job assignment;differential cost minimization;MEC3;O(n2 m2) time complexity;sum-cost minimization problem;Maximum Edge-Cost Cycle Cancelling;maximum-differential-cost minimization;network-flow equivalence transformation;general convex function;Minimization;Cost function;Time complexity;Conferences;Benchmark testing;Algorithm design and analysis;Information systems},
doi={10.1109/INFOCOM.2017.8057085},
ISSN={},
month={May},}
@INPROCEEDINGS{8057086,
author={W. Jiang and Z. Yin and S. M. Kim and T. He},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Transparent cross-technology communication over data traffic},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Cross-technology communication (CTC) techniques are introduced in recent literatures to explore the opportunities of collaboration between heterogeneous wireless technologies, such as WiFi and ZigBee. Their applications include context-aware services and global channel coordination. However, state-of-the-art CTC schemes either suffer from channel inefficiency, low throughput, or disruption to existing networks. This paper presents the CTC via data packets (DCTC), which takes advantage of abundant existing data packets to construct recognizable energy patterns. DCTC features (i) a significant enhancement in CTC throughput while (ii) keeping transparent to upper layer protocols and applications. Our design also features advanced functions including multiplexing to support concurrent transmissions of multiple DCTC senders and adaptive rate control according to the traffic volume. Testbed implementations across WiFi and ZigBee platforms demonstrate reliable bidirectional communication of over 95% in accuracy while achieving throughput 2.3x of the state of the art. Meanwhile, experiment results show that DCTC has little and bounded impact on the delay and throughput of original data traffic.},
keywords={multiplexing;protocols;telecommunication network reliability;telecommunication traffic;wireless channels;wireless LAN;Zigbee;cross-technology communication techniques;heterogeneous wireless technologies;context-aware services;global channel coordination;bidirectional communication;data traffic;WiFi;ZigBee;adaptive rate control;Throughput;Wireless fidelity;ZigBee;Delays;Wireless communication;Protocols;Wireless sensor networks},
doi={10.1109/INFOCOM.2017.8057086},
ISSN={},
month={May},}
@INPROCEEDINGS{8057087,
author={J. Ren and L. Gao and H. Wang and Z. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Optimise web browsing on heterogeneous mobile platforms: A machine learning based approach},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Web browsing is an activity that billions of mobile users perform on a daily basis. Battery life is a primary concern to many mobile users who often find their phone has died at most inconvenient times. The heterogeneous multi-core architecture is a solution for energy-efficient processing. However, the current mobile web browsers rely on the operating system to exploit the underlying hardware, which has no knowledge of individual web contents and often leads to poor energy efficiency. This paper describes an automatic approach to render mobile web workloads for performance and energy efficiency. It achieves this by developing a machine learning based approach to predict which processor to use to run the web rendering engine and at what frequencies the processors should operate. Our predictor learns offline from a set of training web workloads. The built predictor is then integrated into the browser to predict the optimal processor configuration at runtime, taking into account the web workload characteristics and the optimisation goal: whether it is load time, energy consumption or a trade-off between them. We evaluate our approach on a representative ARM big.LITTLE mobile architecture using the hottest 500 webpages. Our approach achieves 80% of the performance delivered by an ideal predictor. We obtain, on average, 45%, 63.5% and 81% improvement respectively for load time, energy consumption and the energy delay product, when compared to the Linux heterogeneous multi-processing scheduler.},
keywords={Internet;learning (artificial intelligence);Linux;microprocessor chips;mobile computing;multiprocessing systems;online front-ends;power aware computing;search engines;telecommunication power management;telecommunication scheduling;heterogeneous mobile platforms;machine learning;mobile users;battery life;heterogeneous multicore architecture;energy-efficient processing;operating system;web rendering engine;optimal processor configuration;energy consumption;mobile architecture;energy delay product;Linux heterogeneous multiprocessing scheduler;Web browsing;Web contents;energy efficiency;mobile Web browsers;Web workload characteristics;ARM big.LITTLE mobile architecture;Mobile communication;Rendering (computer graphics);Optimization;Energy consumption;Browsers;Measurement;Feature extraction;Mobile Web Browsing;Energy Optimisation;big.LITTLE;Mobile Workloads},
doi={10.1109/INFOCOM.2017.8057087},
ISSN={},
month={May},}
@INPROCEEDINGS{8057088,
author={Q. Xiao and Y. Zhou and S. Chen},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Better with fewer bits: Improving the performance of cardinality estimation of large data streams},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Cardinality estimation is the task of determining the number of distinct elements (or the cardinality) in a data stream, under a stringent constraint that the input data stream can be scanned by just a single pass. This is a fundamental problem with many practical applications, such as traffic monitoring of high-speed networks and query optimization of Internetscale database. To solve the problem, we propose an algorithm named HLL-TailCut+, which implements the estimation standard error 1.0/√m using the memory units of three bits each, whose cost is much smaller than the five-bit memory units used by HyperLogLog, the best previously known cardinality estimator. This makes it possible to reduce the memory cost of HyperLogLog by 45%. For example, when the target estimation error is 1.1%, state-of-the-art HyperLogLog needs 5.6 kilobytes memory. By contrast, our new algorithm only needs 3 kilobytes memory consumption for attaining the same accuracy. Additionally, our algorithm is able to support the estimation of very large stream cardinalities, even on the Tera and Peta scale.},
keywords={data handling;storage management;cardinality estimation;stringent constraint;high-speed networks;query optimization;five-bit memory units;memory cost;target estimation error;stream cardinalities;data stream;memory consumption;estimation standard error;HyperLogLog;word length 3.0 bit;memory size 5.6 KByte;memory size 3.0 KByte;Registers;Estimation;Radiation detectors;Memory management;Google;Algorithm design and analysis;Monitoring},
doi={10.1109/INFOCOM.2017.8057088},
ISSN={},
month={May},}
@INPROCEEDINGS{8057089,
author={A. Furno and M. Fiore and R. Stanica},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Joint spatial and temporal classification of mobile traffic demands},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Mobile traffic data collected by network operators is a rich source of information about human habits, and its analysis provides insights relevant to many fields, including urbanism, transportation, sociology and networking. In this paper, we present an original approach to infer both spatial and temporal structures hidden in the mobile demand, via a first-time tailoring of Exploratory Factor Analysis (EFA) techniques to the context of mobile traffic datasets. Casting our approach to the time or space dimensions of such datasets allows solving different problems in mobile traffic analysis, i.e., network activity profiling and land use detection, respectively. Tests with real-world mobile traffic datasets show that, in both its variants above, the proposed approach (i) yields results whose quality matches or exceeds that of state-of-the-art solutions, and (ii) provides additional joint spatiotemporal knowledge that is critical to result interpretation.},
keywords={mobile computing;spatiotemporal phenomena;statistical analysis;telecommunication traffic;network activity;joint spatial and temporal classification;EFA techniques;real-world mobile traffic datasets;land use detection;mobile traffic analysis;Exploratory Factor Analysis techniques;first-time tailoring;mobile demand;temporal structures;spatial structures;original approach;mobile traffic data;mobile traffic demands;Mobile communication;Loading;Mobile computing;Maximum likelihood estimation;Sociology;Mathematical model;Conferences},
doi={10.1109/INFOCOM.2017.8057089},
ISSN={},
month={May},}
@INPROCEEDINGS{8057090,
author={J. Wang and J. Tang and Z. Xu and Y. Wang and G. Xue and X. Zhang and D. Yang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Spatiotemporal modeling and prediction in cellular networks: A big data enabled deep learning approach},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In this paper, we propose to leverage the emerging deep learning techniques for spatiotemporal modeling and prediction in cellular networks, based on big system data. First, we perform a preliminary analysis for a big dataset from China Mobile, and use traffic load as an example to show non-zero temporal autocorrelation and non-zero spatial correlation among neighboring Base Stations (BSs), which motivate us to discover both temporal and spatial dependencies in our study. Then we present a hybrid deep learning model for spatiotemporal prediction, which includes a novel autoencoder-based deep model for spatial modeling and Long Short-Term Memory units (LSTMs) for temporal modeling. The autoencoder-based model consists of a Global Stacked AutoEncoder (GSAE) and multiple Local SAEs (LSAEs), which can offer good representations for input data, reduced model size, and support for parallel and application-aware training. Moreover, we present a new algorithm for training the proposed spatial model. We conducted extensive experiments to evaluate the performance of the proposed model using the China Mobile dataset. The results show that the proposed deep model significantly improves prediction accuracy compared to two commonly used baseline methods, ARIMA and SVR. We also present some results to justify effectiveness of the autoencoder-based spatial model.},
keywords={cellular radio;learning (artificial intelligence);recurrent neural nets;telecommunication computing;LSAE;multiple local SAE;spatial modeling;spatiotemporal prediction;hybrid deep learning model;spatial dependencies;temporal dependencies;Base Stations;big system data;spatiotemporal modeling;deep learning approach;big data;cellular networks;China Mobile dataset;spatial model;Global Stacked AutoEncoder;temporal modeling;Long Short-Term Memory units;Correlation;Predictive models;Data models;Machine learning;Load modeling;Spatiotemporal phenomena;Mobile communication;Cellular Network;Big Data;Spatiotemporal Modeling;Deep Learning;Autoencoder;Recurrent Neural Network},
doi={10.1109/INFOCOM.2017.8057090},
ISSN={},
month={May},}
@INPROCEEDINGS{8057091,
author={N. Bartolini and T. He and H. Khamfroush},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Fundamental limits of failure identifiability by boolean network tomography},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Boolean network tomography is a powerful tool to infer the state (working/failed) of individual nodes from path-level measurements obtained by egde-nodes. We consider the problem of optimizing the capability of identifying network failures through the design of monitoring schemes. Finding an optimal solution is NP-hard and a large body of work has been devoted to heuristic approaches providing lower bounds. Unlike previous works, we provide upper bounds on the maximum number of identifiable nodes, given the number of monitoring paths and different constraints on the network topology, the routing scheme, and the maximum path length. The proposed upper bounds represent a fundamental limit on the identifiability of failures via Boolean network tomography. This analysis provides insights on how to design topologies and related monitoring schemes to achieve the maximum identifiability under various network settings. Through analysis and experiments we demonstrate the tightness of the bounds and efficacy of the design insights for engineered as well as real networks.},
keywords={Boolean functions;optimisation;telecommunication network topology;path-level measurements;monitoring schemes;NP-hard;failure identifiability;network settings;maximum identifiability;boolean network tomography;network topology;monitoring paths;identifiable nodes;network failures;egde-nodes;NP;Monitoring;Routing;Upper bound;Tomography;Testing;Encoding;Network topology},
doi={10.1109/INFOCOM.2017.8057091},
ISSN={},
month={May},}
@INPROCEEDINGS{8057092,
author={S. I. Nikolenko and K. Kogan and A. F. Anta},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Network simplification preserving bandwidth and routing capabilities},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We introduce structural transformations that allow simplifying a given network while preserving its original “bandwidth” and “routing” capabilities, transparently to specific allocations. We minimize a certain objective such as the aggregate capacity of network links, number of nodes, or number of links, in such a way that all the bandwidth that could be routed in the original network can also be routed in the reduced one. This improves cost-efficiency for both inter- and intra-datacenter connections and simplifies network management. We also identify a fundamental tradeoff between extra added capacity and simplicity of representation for a given network. Our analytic results are supported by extensive simulation results on hundreds of real network topologies. One result is that by adding 10-30% extra capacity to evaluated real-world networks one can simplify them down to a star topology with a single switch, while all routing and bandwidth allocation decisions on the simplified topology can be mapped back to the original network. This is an important step towards simplifying network management via a reduced virtualized network infrastructure.},
keywords={bandwidth allocation;computer centres;computer networks;quality of service;telecommunication network management;telecommunication network routing;telecommunication network topology;telecommunication traffic;extra added capacity;given network;network topologies;real-world networks;network management;reduced virtualized network infrastructure;network simplification preserving bandwidth;routing capabilities;structural transformations;original bandwidth;aggregate capacity;network links;intra-datacenter connections;extensive simulation;Bandwidth;Channel allocation;Routing;Network topology;Capacity planning;Topology;Conferences},
doi={10.1109/INFOCOM.2017.8057092},
ISSN={},
month={May},}
@INPROCEEDINGS{8057093,
author={J. Doncel and S. Aalto and U. Ayesta},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Economies of scale in parallel-server systems},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We consider a parallel-server system with K homogeneous servers where incoming tasks, arriving at rate λ, are dispatched by n dispatchers. Servers are FCFS queues and dispatchers implement a size-based policy such that the servers are equally loaded. We compare the performance of a system with n> 1 dispatchers and of a system with a single dispatcher. Every dispatcher handles a fraction 1/n of the incoming traffic and balances the load to K/n servers. We show that the performance of a system with n dispatchers, K servers and arrival rate λ coincides with that of a system with one dispatcher, K/n servers and arrival rate λ/n. Therefore, the performance comparison can be interpreted as the economies of scale in a system with one dispatcher when we scale up the number of servers and the arrival rate proportionately. We consider two continuous service time distributions: uniform and Bounded Pareto that have increasing and decreasing failure rates, respectively; and a discrete distribution with two values, which is the distribution that maximizes the variance for a given mean. We show that the performance degradation is small for uniformly distributed job sizes, but that for Bounded Pareto and two points distributions it can be unbounded.},
keywords={Pareto distribution;queueing theory;resource allocation;telecommunication traffic;parallel-server system;K homogeneous servers;n dispatchers;single dispatcher;incoming traffic;load balancing;FCFS queues;size-based policy;continuous service time distributions;uniform distribution;bounded Pareto distribution;failure rates;discrete distribution;variance maximization;Servers;Degradation;Routing;Economies of scale;Conferences;Time factors},
doi={10.1109/INFOCOM.2017.8057093},
ISSN={},
month={May},}
@INPROCEEDINGS{8057094,
author={X. Fu and Z. Xu and Q. Peng and L. Fu and X. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Complexity vs. optimality: Unraveling source-destination connection in uncertain graphs},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Determination of source-destination connectivity in networks has long been a fundamental problem, where most existing works are based on deterministic graphs that overlook the inherent uncertainty in network links. To overcome such limitation, this paper models the network as an uncertain graph where each edge e exists independently with some probability p(e). The problem examined is that of determining whether a given pair of nodes, a source s and a destination t, are connected by a path or separated by a cut. Assuming that during each determining process we are associated with an underlying graph, the existence of each edge can be unraveled through edge testing at a cost of c(e). Our goal is to find an optimal strategy incurring the minimum expected testing cost with the expectation taken over all possible underlying graphs that form a product distribution. Formulating it into a combinatorial optimization problem, we first characterize the computational complexity of optimally determining source-destination connectivity in uncertain graphs. Specifically, through proving the NP-hardness of two closely related problems, we show that, contrary to its counterpart in deterministic graphs, this problem cannot be solved in polynomial time unless P=NP. Driven by the necessity of designing an exact algorithm, we then apply the Markov Decision Process framework to give a dynamic programming algorithm that derives the optimal strategies. As the exact algorithm may have prohibitive time complexity in practical situations, we further propose two more efficient approximation schemes compromising the optimality. The first one is a simple greedy approach with linear approximation ratio. Interestingly, we show that naive as it is, it has comparable performance than some other seemingly more sophisticated algorithms. Second, by harnessing the sub-modularity of the problem, we further design a more elaborate algorithm with better approximation ratio. The effectiveness of the proposed algorithms are justified through extensive simulations on three real network datasets, from which we demonstrate that the proposed algorithms yield strategies with smaller expected cost than conventional heuristics.},
keywords={approximation theory;computational complexity;dynamic programming;graph theory;greedy algorithms;Markov processes;optimisation;probability;uncertain graph;source-destination connectivity;deterministic graphs;network links;edge testing;combinatorial optimization problem;computational complexity;exact algorithm;Markov Decision Process framework;dynamic programming algorithm;prohibitive time complexity;network datasets;smaller expected cost;source-destination connection;linear approximation ratio;approximation scheme;Approximation algorithms;Testing;Heuristic algorithms;Algorithm design and analysis;Markov processes;Dynamic programming;Reliability},
doi={10.1109/INFOCOM.2017.8057094},
ISSN={},
month={May},}
@INPROCEEDINGS{8057095,
author={K. Chen and G. Tan},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={SatProbe: Low-energy and fast indoor/outdoor detection based on raw GPS processing},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Indoor-outdoor (IO) detection provides very useful hints for a mobile device to perform context-aware services. To that end, GPS presents a viable solution by relating a device's IO status with its positioning performance, which depends on the device's exposure to the open sky. This approach, however, is prohibitively expensive in terms of energy consumption and response time. Recent work has thus been focused on exploiting low-energy sensors such as light, cellular, and magnetic sensors to infer the IO status indirectly, at the cost of reduced adaptability or explicit user involvement. In this paper, we propose an improving solution to this problem. Our method, called SatProbe, reverts to the GPS approach for its directness and robustness, but avoids its drawback by extracting only the number of visible satellites from the raw GPS data, instead of going through extensive computation to obtain a final position. This metric provides a clear indicator of the IO status, yet can be obtained with great efficiency. Experiments on 79 raw GPS traces with 2595 detection points across a variety of environments show that SatProbe produces higher detection accuracy than previous solutions, with more than an order of magnitude reductions in energy consumption and detection time.},
keywords={Global Positioning System;magnetic sensors;mobile computing;ubiquitous computing;fast indoor/outdoor detection;raw GPS processing;indoor-outdoor detection;mobile device;context-aware services;IO status;SatProbe;Global Positioning System;Satellites;Receivers;Magnetic sensors;Correlation;Multiaccess communication},
doi={10.1109/INFOCOM.2017.8057095},
ISSN={},
month={May},}
@INPROCEEDINGS{8057096,
author={J. Wang and N. Tan and J. Luo and S. J. Pan},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={WOLoc: WiFi-only outdoor localization using crowdsensed hotspot labels},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Given the ever-expanding scale of WiFi deployments in metropolitan areas, we have reached the point where accurate GPS-free outdoor localization becomes possible by relying solely on the WiFi infrastructure. Nevertheless, the existing industrial practices do not seem to have the right implementation to achieve an adequate accuracy, while the academic researches that are mostly attracted by indoor localization have largely neglected this outdoor aspect. In this paper, we propose WOLoc (WiFi-only Outdoor Localization) as a solution that offers meter-level accuracy, by holistically treating the large number of WiFi hotspot labels gather by crowdsensing. On one hand, we do not take these labels as fingerprints as it is almost impossible to extend indoor localization mechanisms by fingerprinting metropolitan areas. On the other hand, we avoid the over-simplified local synthesis methods (e.g., centroid) that significantly lose the information contained in the labels. Instead, we accommodate all the labeled and unlabeled data for a given area using a semi-supervised manifold learning technique, and the output concerning the unlabeled part will become the estimated locations for both users and WiFi hotspots. We conduct extensive experiments with WOLoc in several outdoor areas, and the results have strongly indicated the efficacy of our solution.},
keywords={Global Positioning System;learning (artificial intelligence);wireless LAN;WOLoc;WiFi-only outdoor localization;crowdsensed hotspot labels;WiFi deployments;metropolitan areas;WiFi infrastructure;WiFi-only Outdoor Localization;meter-level accuracy;WiFi hotspot labels;indoor localization mechanisms;GPS-free outdoor localization;Wireless fidelity;Urban areas;Manifolds;Conferences;Global Positioning System;Estimation;Roads},
doi={10.1109/INFOCOM.2017.8057096},
ISSN={},
month={May},}
@INPROCEEDINGS{8057097,
author={R. Margolies and R. Becker and S. Byers and S. Deb and R. Jana and S. Urbanek and C. Volinsky},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Can you find me now? Evaluation of network-based localization in a 4G LTE network},
year={2017},
volume={},
number={},
pages={1-9},
abstract={User location is of critical importance to cellular network operators. It is often used for network capacity planning and to aid in the analysis of service and network diagnostics. However, existing localization techniques rely on user-provided information (e.g., Angle-of-Arrival), which are not available to the operator, and often require a significant effort to collect training data. Our main contribution is the design and evaluation of the Network-Based Localization (NBL) System for localizing a user in a 4G LTE network. The NBL System consists of 2 stages. In an offline stage, we develop RF coverage maps based on a large-scale crowd-sourced channel measurement campaign. Then, in an online stage, we present a localization algorithm to quickly match RF measurements (which are already collected as part of normal network operation) to coverage map locations. The system is more practical than related works, as it does not make any assumptions about user mobility, nor does it require expensive manual training measurements. Despite the realistic assumptions, our extensive evaluations in a national 4G LTE network show that the NBL System achieves a localization accuracy which is comparable to related works (i.e., a median accuracy of 5% of the cell's coverage region).},
keywords={4G mobile communication;cellular radio;Long Term Evolution;mobility management (mobile radio);telecommunication network planning;wireless channels;cellular network operators;RF coverage maps;RF measurements;user mobility;localization techniques;4G LTE network;network capacity planning;network-based localization system;crowd-sourced channel measurement;Radio frequency;Long Term Evolution;Training;Cellular networks;Training data;Area measurement;Localization;wireless networks;crowd-sourcing},
doi={10.1109/INFOCOM.2017.8057097},
ISSN={},
month={May},}
@INPROCEEDINGS{8057098,
author={M. Fida and A. Lutu and M. K. Marina and Ö. Alay},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={ZipWeave: Towards efficient and reliable measurement based mobile coverage maps},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The accuracy of measurement-driven mobile coverage maps depends on the quality, density and pattern of the signal strength observations. Thus, identifying an efficient measurement data collection methodology is essential, especially when considering the cost associated with the measurement collection approaches (e.g., drive tests, crowd approaches). We propose ZipWeave, a novel measurement data collection and fusion framework for building efficient and reliable measurement-based mobile coverage maps. ZipWeave incorporates a novel nonuniform sampling strategy to achieve reliable coverage maps with reduced sample size. Assuming prior knowledge of the propagation characteristics of the region of interest, we first examine the potential gains of this non-uniform sampling strategy in different cases via a measurement-based statistical analysis methodology; this involves irregular spatial tessellation of the region of interest into sub-regions with internally similar radio propagation characteristics and sampling based on these sub-regions. We then present a practical form of ZipWeave nonuniform sampling strategy that can be used even without any prior information. In all our evaluations, we show that the ZipWeave non-uniform sampling approach reduces the samples by half compared to the common systematic-random sampling, while maintaining similar accuracy. Moreover, we show that the other key feature of ZipWeave to combine high-quality controlled measurements (that present limited geographic footprint similar to drive tests) with crowdsourced measurements (that cover a wider footprint) leads to more reliable mobile coverage maps overall.},
keywords={mobile radio;quality control;radiowave propagation;sampling methods;signal sampling;statistical analysis;reliable measurement;measurement-driven mobile coverage maps;measurement data collection;radio propagation characteristics;measurement data collection methodology;nonuniform sampling strategy;reliable mobile coverage maps;crowdsourced measurements;high-quality controlled measurements;systematic-random sampling;ZipWeave nonuniform sampling strategy;statistical analysis methodology;reduced sample size;fusion framework;crowd approaches;drive tests;measurement collection approaches;signal strength observations;Reliability;Mobile communication;Atmospheric measurements;Battery charge measurement;Particle measurements;Monitoring;Urban areas},
doi={10.1109/INFOCOM.2017.8057098},
ISSN={},
month={May},}
@INPROCEEDINGS{8057099,
author={J. Tan and C. Nguyen and X. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={SilentTalk: Lip reading through ultrasonic sensing on mobile phones},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The recently enhanced computing capability and rich sensing functionality on mobile devices lead to the ubiquitous application of speech recognition. Traditional speech recognition records acoustic signals or visual images to interpret speech. However, the acoustic based scheme has many drawbacks. It is easily affected by the environmental noise when users are in the factory or market, and can not be used in a place where people need to be quite such as library. Specifically the current design is not suitable for people with speaking or hearing difficulties. Unfortunately, the visual-based approach is sensitive to fight conditions which shows poor performance in the dark area. As a result, it is necessary to provide an new human-computer interaction channel to assist speech recognition. This paper presents SilentTalk, a non-invasive lip reading system based on ultrasonic Doppler effect The main idea is to generate ultrasonic signals from a mobile phone, then capture the reflections and analyze the fine-grained frequency shift caused by mouth movements. A Frequency Shift Detection Model (FSDM) is proposed to quantify the correlation between frequency variations and mouth movements that form different syllables. SilentTalk then applies a Continuous Lip Reading Model (CLRM) on top of FSDM to realize continuous lip reading. Based on Markov assumption, CLRM effectively combines pronunciation rules and context knowledge to connect isolated syllables to words and sentences. Experiments show that SilentTalk can identify 12 basic mouth motions up to 95.4% accuracy in English. The system can also recognize short sentences up to six words with an average accuracy of 74.8%.},
keywords={Doppler effect;feature extraction;mobile handsets;speech recognition;SilentTalk;ultrasonic sensing;mobile phone;rich sensing functionality;mobile devices;ubiquitous application;visual images;acoustic based scheme;environmental noise;speaking hearing difficulties;visual-based approach;human-computer interaction channel;noninvasive lip reading system;ultrasonic signals;fine-grained frequency shift;mouth movements;Frequency Shift Detection Model;FSDM;frequency variations;Continuous Lip Reading Model;speech recognition;ultrasonic Doppler effect;Markov assumption;Conferences},
doi={10.1109/INFOCOM.2017.8057099},
ISSN={},
month={May},}
@INPROCEEDINGS{8057100,
author={Y. Wei and H. Wu and H. Wang and H. Tsai and K. C. Lin and R. Boubezari and H. Le Minh and Z. Ghassemlooy},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={LiCompass: Extracting orientation from polarized light},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Accurate orientation information is the key in many applications, ranging from map reconstruction with crowdsourcing data, location data analytics, to accurate indoor localization. Many existing solutions rely on noisy magnetic and inertial sensor data, leading to limited accuracy, while others leverage multiple, dense anchor points to improve the accuracy, requiring significant deployment efforts. This paper presents LiCompass, the first system that enables a commodity camera to accurately estimate the object orientation using just a single optical anchor. Our key idea is to allow a camera to observe varying intensity level of polarized light when it is in different orientations and, hence, perform estimation directly from image pixel intensity. As the estimation relies only on pixel intensity, instead of the location of the anchor in an image, the system performs reliably at long distance, with low resolution images, and with large perspective distortion. LiCompass' core designs include an elaborate optical anchor design and a series of signal processing techniques based on trigonometric properties, which extend the range of orientation estimation to full 360 degrees. Our prototype evaluation shows that LiCompass produces very accurate estimates with median errors of merely 2.5 degrees at 5 meters and 7.4 degrees at 2.5 meters with an irradiance angle of 55 degrees.},
keywords={cameras;image resolution;image sensors;light polarisation;navigation;accurate indoor localization;noisy magnetic sensor data;commodity camera;object orientation;single optical anchor;varying intensity level;polarized light;image pixel intensity;low resolution images;orientation estimation;LiCompass core design;optical anchor design;Cameras;Estimation;Optical polarization;Adaptive optics;Optical imaging;Optical distortion;Optical receivers},
doi={10.1109/INFOCOM.2017.8057100},
ISSN={},
month={May},}
@INPROCEEDINGS{8057101,
author={H. Chen and F. Li and Y. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={EchoTrack: Acoustic device-free hand tracking on smart phones},
year={2017},
volume={},
number={},
pages={1-9},
abstract={This paper explores the limits of acoustic ranging on smart phone in the scenario of device-free hand tracking. Tracking the hand is challenging since it requires continuously locating the moving hand in the air with fine resolution. Existing work on hand tracking relies on special hardware or requires users hold the mobile device. This paper presents EchoTrack, which continuously locates the hand by leveraging mobile audio hardware advances without special infrastructure supported. EchoTrack measures the distance from the hand to the speaker array embedded in smart phone via the chirp's Time of Flight (TOF). The speaker array and hand yield a unique triangle. The hand can be located with this triangular geometry. The trajectory accuracy can be improved with the method of Doppler shift compensation and trajectory correction (i.e., roughness penalty smoothing method). We implement a prototype on smart phone and the evaluation shows that EchoTrack can achieve tracking accuracy within about three centimeters of 76% and two centimeters of 48%.},
keywords={Doppler shift;gesture recognition;human computer interaction;smart phones;tracking accuracy;EchoTrack;Acoustic device-free hand tracking;smart phone;acoustic ranging;moving hand;mobile device;speaker array;mobile audio hardware;Doppler shift compensation;Chirp;Microphones;Smart phones;Distance measurement;Trajectory;Hardware;Doppler shift},
doi={10.1109/INFOCOM.2017.8057101},
ISSN={},
month={May},}
@INPROCEEDINGS{8057102,
author={H. Xu and Z. Yang and Z. Zhou and K. Yi and C. Peng},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={TUM: Towards ubiquitous multi-device localization for cross-device interaction},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Cross-device interaction is becoming an increasingly hot topic as we often have multiple devices at our immediate disposal in this era of mobile computing. Various cross-device applications such as file sharing, multi-screen display, and cross-device authentication have been proposed and investigated. However, one of the most fundamental enablers remains unsolved: How to achieve ubiquitous multi-device localization? Though pioneer efforts have resorted to gesture-assisted or sensing-assisted localization, they either require extensive user participation or impose some strong assumptions on device sensing abilities. This introduces extra costs and constraints, and thus degrades their practicality. To overcome these limitations, we propose TUM, an acoustic-assisted localization scheme Towards Ubiquitous Multi-device localization. The basic idea of TUM is to utilize the dual-microphones and speakers to obtain distance cues among devices. At the same time it resolves the location ambiguity with the help of MEMS sensors. We devise techniques for distance constraint extraction, static localization, continuous localization, and multi-device localization, and build a prototype that runs on commodity devices. Extensive experiments show that TUM provides a real-time 3D relative localization service under 10cm mean error for both static and continuous localization.},
keywords={array signal processing;microphones;mobile computing;peer-to-peer computing;sensors;ubiquitous computing;wireless sensor networks;TUM;ubiquitous multidevice localization;cross-device interaction;cross-device authentication;device sensing abilities;continuous localization;acoustic-assisted localization scheme;dual-microphones;MEMS sensors;distance constraint extraction;static localization;multidevice localization;static localization;Microphones;Acoustics;Sensors;Smart devices;Distance measurement;Three-dimensional displays;Clocks},
doi={10.1109/INFOCOM.2017.8057102},
ISSN={},
month={May},}
@INPROCEEDINGS{8057103,
author={W. Jiang and J. Wu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Active opinion-formation in online social networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Recommendation systems usually try to “guess” a user's preferences from the system's view. We study another side of recommendation: active opinion-formation from the perspective of the user. In real life, a user's opinion evolves with time and refines when new evidence occurs. Then, how does an online user form his/her own opinion actively in large social networks? The problem has three challenges: the factor, the effect and the open environment. To address those challenges, we investigate: (1) what factors or channels a user will consider, (2) how those channels will take effect, and (3) an incremental approach to incorporate multiple channels. We explore three types of channels: the internal opinion of an individual user, influences from trusted friends, and influences from public channels. A novel simulator, OpinionFormer, is proposed to incorporate those channels incrementally. It differentiates the effects of friends and public channels as well as positive and negative opinions. We validate the performance of OpinionFormer by predicting users' opinions using real-world data sets. Experimental results show that our model can improve accuracy over other models that ignore some channels or that neglect the evolving features.},
keywords={recommender systems;social networking (online);internal opinion;individual user;public channels;positive opinions;negative opinions;active opinion-formation;online social networks;recommendation systems;online user;OpinionFormer simulator;friends;user preferences;Conferences;Social network services;Containers;Open systems;Temperature measurement;Frequency modulation;opinion formation;internal opinion;trusted friend;public channel;fluid dynamics},
doi={10.1109/INFOCOM.2017.8057103},
ISSN={},
month={May},}
@INPROCEEDINGS{8057104,
author={A. Zhiyuli and X. Liang and Z. Xu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Learning distributed representations for large-scale dynamic social networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Learning distributed representations of symbolic data were introduced by Hinton[1], and first developed in modeling networks for learning the node vectors by Perozzi et al (2014). In this work, we proposed Dnps, a novel nodes embedding approach for acquiring distributed representations of large-scale dynamic social networks. Dnps is suitable for many types of social networks: dynamic/static, directed/undirected, and weighted/unweighted. Recently, several works of nodes embedding were proposed. However, they were designed for static networks, such as language networks. To address this problem, first, we develop a damping based positive sampling (DpS) algorithm to learn the hierarchical structure of social networks. Then, we devise a local search based DpS algorithm to obtain incremental information of network evolution. Finally, we show Dnps's potentials on future link prediction task for three real-life large-scale dynamic social networks. The results show that Dnps consistently outperforms all baseline methods and exhibits an improvement of 12%, 6%, 4% on Digg, Flickr and YouTube over the second-highest level, respectively. Moreover, Dnps is also scalable. For example, Dnps can speed up the training process in 2 ~ 36 times compared with benchmarks on Flickr network. The source codes of the project is available online<sup>1</sup>.},
keywords={computational complexity;graph theory;learning (artificial intelligence);search problems;social networking (online);speech processing;statistical distributions;network evolution;large-scale dynamic social networks;Dnps;Flickr network;distributed representations;static networks;language networks;node embedding;symbolic data;node vectors;damping based positive sampling algorithm;DpS algorithm;Digg;YouTube;Social network services;Damping;Heuristic algorithms;Training;Algorithm design and analysis;Prediction algorithms;Conferences},
doi={10.1109/INFOCOM.2017.8057104},
ISSN={},
month={May},}
@INPROCEEDINGS{8057105,
author={W. Chen and C. G. Brinton and D. Cao and M. Chiang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Behavior in social learning networks: Early detection for online short-courses},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We study learning outcome prediction for online courses. Whereas prior work has focused on semester-long courses with frequent student assessments, we focus on short-courses that have single outcomes assigned by instructors at the end. The lack of performance data makes the behavior of learners, captured as they interact with course content and with one another in Social Learning Networks (SLN), essential for prediction. Our method defines several (machine) learning features based on behaviors collected on the modes of (human) learning in a course, and uses them in appropriate classifiers. Through evaluation on data captured from three two-week courses hosted through our delivery platforms, we make three key observations: (i) behavioral data is predictive of learning outcomes in short-courses (our classifiers achieving AUCs ≥ 0.8 after the two weeks), (ii) it has an early detection capability (AUCs ≥ 0.7 with the first week of data), and (iii) the content features have an “earliest” detection capability (with higher AUC in the first few days), while the SLN features become the more predictive set over time, as the network matures. We also discuss how our method can generate behavioral analytics for instructors.},
keywords={computer aided instruction;distance learning;educational courses;learning (artificial intelligence);pattern classification;social networking (online);social learning networks;outcome prediction;semester-long courses;performance data;course content;two-week courses;behavioral data;early detection capability;behavioral analytics;student assessment;online short-courses;Feature extraction;Training;Programmable logic arrays;Data models;Computational modeling;Conferences;Discussion forums},
doi={10.1109/INFOCOM.2017.8057105},
ISSN={},
month={May},}
@INPROCEEDINGS{8057106,
author={G. Liu and Q. Chen and Q. Yang and B. Zhu and H. Wang and W. Wang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={OpinionWalk: An efficient solution to massive trust assessment in online social networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Massive trust assessment (MTA) in an Online Social Network (OSN), i.e., computing the trustworthiness of all users in the network, is crucial in various OSN-related applications. Existing solutions are either too slow or inaccurate in addressing the MTA problem. We propose the OpinionWalk algorithm that accurately and efficiently conducts MTA in an OSN. OpinionWalk models trust by the Dirichlet distribution and uses a matrix to represent the direct trust relations among users. From the perspective of a user, other users' trustworthiness are stored in a column vector that is iteratively updated when the algorithm “walks” through the network, in a breadth-first search manner. We identify the overlapping subproblems property in MTA and prove OpinionWalk is a more efficient solution. The accuracy and execution time of OpinionWalk are evaluated and compared to benchmark algorithms including EigenTrust, TrustRank, MoleTrust, TidalTrust and AssessTrust, using two real-world datasets (Advogato and Pretty Good Privacy). Experimental results indicate that OpinionWalk is an efficient and accurate solution to MTA, compared to previous algorithms.},
keywords={data privacy;security of data;social networking (online);trusted computing;OpinionWalk models trust;direct trust relations;benchmark algorithms;OSN;Pretty Good Privacy;Advogato;AssessTrust;TidalTrust;MoleTrust;TrustRank;EigenTrust;breadth-first search;column vector;Dirichlet distribution;OpinionWalk algorithm;MTA problem;OSN-related applications;online social networks;massive trust assessment;Computational modeling;Social network services;Time complexity;Statistical distributions;Network topology;Algorithm design and analysis;Conferences;Massive trust assessments;online social networks;threes-valued subjective logic;trust model},
doi={10.1109/INFOCOM.2017.8057106},
ISSN={},
month={May},}
@INPROCEEDINGS{8057107,
author={Z. Yin and W. Jiang and S. M. Kim and T. He},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={C-Morse: Cross-technology communication with transparent Morse coding},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Recent research on CTC (cross-technology communication) demonstrates the viability of direct coordination among heterogeneous devices (e.g., WiFi and ZigBee) with incompatible physical layers. Although encouraging, current solutions suffer from either severe inefficiency in channel utilization or low throughput using limited beacons. To address these limitations, this paper presents C-Morse, which leverages all traffic (such as through data packets, beacons and other control frames) to achieve a high cross-technology communication throughput. The key idea of C-Morse is to slightly perturb the transmission timing of existing WiFi packets to construct recognizable radio energy patterns without introducing noticeable delays to upper layers. At the receiver side, ZigBee captures such patterns by sensing the RSSI value, and then decodes the transmitted symbols. C-Morse also introduces a novel timing-based multiplexing technique to allow the coexistence of multiple C-Morse access points and reject other interference, showing a reliable symbol delivery ratio. As a result, C-Morse achieves a free side-channel, whose CTC throughput is as much as 9 χ of the present state of the art, while maintaining the through traffic within a negligible delay that goes unnoticed by applications and end-users.},
keywords={channel coding;decoding;interference suppression;multiplexing;radiofrequency interference;telecommunication traffic;wireless channels;wireless LAN;wireless sensor networks;Zigbee;recognizable radio energy patterns;multiple C-Morse access points;transparent Morse coding;heterogeneous devices;channel utilization;data packets;CTC;cross-technology communication;WiFi packets;ZigBee;telecommunication traffic;radio energy pattern;RSSI;decoding;timing-based multiplexing technique;interference;symbol delivery ratio;free side-channel;Wireless fidelity;ZigBee;Delays;Wireless communication;Throughput;Wireless sensor networks},
doi={10.1109/INFOCOM.2017.8057107},
ISSN={},
month={May},}
@INPROCEEDINGS{8057108,
author={X. Guo and X. Zheng and Y. He},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={WiZig: Cross-technology energy communication over a noisy channel},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The proliferation of loT applications drives the need of ubiquitous connections among heterogeneous wireless devices. Cross-Technology Communication (CTC) is a significant technique to directly exchange information among heterogeneous devices that follow different standards. By exploiting a side-channel like frequency, amplitude or temporal modulation, the existing works enable CTC but have limited performance under channel noise. In this paper, we propose WiZig, a novel CTC technique that employs modulation techniques in both the amplitude and temporal dimensions to optimize the throughput over a noisy channel. We establish a theoretical model of the energy communication channel to clearly understand the channel capacity. We then devise an online rate adaptation algorithm to adjust the modulation strategy according to the channel condition. Based on the theoretical model, WiZig can accurately control the number of encoded energy amplitudes and the length of a receiving window, so as to optimize the CTC throughput. We implement a prototype of WiZig on a software radio platform and a commercial ZigBee device. The evaluation show that WiZig achieves a throughput of 153.85 bps with less than 1 % symbol error rate in a real environment. The results demonstrate that WiZig realizes efficient and reliable CTC under varied channel conditions.},
keywords={channel capacity;error statistics;modulation;software radio;telecommunication power management;wireless channels;Zigbee;heterogeneous devices;temporal modulation;channel noise;WiZig;novel CTC technique;modulation techniques;temporal dimensions;noisy channel;theoretical model;energy communication channel;channel capacity;online rate adaptation algorithm;modulation strategy;channel condition;encoded energy amplitudes;CTC throughput;commercial ZigBee device;varied channel conditions;Cross-technology energy communication;ubiquitous connections;heterogeneous wireless devices;loT applications;symbol error rate;Receivers;Wireless communication;Throughput;Error analysis;Noise measurement;Wireless sensor networks;Modulation},
doi={10.1109/INFOCOM.2017.8057108},
ISSN={},
month={May},}
@INPROCEEDINGS{8057109,
author={Z. Chi and Z. Huang and Y. Yao and T. Xie and H. Sun and T. Zhu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={EMF: Embedding multiple flows of information in existing traffic for concurrent communication among heterogeneous IoT devices},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The exponentially increasing number of IoT devices makes the unlicensed industrial, scientific, and medical (ISM) radio bands (e.g., 2.4 GHz) extremely crowded. Currently, there is no efficient solution to coordinate the large amount heterogeneous IoT devices that have different communication technologies (e.g., WiFi and ZigBee). To fill this gap, in this paper, we introduce embedded multiple flows (EMF) communication method, which (i) embeds different pieces of information in existing traffic and (ii)concurrently sends out these information from one IoT sender to multiple IoT receivers that have a different communication technology from the sender. By doing this, our EMF method (i) enables cross-technology communication among heterogeneous IoT devices, (ii) does not introduce any extra control traffic, and (iii) is transparent to the higher layer applications. Our approach is implemented on USRPs and commercial off-the-shelf (COTS) ZigBee devices. We also conducted extensive experiments to evaluate our approach in real-world settings. The evaluation results show that EMF's throughput is more than 14 times higher than the latest cross-technology communication technique (i.e. FreeBee[1]).},
keywords={embedded systems;Internet of Things;Zigbee;IoT sender;multiple IoT receivers;EMF method;Embedding multiple flows;concurrent communication;heterogeneous IoT devices;embedded multiple flows communication method;USRP;commercial off-the-shelf ZigBee devices;cross-technology communication technique;unlicensed industrial scientific and medical radio bands;ISM bands;frequency 2.4 GHz;Wireless fidelity;ZigBee;Receivers;Modulation;Throughput;Bit error rate;Logic gates},
doi={10.1109/INFOCOM.2017.8057109},
ISSN={},
month={May},}
@INPROCEEDINGS{8057110,
author={T. Osuki and K. Sakai and S. Fukumoto},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Contact avoidance routing in delay tolerant networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Delay tolerant networks (DTNs) are widely adopted to many network applications, such as disaster recovery and battlefield communications. Such critical network scenarios call for an outright prevention mechanism against contact-based attacks, e.g., blackmailing a legitimate user to compromise sensitive information at a contact. To the best of our knowledge, there is no work on secure routing protocol against contact-based attacks in DTNs. Therefore, in this paper, we first formulate the problem of contact avoidance routing, in which the node holding a message tries to avoid having a contact with an adversary. By applying the phase-type distribution, we build the secure opportunistic path model, which integrates the delivery probability within the deadline and the safety of opportunistic paths. Then, we propose a contact avoidance routing (CAR) protocol to securely deliver a message to its destination against the contact-based compromise attack. In addition, we further propose an adaptive CAR (A-CAR) to accommodate complicated network scenarios, where the capabilities of adversaries are parameterized. The extensive simulations using real traces as well as random graphs demonstrate that the proposed CAR and A-CAR protocols achieve their design goals.},
keywords={computer network security;delay tolerant networks;probability;routing protocols;delay tolerant networks;DTNs;network applications;critical network scenarios;outright prevention mechanism;secure routing protocol;secure opportunistic path model;contact avoidance routing protocol;phase-type distribution;contact-based attacks;Routing;Routing protocols;Automobiles;Security;Delays;Adaptation models;Contact avoidance routing;network security;delay tolerant networks;DTNs},
doi={10.1109/INFOCOM.2017.8057110},
ISSN={},
month={May},}
@INPROCEEDINGS{8057111,
author={H. Jin and L. Su and K. Nahrstedt},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={CENTURION: Incentivizing multi-requester mobile crowd sensing},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The recent proliferation of increasingly capable mobile devices has given rise to mobile crowd sensing (MCS) systems that outsource the collection of sensory data to a crowd of participating workers that carry various mobile devices. Aware of the paramount importance of effectively incentivizing participation in such systems, the research community has proposed a wide variety of incentive mechanisms. However, different from most of these existing mechanisms which assume the existence of only one data requester, we consider MCS systems with multiple data requesters, which are actually more common in practice. Specifically, our incentive mechanism is based on double auction, and is able to stimulate the participation of both data requesters and workers. In real practice, the incentive mechanism is typically not an isolated module, but interacts with the data aggregation mechanism that aggregates workers' data. For this reason, we propose CENTURION, a novel integrated framework for multi-requester MCS systems, consisting of the aforementioned incentive and data aggregation mechanism. CENTURION's incentive mechanism satisfies truthfulness, individual rationality, computational efficiency, as well as guaranteeing non-negative social welfare, and its data aggregation mechanism generates highly accurate aggregated results. The desirable properties of CENTURION are validated through both theoretical analysis and extensive simulations.},
keywords={data aggregation;mobile computing;sensor fusion;mobile crowd sensing systems;data aggregation mechanism;multirequester MCS systems;mobile devices;CENTURION incentive mechanism;multirequester mobile crowd sensing systems;sensory data collection;Sensors;Reliability;Data aggregation;Mobile communication;Conferences;Mobile handsets},
doi={10.1109/INFOCOM.2017.8057111},
ISSN={},
month={May},}
@INPROCEEDINGS{8057112,
author={C. Huang and D. Wang and S. Zhu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Where are you from: Home location profiling of crowd sensors from noisy and sparse crowdsourcing data},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Crowdsourcing has emerged as an important data collection paradigm in participatory and human-centric sensing applications. While many crowdsourcing studies focus on sensing and recovering the status of the physical world, this paper investigates the problem of profiling the crowd sensors (i.e., humans). In particular, we study the problem of accurately inferring the home locations of people from the noisy and sparse crowdsourcing data they contribute. In this study, we propose a semi-supervised framework, Where Are You From (WAYF), to accurately infer the home locations of people by explicitly exploring the localness of people and the dependency between people based on their check-in behaviors under a rigorous analytical framework. We perform extensive experiments to evaluate the performance of our scheme and compared it to the state-of-the-art techniques using three real world data traces collected from Foursquare. The results showed the effectiveness of our scheme in accurately profiling the home locations of people.},
keywords={mobile computing;sensor fusion;social networking (online);crowd sensors;home locations;noisy crowdsourcing data;sparse crowdsourcing data;Home location profiling;participatory;human-centric sensing;data collection;where are you from;WAYF;Foursquare;Urban areas;Crowdsourcing;Sensors;Social network services;Manganese;Noise measurement;Conferences;Home Location Profiling;Crowdsourcing;Location Based Social Networks (LBSN)},
doi={10.1109/INFOCOM.2017.8057112},
ISSN={},
month={May},}
@INPROCEEDINGS{8057113,
author={A. Chakraborty and M. S. Rahman and H. Gupta and S. R. Das},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={SpecSense: Crowdsensing for efficient querying of spectrum occupancy},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We describe an end-to-end platform called SpecSense to support large scale spectrum monitoring. SpecSense crowdsources spectrum monitoring to low-cost, low-power commodity SDR/embedded platforms and provides necessary analytics support in a central spectrum server. In this work, we describe SpecSense and address specific challenges related to accurately estimate spectrum occupancy on demand with low overhead. To address the accuracy question, we augment state-of-the-art spatial interpolation techniques to accommodate scenarios where RF propagation characteristics change across space. To address the overhead question, we solve the sensor selection problem to select the minimum number of spectrum sensors that can best estimate the spectrum at the requested locations.},
keywords={cognitive radio;crowdsourcing;embedded systems;interpolation;query processing;radio spectrum management;software radio;telecommunication computing;efficient querying;end-to-end platform;central spectrum server;spectrum sensors;spectrum occupancy estimation;spectrum monitoring;RF propagation characteristics;SpecSense;low-cost low-power commodity SDR;embedded platforms;spatial interpolation techniques;sensor selection problem;Interpolation;Radio frequency;Monitoring;RF signals;Crowdsourcing;Sensors;Conferences},
doi={10.1109/INFOCOM.2017.8057113},
ISSN={},
month={May},}
@INPROCEEDINGS{8057114,
author={C. Miao and L. Su and W. Jiang and Y. Li and M. Tian},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={A lightweight privacy-preserving truth discovery framework for mobile crowd sensing systems},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The recent proliferation of human-carried mobile devices has given rise to the mobile crowd sensing (MCS) systems. However, the sensory data provided by the participating workers are usually not reliable. As an efficient technique to extract truthful information from unreliable data, truth discovery has drawn significant attention. Currently, the privacy concern of the participating workers poses a major challenge on the design of truth discovery mechanisms. Although the existing mechanism can conduct truth discovery with high accuracy and strong privacy guarantee, tremendous overhead is incurred on the worker side. In this paper, we propose a novel lightweight privacy preserving truth discovery framework, L-PPTD, which is implemented by involving two non-colluding cloud platforms and adopting additively homomorphic cryptosystem. This framework not only achieves the protection of each worker's sensory data and reliability information but also introduces little overhead to the workers. In order to further reduce each worker's overhead in the scenarios where only the sensory data need to be protected, we propose another more lightweight framework named L<sup>2</sup>-PPTD. The desirable performance of the proposed frameworks is verified through extensive experiments conducted on real world MCS systems.},
keywords={cloud computing;data privacy;mobile computing;homomorphic cryptosystem;privacy concern;unreliable data;human-carried mobile devices;mobile crowd sensing systems;lightweight privacy-preserving truth discovery framework;world MCS systems;sensory data;reliability information;noncolluding cloud platforms;worker side;strong privacy guarantee;truth discovery mechanisms;participating workers;Reliability;Sensors;Cryptography;Privacy;Mobile handsets;Zinc},
doi={10.1109/INFOCOM.2017.8057114},
ISSN={},
month={May},}
@INPROCEEDINGS{8057115,
author={J. Li and Y. Zhu and J. Yu and C. Long and G. Xue and S. Qian},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Online auction for IaaS clouds: Towards elastic user demands and weighted heterogeneous VMs},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Auctions have been adopted by many major cloud providers, such as Amazon EC2. Unfortunately, only simple auctions have been implemented. Such simple auction has serious limitations, such as being unable to accept elastic user demands and having to allocate different types of VMs independently. These limitations create a big gap between the real needs of cloud users and the available services of cloud providers. In response to the limitations of the existing auction mechanisms, this paper proposes a novel online auction mechanism for IaaS clouds, with the unique features of an elastic model for inputting time-varying user demands and a unified model for requesting heterogeneous VMs together. However, several major challenges should be addressed, such as NP hardness of optimal VM allocation, time-varying user demands and potential misreports of private information of cloud users. We propose a truthful online auction mechanism for maximizing the profit of the cloud provider in IaaS clouds, which is composed of a price-based allocation rule and a payment rule. In the allocation rule, the online auction mechanism determines the number of VMs of each type to each user. In the payment rule, by introducing a marginal price function for each type of VMs, the mechanism determines how much the cloud provider should charge each cloud user. With solid theoretical analysis and trace-driven simulations, we demonstrate that our mechanism is truthful and individually rational, and has a polynomial-time complexity.},
keywords={cloud computing;computational complexity;electronic commerce;pricing;resource allocation;virtual machines;IaaS clouds;cloud provider;cloud user;marginal price function;unified model;time-varying user demands;weighted heterogeneous VM;elastic user demands;online auctions;payment rule;price-based allocation rule;Cloud computing;Resource management;Cost accounting;Servers;Computational modeling;Pricing;Upper bound;IaaS Clouds;online auctions;time-varying;elastic user demands;weighted heterogeneous VMs;profit maximization},
doi={10.1109/INFOCOM.2017.8057115},
ISSN={},
month={May},}
@INPROCEEDINGS{8057116,
author={H. Tan and Z. Han and X. Li and F. C. M. Lau},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Online job dispatching and scheduling in edge-clouds},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In edge-cloud computing, a set of edge servers are deployed near the mobile devices such that these devices can offload jobs to the servers with low latency. One fundamental and critical problem in edge-cloud systems is how to dispatch and schedule the jobs so that the job response time (defined as the interval between the release of a job and the arrival of the computation result at its device) is minimized. In this paper, we propose a general model for this problem, where the jobs are generated in arbitrary order and times at the mobile devices and offloaded to servers with both upload and download delays. Our goal is to minimize the total weighted response time over all the jobs. The weight is set based on how latency sensitive the job is. We derive the first online job dispatching and scheduling algorithm in edge-clouds, called OnDisc, which is scalable in the speed augmentation model; that is, OnDisc is (1 + ε)-speed O(1/ε)-competitive for any constant ε ϵ (0,1). Moreover, OnDisc can be easily implemented in distributed systems. Extensive simulations on a real-world data-trace from Google show that OnDisc can reduce the total weighted response time dramatically compared with heuristic algorithms.},
keywords={cloud computing;mobile computing;telecommunication scheduling;upload delays;download delays;OnDisc;speed augmentation model;distributed systems;edge servers;edge-cloud computing;scheduling algorithm;online job dispatching;total weighted response time;mobile devices;job response time;edge-cloud systems;Servers;Cloud computing;Mobile handsets;Algorithm design and analysis;Dispatching;Time factors;Mobile communication},
doi={10.1109/INFOCOM.2017.8057116},
ISSN={},
month={May},}
@INPROCEEDINGS{8057117,
author={R. Zhu and D. Niu and Z. Li},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Robust web service recommendation via quantile matrix factorization},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We study the problem of personalized Quality of Service (QoS) estimation for web services. State-of-the-art methods use matrix factorization or collaborative prediction to estimate web service response times and throughput for each user based on partial measurements collected from past invocations. We point out that in reality, both the response times and through-put of web services follow highly skewed distributions. In this case, the conditional mean QoS estimates generated by traditional matrix completion approaches can be heavily biased toward a few outliers, leading to poor web service recommendation performance. In this paper, we propose the Quantile Matrix Factorization (QMF) technique for web service recommendation by introducing quantile regression into the matrix factorization framework. We propose a novel and efficient algorithm based on Iterative Reweighted Least Squares (IRLS) to solve the QMF problem involving a non-smooth objective function. We further extend the proposed QMF approach to take into account user and service side attributes. Extensive evaluation based on a large-scale QoS dataset has shown that our schemes significantly outperform various state-of-the-art web service QoS estimation schemes in terms of personalized recommendation performance.},
keywords={iterative methods;least squares approximations;matrix decomposition;quality of service;recommender systems;regression analysis;Web services;robust web service recommendation;web service response times;Quantile Matrix Factorization technique;quantile regression;QMF problem;quality of service estimation;throughput estimation;conditional mean QoS estimation;matrix completion approaches;iterative reweighted least squares;IRLS;nonsmooth objective function;user side attribute;service side attribute;Web services;Quality of service;Time factors;Throughput;Estimation;Measurement;Collaboration},
doi={10.1109/INFOCOM.2017.8057117},
ISSN={},
month={May},}
@INPROCEEDINGS{8057118,
author={X. Zhang and C. Wu and Z. Li and F. C. M. Lau},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Proactive VNF provisioning with multi-timescale cloud resources: Fusing online learning and online optimization},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Network Function Virtualization (NFV) represents a new paradigm of network service provisioning. NFV providers acquire cloud resources, install virtual network functions (VNFs), assemble VNF service chains for customer usage, and dynamically scale VNF deployment against input traffic fluctuations. While existing literature on VNF scaling mostly adopts a reactive approach, we target a proactive approach that is more practical given the time overhead for VNF deployment. We aim to effectively estimate upcoming traffic rates and adjust VNF deployment a priori, for flow service quality assurance and resource cost minimization. We adapt online learning techniques for predicting future service chain workloads. We further combine the online learning method with a multi-timescale online optimization algorithm for VNF scaling, through minimization of the regret due to inaccurate demand prediction and minimization of the cost incurred by sub-optimal online decisions in a joint online optimization framework. The resulting proactive online VNF provisioning algorithm achieves a good performance guarantee, as shown by both theoretical analysis and simulation under realistic settings.},
keywords={cloud computing;learning (artificial intelligence);optimisation;telecommunication traffic;virtualisation;NFV;network service provisioning;input traffic fluctuations;VNF scaling;reactive approach;proactive approach;traffic rates;flow service quality assurance;resource cost minimization;online learning techniques;future service chain workloads;online learning method;sub-optimal online decisions;joint online optimization framework;multitimescale cloud resources;Network Function Virtualization;dynamically scale VNF deployment;proactive online VNF provisioning algorithm;Prediction algorithms;Algorithm design and analysis;Cloud computing;Optimization;Minimization;Hardware;Dynamic scheduling},
doi={10.1109/INFOCOM.2017.8057118},
ISSN={},
month={May},}
@INPROCEEDINGS{8057119,
author={S. Sharifian and F. Lin and R. Safavi-Naini},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Secret key agreement using a virtual wiretap channel},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Key agreement using physical layer properties of communication channels is a well studied problem. iJam is a physical layer key agreement protocol that achieves security by creating a “virtual” wiretap channel for the adversary through a subprotocol between the sender and the receiver that uses self-jamming by the receiver. The protocol was implemented and its security was shown through extensive experiments. The self-jamming subprotocol of iJam was later modelled as a wiretap channel and used for designing a secure message transmission protocol with provable security. We use the same wiretap model of the subprotocol to design secret key agreement protocols with provable security. We propose two protocols that use the wiretap channel once from Alice to Bob, and a protocol that uses two wiretap channels, one from Alice to Bob, and one in the opposite direction. We provide security proof and efficiency analysis for the protocols. The protocols effectively give physical layer security protocols that can be implemented and have provable security. We discuss our results and propose directions for future research.},
keywords={cryptographic protocols;jamming;telecommunication security;virtual wiretap channel;self-jamming subprotocol;iJam;secure message transmission protocol;provable security;wiretap model;secret key agreement protocols;security proof;physical layer security protocols;physical layer properties;communication channels;physical layer key agreement protocol;Protocols;Security;Receivers;Jamming;Random variables;Physical layer;Wireless communication},
doi={10.1109/INFOCOM.2017.8057119},
ISSN={},
month={May},}
@INPROCEEDINGS{8057120,
author={P. Wang and R. Safavi-Naini},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Interactive message transmission over adversarial wiretap channel II},
year={2017},
volume={},
number={},
pages={1-9},
abstract={In Wyner wiretap II model of communication, Alice and Bob are connected by a channel that can be eavesdropped by an adversary with unlimited computation who can select a fraction of communication to view, and the goal is to provide perfect information theoretic security. Information theoretic security is increasingly important because of the threat of quantum computers that can effectively break algorithms and protocols that are used in today's public key infrastructure. We consider interactive protocols for wiretap II channel with active adversary who can eavesdrop and add adversarial noise to the eavesdropped part of the codeword. These channels capture wireless setting where malicious eavesdroppers at reception distance of the transmitter can eavesdrop the communication and introduce jamming signal to the channel. We derive a new upperbound R ≤ 1 - ρ for the rate of interactive protocols over two-way wiretap II channel with active adversaries, and construct a perfectly secure protocol family with achievable rate 1 - 2ρ + ρ2. This is strictly higher than the rate of the best one round protocol which is 1 - 2ρ, hence showing that interaction improves rate. We also prove that even with interaction, reliable communication is possible only if ρ <; 1/2. An interesting aspect of this work is that our bounds will also hold in network setting when two nodes are connected by n paths, a ρ of which is corrupted by the adversary. We discuss our results, give their relations to the other works, and propose directions for future work.},
keywords={cryptographic protocols;jamming;telecommunication security;wireless channels;interactive message transmission;adversarial wiretap channel II;Wyner wiretap II model;perfect information theoretic security;quantum computers;public key infrastructure;interactive protocols;active adversary;adversarial noise;perfectly secure protocol family;wireless setting;two-way wiretap II channel;jamming signal;Protocols;Reliability;Security;Mobile communication;Random variables;Upper bound;Conferences},
doi={10.1109/INFOCOM.2017.8057120},
ISSN={},
month={May},}
@INPROCEEDINGS{8057121,
author={K. Jiang and T. Jing and Z. Li and Y. Huo and F. Zhang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Analysis of secrecy performance in fading multiple access wiretap channel with SIC receiver},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Recently, a new paradigm of multiple access (MAC) along with one eavesdropper to achieve secrecy transmissions has been getting in focus. However, all existing work on such multiple access wiretap channel (MAC-WT) mainly concentrates on the secrecy performance of the system as a whole from an information theoretic perspective. In this work, we investigate the secrecy performance of a single transmitter in the quasi-static Rayleigh fading MAC-WT on basis of two decoding methods, zero-forcing (ZF) and minimum mean-square error (MMSE), jointly with successive interference cancellation (SIC). We evaluate the secrecy performance in three metrics: positive secrecy capacity probability, secrecy outage probability and effective secrecy throughput. The analytical and simulation results show that, 1) the SIC order has great impacts on the secrecy performance for both methods; 2) MMSE-SIC outperforms ZF-SIC, while the performance gap can be overcome via adjusting SIC order, or increasing SNR, or enhancing the spatial diversity gain; 3) in high SNR regime, the secrecy performance is only determined by the relative distance to eavesdropper over legitimate receiver rather than the SNR.},
keywords={channel capacity;decoding;fading channels;least mean squares methods;multi-access systems;radio receivers;Rayleigh channels;telecommunication security;wireless channels;secrecy performance;multiple access wiretap channel;secrecy transmissions;quasistatic Rayleigh fading MAC-WT;positive secrecy capacity probability;secrecy outage probability;effective secrecy throughput;SIC;Decoding;Silicon carbide;Signal to noise ratio;Transmitters;Fading channels;Interference;Receivers},
doi={10.1109/INFOCOM.2017.8057121},
ISSN={},
month={May},}
@INPROCEEDINGS{8057122,
author={M. Bradbury and A. Jhumka},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Understanding source location privacy protocols in sensor networks via perturbation of time series},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Source location privacy (SLP) is becoming an important property for a large class of security-critical wireless sensor network applications such as monitoring and tracking. Much of the previous work on SLP has focused on the development of various protocols to enhance the level of SLP imparted to the network, under various attacker models and other conditions. Other work has focused on analysing the level of SLP being imparted by a specific protocol. In this paper, we adopt a different approach where we model the attacker movement as a time series and use information theoretic concepts to infer the properties of a routing protocol that imparts high levels of SLP. We propose the notion of a properly competing path that causes an attacker to “stall” when moving towards the source. This concept provides the basis for developing a perturbation model, similar to those in privacy-preserving data mining. We then show how to use properly competing paths to develop properties of an SLP-aware routing protocol. Further, we show how different SLP-aware routing protocols can be obtained through different instantiations of the framework. Those instantiations are obtained based on a notion of information loss achieved through the use of the perturbation model proposed.},
keywords={data mining;data privacy;routing protocols;telecommunication security;time series;wireless sensor networks;attacker movement;time series;information theoretic concepts;perturbation model;privacy-preserving data mining;SLP-aware routing protocol;source location privacy protocols;security-critical wireless sensor network applications;properly-competing path;Routing protocols;Privacy;Routing;Time series analysis;Wireless sensor networks;Phantoms;Source Location Privacy;Wireless Sensor Networks;Entropy;Mutual Information;Time Series},
doi={10.1109/INFOCOM.2017.8057122},
ISSN={},
month={May},}
@INPROCEEDINGS{8057123,
author={L. Zheng and C. Joe-Wong and J. Chen and C. G. Brinton and C. W. Tan and M. Chiang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Economic viability of a virtual ISP},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Growing mobile data usage has led to end users paying substantial data costs, while Internet service providers (ISPs) struggle to upgrade their networks to keep up with demand and maintain high quality-of-service (QoS). This problem is particularly severe for smaller ISPs with less capital. Instead of simply upgrading their network infrastructure, ISPs can pool their networks to provide a good QoS and attract more users. Such a vISP (virtual ISP), for example, Google's Project Fi, allows users to access any of its partner ISPs' networks. We provide the first systematic analysis of a vISP's economic impact, showing that the vISP provides a viable solution for smaller ISPs attempting to attract more users, but may not maintain a positive profit if users' data demands evolve. To do so, we consider users' decisions of whether to defect from their current ISP to the vISP, as well as ISPs' decisions on whether to partner with the vISP. We derive the vISP's dependence on user behavior and partner ISPs: users with very light or very heavy usage are the most likely to defect, while ISPs with heavy-usage customers can benefit from declining to partner with the vISP. Our analytical results are verified with extensive numerical simulations.},
keywords={Internet;microeconomics;mobile radio;quality of service;Internet service providers struggle;quality-of-service;network infrastructure;virtual ISP;current ISP;economic viability;mobile data usage;end users;QoS;ISP networks;Google Project Fi;ISP decisions;Mobile communication;Quality of service;Throughput;Economics;Wireless fidelity;Switches;Pricing},
doi={10.1109/INFOCOM.2017.8057123},
ISSN={},
month={May},}
@INPROCEEDINGS{8057124,
author={D. Mitra and Q. Wang and A. Hong},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Emerging internet content and service providers' relationships: Models and analyses of engineering, business and policy impact},
year={2017},
volume={},
number={},
pages={1-9},
abstract={We study engineering and business relationships between Content Providers and broadband access ISPs in various organizational and policy environments. We focus on pricing and capacity decisions for bandwidth and caches for delivery of the CP's content over the “last mile” of the ISP's infrastructure. We model the CP-ISP interaction by the Stackelberg “leader-follower” game and the Integrated Operations model. We consider cases where premium bandwidth is offered to subscribers of the CP's service over the last mile, and cases where this is prohibited by Net Neutrality regulations. We develop a uniform solution procedure for all four resulting models. We explore the connections between optimal bandwidth and cache deployments, and, together with fees, their impact on the number of users, and related business and policy topics. We show that the decrease in profitability of caching due to Net Neutrality regulations is greater than the decrease from Integrated Operations to the Stackelberg game. In the Stackelberg game we prove that if a certain condition is satisfied, then with Net Neutrality the ISP will increase the cache price so that it is unprofitable for the CP to use caches. Moreover, this condition is satisfied in a typical case studied in detail.},
keywords={game theory;Internet;pricing;policy impact;capacity decisions;CP-ISP interaction;Stackelberg leader-follower game;Integrated Operations model;Net Neutrality regulations;optimal bandwidth;cache deployments;cache price;Internet service providers;pricing decisions;Internet content providers;broadband access ISP;CP content;CP service;Bandwidth;Artificial neural networks;Network neutrality;Elasticity;Business;Internet},
doi={10.1109/INFOCOM.2017.8057124},
ISSN={},
month={May},}
@INPROCEEDINGS{8057125,
author={J. Z. F. Pang and H. Fu and W. I. Lee and A. Wierman},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={The efficiency of open access in platforms for networked cournot markets},
year={2017},
volume={},
number={},
pages={1-9},
abstract={This paper studies how the efficiency of an online platform is impacted by the degree to which access of platform participants is open or controlled. The study is motivated by an emerging trend within platforms to impose increasingly fine-grained control over the options available to platform participants. While early online platforms allowed open access, e.g., Ebay allows any seller to interact with any buyer; modern platforms often impose matches directly, e.g., Uber directly matches drivers to riders. This control is performed with the goal of achieving more efficient market outcomes. However, the results in this paper highlight that imposing matches may create new strategic incentives that lead to increased inefficiency. In particular, in the context of networked Cournot competition, we prove that open access platforms guarantee social welfare within 7/16 of the optimal; whereas controlled allocation platforms can have social welfare unboundedly worse than optimal.},
keywords={Internet;networked cournot markets;online platform;platform participants;fine-grained control;open access platforms;controlled allocation platforms;Open Access;Resource management;Production;Economics;Conferences;Market research;Companies},
doi={10.1109/INFOCOM.2017.8057125},
ISSN={},
month={May},}
@INPROCEEDINGS{8057126,
author={D. X. Mendes and E. de Souza e Silva and D. Menasché and R. Leão and D. Towsley},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={An experimental reality check on the scaling laws of swarming systems},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Swarming systems, such as BitTorrent, are one of the most common solutions for scalable, robust and inexpensive content distribution. Although the service capacity of swarming systems has been studied for decades through modeling and analysis, there is a lack of experimental evidence about how the throughput of such systems behaves in under-provisioned regimes. The aim of this paper is to fill this gap. In this paper, we consider a closed-loop model to assess the throughput of peer-to-peer systems. Then, we show through controlled experiments using BitTorrent clients that some analytical findings recently reported in the literature, such as the missing piece syndrome, occur in practice. In particular, we indicate that when seeds have a small effective service capacity, or when seeds are intermittent, the throughput saturates as the population size grows. Finally, we discuss the implications of such findings on the modeling and design of swarming systems.},
keywords={peer-to-peer computing;scaling laws;modeling analysis;closed-loop model;peer-to-peer systems;BitTorrent clients;content distribution;swarming systems;missing piece syndrome;Throughput;Sociology;Statistics;Analytical models;Computational modeling;Scalability;Peer-to-peer computing},
doi={10.1109/INFOCOM.2017.8057126},
ISSN={},
month={May},}
@INPROCEEDINGS{8057127,
author={C. Lin and Y. Chen and K. C. Lin and W. Chen},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={acPad: Enhancing channel utilization for 802.11ac using packet padding},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Multi-User Multiple Input Multiple Output (MU-MIMO) enables a multi-antenna access point (AP) to serve multiple users simultaneously, and has been adopted as the IEEE 802.11ac standard. While several PHY-MAC designs have recently been proposed to improve the throughput performance of a MU-MIMO WLAN, they, however, usually assume that all the concurrent streams are of roughly equal length. In reality, users usually have frames with heterogeneous lengths even after aggregation, leading to different lengths of transmission time. Hence, the concurrent transmission opportunities might not always be fully utilized when some streams finish earlier than the others in a transmission opportunity (TXOP). To resolve this inefficiency, this paper presents acPad, a PHY-MAC design that adds additional frames to fill up the idle channel time and better utilize the spatial multiplexing gain. Our acPad identifies proper users as the padding so as to improve the padding gain, while preventing this padding from harming all the ongoing streams. Our evaluation via large-scale trace-driven simulations demonstrates that acPad improves the throughput by up to 2.83×, or by 1.36× on average, as compared to the conventional 802.11ac.},
keywords={access protocols;antenna arrays;MIMO communication;multiplexing;wireless channels;wireless LAN;PHY-MAC design;acPad;channel utilization;packet padding;MultiUser Multiple Input Multiple Output;IEEE 802.11ac standard;MU-MIMO WLAN;multiantenna access point;spatial multiplexing gain;Signal to noise ratio;Interference;Precoding;Throughput;MIMO;Standards;Array signal processing},
doi={10.1109/INFOCOM.2017.8057127},
ISSN={},
month={May},}
@INPROCEEDINGS{8057128,
author={S. Kim and J. Yi and Y. Son and S. Yoo and S. Choi},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Quiet ACK: ACK transmit power control in IEEE 802.11 WLANs},
year={2017},
volume={},
number={},
pages={1-9},
abstract={With increasing demand for wireless connectivity, IEEE 802.11 WLANs have become ubiquitous and continue to grow in number. This leads to high density of basic service sets with the significant co-channel interference (CCI) among them. This paper sheds light on the CCI caused by 802.11 MAC ACK frames, which has been less studied than the CCI caused by data frames. Based on stochastic geometry analysis, we propose Quiet ACK (QACK), a dynamic transmit power control algorithm for ACK frames. Fine-grained transmit power adjustment is enabled by CCI detection and CCI power estimation in the middle of a data frame reception. Our prototype using software-defined radio shows the feasibility and performance gain of QACK, i.e., 1.5x higher throughput than the legacy 802.11 WLANs. The performance of QACK is further evaluated in more general WLAN environments via extensive simulations using ns-3.},
keywords={access protocols;cochannel interference;power control;wireless LAN;wireless connectivity;MAC ACK frames;Quiet ACK;QACK;dynamic transmit power control algorithm;fine-grained transmit power adjustment;CCI detection;data frame reception;ACK transmit power control;IEEE 802.11 WLAN;co-channel interference;software-defined radio;Interference;Power control;IEEE 802.11 Standard;Wireless LAN;Power system reliability;Probability;Heuristic algorithms},
doi={10.1109/INFOCOM.2017.8057128},
ISSN={},
month={May},}
@INPROCEEDINGS{8057129,
author={G. Lee and Y. Shin and J. Koo and J. Choi and S. Choi},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={ACT-AP: ACTivator access point for multicast over WLAN},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Multicast is a major solution in supporting the explosive growth of the wireless video traffic demand. Also, power saving is a key technology to extend battery life of mobile devices. To meet both purposes, IEEE 802.11 wireless local area network (WLAN) supports power save mode (PSM) for station (STA) while receiving multicast packets. According to recent studies, off-the-shelf chipsets configured to use PSM show un-desired functions, thus resulting in many multicast packet losses. From our extensive measurement, we also verify degradation of multicast performance with widely-used off-the-shelf chipsets using PSM, and present previously-unknown undesired functions. Without modification of the chipsets, STA in PSM cannot enjoy reliable multicast service. Given this, we develop a practical and readily-applicable AP-side solution, called ACT-AP, which avoids multicast packet losses by preventing STA from operating in PSM. Our prototype implementation with off-the-shelf chipsets demonstrates that ACT-AP improves packet delivery ratio by up to 216% with little additional protocol overhead. To our best knowledge, ACT-AP is the first practical effort to support multicast to real devices with undesired functions in PSM.},
keywords={mobile radio;multicast communication;protocols;telecommunication power management;telecommunication traffic;wireless LAN;IEEE 802.11 wireless local area network;WLAN;PSM;multicast packet losses;reliable multicast service;readily-applicable AP-side;packet delivery ratio;ACTivator access point;wireless video traffic demand;mobile devices;ACT-AP;power save mode;Power system management;Wireless LAN;Unicast;Packet loss;Semiconductor device measurement;IEEE 802.11 Standard},
doi={10.1109/INFOCOM.2017.8057129},
ISSN={},
month={May},}
@INPROCEEDINGS{8057130,
author={R. K. Sheshadri and D. Koutsonikolas},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={On packet loss rates in modern 802.11 networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The knowledge of link packet loss rates (PLRs) at different PHY layer configurations is vital for a number of wireless network optimization schemes. However, the very large number of PHY layer configurations offered by modern 802.11 n/ac networks has made probing-based PLR estimation at each available configuration extremely challenging. In this paper, we seek to answer the question “How to estimate the PLRs at each available PHY layer configuration with minimal overhead?” Our analysis of the PLR datasets collected from three 802.11 n/ac testbeds reveals that, for any given link, there are several configurations with similar PLR. However, capturing this similarity using well-known link quality indicators like RSSI, or PHY layer features such as MCS or number of MIMO streams is hard. Consequently, we explore the approach of clustering the available PHY layer configurations into a small number of clusters with similar PLR, independent of any other parameter, and only probe one representative configuration in each cluster. Using two real-world case studies - rate adaptation and multihop routing, we show that the proposed clustering-based PLR estimation helps network optimization schemes to reach optimal configurations faster leading to significant performance improvements.},
keywords={optimisation;telecommunication network routing;wireless LAN;multihop routing;rate adaptation;PHY layer configurations;PHY layer features;link quality indicators;PLR estimation;802.11 n/ac networks;link packet loss rates;MIMO;IEEE 802.11n Standard;Bit rate;Estimation;Probes},
doi={10.1109/INFOCOM.2017.8057130},
ISSN={},
month={May},}
@INPROCEEDINGS{8057131,
author={A. Marcone and M. Pierobon and M. Magarini},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={A parity check analog decoder for molecular communication based on biological circuits},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Molecular Communication (MC) is an enabling paradigm for the interconnection of future devices and networks in the biological environment, with applications ranging from bio-medicine to environmental monitoring and control. The engineering of biological circuits, which allows to manipulate the molecular information processing abilities of biological cells, is a candidate technology for the realization of MC-enabled devices. In this paper, inspired by recent studies favoring the efficiency of analog computation over digital in biological cells, an analog decoder design is proposed based on biological circuit components. In particular, this decoder computes the a-posteriori log-likelihood ratio of parity-check-encoded bits from a binary-modulated concentration of molecules. The proposed design implements the required L-value and the box-plus operations entirely in the biochemical domain by using activation and repression of gene expression, and reactions of molecular species. Each component of the circuit is designed and tuned in this paper by comparing the resulting functionality with that of the corresponding analytical expression. Despite evident differences with classical electronics, biochemical simulation data of the resulting biological circuit demonstrate very close performance in terms of Mean Squared Error (MSE) and Bit Error Rate (BER), and validate the proposed approach for the future realization of MC components.},
keywords={computational complexity;decoding;error statistics;mean square error methods;molecular communication (telecommunication);parity check codes;parity check analog decoder;molecular communication;biological circuits;biological environment;environmental monitoring;molecular information processing abilities;biological cells;analog computation;molecular species;MC components;biomedicine;a-posteriori log-likelihood ratio;binary-modulated concentration;L-value;box-plus operations;biochemical simulation data;mean squared error;MSE;bit error rate;BER;gene expression;Biological information theory;Cells (biology);Decoding;Proteins;Transmitters;Receivers;Mathematical model},
doi={10.1109/INFOCOM.2017.8057131},
ISSN={},
month={May},}
@INPROCEEDINGS{8057132,
author={S. Basagni and V. Di Valerio and P. Gjanci and C. Petrioli},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Finding MARLIN: Exploiting multi-modal communications for reliable and low-latency underwater networking},
year={2017},
volume={},
number={},
pages={1-9},
abstract={This paper concerns the smart exploitation of multimodal communication capabilities of underwater nodes to enable reliable and swift underwater networking. To contrast adverse and highly varying channel conditions we define a smart framework enabling nodes to acquire knowledge on the quality of the communication to neighboring nodes over time. Following a model-based reinforcement learning approach, our framework allows senders to select the best forwarding relay for its data jointly with the best communication device to reach that relay. We name the resulting forwarding method MARLIN, for MultimodAl Reinforcement Learning-based RoutINg. Applications can choose whether to seek reliable routes to the destination, or whether faster packet delivery is more desirable. We evaluate the performance of MARLIN in varying networking scenarios where nodes communicate through two acoustic modems with widely different characteristics. MARLIN is compared to state-of-the-art forwarding protocols, including a channel-aware solution, a machine learning-based solution and to a flooding protocol extended to use multiple modems. Our results show that a smartly learned selection of relay and modem is key to obtain a packet delivery ratio that is twice as much that of other protocols, while maintaining low latencies and energy consumption.},
keywords={learning (artificial intelligence);marine communication;modems;radio networks;routing protocols;MARLIN;forwarding method;MultimodAl Reinforcement Learning-based RoutINg;flooding protocol;multiple modems;packet delivery ratio;smartly learned selection;machine learning;channel-aware solution;state-of-the-art forwarding protocols;acoustic modems;networking scenarios;faster packet delivery;reliable routes;communication device;forwarding relay;reinforcement learning approach;neighboring nodes;smart framework;channel conditions;swift underwater networking;reliable networking;underwater nodes;multimodal communications;Modems;Reliability;Protocols;Relays;Routing;Computer network reliability;Quality of service;Underwater Wireless Sensor Networks;multimodal communications;reinforcement learning-based routing},
doi={10.1109/INFOCOM.2017.8057132},
ISSN={},
month={May},}
@INPROCEEDINGS{8057133,
author={G. E. Santagati and T. Melodia},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={An implantable low-power ultrasonic platform for the Internet of Medical Things},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Wirelessly networked systems of implantable medical devices endowed with sensors and actuators will be the basis of many innovative, sometimes revolutionary therapies. The biggest obstacle in realizing this vision of networked implantable devices is posed by the dielectric nature of the human body, which strongly attenuates radio-frequency (RF) electromagnetic waves. In this paper we present the first hardware and software architecture of an Internet of Medical Things (IoMT) platform with ultrasonic connectivity for intra-body communications that can be used as a basis for building future IoT-ready medical implantable and wearable devices. We show that ultrasonic waves can be efficiently generated and received with low-power and mm-sized components, and that despite the conversion loss introduced by ultrasonic transducers the gap in attenuation between 2.4 GHz RF and ultrasonic waves is still substantial, e.g., ultrasounds offer 70 dB less attenuation over 10 cm. We show that the proposed IoMT platform requires much lower transmission power compared to 2.4 GHz RF with equal reliability in tissues, e.g., 35 dBm lower over 12 cm for 10<sup>-3</sup> Bit Error Rate (BEr) leading to lower energy per bit and longer device lifetime. Finally, we show experimentally that 2.4 GHz RF links are not functional at all above 12 cm, while ultrasonic links achieve a reliability of 10<sup>-6</sup> up to 20 cm with less than 0 dBm transmission power.},
keywords={biomedical communication;biomedical ultrasonics;error statistics;Internet of Things;low-power electronics;prosthetics;ultrasonic transducers;low-power ultrasonic platform;wirelessly networked systems;implantable medical devices;sensors;actuators;revolutionary therapies;networked implantable devices;dielectric nature;human body;radio-frequency electromagnetic waves;software architecture;ultrasonic connectivity;wearable devices;ultrasonic waves;mm-sized components;ultrasonic transducers the gap;attenuation;IoMT platform;lower transmission power;longer device lifetime;ultrasonic links;intrabody communications;RF links;transmission power;Internet of Medical Things platform;frequency 2.4 GHz;noise figure 70.0 dB;size 10.0 cm;size 12.0 cm;size 20.0 cm;Acoustics;Radio frequency;Sensors;Implants;Hardware;Wireless communication;Field programmable gate arrays},
doi={10.1109/INFOCOM.2017.8057133},
ISSN={},
month={May},}
@INPROCEEDINGS{8057134,
author={Z. Zhang and P. Kumar},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={mEEC: A novel error estimation code with multi-dimensional feature},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Error estimation code estimates the bit error ratio of the received data bits with low overhead. It has many applications, especially in estimating the number of errors in a packet transmitted over a wireless link. In this paper, we propose a novel error estimation code, mEEC, that outperforms the existing code by more than 10%-20% depending on the packet sizes, at the same time being less biased. mEEC is mainly based on the idea of grouping multiple blocks of sampled data bits into a super-block, thus creating a multi-dimensional feature. It then compresses these features into a single number, called the color, as the coded bits. Through an intelligent coloring scheme, the blocks in a super-block share the cost of covering low probability events, which allows the decoder to recover the actual feature values from the color even in the presence of error. mEEC also adopts a lightweight redistribution step, which is guided by the solution of an optimization problem and further reduces the estimation errors and bias. We also show that mEEC can be implemented with reasonable storage sizes and low time complexity.},
keywords={error correction codes;estimation theory;mEEC;estimation errors;multidimensional feature;bit error ratio;coded bits;data bits;error estimation code;Conferences},
doi={10.1109/INFOCOM.2017.8057134},
ISSN={},
month={May},}
@INPROCEEDINGS{8057135,
author={H. Pan and G. Xie and Z. Li and P. He and L. Mathy},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={FlowConvertor: Enabling portability of SDN applications},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Software-Defined Networking (SDN) provides network administrators opportunities to control network devices more simply and easily than in traditional networking. However, heterogeneity in switch hardware, especially in forwarding pipeline architecture, renders the task of network application developers and network administrators tedious, by hampering portability across switch models. In this paper, we propose FlowConvertor, an algorithm capable of converting rules from any forwarding pipeline to any other different forwarding pipeline, as long as both pipelines offer compatible operations. More precisely, FlowConvertor is an online algorithm that operates on flow updates issued to the origin pipeline and computes the corresponding updates for the target pipeline in real time. Performance evaluation shows that the latency introduced by FlowConvertor on the path between the SDN controller and the target switch is of the order of 1ms in most cases, and is thus acceptable for practical deployment.},
keywords={computer network management;pipelines;software defined networking;forwarding pipeline architecture;switch hardware;traditional networking;network devices;network administrators opportunities;Software-Defined Networking;SDN applications;target switch;SDN controller;target pipeline;origin pipeline;flow updates;online algorithm;FlowConvertor;switch models;network application developers;time 1.0 ms;Switches;Pipelines;Metadata;Pipeline processing;Hardware;Engines;Ports (Computers)},
doi={10.1109/INFOCOM.2017.8057135},
ISSN={},
month={May},}
@INPROCEEDINGS{8057136,
author={K. Poularakis and G. Iosifidis and G. Smaragdakis and L. Tassiulas},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={One step at a time: Optimizing SDN upgrades in ISP networks},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Nowadays, there is a fast-paced shift from legacy telecommunication systems to novel Software Defined Network (SDN) architectures that can support on-the-fly network reconfiguration, therefore, empowering advanced traffic engineering mechanisms. Despite this momentum, migration to SDN cannot be realized at once especially in high-end cost networks of Internet Service Providers (ISPs). It is expected that ISPs will gradually upgrade their networks to SDN over a period that spans several years. In this paper, we study the SDN upgrading problem in an ISP network: which nodes to upgrade and when. We consider a general model that captures different migration costs and network topologies, and two plausible ISP objectives; first, the maximization of the traffic that traverses at least one SDN node, and second, the maximization of the number of dynamically selectable routing paths enabled by SDN nodes. We leverage the theory of submodular and supermodular functions to devise algorithms with provable approximation ratios for each objective. Using real-world network topologies and traffic matrices, we evaluate the performance of our algorithms and show up to 54% gains over state-of-the-art methods. Moreover, we describe the interplay between the two objectives; maximizing one may cause a factor of 2 loss to the other.},
keywords={Internet;optimisation;software defined networking;telecommunication network routing;telecommunication network topology;telecommunication traffic;ISP network;Software Defined Network architectures;on-the-fly network reconfiguration;advanced traffic engineering mechanisms;Internet Service Providers;telecommunication systems;network topologies;traffic maximization;Approximation algorithms;Routing;Network topology;Routing protocols;Conferences;Optimization},
doi={10.1109/INFOCOM.2017.8057136},
ISSN={},
month={May},}
@INPROCEEDINGS{8057137,
author={H. Wang and A. Srivastava and L. Xu and S. Hong and G. Gu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Bring your own controller: Enabling tenant-defined SDN apps in IaaS clouds},
year={2017},
volume={},
number={},
pages={1-9},
abstract={The need of customized network functions for enterprises in Infrastructure-as-a-Service (IaaS) clouds is emerging. However, existing network functions in IaaS clouds are very limited, inflexible, and hard to control by the tenants. Recently, the introduction of Software-Defined Networking (SDN) technology brings the hope of flexible control of network flows and creation of diverse network functions. Unfortunately, enterprises lose access to the SDN controller when they move to clouds. Moreover, the cloud SDN controller is only managed by the provider administrators for security and performance reasons. To allow enterprise tenants to develop and deploy their own SDN apps in the cloud, in this paper, we introduce a new cloud usage paradigm: Bring Your Own Controller (BYOC). BYOC offers each tenant an individual SDN controller, where tenants can deploy SDN apps to manage their network. To manage these tenant SDN controllers, we propose BYOC-Visor, a new SDN-based virtualization platform. BYOC-VISOR addresses several security and performance challenges which are specific to IaaS clouds. We show that BYOC-Visor supports different controller platforms and diverse SDN security applications such as firewall, IDS, and access control. We implement a prototype system and the performance evaluation results show that our system has low overhead.},
keywords={Bring Your Own Device;cloud computing;computer network management;computer network security;software defined networking;virtualisation;IaaS clouds;customized network functions;Software-Defined Networking technology;diverse network functions;cloud SDN controller;enterprise tenants;cloud usage paradigm;individual SDN controller;tenant SDN controllers;BYOC-Visor;diverse SDN security applications;tenant-defined SDN apps;infrastructure-as-a-service clouds;flexible network flow control;Bring Your Own Controller;BYOC;network management;SDN-based virtualization platform;prototype system;performance evaluation;BYOC;Cloud computing;Topology;Network topology;Security;Control systems;Virtualization;Prototypes},
doi={10.1109/INFOCOM.2017.8057137},
ISSN={},
month={May},}
@INPROCEEDINGS{8057138,
author={H. Mekky and F. Hao and S. Mukherjee and T. V. Lakshman and Z. Zhang},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Network function virtualization enablement within SDN data plane},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Software Defined Networking (SDN) can benefit a Network Function Virtualization solution by chaining a set of network functions (NF) to create a network service. Currently, control on NFs is isolated from the SDN, which creates routing inflexibility, flow imbalance and choke points in the network as the controller remains oblivious to the number, capacity and placement of NFs. Moreover, a NF may modify packets in the middle, which makes flow identification at a SDN switch challenging. In this paper, we postulate native NFs within the SDN data plane, where the same logical controller controls both network services and routing. This is enabled by extending SDN to support stateful flow handling based on higher layers in the packet beyond layers 2-4. As a result, NF instances can be chained on demand, directly on the data plane. We present an implementation of this architecture based on Open vSwitch, and show that it enables popular NFs effectively using detailed evaluation and comparison with other alternative solutions.},
keywords={computer networks;software defined networking;virtualisation;SDN data plane;logical controller;network services;Software Defined Networking;network functions;network service;routing inflexibility;flow imbalance;flow identification;network function virtualization;SDN switch;Switches;Noise measurement;Kernel;Routing;Inductors},
doi={10.1109/INFOCOM.2017.8057138},
ISSN={},
month={May},}
@INPROCEEDINGS{8057139,
author={C. Q. Wu},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={Bandwidth scheduling in overlay networks with linear capacity constraints},
year={2017},
volume={},
number={},
pages={1-9},
abstract={An increasing number of high-performance networks are built over the existing IP network infrastructure to provision dedicated channels for big data transfer. The links in these overlay networks correspond to underlying paths and may share lower-level link segments. We consider a model of overlay networks that incorporates correlated link capacities and linear capacity constraints (LCCs) to formulate such shared bottleneck components. The overlay links are typically shared by multiple users through advance reservations, resulting in varying bandwidth availability in future time. Therefore, efficient bandwidth scheduling algorithms are needed to improve the network resource utilization and also meet the user's transport requirements. We investigate two advance scheduling problems in overlay networks with LCCs: Fixed-Bandwidth Path and Varying-Bandwidth Path, with the objective to minimize the data transfer end time for a given data size. We prove that both problems are NP-complete and non-approximable, and propose heuristic algorithms using a gradual relaxation procedure on the maximum number of links from each LCC allowed for path computation. The performance superiority of these heuristics is verified by extensive simulation results in comparison with optimal and greedy strategies.},
keywords={Big Data;computational complexity;data communication;greedy algorithms;IP networks;minimisation;overlay networks;telecommunication channels;telecommunication links;telecommunication scheduling;overlay networks;linear capacity constraints;high-performance networks;lower-level link segments;link capacities;overlay links;network resource utilization;advance scheduling problems;Fixed-Bandwidth Path;Varying-Bandwidth Path;IP network infrastructure;bandwidth scheduling algorithms;Big Data transfer;LCC;data transfer end time minimisation;NP-complete;heuristic algorithms;gradual relaxation procedure;greedy strategy;Bandwidth;Overlay networks;Scheduling;Processor scheduling;IP networks;Data transfer;Approximation algorithms;bandwidth scheduling;overlay networks;approximate algorithm},
doi={10.1109/INFOCOM.2017.8057139},
ISSN={},
month={May},}
@INPROCEEDINGS{8057140,
author={P. Rahimzadeh and C. Joe-Wong and K. Shin and Y. Im and J. Lee and S. Ha},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications},
title={SVC-TChain: Incentivizing good behavior in layered P2P video streaming},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Video streaming applications based on Peer-to-Peer (P2P) systems are popular for their scalability, which is hard to achieve with traditional client-server approaches. In particular, layered video streaming has been much-studied due to its ability to differentiate users' streaming qualities in heterogeneous user environments. Previous work, however, has shown that user misbehavior (e.g., free-riding and protocol deviation) poses a serious threat to P2P systems that are not equipped with proper incentive mechanisms. We propose a method to disincentivize such misbehavior. Our SVC-TChain is a layered P2P video streaming method based on scalable video coding (SVC), which uses the recently proposed T-Chain incentive mechanism to discourage free-riding. After introducing T-Chain, we present the first analytical framework to study SVC piece selection with multiple video layers, using it to efficiently choose SVC-TChain's optimal piece selection parameters and thus discourage deviations from the piece selection policy. Extensive experimental results show that SVC-TChain outperforms layered extensions of BiTos and Give-to-Get, two popular P2P video streaming approaches, both in the absence of user misbehavior and when some users misbehave.},
keywords={peer-to-peer computing;video coding;video streaming;layered P2P video streaming method;scalable video coding;free-riding;SVC piece selection;multiple video layers;piece selection policy;user misbehavior;video streaming applications;Peer-to-Peer systems;traditional client-server approaches;particular video streaming;layered video streaming;heterogeneous user environments;protocol deviation;incentive mechanisms;T-Chain incentive mechanism;P2P video streaming approaches;Streaming media;Static VAr compensators;Video coding;Peer-to-peer computing;Standards;Encryption},
doi={10.1109/INFOCOM.2017.8057140},
ISSN={},
month={May},}

