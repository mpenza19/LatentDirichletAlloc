@INPROCEEDINGS{1498511,
author={C. Gkantsidis and P. R. Rodriguez},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Network coding for large scale content distribution},
year={2005},
volume={4},
number={},
pages={2235-2245 vol. 4},
abstract={We propose a new scheme for content distribution of large files that is based on network coding. With network coding, each node of the distribution network is able to generate and transmit encoded blocks of information. The randomization introduced by the coding process eases the scheduling of block propagation, and, thus, makes the distribution more efficient. This is particularly important in large unstructured overlay networks, where the nodes need to make block forwarding decisions based on local information only. We compare network coding to other schemes that transmit unencoded information (i.e. blocks of the original file) and, also, to schemes in which only the source is allowed to generate and transmit encoded packets. We study the performance of network coding in heterogeneous networks with dynamic node arrival and departure patterns, clustered topologies, and when incentive mechanisms to discourage free-riding are in place. We demonstrate through simulations of scenarios of practical interest that the expected file download time improves by more than 20-30% with network coding compared to coding at the server only and, by more than 2-3 times compared to sending unencoded information. Moreover, we show that network coding improves the robustness of the system and is able to smoothly handle extreme situations where the server and nodes leave the system.},
keywords={content management;pattern clustering;telecommunication network topology;Internet;scheduling;encoding;network coding;content distribution network;encoded information transmission;block propagation;unstructured overlay network;block forwarding decision;heterogeneous network;dynamic node arrival;pattern departure;clustered topology;incentive mechanism;Network coding;Large-scale systems;Peer to peer computing;File servers;Network servers;Network topology;Web server;Bandwidth;Educational institutions;Distributed computing},
doi={10.1109/INFCOM.2005.1498511},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498512,
author={S. Ganguly and A. Saxena and S. Bhatnagar and R. Izmailov and S. Banerjee},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Fast replication in content distribution overlays},
year={2005},
volume={4},
number={},
pages={2246-2256 vol. 4},
abstract={We present SPIDER-a system for fast replication or distribution of large content from a single source to multiple sites interconnected over Internet or via a private network. In order to exploit spatial diversity of the underlying network, SPIDER uses an overlay structure composed of dedicated transit nodes (TNs). The data transport mechanism in SPIDER leverages this overlay structure to provide a coordinated approach that minimizes the maximum time to replicate to all destination sites (the make span of content replication). In order to achieve this objective, SPIDER employs two orthogonal components: a) creation of multiple dynamic distribution trees using the transit nodes b) end-to-end reliable data transport with flow control on these trees by chaining point-to-point TCPs. We further present simulations based results to quantify benefits of tree construction algorithms in random topologies. We evaluate the real implementation of the SPIDER in Planet Lab and observe a 2-6 times speed up compared to different existing schemes.},
keywords={replicated databases;content management;Internet;telecommunication congestion control;transport protocols;telecommunication network topology;trees (mathematics);information dissemination;computer network reliability;fast replication;content distribution overlay network;SPIDER;multiple sites interconnection;Internet;spatial diversity;transit node;TN;data transport mechanism;multiple dynamic distribution tree;flow control;point-to-point TCP;tree construction algorithm;random topology;Planet Lab;Motion pictures;Peer to peer computing;Internet;Web server;Application software;Intelligent networks;National electric code;Laboratories;IP networks;Topology},
doi={10.1109/INFCOM.2005.1498512},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498513,
author={M. Dai and D. Loguinov},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Analysis and modeling of MPEG-4 and H.264 multi-layer video traffic},
year={2005},
volume={4},
number={},
pages={2257-2267 vol. 4},
abstract={This paper presents a frame-level hybrid framework for modeling H.264 and MPEG-4 multi-layer variable bit rate (VBR) video traffic. In this work, the base layer is modeled using a combination of wavelet and time-domain methods and the enhancement layer is linearly predicted from the base layer using the cross-layer correlation. Unlike previous studies, we analyze and successfully model both inter-GOP and intra-GOP correlation in VBR sequences. To accurately capture long-range dependent (LRD) and short-range dependent (SRD) properties of VBR traffic, we use wavelets to model the distribution of I-frame sizes and a simple time-domain model for P/B frame sizes. Simulation results demonstrate that our model effectively preserves the temporal burstiness and captures important statistical features (e.g., the autocorrelation function and the frame-size distribution) of original traffic. We also show that our model has better performance than the previous methods in both single and multi-layer sequences.},
keywords={video coding;code standards;telecommunication standards;linear predictive coding;error statistics;wavelet transforms;correlation theory;sequences;time-domain analysis;MPEG-4;H.264 multilayer video traffic;variable bit rate;VBR sequence;wavelet transform;time-domain method;linear prediction;cross-layer correlation;group of pictures;inter-GOP;intra-GOP;long-range dependent;LRD;short-range dependent;SRD;I-frame size;P-B frame size;enhancement layer;MPEG 4 Standard;Traffic control;Telecommunication traffic;Video sequences;Predictive models;Time domain analysis;Streaming media;Quality of service;Bit rate;Autocorrelation},
doi={10.1109/INFCOM.2005.1498513},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498514,
author={S. Tao and K. Xu and A. Estepa and T. F. L. Gao and R. Guerin and J. Kurose and D. Towsley and Z. -. Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Improving VoIP quality through path switching},
year={2005},
volume={4},
number={},
pages={2268-2278 vol. 4},
abstract={The current best-effort Internet cannot readily provide the service guarantees that VoIP applications often require. Path switching can potentially address this problem without requiring new network mechanisms, simply by leveraging the robustness to performance variations available from connectivity options such as multi-homing and overlays. In this paper, we evaluate the effectiveness and benefits of path switching in improving the quality of VoIP applications, and demonstrate its feasibility through the design and implementation of a prototype gateway. We argue for an application-driven path switching system that accounts for both network path characteristics and application-specific factors (e.g., codec algorithms, playout buffering schemes). We also develop an application path quality estimator based on the ITU-T E-model for voice quality assessment, and an application-driven path switching algorithm that dynamically adapts the time scales over which path switching decisions are made to maximize voice quality. Through network emulation and experiments over a wide-area multi-homed test bed, we show that, with sufficient path diversity, path switching can yield meaningful improvements in voice quality. Hence by exploiting the inherent path diversity of the Internet, application-driven path switching is a viable option in providing quality-of-service to applications.},
keywords={Internet telephony;internetworking;network servers;telecommunication switching;quality of service;wide area networks;diversity reception;VoIP quality;application-driven path switching;Internet;gateway prototype;application-driven path switching system;application path quality estimator;ITU-T E-model;voice quality assessment;wide-area multihomed test bed;path diversity;quality-of-service;Web and internet services;Robustness;Prototypes;Switching systems;Codecs;Quality assessment;Heuristic algorithms;Emulation;Testing;Quality of service},
doi={10.1109/INFCOM.2005.1498514},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498515,
author={S. Ray and W. Lai and I. C. Paschalidis},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Deployment optimization of sensornet-based stochastic location-detection systems},
year={2005},
volume={4},
number={},
pages={2279-2289 vol. 4},
abstract={We propose a systematic framework for designing a stochastic indoor location detection system with associated performance guarantees using a hierarchical wireless sensor network. To detect the location of a mobile sensor, we rely on RF-characteristics of the signal transmitted by the mobile sensor, as it is received by the clusterheads. The problem of location detection is posed as a hypothesis testing problem over a discretized space. We leverage large deviations and decision theory results to characterize the probability of error and use this characterization to optimally place clusterheads. The placement problem is NP-hard and we formulate it as a linear integer programming problem. We leverage special-purpose algorithms from the theory of discrete facility location to solve large problem instances efficiently. For the resultant placement we provide asymptotic guarantees on the probability of error in location detection under quite general conditions. Numerical and simulation results show that our proposed framework is computationally feasible and the resultant clusterhead placement performs near-optimum even with a small number of observation samples.},
keywords={wireless sensor networks;computational complexity;linear programming;integer programming;decision theory;sensor fusion;mobile computing;indoor radio;mobile sensornet optimization;stochastic indoor location-detection system;wireless sensor network;RF-characteristics;resultant clusterhead platform;hypothesis testing problem;discretized space;decision theory;error probability;NP-hard problem;linear integer programming problem;Stochastic systems;Wireless sensor networks;Sensor phenomena and characterization;Systems engineering and theory;Design engineering;Intelligent sensors;Global Positioning System;Wireless LAN;Sensor systems;Computer aided manufacturing},
doi={10.1109/INFCOM.2005.1498515},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498516,
author={S. Toumpis and L. Tassiulas},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Packetostatics: deployment of massively dense sensor networks as an electrostatics problem},
year={2005},
volume={4},
number={},
pages={2290-2301 vol. 4},
abstract={We investigate the spatial distribution of wireless nodes that can transport a given volume of traffic in a sensor network, while requiring the minimum number of wireless nodes. The traffic is created at a spatially distributed set of sources, and must arrive at a spatially distributed set of sinks. Under a general assumption on the physical and medium access control (MAC) layers, the optimal distribution of nodes induces a traffic flow identical to the electrostatic field that would exist if the sources and sinks of traffic were substituted with an appropriate distribution of electric charge. This analogy between electrostatics and wireless sensor networks can be extended in a number of different ways. For example, Thomson's theorem on the distribution of electric charge on conductors gives the optimal distribution of traffic sources and sinks (that minimizes the number of nodes needed) when we have a limited degree of freedom on their initial placement. Electrostatics problems with Neumann boundary conditions and topologies with different types of dielectric materials can also be interpreted in the context of wireless sensor networks. The analogy also has important limitations. For example, if we move to a three dimensional topology, adapting our general assumption on the physical and MAC layers accordingly, or we stay in the two dimensional plane but use an alternative assumption, that is more suited to ultra wide band communication, the optimal traffic distribution is not in general irrotational, and so can not be interpreted as an electrostatic field. Finally, the analogy cannot be extended to include networks that support more than one type of traffic.},
keywords={wireless sensor networks;electric fields;electric charge;ultra wideband communication;telecommunication traffic;dielectric materials;access protocols;optimisation;boundary-value problems;ad hoc networks;packetostatics;massively dense sensor network;electrostatics field;spatial distribution;network traffic flow;medium access control;MAC layer;optimal distribution;electric charge;Neumann boundary condition;dielectric material;ultra wide band communication;Thomson theorem;wireless ad hoc network;Electrostatics;Wireless sensor networks;Communication system traffic control;Telecommunication traffic;Network topology;Media Access Protocol;Conducting materials;Boundary conditions;Dielectric materials;Ultra wideband communication},
doi={10.1109/INFCOM.2005.1498516},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498517,
author={G. Wang and G. Cao and T. La Porta and W. Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Sensor relocation in mobile sensor networks},
year={2005},
volume={4},
number={},
pages={2302-2312 vol. 4},
abstract={Recently there has been a great deal of research on using mobility in sensor networks to assist in the initial deployment of nodes. Mobile sensors are useful in this environment because they can move to locations that meet sensing coverage requirements. This paper explores the motion capability to relocate sensors to deal with sensor failure or respond to new events. We define the problem of sensor relocation and propose a two-phase sensor relocation solution: redundant sensors are first identified and then relocated to the target location. We propose a Grid-Quorum solution to quickly locate the closest redundant sensor with low message complexity, and propose to use cascaded movement to relocate the redundant sensor in a timely, efficient and balanced way. Simulation results verify that the proposed solution outperforms others in terms of relocation time, total energy consumption, and minimum remaining energy.},
keywords={wireless sensor networks;energy conservation;communication complexity;redundancy;mobile communication;mobile sensor network;two-phase sensor relocation solution;Grid-Quorum solution;redundant sensor;message complexity;Intelligent networks;Sensor phenomena and characterization;Costs;Intelligent sensors;Energy consumption;Delay;Network topology;Computer science;Surveillance;Smart homes},
doi={10.1109/INFCOM.2005.1498517},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498518,
author={J. Wu and S. Yang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={SMART: a scan-based movement-assisted sensor deployment method in wireless sensor networks},
year={2005},
volume={4},
number={},
pages={2313-2324 vol. 4},
abstract={The efficiency of sensor networks depends on the coverage of the monitoring area. Although in general a sufficient number of sensors are used to ensure a certain degree of redundancy in coverage so that sensors can rotate between active and sleep modes, a good sensor deployment is still necessary to balance the workload of sensors. In a sensor network with locomotion facilities, sensors can move around to self-deploy. The movement-assisted sensor deployment deals with moving sensors from an initial unbalanced state to a balanced state. Therefore, various optimization problems can be defined to minimize different parameters, including total moving distance, total number of moves, communication/computation cost, and convergence rate. In this paper, we propose a Scan-based Movement-Assisted sensoR deploymenT method (SMART) that uses scan and dimension exchange to achieve a balanced state. SMART also addresses a unique problem called communication holes in sensor networks. Using the concept of load balancing, SMART achieves good performance especially when applied to uneven distribution sensor networks, and can be a complement to the existing sensor deployment methods. Extensive simulation has been done to verify the effectiveness of the proposed scheme.},
keywords={wireless sensor networks;resource allocation;monitoring;scan-based movement-assisted sensor deployment;SMART method;wireless sensor network;monitoring area;workload balance;locomotion facility;communication hole;uneven distribution sensor network;Wireless sensor networks;Intelligent sensors;Intelligent networks;Force sensors;Cost function;Convergence;Load management;Condition monitoring;Parallel processing;Computer science},
doi={10.1109/INFCOM.2005.1498518},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498519,
author={S. Mao and S. S. Panwar and Y. T. Hou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On optimal partitioning of realtime traffic over multiple paths},
year={2005},
volume={4},
number={},
pages={2325-2336 vol. 4},
abstract={Multipath transport provides higher usable bandwidth for a session. It has also been shown to provide load balancing and error resilience for end-to-end multimedia sessions. Two key issues in the use of multiple paths are (1) how to minimize the end-to-end delay, which now includes the delay along the paths and the resequencing delay at the receiver, and (2) how to select paths. In this paper, we present an analytical framework for the optimal partitioning of realtime multimedia traffic that minimizes the total end-to-end delay. Specifically, we formulate optimal traffic partitioning as a constrained optimization problem using deterministic network calculus, and derive its closed form solution. Compared with previous work, our scheme is simpler to implement and enforce. This analysis also greatly simplifies the solution to the path selection problem as compared to previous efforts. Analytical results show that for a given flow and a set of paths, we can choose a minimal subset to achieve the minimum end-to-end delay with O(N) time, where N is the number of available paths. The selected path set is optimal in the sense that adding any rejected path to the set will only increase the end-to-end delay.},
keywords={real-time systems;optimisation;resource allocation;telecommunication traffic;calculus;multimedia communication;delays;optimal partitioning;realtime traffic;multiple paths transport;load balancing;error resilience;end-to-end delay;multimedia session;constrained optimization problem;deterministic network calculus;closed form solution;Delay;Telecommunication traffic;Routing;Forward error correction;Decoding;Computer errors;Resilience;Constraint optimization;Calculus;Closed-form solution},
doi={10.1109/INFCOM.2005.1498519},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498520,
author={J. Chandrashekar and Z. Duan and Z. -. Zhang and J. Krasky},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Limiting path exploration in BGP},
year={2005},
volume={4},
number={},
pages={2337-2348 vol. 4},
abstract={Slow convergence in the Internet can be directly attributed to the "path exploration" phenomenon, inherent in all path vector protocols. The root cause for path exploration is the dependency among paths propagated through the network. Addressing this problem in BGP is particularly difficult as the AS paths exchanged between BGP routers are highly summarized. In this paper, we describe why path exploration cannot be countered effectively within the existing BGP framework, and propose a simple, novel mechanism - forward edge sequence numbers - to annotate the AS paths with additional "path dependency" information. We then develop an enhanced path vector algorithm, EPIC, shown to limit path exploration and lead to faster convergence. In contrast to other solutions, ours is shown to be correct on a very general model of Internet topology and BGP operation. Using theoretical analysis and simulations, we demonstrate that EPIC can achieve a dramatic improvement in routing convergence, compared to BGP and other existing solutions.},
keywords={network servers;internetworking;telecommunication network topology;routing protocols;Internet;limiting path exploration;BGP router;slow convergence;Internet topology;path vector protocol;paths propagation;AS path;path dependency information;EPIC;forward edge sequence number;Routing protocols;Internet;Convergence;Computer science;Topology;Analytical models;Delay effects;Streaming media;Damping},
doi={10.1109/INFCOM.2005.1498520},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498521,
author={V. Tabatabaee and B. Bhattacharjee and R. J. La and M. A. Shayman},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Differentiated traffic engineering for QoS provisioning},
year={2005},
volume={4},
number={},
pages={2349-2359 vol. 4},
abstract={We introduce a new approach for QoS provisioning in packet networks based on the notion of differentiated traffic engineering (DTE). We consider a single AS network capable of source based multi-path routing. We do not require sophisticated queuing or per-class scheduling at individual routers; instead, if a link is used to forward QoS sensitive packets, we maintain its utilization below a threshold. As a consequence, DTE eliminates the need for per-flow (IntServ) or per-class (DiffServ) packet processing tasks such as traffic classification, queueing, shaping, policing and scheduling in the core and hence poses a lower burden on the network management unit. Conversely, DTE utilizes network bandwidth much more efficiently than simple over-provisioning. In this paper, we propose a complete architecture and an algorithmic structure for DTE. We show that our scheme can be formulated as a non-convex optimization problem, and we present an optimal solution framework based on simulated annealing. We present a simulation-based performance evaluation of DTE, and compare our scheme to existing (gradient projection) methods.},
keywords={quality of service;telecommunication network routing;telecommunication traffic;telecommunication links;optimisation;performance evaluation;DiffServ networks;computer network management;QoS provisioning;quality of service;packet networks;differentiated traffic engineering;DTE;source based multipath routing;network link;nonconvex optimization problem;simulation-based performance evaluation;network management;Traffic control;Telecommunication traffic;Diffserv networks;Bandwidth;Tellurium;Computer architecture;Communication system traffic control;Educational institutions;Maintenance engineering;Routing},
doi={10.1109/INFCOM.2005.1498521},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498522,
author={H. Wang and H. Xie and L. Qiu and A. Silberschatz and Y. R. Yang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Optimal ISP subscription for Internet multihoming: algorithm design and implication analysis},
year={2005},
volume={4},
number={},
pages={2360-2371 vol. 4},
abstract={Multihoming is a popular method used by large enterprises and stub ISPs to connect to the Internet to reduce cost and improve performance. Recently researchers have studied the potential benefits of multihoming and proposed protocols and algorithms to realize these benefits. They focus on how to dynamically select which ISPs to use for forwarding and receiving packets, and assume that the set of subscribed ISPs is given a priori. In practice, a user often has the freedom to choose which subset of ISPs among all available ISPs to subscribe to. We call the problem of how to choose the optimal set of ISPs the ISP subscription problem. In this paper, We design a dynamic programming algorithm to solve the ISP subscription problem optimally. We also design a more efficient algorithm for a large class of common pricing functions. Using real traffic traces and realistic pricing data, we show that our algorithm reduces users' cost. Next we study how ISPs respond to users' optimal ISP subscription by adjusting their pricing strategies. We call this problem the ISP pricing problem. Using a realistic charging model, we formulate the problem as a non-cooperative game. We first prove that if cost is the only criterion used by a user to determine which subset of ISPs to subscribe to, at any equilibrium all ISPs receive zero revenue. We then study a more practical formulation in which different ISPs provide different levels of reliability and users choose ISPs to both improve reliability and reduce cost. We analyze this problem and show that at any equilibrium an ISP's revenue is positive and determined by its reliability.},
keywords={Internet;telecommunication services;computer network reliability;dynamic programming;telecommunication traffic;transport protocols;subscriber loops;multihoming method;stub ISP;Internet service provider;protocol;forwarding-receiving packet;dynamic programming algorithm;subscription problem;pricing function;traffic traces;reliability;Algorithm design and analysis;Subscriptions;Internet;Pricing;Routing;Dynamic programming;Heuristic algorithms;Cost function;Computer science;Protocols},
doi={10.1109/INFCOM.2005.1498522},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498523,
author={W. Feng and E. Kaiser and A. Luu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Design and implementation of network puzzles},
year={2005},
volume={4},
number={},
pages={2372-2382 vol. 4},
abstract={Client puzzles have been proposed in a number of protocols as a mechanism for mitigating the effects of distributed denial of service (DDoS) attacks. In order to provide protection against simultaneous attacks across a wide range of applications and protocols, however, such puzzles must be placed at a layer common to all of them; the network layer. Placing puzzles at the IP layer fundamentally changes the service paradigm of the Internet, allowing any device within the network to push load back onto those it is servicing. An advantage of network layer puzzles over previous puzzle mechanisms is that they can be applied to all traffic from malicious clients, making it possible to defend against arbitrary attacks as well as making previously voluntary mechanisms mandatory. In this paper, we outline goals which must be met for puzzles to be deployed effectively at the network layer. We then describe the design, implementation, and evaluation of a system that meets these goals by supporting efficient, fine-grained control of puzzles at the network layer. In particular, we describe modifications to existing puzzle protocols that allow them to work at the network layer, a hint-based hash-reversal puzzle that allows for the generation and verification of fine-grained puzzles at line speed in the fast path of high-speed routers, and an iptables implementation that supports transparent deployment at arbitrary locations in the network.},
keywords={Internet;IP networks;telecommunication traffic;cryptography;routing protocols;client puzzles;protocols;distributed denial of service attack;DDoS;IP layer;Internet;network traffic;network layer;hint-based hash-reversal puzzle;fine-grained puzzle;high-speed routers;arbitrary location;Protocols;Computer crime;Protection;Communication system traffic control;IP networks;Filtering;Web and internet services;Telecommunication traffic;Control systems;Viruses (medical)},
doi={10.1109/INFCOM.2005.1498523},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498524,
author={P. Key and L. Massoulie and M. Vojnovic},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Farsighted users harness network time-diversity},
year={2005},
volume={4},
number={},
pages={2383-2394 vol. 4},
abstract={Fluctuations in network conditions are a common phenomenon. They arise in the current wired Internet due to changes in demand, and in wireless networks due to changing interference patterns. However, current congestion control design typically does not account for this, and in this sense the majority of congestion controllers proposed so far can be deemed as "myopic". The present work deals with the following question: how should network end-users exploit such temporal fluctuations? We introduce a formal framework, in which time diversity is explicitly described by phases in network condition. We propose as bandwidth allocation criterion the solution to an optimization problem, which features both classical (myopic) users and so-called farsighted users. We identify the corresponding farsighted user strategy as that maximizing throughput subject to a social norm related to TCP-friendliness. We establish basic desirable properties of the resulting allocations. We propose adaptive decentralized algorithms for farsighted users to achieve their target allocation. The algorithms do not require either explicit knowledge of dynamics in network conditions, or special feedback from the network.},
keywords={Internet;telecommunication congestion control;diversity reception;optimisation;transport protocols;radiofrequency interference;bandwidth allocation;wired Internet;wireless network;interference pattern;congestion control design;myopic;time diversity;bandwidth allocation criterion;optimization problem;maximization;TCP;transmission control protocol;adaptive decentralized algorithm;Fluctuations;Throughput;Microeconomics;Interference;Internet;Costs;IP networks;Wireless networks;Control design;Channel allocation},
doi={10.1109/INFCOM.2005.1498524},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498525,
author={M. Kodialam and T. V. Lakshman and S. Sengupta},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Configuring networks with content filtering nodes with applications to network security},
year={2005},
volume={4},
number={},
pages={2395-2404 vol. 4},
abstract={With the rapid increase in the frequency of worm attacks, there has been significant interest in developing network based mechanisms that slow or contain worm propagation. One suggested network-based approach is the use of special content filtering nodes that examine the complete content of each packet and block traffic that contain strings matching a pre-specified set of worm signatures. To be effective, containment systems need to have fast reaction times (content filtering with the appropriate signatures must be activated very soon after the start of an attack) and need to be comprehensive in the sense that every packet routed through the network must be examined at least once. Since network-based content filtering is expensive, it is desirable to make the best use of deployable content filtering capability. This requires intelligent placement of the content filtering nodes in the network and use of appropriate network routing to maximize the carried traffic. In this paper, we study the impact of the content filtering requirement on network capacity. First, we develop an intelligent heuristic for deployment of content filtering nodes in the network. Next, given a set of deployed content filtering nodes, we develop a fully polynomial time approximation scheme (FP-TAS) that maximizes the traffic carried by the network subject to the constraint that all traffic passes through a content filtering node at least once. Simulation studies using the developed schemes show that for large networks, most of the traffic can be examined even when only 10% of the network nodes are content filtering capable.},
keywords={computer viruses;filtering theory;telecommunication traffic;telecommunication network routing;polynomial approximation;optimisation;telecommunication security;worm propagation;content filtering node;network traffic;worm signatures;containment system;packet routing;network-based content filtering;maximization;fully polynomial time approximation scheme;FP-TAS;network security;Filtering;Computer worms;Telecommunication traffic;Intelligent networks;Traffic control;Routing;Polynomials;Frequency;Computational modeling;Computer security},
doi={10.1109/INFCOM.2005.1498525},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498526,
author={A. Kamra and H. Feng and V. Misra and A. D. Keromytis},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The effect of DNS delays on worm propagation in an IPv6 Internet},
year={2005},
volume={4},
number={},
pages={2405-2414 vol. 4},
abstract={It is a commonly held belief that IPv6 provides greater security against random-scanning worms by virtue of a very sparse address space. We show that an intelligent worm can exploit the directory and naming services necessary for the functioning of any network, and we model the behavior of such a worm in this paper. We explore via analysis and simulation the spread of such worms in an IPv6 Internet. Our results indicate that such a worm can exhibit propagation speeds comparable to an IPv4 random-scanning worm. We develop a detailed analytical model that reveals the relationship between network parameters and the spreading rate of the worm in an IPv6 world. We also develop a simulator based on our analytical model. Simulation results based on parameters chosen from real measurements and the current Internet indicate that an intelligent worm can spread surprising fast in an IPv6 world by using simple strategies. The performance of the worm depends heavily on these strategies, which in turn depend on how secure the directory and naming services of a network are. As a result, additional work is needed in developing detection and defense mechanisms against future worms, and our work identifies directory and naming services as the natural place to do it.},
keywords={IP networks;computer viruses;telecommunication services;delays;stochastic processes;queueing theory;Internet;telecommunication security;IPv6;security;random-scanning worm;intelligent worm;Internet;network service;DNS delays;stochastic process;queueing theory;worm propagation;Delay effects;Propagation delay;Internet;Computer worms;Analytical models;Computer science;Cities and towns;Computer security;Intelligent networks;Current measurement},
doi={10.1109/INFCOM.2005.1498526},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498527,
author={M. Andrews and L. Qian and A. Stolyar},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Optimal utility based multi-user throughput allocation subject to throughput constraints},
year={2005},
volume={4},
number={},
pages={2415-2424 vol. 4},
abstract={We consider the problem of scheduling multiple users sharing a time-varying wireless channel. (As an example, this is a model of scheduling in 3G wireless technologies, such as CDMA2000 3G1xEV-DO downlink scheduling.) We introduce an algorithm which seeks to optimize a concave utility function /spl Sigma//sub i/H/sub i/(R/sub i/) of the user throughputs R/sub i/, subject to certain lower and upper throughput bounds: R/sub i//sup min//spl les/R/sub i//spl les/R/sub i//sup max/. The algorithm, which we call the gradient algorithm with minimum/maximum rate constraints (GMR) uses a token counter mechanism, which modifies an algorithm solving the corresponding unconstrained problem, to produce the algorithm solving the problem with throughput constraints. Two important special cases of the utility functions are /spl Sigma//sub i/log R/sub i/ and /spl Sigma//sub i/R/sub i/, corresponding to the common proportional fairness and throughput maximization objectives. We study the dynamics of user throughputs under GMR algorithm, and show that GMR is asymptotically optimal in the following sense. If, under an appropriate scaling, the throughput vector R(t) converges to a fixed vector R/sup +/ as time t/spl rarr//spl infin/ then R/sup +/ is an optimal solution to the optimization problem described above. We also present simulation results showing the algorithm performance.},
keywords={3G mobile communication;time-varying channels;scheduling;optimisation;gradient methods;code division multiple access;multiuser channels;scheduling;3G time-varying wireless channel;optimization;concave utility function;gradient algorithm;minimum-maximum rate constraint;GMR;token counter mechanism;multiuser throughput allocation;CDMA;code division multiple access;Throughput;Scheduling algorithm;Signal to noise ratio;Constraint optimization;Downlink;Counting circuits;Wireless sensor networks;Multiaccess communication;Control systems},
doi={10.1109/INFCOM.2005.1498527},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498528,
author={G. van Kessel and R. Nunez-Queija and S. Borst},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Differentiated bandwidth sharing with disparate flow sizes},
year={2005},
volume={4},
number={},
pages={2425-2435 vol. 4},
abstract={We consider a multi-class queueing system operating under the discriminatory processor-sharing (DPS) discipline. The DPS discipline provides a natural approach for modeling the flow-level performance of differentiated bandwidth-sharing mechanisms. Motivated by the extreme diversity in flow sizes observed in the Internet, we examine the system performance in an asymptotic regime where the flow dynamics of the various classes occur on separate time scales. Specifically, from the perspective of a given class, the arrival and service completions of some of the competing classes (called mice) evolve on an extremely fast time scale. In contrast, the flow dynamics of the remaining classes (referred to as elephants) occur on a comparatively slow time scale. Assuming a strict separation of time scales, we obtain simple explicit expressions for various performance measures of interest, such as the distribution of the numbers of flows, mean delays, and flow throughputs. In particular, the latter performance measures are insensitive, in the sense that they only depend on the service requirement distributions through their first moments. Numerical experiments show that the limiting results provide remarkably accurate approximations in certain cases.},
keywords={queueing theory;telecommunication congestion control;Internet;telecommunication services;diversity reception;transport protocols;multiclass queueing system;discriminatory processor-sharing discipline;DPS;flow-level performance;differentiated bandwidth-sharing mechanism;diversity;Internet;service completion;Bandwidth;Delay;Global Positioning System;Mathematics;Computer science;Internet;System performance;Mice;Fluid flow measurement;Time measurement},
doi={10.1109/INFCOM.2005.1498528},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498529,
author={A. Das and D. Dutta and A. Helmy and A. Goel and J. Heidemann},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Low-state fairness: lower bounds and practical enforcement},
year={2005},
volume={4},
number={},
pages={2436-2446 vol. 4},
abstract={Providing approximate max-min fair bandwidth allocation among flows within a network or at a single router has been an important research problem. In this paper, we study the space complexity of fairness algorithms, and the communication complexity of distributed global fairness algorithms. We show that in order to enforce max-min fairness with bounded errors, a router must maintain per-flow state. Then we present a practical edge-marking based architecture to demonstrate the enforcement of approximate global max-min fairness for representative scenarios with multiple bottlenecks and non-responsive traffic. We validate our architecture using packet level simulations.},
keywords={minimax techniques;bandwidth allocation;telecommunication traffic;routing protocols;transport protocols;queueing theory;communication complexity;bandwidth allocation;max-min approximation;network router;communication complexity;distributed global fairness algorithm;edge-marking based architecture;representative scenario;nonresponsive traffic;packet level simulation;Channel allocation;Bandwidth;Internet;Complexity theory;Communication system traffic control;Traffic control;Protocols;Scheduling algorithm;Degradation;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1498529},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498530,
author={O. Komolafe and J. Sventek},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={RSVP performance evaluation using multi-objective evolutionary optimisation},
year={2005},
volume={4},
number={},
pages={2447-2457 vol. 4},
abstract={The proposed uses of the resource reservation protocol (RSVP) now extend beyond reserving resources in Internet protocol (IP) networks to being a generic signaling protocol for generalised multi-protocol label switching (GMPLS). In any implementation of RSVP, there are a number of discretionary timing parameters, the values of which affect the efficacy of RSVP in establishing and maintaining reservations/connections. This work frames the interactions between key RSVP timing parameters and performance metrics as a multi-objective optimisation problem which, due to its intractable nature, is tackled using a reputable multi-objective evolutionary algorithm. It is shown that this approach is a feasible means of exploring many of the innate tradeoffs in soft-state protocols such as RSVP. This approach facilitates an extensive comparison of a number of variants of RSVP: standard RSVP, RSVP featuring the recently standardised retransmission algorithm and two subsequent variants of this algorithm, supporting the asymmetric delivery of RSVP control messages. These RSVP variants are compared in terms of multiple performance metrics under a number of different exemplar network conditions, giving insight into their relative merits. Furthermore, the relative significance of the different timing parameters is investigated and their most expedient values determined.},
keywords={resource allocation;IP networks;Internet;transport protocols;telecommunication signalling;multiprotocol label switching;optimisation;performance evaluation;resource reservation protocol;RSVP control message;Internet protocol;IP network;generic signaling protocol;generalised multiprotocol label switching;GMPLS;discretionary timing parameter;multiobjective optimisation problem;evolutionary algorithm;performance evaluation;Timing;Measurement;Evolutionary computation;Multiprotocol label switching;Routing protocols;IP networks;Web and internet services;Intserv networks;Wavelength routing;Packet switching},
doi={10.1109/INFCOM.2005.1498530},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498531,
author={I. C. Paschalidis and W. Lai and D. Starobinski},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Asymptotically optimal transmission policies for low-power wireless sensor networks},
year={2005},
volume={4},
number={},
pages={2458-2469 vol. 4},
abstract={We consider wireless sensor networks with multiple gateways and multiple classes of traffic carrying data generated by different sensory inputs. The objective is to devise joint routing, power control and transmission scheduling policies in order to gather data in the most efficient manner while respecting the needs of different sensing tasks (fairness). We formulate the problem as maximizing the utility of transmissions subject to explicit fairness constraints. We propose an efficient decomposition algorithm drawing upon large-scale decomposition ideas in mathematical programming. We show that our algorithm terminates in a finite number of iterations and produces a policy that is asymptotically optimal at low transmission power levels. Moreover, numerical results establish that this policy is near-optimal even at high power levels. We also demonstrate how to adapt our algorithm to accommodate energy constraints and node failures. The approach we introduce can efficiently determine near-optimal transmission policies for dramatically larger problem instances than an alternative enumeration approach.},
keywords={wireless sensor networks;telecommunication traffic;mathematical programming;constraint theory;scheduling;protocols;network servers;power control;optimal control;asymptotic optimal transmission policy;low-power wireless sensor network;multiple gateway;multiple traffic class;power control;transmission scheduling;explicit fairness constraint;decomposition algorithm;mathematical programming;energy constraint;Wireless sensor networks;Systems engineering and theory;Data engineering;Power control;Condition monitoring;Electronic mail;Routing;Sensor systems;Computer networks;Manufacturing},
doi={10.1109/INFCOM.2005.1498531},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498532,
author={G. Lu and N. Sadagopan and B. Krishnamachari and A. Goel},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Delay efficient sleep scheduling in wireless sensor networks},
year={2005},
volume={4},
number={},
pages={2470-2481 vol. 4},
abstract={Medium access techniques for wireless sensor networks raise the important question of providing periodic energy-efficient radio sleep cycles while minimizing the end-to-end communication delays. This study aims to minimize the communication latency given that each sensor has a duty cycling requirement of being awake for only 1/k time slots on an average. As a first step we consider the single wake-up schedule case, where each sensor can choose exactly one of the k slots to wake up. We formulate a novel graph-theoretical abstraction of this problem in the general setting of a low-traffic wireless sensor network with arbitrary communication flows and prove that minimizing the end-to-end communication delays is in general NP-hard. However, we are able to derive and analyze optimal solutions for two special cases: tree topologies and ring topologies. Several heuristics for arbitrary topologies are proposed and evaluated by simulations. Our simulations suggest that distributed heuristics may perform poorly because of the global nature of the constraints involved. We also show that by carefully choosing multiple wake-up slots for each sensor significant delay savings can be obtained over the single wake-up schedule case while maintaining the same duty cycling. Using this technique, we propose algorithms that offer a desirable bound of d+O(k) on the delay for specialized topologies like the tree and grid and a weaker guarantee of O((d+k)log n) for arbitrary graphs, where d is the shortest path between 2 nodes in the underlying topology and n is the total number of nodes.},
keywords={wireless sensor networks;energy conservation;graph theory;trees (mathematics);telecommunication network topology;scheduling;delay efficient sleep scheduling;wireless sensor network;medium access technique;periodic energy-efficient radio;sleep cycle;end-to-end communication delay;communication latency;duty cycling requirement;single wake-up schedule;graph-theoretical abstraction;tree topology;ring topology;Sleep;Intelligent networks;Wireless sensor networks;Delay;Network topology;Energy efficiency;Telecommunication traffic;Tree graphs;Processor scheduling;Computer science},
doi={10.1109/INFCOM.2005.1498532},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498533,
author={Hai Liu and P. Wan and C. -. Yi and Xiaohua Jia and S. Makki and N. Pissinou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Maximal lifetime scheduling in sensor surveillance networks},
year={2005},
volume={4},
number={},
pages={2482-2491 vol. 4},
abstract={This paper addresses the maximal lifetime scheduling problem in sensor surveillance networks. Given a set of sensors and targets in a Euclidean plane, a sensor can watch only one target at a time, our task is to schedule sensors to watch targets, such that the lifetime of the surveillance system is maximized, where the lifetime is the duration that all targets are watched. We propose an optimal solution to find the target watching schedule for sensors that achieves the maximal lifetime. Our solution consists of three steps: 1) computing the maximal lifetime of the surveillance system and a workload matrix by using linear programming techniques; 2) decomposing the workload matrix into a sequence of schedule matrices that can achieve the maximal lifetime; 3) obtaining a target watching timetable for each sensor based on the schedule matrices. Simulations have been conducted to study the complexity of our proposed method and to compare with the performance of a greedy method.},
keywords={surveillance;linear programming;matrix algebra;scheduling;wireless sensor networks;greedy algorithms;maximal lifetime scheduling;sensor surveillance network;Euclidean plane;optimal solution;target watching schedule;workload matrix schedule;linear programming technique;greedy method;Intelligent networks;Surveillance;Sensor systems;Watches;Wireless sensor networks;Sensor phenomena and characterization;Processor scheduling;Matrix decomposition;Monitoring;Computer science},
doi={10.1109/INFCOM.2005.1498533},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498534,
author={S. Gandham and M. Dawande and R. Prakash},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Link scheduling in sensor networks: distributed edge coloring revisited},
year={2005},
volume={4},
number={},
pages={2492-2501 vol. 4},
abstract={We consider the problem of link scheduling in a sensor network employing a TDMA MAC protocol. Our link scheduling algorithm involves two phases. In the first phase, we assign a color to each edge in the network such that no two edges incident on the same node are assigned the same color. We propose a distributed edge coloring algorithm that needs at most (/spl delta/+1) colors, where /spl delta/ is the maximum degree of the graph. To the best of our knowledge, this is the first distributed algorithm that can edge color a graph with at most (/spl delta/+1) colors. In the second phase, we map each color to a unique timeslot and attempt to identify a direction of transmission along each edge such that the hidden terminal and the exposed terminal problems are avoided. Next, considering topologies for which a feasible solution does not exist, we obtain a direction of transmission for each edge using additional timeslots, if necessary. Finally, we show that reversing the direction of transmission along every edge leads to another feasible direction of transmission. Using both the transmission assignments we obtain a TDMA MAC schedule, which enables two-way communication between every pair of neighbors. For acyclic topologies, we show that at most 2(/spl delta/+1) timeslots are required. Through simulations we show that for sparse graphs with cycles the number of timeslots assigned is close to 2(/spl delta/+1).},
keywords={telecommunication links;scheduling;time division multiple access;wireless sensor networks;access protocols;telecommunication network topology;graph theory;link scheduling;sensor network;distributed edge coloring algorithm;TDMA MAC protocol;acyclic topology;sparse graph;Intelligent networks;Media Access Protocol;Time division multiple access;Access protocols;Wireless sensor networks;Base stations;Delay;Processor scheduling;Computer science;Remote monitoring},
doi={10.1109/INFCOM.2005.1498534},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498535,
author={S. Vasudevan and J. Kurose and D. Towsley},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On neighbor discovery in wireless networks with directional antennas},
year={2005},
volume={4},
number={},
pages={2502-2512 vol. 4},
abstract={We consider the problem of neighbor discovery in static wireless ad hoc networks with directional antennas. We propose several probabilistic algorithms in which nodes perform random, independent transmissions to discover their one-hop neighbors. Our neighbor discovery algorithms are classified into two groups, viz. Direct-Discovery Algorithms in which nodes discover their neighbors only upon receiving a transmission from their neighbors and Gossip-based algorithms in which nodes gossip about their neighbors' location information to enable faster discovery. We first consider the operation of these algorithms in a slotted, synchronous system and mathematically derive their optimal parameter settings. We show how to extend these algorithms for an asynchronous system and describe their optimal design. Analysis and simulation of the algorithms show that nodes discover their neighbors much faster using gossip-based algorithms than using direct-discovery algorithms. Furthermore, the performance of gossip-based algorithms is insensitive to an increase in node density. The efficiency of a neighbor discovery algorithm also depends on the choice of antenna beamwidth. We discuss in detail how the choice of beamwidth impacts the performance of the discovery process and provide insights into how nodes can configure their beamwidths.},
keywords={ad hoc networks;probability;optimisation;telecommunication network topology;directive antennas;neighbor discovery algorithm;directional antenna;static wireless ad hoc network;probabilistic algorithm;random independent transmission;direct-discovery algorithm;gossip-based algorithm;synchronous system;optimal parameter setting;antenna beamwidth;Intelligent networks;Wireless networks;Directional antennas;Ad hoc networks;Routing protocols;Wireless sensor networks;Directive antennas;Transmitting antennas;Algorithm design and analysis;Monitoring},
doi={10.1109/INFCOM.2005.1498535},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498536,
author={M. Cagalj and S. Ganeriwal and I. Aad and J. -. Hubaux},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On selfish behavior in CSMA/CA networks},
year={2005},
volume={4},
number={},
pages={2513-2524 vol. 4},
abstract={CSMA/CA protocols rely on the random deferment of packet transmissions. Like most other protocols, CSMA/CA was designed with the assumption that the nodes would play by the rules. This can be dangerous, since the nodes themselves control their random deferment. Indeed, with the higher programmability of the network adapters, the temptation to tamper with the software or firmware is likely to grow; by doing so, a user could obtain a much larger share of the available bandwidth at the expense of other users. We use a game-theoretic approach to investigate the problem of the selfish behavior of nodes in CSMA/CA networks, specifically geared towards the most widely accepted protocol in this class of protocols, IEEE 802.11. We characterize two families of Nash equilibria in a single stage game, one of which always results in a network collapse. We argue that this result provides an incentive for cheaters to cooperate with each other. Explicit cooperation among nodes is clearly impractical. By applying the model of dynamic games borrowed from game theory, we derive the conditions for the stable and optimal functioning of a population of cheaters. We use this insight to develop a simple, localized and distributed protocol that successfully guides multiple selfish nodes to a Pareto-optimal Nash equilibrium.},
keywords={carrier sense multiple access;game theory;protocols;wireless LAN;Pareto optimisation;carrier sense multiple access;CSMA-CA network;packet transmission;network adapters;firmware;dynamic game-theoretic approach;IEEE 802.11;Nash equilibria;explicit cooperation;distributed protocol;multiple selfish node;Pareto-optimal Nash equilibrium;Intelligent networks;Multiaccess communication;Game theory;Nash equilibrium;Wireless application protocol;Wireless networks;Microprogramming;Bandwidth;Collision avoidance;Media Access Protocol},
doi={10.1109/INFCOM.2005.1498536},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498537,
author={X. Yang and N. Vaidya},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On physical carrier sensing in wireless ad hoc networks},
year={2005},
volume={4},
number={},
pages={2525-2535 vol. 4},
abstract={The aggregate throughput of a wireless ad hoc network depends on the channel capacity, channel utilization (i.e., the fraction of channel capacity used for generating good put), and the concurrent transmissions allowed in the network. While channel utilization is determined by MAC overhead, physical carrier sense has been used as an effective way to avoid interference and exploit spatial reuse. Prior research has attempted to identify the optimal carrier sense range that can maximize the aggregate throughput. However, the impact of MAC overhead has been ignored. In this paper, we use both an analytical model and simulation results to show that MAC overhead has significant impact on the choice of optimal carrier sense range. If MAC overhead is not taken into account properly in determining the optimal carrier sense range, the aggregate throughput can suffer a significant loss.},
keywords={ad hoc networks;channel capacity;access protocols;optimisation;optimal physical carrier sense;wireless ad hoc network;aggregate throughput;channel capacity;MAC overhead;spatial reuse;Intelligent networks;Wireless sensor networks;Ad hoc networks;Aggregates;Throughput;Media Access Protocol;Channel capacity;Wireless communication;Interference;Access protocols},
doi={10.1109/INFCOM.2005.1498537},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498538,
author={J. D. Herdtner and E. K. P. Chong},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Throughput-storage tradeoff in ad hoc networks},
year={2005},
volume={4},
number={},
pages={2536-2542 vol. 4},
abstract={Gupta and Kumar (2000) showed that the throughput capacity of static ad hoc networks with n randomly positioned nodes is /spl Theta/(/spl radic/(n/log n)). Grossglauser and Tse showed that node mobility increases the capacity to /spl Theta/(n), a substantial improvement. Achieving maximum capacity requires nodes to relay transmissions through other nodes. Each node must have a relay buffer for temporarily storing packets before forwarding them to their destination. We establish that if relay buffer sizes are bounded above by a constant, then mobility does not substantially increase the throughput capacity of mobile ad hoc networks. In particular, we show that the capacity of mobile networks with finite buffers is at most /spl Theta/(/spl radic/n). Finally we establish a scaling law relationship that characterizes the fundamental tradeoff between throughput capacity and relay buffer size. In particular, we show that the throughput capacity is at most /spl Theta/(/spl radic/(nb/sub n/)), where b/sub n/ is the size of the relay buffers.},
keywords={ad hoc networks;buffer storage;mobile radio;optimisation;throughput-storage tradeoff;static mobile ad hoc network;randomly positioned node mobility;relay buffer;packet storage;scaling law;Intelligent networks;Ad hoc networks;Relays;Throughput;Mobile communication;Buffer storage;Mobile ad hoc networks;Wireless sensor networks;Base stations;Batteries},
doi={10.1109/INFCOM.2005.1498538},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498539,
author={Y. Liu and H. Zhang and W. Gong and D. Towsley},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On the interaction between overlay routing and underlay routing},
year={2005},
volume={4},
number={},
pages={2543-2553 vol. 4},
abstract={In this paper, we study the interaction between overlay routing and traffic engineering (TE) in a single autonomous system (AS). We formulate this interaction as a two-player non-cooperative non-zero sum game, where the overlay tries to minimize the delay of its traffic and the TE's objective is to minimize network cost. We study a Nash routing game with best-reply dynamics, in which the overlay and TE have equal status, and take turns to compute their optimal strategies based on the response of the other player in the previous round. We prove the existence, uniqueness and global stability of Nash equilibrium point (NEP) for a simple network. For general networks, we show that the selfish behavior of an overlay can cause huge cost increases and oscillations to the whole network. Even worse, we have identified cases, both analytically and experimentally, where the overlay's cost increases as the Nash routing game proceeds even though the overlay plays optimally based on TE's routing at each round. Experiments are performed to verify our analysis.},
keywords={telecommunication network routing;telecommunication traffic;game theory;overlay routing;underlay routing;traffic engineering;TE;autonomous system;single AS;two-player noncooperative nonzero sum game;Nash routing game;Nash equilibrium point;NEP stability;Routing;Tellurium;Telecommunication traffic;Costs;Application software;Physics computing;Multiprotocol label switching;Computer science;Stability;Nash equilibrium},
doi={10.1109/INFCOM.2005.1498539},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498540,
author={J. Han and D. Watson and F. Jahanian},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Topology aware overlay networks},
year={2005},
volume={4},
number={},
pages={2554-2565 vol. 4},
abstract={Recently, overlay networks have emerged as a means to enhance end-to-end application performance and availability. Overlay networks attempt to leverage the inherent redundancy of the Internet's underlying routing infrastructure to detour packets along an alternate path when the given primary path becomes unavailable or suffers from congestion. However, the effectiveness of these overlay networks depends on the natural diversity of overlay paths between two endhosts in terms of physical links, routing infrastructure, administrative control, and geographical distribution. Several recent studies realized that a measurable number of path outages were unavoidable even with use of such overlay networks. This stems from the fact that overlay paths might overlap with each other when overlay nodes are selected without considering the underlying topology. An overlay network's ability to quickly recover from path outages and congestion is limited unless we ensure path independence at the IP layer. This paper proposes a novel framework for topology-aware overlay networks. In this framework, we expressly design overlay networks, aiming to maximize path independence without degrading performance. We develop measurement-based heuristics for 1) placement of overlay nodes inside an ISP and 2) selection of a set of ISPs. We base our analysis on extensive data collection from 232 points in 10 ISPs, and 100 PlanetLab nodes. On top of node placement, we present measurement-based verification to conclude that single-hop overlay routing performs as well as multi-hop routing with respect to both availability and performance. Our analysis results show that a single-hop overlay path provides the same degree of path diversity as the multi-hop overlay path for more than 90% of source and destination pairs. Finally, we validate the proposed framework using real Internet outages to show that our architecture is able to provide a significant amount of resilience to real-world failures.},
keywords={telecommunication network topology;Internet;telecommunication congestion control;telecommunication links;IP networks;telecommunication traffic;telecommunication network routing;topology aware overlay network;end-to-end application performance;Internet;physical link;administrative control;geographical distribution;IP layer;ISP;extensive data collection;PlanetLab node;measurement-based verification;multihop routing infrastructure;path diversity;Network topology;Routing;Extraterrestrial measurements;Availability;IP networks;Degradation;Data analysis;Performance evaluation;Internet;Resilience},
doi={10.1109/INFCOM.2005.1498540},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498541,
author={N. Christin and J. Chuang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A cost-based analysis of overlay routing geometries},
year={2005},
volume={4},
number={},
pages={2566-2577 vol. 4},
abstract={In this paper, we propose a cost-based model to evaluate the resources that each node has to contribute for participating in an overlay network. Such a cost model allows to gauge potential disincentives for nodes to collaborate, and provides a measure of the "total cost" of a network, which is a possible benchmark to distinguish between different network architectures. We characterize the cost imposed on a node as a parameterized function of the experienced load and of the node connectivity, and express benefits in terms of cost reductions. We discuss the notions of social optimum and Nash equilibrium with respect to the proposed cost model. We show that the social optimum may significantly deviate from a Nash equilibrium when nodes value the resources they use to forward traffic on behalf of other nodes. Through analytical and numerical results, we then use the proposed cost model to evaluate some of the topologies recently proposed for overlay networks, and to exhibit some of the challenges systems designers may face. We conclude by outlining some of the open questions this research has raised.},
keywords={cost reduction;telecommunication network routing;optimisation;peer-to-peer computing;resource allocation;cost-based analysis;overlay routing geometry;resource evaluation;parameterized function;node connectivity;cost reduction;social optimum;Nash equilibrium;Routing;Peer to peer computing;Network topology;Cost function;Nash equilibrium;Information geometry;Information management;Solid modeling;Collaboration;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1498541},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498542,
author={W. Wang and B. Li},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Market-driven bandwidth allocation in selfish overlay networks},
year={2005},
volume={4},
number={},
pages={2578-2589 vol. 4},
abstract={Selfish overlay networks consist of autonomous nodes that develop their own strategies by optimizing towards their local objectives and self-interests, rather than following prescribed protocols. It is thus important to regulate the behavior of selfish nodes, so that system-wide properties are optimized. In this paper, we investigate the problem of bandwidth allocation in overlay networks, and propose to use a market-driven approach to regulate the behavior of selfish nodes that either provide or consume services. In such markets, consumers of services select the best service providers, taking into account both the performance and the price of the service. On the other hand, service providers are encouraged to strategically decide their respective prices in a pricing game, in order to maximize their economic revenues and minimize losses in the long run. In order to overcome the limitations of previous models towards similar objectives, we design a decentralized algorithm that uses reinforcement learning to help selfish nodes to incrementally adapt to the local market, and to make optimized strategic decisions based on past experiences. We have simulated our proposed algorithm in randomly generated overlay networks, and have shown that the behavior of selfish nodes converges to their optimal strategies, and resource allocations in the entire overlay are near-optimal, and efficiently adapts to the dynamics of overlay networks.},
keywords={bandwidth allocation;resource allocation;learning (artificial intelligence);market opportunities;pricing;customer services;optimisation;game theory;protocols;peer-to-peer computing;market-driven bandwidth allocation;selfish overlay network;autonomous node;system-wide property optimization;consumer service;pricing game;economic revenue;decentralized algorithm;reinforcement learning;local market;optimized strategic decision;resource allocation;Channel allocation;Intelligent networks;Peer to peer computing;Bandwidth;Pricing;Data communication;Streaming media;Context modeling;Tellurium;Protocols},
doi={10.1109/INFCOM.2005.1498542},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498543,
author={R. Yim and M. Rosenblum and V. Tarokh},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Delay bounds for packetizing time-varying fluid policies with speedup and lookahead in single server systems},
year={2005},
volume={4},
number={},
pages={2590-2601 vol. 4},
abstract={We consider an online, processor sharing system with a single server in a packet-switched network where the processor multiplexes packets from multiple input ports onto the same output link. Under a fluid model, in which incoming data is treated as infinitely divisible, the multiplexer allocates its output capacity to serve fractions of packets from all input ports simultaneously (which we call a fluid policy). However, due to the packet nature of the network traffic, a multiplexer scheduler must approximate this fluid policy by a schedule in which only whole packets are sent (which we call a packetized policy). We assume that at each time instant, the aggregate service rate demanded by a fluid policy is no greater than the output link capacity. Then, for a single server with N input ports, and a scheduler using speedup s of at least 2 and a lookahead window of L/spl ges/0 time steps, we prove bounds on worst-case maximum additional delay D. In particular, we show that ([Ne/sup -s/]-L-2)/sup +//spl les/D min {([Ne/sup 1-s/]-L)/sup +/, [Ne/sup -s/]}. In the case when no lookahead is used (L=0), a tighter bound can be obtained: ([Ne/sup -s/]-2)/sup +//spl les/D/spl les/[Ne/sup -s/}.},
keywords={delays;network servers;telecommunication traffic;packet switching;resource allocation;processor scheduling;time-varying systems;telecommunication congestion control;delay bound;time-varying fluid policy;server system;online processor sharing system;packet-switched network;packet multiplexing;network traffic;aggregate service rate;packetizing algorithm;Time varying systems;Multiplexing;Telecommunication traffic;Network servers;Scheduling algorithm;Asynchronous transfer mode;Added delay;Intelligent networks;Traffic control;Packet switching},
doi={10.1109/INFCOM.2005.1498543},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498544,
author={X. Yu and J. W. Modestino and X. Tian},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The accuracy of Gilbert models in predicting packet-loss statistics for a single-multiplexer network model},
year={2005},
volume={4},
number={},
pages={2602-2612 vol. 4},
abstract={The Gilbert model (1-st order Markov chain model) and the single-multiplexer model are two frequently used models in the study of packet-loss processes in communication networks. In this paper we investigate the accuracy of the Gilbert model, and higher-order Markov chain extended Gilbert models, in characterizing the packet-loss process associated with a transport network modeled in terms of a single-multiplexer. More specifically, we quantitatively compare the packet-loss statistics predicted by the Gilbert models with those predicted by an exact queueing analysis of the single-multiplexer model. This topic is important since low-complexity Gilbert models are frequently used to characterize end-to-end network packet-loss behavior. On the other hand, network congestion behavior is often characterized in terms of a single bottleneck node modeled as a multiplexer. It is of some interest then to establish the relative accuracy of Gilbert models in predicting the packet-loss behavior on even such a simplified network model. We demonstrate that the Gilbert models have some serious deficiencies in accurately predicting the packet-loss statistics of the single-multiplexer model. The results are shown to have some serious consequences for the performance evaluation of forward error correction (FEC) coding schemes used to combat the effects of packet losses due to network buffer overflows.},
keywords={prediction theory;Markov processes;queueing theory;telecommunication congestion control;buffer storage;forward error correction;computational complexity;multiplexing equipment;packet switching;extended Gilbert model;packet-loss statistic prediction;single-multiplexer network model;higher-order Markov chain;transport network;queueing analysis;network congestion behavior;forward error correction;FEC coding scheme;network buffer overflow;Predictive models;Intelligent networks;Propagation losses;Multiplexing;Buffer overflow;Queueing analysis;Forward error correction;Communication networks;Higher order statistics;Statistical analysis},
doi={10.1109/INFCOM.2005.1498544},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498545,
author={R. Groenevelt and E. Altman},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Analysis of alternating-priority queueing models with (cross) correlated switchover times},
year={2005},
volume={4},
number={},
pages={2613-2624 vol. 4},
abstract={This paper analyzes a single server queuing system in which service is alternated between two queues and the server requires a (finite) switchover time to switch from one queue to the other. The distinction from classical results is that the sequence of switchover times from each of the queues need not be i.i.d. nor independent from each other; each sequence is merely required to form a stationary ergodic sequence. With the help of stochastic recursive equations explicit expressions are derived for a number of performance measures, most notably for the average delay of a customer and the average queue lengths under different service disciplines. With these expressions a comparison is made between the service disciplines and the influence of correlation is studied. Finally, through a number of examples it is shown that the correlation can significantly increase the mean delay and the average queue lengths indicating that the correlation between switchover times should not be ignored. This has important implications for communication systems in which a common communication channel is shared amongst various users and where the time between consecutive data transfers is correlated (for example in ad-hoc networks).},
keywords={queueing theory;telecommunication channels;correlation theory;delays;recursive estimation;sequences;alternating-priority queueing model;cross correlated switchover time;single server queuing system;stationary ergodic sequence;stochastic recursive equation;explicit expression;average queue length;mean delay;communication channel;data transfer;Queueing analysis;Switches;Delay;Ad hoc networks;Stochastic systems;Stochastic processes;Differential equations;Length measurement;Communication switching;Communication systems},
doi={10.1109/INFCOM.2005.1498545},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498546,
author={N. Khude and A. Kumar and A. Karnik},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Time and energy complexity of distributed computation in wireless sensor networks},
year={2005},
volume={4},
number={},
pages={2625-2637 vol. 4},
abstract={We consider a scenario where a wireless sensor network is formed by randomly deploying n sensors to measure some spatial function over a field, with the objective of computing the maximum value of the measurements and communicating it to an operator station. We view the problem as one of message passing distributed computation over a geometric random graph. The network is assumed to be synchronous; at each sampling instant each sensor measures a value, and then the sensors collaboratively compute and deliver the maximum of these values to the operator station. Computation algorithms differ in the messages they need to exchange, and our formulation focuses on the problem of scheduling of the message exchanges. We do not exploit techniques such as source compression, or block coding of the computations. For this problem, we study the computation time and energy expenditure for one time maximum computation, and also the pipeline throughput. We show that, for an optimal algorithm, the computation time, energy expenditure and the achievable rate of computation scale as /spl Theta/(/spl radic/ n/log n), /spl Theta/(n) and /spl Theta/(1/log n) asymptotically (in probability) as the number of sensors n/spl rarr//spl infin/. We also analyze the performance of three specific computational algorithms, namely, the tree algorithm, multihop transmission, and the ripple algorithm, and obtain scaling laws for the computation time and energy expenditure as n/spl rarr//spl infin/. Simulation results are provided to show that our analysis indeed captures the correct scaling; the simulations also yield estimates of the constant multipliers in the scaling laws. Our analyses throughout assume a centralized scheduler and hence our results can be viewed as providing bounds for the performance with a distributed scheduler.},
keywords={computational complexity;wireless sensor networks;message passing;graph theory;scheduling;trees (mathematics);pipeline processing;signal sampling;time complexity;energy complexity;distributed computation algorithm;wireless sensor network;spatial function;message passing;geometric random graph;synchronous network;signal sampling;pipeline throughput;tree algorithm;multihop transmission;ripple algorithm;scaling law;constant multiplier;centralized scheduler;Computer networks;Distributed computing;Wireless sensor networks;Processor scheduling;Performance analysis;Computational modeling;Analytical models;Message passing;Sampling methods;Collaboration},
doi={10.1109/INFCOM.2005.1498546},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498547,
author={M. X. Cheng and L. Ruan and W. Wu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Achieving minimum coverage breach under bandwidth constraints in wireless sensor networks},
year={2005},
volume={4},
number={},
pages={2638-2645 vol. 4},
abstract={This paper addresses the coverage breach problem in wireless sensor networks with limited bandwidths. In wireless sensor networks, sensor nodes are powered by batteries. To make efficient use of battery energy is critical to sensor network lifetimes. When targets are redundantly covered by multiple sensors, especially in stochastically deployed sensor networks, it is possible to save battery energy by organizing sensors into mutually exclusive subsets and alternatively activating only one subset at any time. Active nodes are responsible for sensing, computing and communicating. While the coverage of each subset is an important metric for sensor organization, the size of each subset also plays an important role in sensor network performance because when active sensors periodically send data to base stations, contention for channel access must be considered. The number of available channels imposes a limit on the cardinality of each subset. Coverage breach happens when a subset of sensors cannot completely cover all the targets. To make efficient use of both energy and bandwidth with a minimum coverage breach is the goal of sensor network design. This paper presents the minimum breach problem using a mathematical model, studies the computational complexity of the problem, and provides two approximate heuristics. Effects of increasing the number of channels and increasing the number of sensors on sensor network coverage are studied through numerical simulations. Overall, the simulation results reveal that when the number of sensors increases, network lifetimes can be improved without loss of network coverage if there is no bandwidth constraint; with bandwidth constraints, network lifetimes may be improved further at the cost of coverage breach.},
keywords={constraint theory;wireless sensor networks;computational complexity;telecommunication channels;mathematical programming;energy conservation;minimum coverage breach;bandwidth constraint;wireless sensor networks;battery energy;sensor network lifetime;mutually exclusive subset;channel access;computational complexity;mathematical programming;energy conservation;Bandwidth;Wireless sensor networks;Batteries;Organizing;Base stations;Mathematical model;Computational complexity;Numerical simulation;Computational modeling;Costs},
doi={10.1109/INFCOM.2005.1498547},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498548,
author={E. Felemban and C. -. Lee and E. Ekici and R. Boder and S. Vural},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Probabilistic QoS guarantee in reliability and timeliness domains in wireless sensor networks},
year={2005},
volume={4},
number={},
pages={2646-2657 vol. 4},
abstract={In this paper, we present a novel packet delivery mechanism called multi-path and multi-speed routing protocol (MMSPEED) for probabilistic QoS guarantee in wireless sensor networks. The QoS provisioning is performed in two quality domains, namely, timeliness and reliability. Multiple QoS levels are provided in the timeliness domain by guaranteeing multiple packet delivery speed options. In the reliability domain, various reliability requirements are supported by probabilistic multipath forwarding. All these for QoS provisioning are realized in a localized way without global network information by employing localized geographic packet forwarding augmented with dynamic compensation, which compensates the local decision inaccuracy as a packet travels towards its destination. This way, MMSPEED can guarantee end-to-end requirements in a localized way, which is desirable for scalability and adaptability to large scale dynamic sensor networks. Simulation results show that MMSPEED provides QoS differentiation in both reliability and timeliness domains and, as a result, significantly improves the effective capacity of a sensor network in terms of number of flows that meet both reliability and timeliness requirements.},
keywords={quality of service;telecommunication network reliability;wireless sensor networks;routing protocols;multipath channels;quality of service;QoS guarantee;network reliability;timeliness domain;wireless sensor network;packet delivery mechanism;multipath multispeed routing protocol;MMSPEED;probabilistic multipath forwarding;global network information;localized geographic packet forwarding;dynamic compensation;Intelligent networks;Wireless sensor networks;Sensor phenomena and characterization;Telecommunication traffic;Large-scale systems;Capacitive sensors;Temperature sensors;Network topology;Computer network reliability;Computer networks},
doi={10.1109/INFCOM.2005.1498548},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498549,
author={S. Yuan and S. Varma and J. P. Jue},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Minimum-color path problems for reliability in mesh networks},
year={2005},
volume={4},
number={},
pages={2658-2669 vol. 4},
abstract={In this work, we consider the problem of maximizing the reliability of connections in mesh networks against failure scenarios in which multiple links may fail simultaneously. We consider the single-path connection problem as well as multiple-path (protected) connection problems. The problems are formulated as minimum-color path problems, where each link is associated with one or more colors, and each color corresponds to a given failure event Thus, when a certain color fails, all links which include that color will fail. In a single-path problem, by minimizing the number of colors on the path, the failure probability of the path can be minimized if all colors have the same probability of causing failures. In the case of two paths, where one path is a protection path, if all colors have the same probability of causing failures, the problem becomes that of finding two link-disjoint paths which either have a minimum total number of colors, or which have a minimum number of overlapping colors. By minimizing the total number of colors, the probability that a failure will occur on either of the paths is minimized. On the other hand, by minimizing the number of overlapping colors, the probability that a single failure event will cause both paths to fail simultaneously is minimized. The problems are proved to be NP-complete, and ILP formulations are developed. Heuristic algorithms are proposed for larger instances of the problems, and the heuristics are evaluated through simulation.},
keywords={telecommunication network reliability;integer programming;linear programming;telecommunication links;probability;graph colouring;telecommunication network routing;optical fibre networks;computational complexity;minimum-color path problem;network reliability;mesh network;single-path connection problem;multiple-path connection problem;failure probability;link-disjoint path;NP-complete problem;integer linear programming;ILP formulation;heuristic algorithm;graph theory;Intelligent networks;Mesh networks;Protection;Optical fiber networks;Computer network reliability;Colon;WDM networks;Telecommunication network reliability;Computer science;Heuristic algorithms},
doi={10.1109/INFCOM.2005.1498549},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498550,
author={O. Dousse and M. Franceschetti and P. Thiran},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Information theoretic bounds on the throughput scaling of wireless relay networks},
year={2005},
volume={4},
number={},
pages={2670-2678 vol. 4},
abstract={The throughput of wireless networks is known to scale poorly when the number of users grows. The rate at which an arbitrary pair of nodes can communicate must decrease to zero as the number of users tends to infinity, under various assumptions. One of them is the requirement that the network is fully connected: the computed rate must hold for any pair of nodes of the network. We show that this requirement can be responsible for the lack of throughput scalability. We consider a two-dimensional network of extending area with only one active source-destination pair at any given time, and all remaining nodes acting only as possible relays. Allowing an arbitrary small fraction of the nodes to be disconnected, we show that the per-node throughput remains constant as the network size increases. This result relies on percolation theory arguments and does not hold for one-dimensional networks, where a non-vanishing rate is impossible even if we allow an arbitrary large fraction of nodes to be disconnected. A converse bound is obtained using an ergodic property of shot noises. We show that communications occurring at a fixed nonzero rate imply a fraction of the nodes to be disconnected. Our results are of information theoretic flavor, as they hold without assumptions on the communication strategies employed by the network nodes.},
keywords={shot noise;information theory;ad hoc networks;information theory bound;throughput scaling;wireless relay network;active source-destination pair;percolation theory;ergodic property;shot noise;fixed nonzero rate;Throughput;Relays;Computer networks;H infinity control;Wireless networks;Mobile communication;Scalability;Attenuation;Upper bound;Communication system traffic},
doi={10.1109/INFCOM.2005.1498550},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498551,
author={M. Chiang and S. Zhang and P. Hande},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Distributed rate allocation for inelastic flows: optimization frameworks, optimality conditions, and optimal algorithms},
year={2005},
volume={4},
number={},
pages={2679-2690 vol. 4},
abstract={A common assumption behind most of the recent research on network utility maximization is that traffic flows are elastic, which implies that their utility functions are concave and there are no hard limits on the rate allocated to each flow. These critical assumptions lead to tractability of the analytic models of utility maximization, but also limits applicability of the resulting rate allocation protocols. This paper focuses on inelastic flows and removes these restrictive and often invalid assumptions. We present several optimization frameworks, optimality conditions, and optimal algorithms. First, we consider nonconcave utility functions, which turn utility maximization into nonconvex, constrained optimization problems that are well-known to be difficult. We present conditions under which the current standard price-based distributed algorithm can still converge to the globally optimal rate allocation despite nonconcavity of utility functions. In particular, continuity of price-based rate allocation at all the optimal prices is a sufficient condition for global convergence of rate allocation by the standard algorithm, and continuity at at least one optimal price is a necessary condition. In the second part of the paper, we provide a general problem formulation of rate allocation among time-sensitive flows from real-time and streaming applications, as well as a decomposition into subproblems coordinated by pricing. After simplifying the subproblems by leveraging the optimization structures, we highlight the difficult issues of causality and time-scale, and propose an effective price-based heuristics for admission control and an optimal algorithm for a special case formulation.},
keywords={telecommunication traffic;resource allocation;optimisation;distributed algorithms;pricing;real-time systems;telecommunication congestion control;convergence;packet radio networks;network utility maximization;traffic flows;rate allocation protocol;optimization;price-based distributed algorithm;global convergence;real-time application;streaming application;admission control;resource allocation;Utility programs;Telecommunication traffic;Traffic control;Protocols;Constraint optimization;Distributed algorithms;Sufficient conditions;Convergence;Pricing;Admission control},
doi={10.1109/INFCOM.2005.1498551},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498552,
author={R. S. Bhatia and S. Kodialam and T. V. Lakshman and S. Sengupta},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Capacity allocation and routing of locally restorable bandwidth guaranteed connections},
year={2005},
volume={4},
number={},
pages={2691-2701 vol. 4},
abstract={An important feature of MPLS networks is local restoration where detour paths are set-up a priori. The detour is such that failed links or nodes can be bypassed locally from the first node that is upstream from the failures. This local bypass activation from the first detection point for failures permits much faster recovery than end-to-end path based mechanisms that require failure information to propagate to the network edges. However, local restoration of bandwidth guaranteed connections can be expensive in the additional network capacity needed. Hence, it is important to minimize and share restoration capacity. The problem of routing with local restoration requirements has been studied previously in a dynamic on-line setting. However, there are no satisfactory algorithms for the problem of pre-provisioning fast restorable connections when the aggregate traffic demands are known (as would be the case when a set of routers are to be interconnected over an optical network or for pre-provisioned ATM over MPLS overlays). The contribution of this paper is a fast combinatorial approximation algorithm for maximizing throughput when the routed traffic is required to be locally restorable. To the best of our knowledge, this is the first combinatorial algorithm for the problem with a performance guarantee. Our algorithm is a fully polynomial time approximation scheme (FPTAS), i.e., for any given /spl epsi/>0, it guarantees (1+/spl epsi/)-factor closeness to the optimal solution, and runs in time polynomial in the network size and 1//spl epsi/. We compare the throughput of locally restorable routing with that of unprotected routing and 1+1-dedicated path protection on representative ISP topologies.},
keywords={multiprotocol label switching;telecommunication links;routing protocols;telecommunication traffic;optimisation;polynomial approximation;telecommunication network topology;Internet;telecommunication services;failure analysis;MPLS network;multiprotocol label switching;link failure;upstream;failure detection;end-to-end path based mechanism;network routing;traffic demand;combinatorial approximation algorithm;maximization;fully polynomial time approximation scheme;FPTAS;path protection;representative ISP topology;Routing;Bandwidth;Multiprotocol label switching;Telecommunication traffic;Approximation algorithms;Throughput;Polynomials;Aggregates;Optical fiber networks;Protection},
doi={10.1109/INFCOM.2005.1498552},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498553,
author={W. Zhang and G. Xue and J. Tang and K. Thulasiraman},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Linear time construction of redundant trees for recovery schemes enhancing QoP and QoS},
year={2005},
volume={4},
number={},
pages={2702-2710 vol. 4},
abstract={Medard, Finn, Barry and Gallager proposed an elegant recovery scheme (known as the MFBG scheme) using redundant trees. Xue, Chen and Thulasiraman extended the MFBG scheme and introduced the concept of quality of protection (QoP) as a metric of multifailure recovery capabilities for single failure recovery schemes. In this paper, we present three linear time algorithms for constructing redundant trees for single link failure recovery in 2-edge connected graphs and for single node failure recovery in 2-connected graphs. Our first algorithm aims at high QoP for single link recovery schemes in 2-edge connected graphs. The previous best algorithm has a running time of O(n/sup 2/(m+n)), where n and m are the number of nodes and links in the network. Our algorithm has a running time of O(m+n), with comparable performance. Our second algorithm aims at high QoS for single link recovery schemes in 2-edge connected graphs. Our algorithm improves the previous best algorithm with O(n/sup 2/(m+n)) time complexity to O(m+n) time complexity with comparable performance. Our third algorithm aims at high QoS for single node recovery schemes in 2-connected graphs. Again, our algorithm improves the previous best algorithm with O(n/sup 2/(m+n)) time complexity to O(m+n) time complexity with comparable performance. Simulation results show that our new algorithms outperform previously known linear time algorithms significantly in terms of QoP or QoS, and outperform other known algorithms in terms of running time, with comparable QoP of QoS performance.},
keywords={telecommunication links;trees (mathematics);telecommunication network topology;failure analysis;quality of service;graph colouring;linear time algorithm;trees construction;link failure recovery;2-edge connected graph;QoP;quality of protection;QoS;quality of service;blue-red trees;Protection;Tree graphs;Quality of service;Computer science;SONET;High-speed networks;WDM networks;Wavelength division multiplexing;Solids},
doi={10.1109/INFCOM.2005.1498553},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498554,
author={P. Mutaf and C. Castelluccia},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Compact neighbor discovery: a bandwidth defense through bandwidth optimization},
year={2005},
volume={4},
number={},
pages={2711-2719 vol. 4},
abstract={We present a stateless defense against the neighbor discovery denial-of-service (ND-DoS) attack in IPv6. The ND-DoS attack consists of remotely flooding a target subnet with bogus packets destined for random interface identifiers; a different one for each malicious packet. The 128-bit IPv6 address reserves its 64 low-order bits for the interface ID. Consequently, the malicious packets are very likely to fall on previously unresolved addresses and the target access router (or leaf router) is obligated to resolve these addresses by sending neighbor solicitation packets. Neighbor solicitation packets are link layer multicast (or broadcast), and hence also forwarded by bridges. As a consequence, the attack may consume important bandwidth in subnets with wireless bridges, or access points. This problem is particularly important in the presence of mobile IPv6 devices that expect incoming sessions from the Internet. In this case, address resolution is crucial for the access router to reliably deliver incoming sessions to idle mobile devices with unknown MAC addresses. We propose a novel neighbor solicitation technique using Bloom filters. Multiple IPv6 addresses (bogus or real) that are waiting in the access router's address resolution queue are compactly represented using a Bloom filter. By broadcasting a single neighbor solicitation message that carries the Bloom filter, multiple IPv6 addresses are concurrently solicited. Legitimate neighbor solicitation triggering packets are not denied service. An on-link host can detect its address in the received Bloom filter and return its MAC address to the access router. A bandwidth gain around 40 can be achieved in all cells of the target subnet. This approach that we call compact neighbor discovery (CND) is the first bandwidth DoS defense that we are aware of to employ a bandwidth optimization.},
keywords={quality of service;security of data;radio links;mobile radio;IP networks;Internet;optimisation;computer network reliability;queueing theory;filtering theory;access protocols;routing protocols;neighbor discovery denial-of-service attack;ND-DoS;random interface;target access router;solicitation packet;link layer multicast;wireless bridge;access point;mobile IPv6 device;Internet;address resolution;reliability;MAC address;Bloom filters;queueing theory;broadcasting;compact neighbor discovery;CND;optimization;Bandwidth;Computer crime;Internet;Neodymium;Broadcasting;Bridges;Information filtering;Information filters;IP networks;Routing},
doi={10.1109/INFCOM.2005.1498554},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498555,
author={M. Sharif and B. Hassibi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A delay analysis for opportunistic transmission in fading broadcast channels},
year={2005},
volume={4},
number={},
pages={2720-2730 vol. 4},
abstract={We consider a single-antenna broadcast block fading channel (downlink scheduling) with n users where the transmission is packet-based and all users are backlogged. We define the delay as the minimum number of channel uses that guarantees all n users successfully receive m packets. This is a more stringent notion of delay than average delay and is the worst case delay among the users. A delay optimal scheduling scheme, such as round-robin, achieves the delay of mn. In a heterogeneous network and for the optimal throughput strategy where the transmitter sends the packet to the user with the best channel conditions, we derive the moment generating-function of the delay for any m and n. For large n and in a homogeneous network, the expected delay in receiving one packet by all the receivers scales as n logn, as opposed to n for the round-robin scheduling. We also show that when m grows faster than (logn)/sup r/, for some r>1, then the expected value of delay scales like mn. This roughly determines the time-scale required for the system to behave fairly in a homogeneous network. We then propose a scheme to significantly reduce the delay at the expense of a small throughput hit. We further look into two generalizations of our work: i) the effect of temporal channel correlation and ii) the advantage of multiple transmit antennas on the delay. For a channel with memory of two, we prove that the delay scales again like n logn no matter how severe the correlation is. For a system with M transmit antennas, we prove that the expected delay in receiving one packet by all the users scales like n log n/(M+O(M/sup 2//n)) for large n when M is not growing faster than logn. Thus, when the temporal channel correlation is zero, multiple transmit antenna systems do not reduce the delay significantly. However, when channel correlation is present, they can lead to significant gains by "decorrelating" the effective channel through means such as random beamforming.},
keywords={broadcast channels;Rayleigh channels;packet radio networks;cellular radio;delays;scheduling;decorrelation;transmitting antennas;antenna arrays;queueing theory;single-antenna;broadcast block fading channel;packet-based transmission;delay;optimal scheduling scheme;heterogeneous network;homogeneous network;round-robin scheduling;temporal channel correlation;multiple transmit antenna;decorrelation;cellular network;information theory;queueing theory;Fading;Broadcasting;Optimal scheduling;Transmitting antennas;Throughput;Downlink;Transmitters;Delay effects;Receiving antennas;Decorrelation},
doi={10.1109/INFCOM.2005.1498555},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498556,
author={P. De and A. Raniwala and S. Sharma and T. Chiueh},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={MiNT: a miniaturized network testbed for mobile wireless research},
year={2005},
volume={4},
number={},
pages={2731-2742 vol. 4},
abstract={Most mobile wireless networking research today relies on simulations. However, fidelity of simulation results has always been a concern, especially when the protocols being studied are affected by the propagation and interference characteristics of the radio channels. Inherent difficulty in faithfully modeling the wireless channel characteristics has encouraged several researchers to build wireless network testbeds. A full-fledged wireless testbed is spread over a large physical space because of the wide coverage area of radio signals. This makes a large-scale testbed difficult and expensive to set up, configure, and manage. This paper describes a miniaturized 802.11b-based, multi-hop wireless network testbed called MiNT. MiNT occupies a significantly small space, and dramatically reduces the efforts required in setting up a multi-hop wireless network used for wireless application/protocol testing and evaluation. MiNT is also a hybrid simulation platform that can execute ns-2 simulation scripts with the link, MAC and physical layer in the simulator replaced by real hardware. We demonstrate the fidelity of MiNT by comparing experimental results on it with similar experiments conducted on a non-miniaturized testbed. We also compare the results of experiments conducted using hybrid simulation on MiNT with those obtained using pure simulation. Finally, using a case study we show the usefulness of MiNT in wireless application testing and evaluation.},
keywords={wireless LAN;radio links;access protocols;large-scale systems;radiofrequency interference;radiowave propagation;telecommunication channels;mobility management (mobile radio);mobile wireless networking research;interference characteristic;radio channel;full-fledged wireless testbed;radio signals;large-scale testbed;network management;miniaturized 802.11b-based network;multihop wireless network;MiNT;protocol testing;network link;MAC;medium access control;physical layer;Testing;Wireless networks;Computational modeling;Wireless application protocol;Routing protocols;Access protocols;Spread spectrum communication;Radio propagation;Computer science;USA Councils},
doi={10.1109/INFCOM.2005.1498556},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498557,
author={J. -. Le Boudec and M. Vojnovic},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Perfect simulation and stationarity of a class of mobility models},
year={2005},
volume={4},
number={},
pages={2743-2754 vol. 4},
abstract={We define "random trip", a generic mobility model for independent mobiles that contains as special cases: the random waypoint on convex or non convex domains, random walk with reflection or wrapping, city section, space graph and other models. We use Palm calculus to study the model and give a necessary and sufficient condition for a stationary regime to exist. When this condition is satisfied, we compute the stationary regime and give an algorithm to start a simulation in steady state (perfect simulation). The algorithm does not require the knowledge of geometric constants. For the special case of random waypoint, we provide for the first time a proof and a sufficient and necessary condition of the existence of a stationary regime. Further, we extend its applicability to a broad class of non convex and multi-site examples, and provide a ready-to-use algorithm for perfect simulation. For the special case of random walks with reflection or wrapping, we show that, in the stationary regime, the mobile location is uniformly distributed and is independent of the speed vector, and that there is no speed decay. Our framework provides a rich set of well understood models that can be used to simulate mobile networks with independent node movements. Our perfect sampling is implemented to use with ns-2, and it is freely available to download from http://ica1www.epfl.ch/RandomTrip.},
keywords={mobility management (mobile radio);graph theory;sampling methods;random processes;random trip model;generic mobility model;space graph;Palm calculus;mobile network location;sampling method;Reflection;Wrapping;Calculus;Computational modeling;Cities and towns;Sufficient conditions;Steady-state;Sampling methods},
doi={10.1109/INFCOM.2005.1498557},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498558,
author={B. Sirkeci-Mersen and A. Scaglione},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A continuum approach to dense wireless networks with cooperation},
year={2005},
volume={4},
number={},
pages={2755-2763 vol. 4},
abstract={We consider a multi-hop wireless network in which a single source-destination pair communicates with the help of multiple cooperative relays. The relays deliver the source message by transmitting it in groups at every hop. The group transmissions increase the signal-to-noise ratio (SNR) of the received signal, and improve the range of communication. In this paper, we analyze the behavior of cooperative network with respect to the network parameters such as source/relay transmission powers and the decoding threshold (the minimum SNR required to decode a transmission). It is shown that if the decoding threshold is below a critical value, the message is delivered to the destination regardless of the distance between the source and the destination. Otherwise, the number of transmitting nodes diminishes at every hop, and the message does not reach to a destination far away. Our approach is based on the idea of continuum approximation, which is valid when the network density is high.},
keywords={decoding;radio networks;multihop wireless network;source-destination pair communication;cooperative network;network parameter;decoding;Wireless networks;Relays;Decoding;Signal to noise ratio;Strips;Spread spectrum communication;Protocols;Context;Broadcasting;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1498558},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498559,
author={M. Claypool and R. Kinicki and A. Kumar},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Traffic sensitive active queue management},
year={2005},
volume={4},
number={},
pages={2764-2769 vol. 4},
abstract={Delay sensitive applications, such as voice over IP and network games, often sacrifice throughput for lower delay to obtain better quality. Unfortunately, the Internet does not allow an application to choose the amount of delay or throughput it receives and instead packets from all applications receive the same best-effort service. This paper presents a new QoS mechanism called the traffic sensitive quality of service controller (TSQ) that provides better delay performance for delay sensitive applications and higher throughput for throughput sensitive applications. Also contributed are quality metrics for some typical Internet applications that can be used by an application to adapt its delay hints and evaluate QoS based on current Internet traffic conditions. Experiments suggest TSQ's benefits to performance along with retention of the current best-effort Internet environment without complicated traffic monitoring or policing.},
keywords={quality of service;telecommunication traffic;delay estimation;Internet;queueing theory;computer network management;delay sensitive application;QoS mechanism;traffic sensitive quality of service controller;TSQ;Internet;active queue management;Traffic control;Delay;Quality of service;Throughput;Web and internet services;Internet telephony;Communication system traffic control;Computer science;Videoconference;Games},
doi={10.1109/INFCOM.2005.1498559},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498560,
author={Kuan-Ta Chen and Polly Huang and Chun-Ying Huang and Chin-Laung Lei},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The impact of network variabilities on TCP clocking schemes},
year={2005},
volume={4},
number={},
pages={2770-2775 vol. 4},
abstract={TCP employs a self-clocking scheme that times the sending of packets. In that, the data packets are sent in a burst when the returning acknowledgement packets are received. This self-clocking scheme (also known as ack-clocking) is deemed a key factor to the the burstiness of TCP traffic and the source of various performance problems-high packet loss, long delay, and high delay jitter. Previous work has suggested contradictively the effectiveness of TCP pacing as a remedy to alleviate the traffic burstiness. In this paper, we analyze systematically, and in more robust experiments the impact of network variabilities on the behavior of TCP clocking schemes. We find that 1) aggregated pacing traffic could be burstier than aggregated ack-clocking traffic. Physical explanation and experimental simulations are provided to support this argument. 2) The round-trip time heterogeneity and flow multiplexing significantly influence the behaviors of both ack-clocking and pacing schemes. Evaluating the performance of clocking schemes without considering these effects is prone to inconsistent results. 3) Pacing outperforms ack-clocking in more realistic settings from the traffic burstiness point of view.},
keywords={transport protocols;telecommunication traffic;TCP clocking scheme;transmission control protocol;self-clocking scheme;round-trip time heterogeneity;flow multiplexing;Clocks;Telecommunication traffic;Traffic control;Delay;Performance analysis;Size control;Performance loss;Jitter;Robustness;Smoothing methods},
doi={10.1109/INFCOM.2005.1498560},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498561,
author={Cheng-Yuan Ho and Yi-Cheng Chan and Yaw-Chung Chen},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={An efficient mechanism of TCP-Vegas on mobile IP networks},
year={2005},
volume={4},
number={},
pages={2776-2780 vol. 4},
abstract={Mobile IP network provides hosts the connectivity to the Internet while changing locations. However, when using TCP Vegas over a mobile network, it may respond to a handoff by invoking a congestion control algorithm, thereby resulting in performance degradation, because TCP Vegas is sensitive to the change of RTT (round-trip time) and it may recognize the increased RTT as a result of network congestion. Since TCP Vegas could not differentiate whether the increased RTT is due to route change or network congestion. This work investigates how to improve the performance of Vegas after a mobile IP handoff and proposes a variation of TCP Vegas, so-called Demo-Vegas, which is able to detect the movement of two end-hosts of a connection, and re-measure the base RTT (minimum round-trip time) if necessary. The proposed mechanism maintains end-to-end semantics, and operates under the existing network infrastructure. Demo-Vegas presents a simple modification in the two end sides of a connection and uses one reserved bit in TCP header. Simulation results demonstrate that Demo-Vegas features higher performance than Vegas in mobile IP networks.},
keywords={IP networks;Internet;transport protocols;telecommunication congestion control;mobility management (mobile radio);mobile IP network;Internet;TCP Vegas;transmission control protocol;congestion control algorithm;RTT;round-trip time;Demo-Vegas;end-to-end semantic;IP networks;TCPIP;Protocols;Internet;Routing;Mobile computing;Computer science;Degradation;Computational modeling;Helium},
doi={10.1109/INFCOM.2005.1498561},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498562,
author={N. Kamiyama},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Identifying high-rate flows with less memory},
year={2005},
volume={4},
number={},
pages={2781-2785 vol. 4},
abstract={Unfairness among best-effort flows is a serious problem in the Internet. In particular, UDP flows or unresponsive flows that do not obey the TCP flow control mechanism or normal TCP flows with small RTT can consume a large share of the available bandwidth. Since they will seriously affect other flows, it is important to identify these high-rate flows and limit their throughput by selectively dropping their packets. In this paper, we propose a novel method that identifies high-rate flows using sampled packets. By reducing the timeout length for holding the flow state, the proposed method accurately identifies high-rate flows while using only a small amount of memory. We derive the identification probability for flows with arbitrary rates and obtain an identification curve that clearly reveals the identification accuracy.},
keywords={Internet;telecommunication congestion control;transport protocols;sampling methods;probability;Internet;UDP;user datagram protocol;TCP flow control mechanism;transmission control protocol;sampled packet;identification probability;Internet;Throughput;Sampling methods;Bandwidth;Information analysis;Laboratories;Stochastic processes},
doi={10.1109/INFCOM.2005.1498562},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498563,
author={T. Harks and T. Poschwatta},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Utility fair congestion control for real-time traffic},
year={2005},
volume={4},
number={},
pages={2786-2791 vol. 4},
abstract={This paper deals with a new approach to integrate congestion control for real-time applications and elastic traffic into a unified framework. In our previous work, we proposed a new fairness criterion, utility proportional fairness, that takes characteristics of real-time applications into account. We complement this framework by deriving a general method to generate utility functions for layered multimedia applications. Finally, we demonstrate our approach through ns-simulations.},
keywords={telecommunication congestion control;real-time systems;telecommunication traffic;queueing theory;congestion control;real-time application;elastic traffic;unified framework;utility proportional fairness;layered multimedia application;ns-simulations;Bandwidth;Aggregates;Encoding;Channel allocation;Distributed algorithms;Postal services;Wireless networks;Resource management;Telecommunication traffic;Traffic control},
doi={10.1109/INFCOM.2005.1498563},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498564,
author={R. Wakikawa and Y. Ohara and J. Murai},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Virtual mobility control domain for enhancements of mobility protocols},
year={2005},
volume={4},
number={},
pages={2792-2797 vol. 4},
abstract={In this paper, virtual mobility control domain (VMCD) is proposed to enhance mobility protocols such as mobile IP and network mobility (NEMO). These mobility protocols rely on a single agent called the home agent. This leads to protocol weakness in terms of system robustness and redundant routes. In VMCD, multiple anchor points serving the same home network are placed as home agents at different networks on the Internet backbone. These anchor points advertise the route of the same home network to the backbone from different networks. It is similar to anycast routing approach of root DNS. By genuine routing, packets meant for mobile nodes are always drawn into the closest anchor point and are delivered to the mobile node by the anchor point on behalf of home agent. In addition, even if one of the anchor points fails, another anchor point immediately takes over for the failed anchor point. VMCD provides better routes for mobile nodes and protocol robustness with minimal involvement of end nodes. This paper discusses the VMCD solutions and shows the efficiency and effectiveness of VMCD.},
keywords={mobility management (mobile radio);mobile computing;routing protocols;Internet;IP networks;virtual private networks;virtual mobility control domain;VMCD;mobility protocol;home agent;multiple anchor point;Internet backbone;routing approach;root DNS;Protocols;Home automation;Routing;Spine;Robustness;IP networks;Mobile communication;Web and internet services;Cellular phones;Vehicles},
doi={10.1109/INFCOM.2005.1498564},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498565,
author={M. Meo and F. Milan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A rational model for service rate allocation in peer-to-peer networks},
year={2005},
volume={4},
number={},
pages={2798-2802 vol. 4},
abstract={In peer-to-peer networks, nodes can be both resource providers and resource consumers at the same time. In this sense, the services offered by a peer-to-peer network rely on resource sharing among peers. This work focuses on how peers share their access link capacity between upload and download rates. In our model peers are rational agents, and choose their strategy in order to maximize their own utility. We suppose that the bottleneck is not in the network core, but in the network edge: the access link capacity of each peer connected to the network is a scarce resource and the peers have to compete for it. Instead of trying to settle the controversies which can arise, we imagine that every peer organizes an auction to give away its bandwidth. While the service rate is always granted to the peer who makes the lowest request, the amount of allocated rate depends on the implemented auction mechanism. Numerical experiments show that in a peer-to-peer game where the access link capacities are homogeneous, a second-price auction guarantees that the equilibrium rate allocation is optimal.},
keywords={peer-to-peer computing;resource allocation;telecommunication links;telecommunication services;peer-to-peer network;resource sharing;access link capacity;rational agent;maximization;service rate allocation;second-price auction guarantee;Intelligent networks;Peer to peer computing;Resource management;Bandwidth;Modems;Ethernet networks;Local area networks;Downlink;Game theory;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1498565},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498566,
author={T. Guven and R. J. La and M. A. Shayman and B. Bhattacharjee},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Measurement-based multipath multicast},
year={2005},
volume={4},
number={},
pages={2803-2808 vol. 4},
abstract={We propose a measurement-based routing algorithm to load balance intradomain traffic along multiple paths for multiple multicast sources. Multiple paths are established using application-layer overlaying. The proposed algorithm is able to converge under different network models, where each model reflects a different set of assumptions about the multicasting capabilities of the network. The algorithm is derived from simultaneous perturbation stochastic approximation and relies only on noisy estimates from measurements. Simulation results are presented to demonstrate the additional benefits obtained by incrementally increasing the multicasting capabilities.},
keywords={telecommunication network routing;telecommunication traffic;resource allocation;multicast communication;convergence of numerical methods;stochastic processes;perturbation techniques;approximation theory;measurement-based routing algorithm;load balance intradomain traffic;multipath multicast source;application-layer overlaying;convergence;perturbation stochastic approximation;Telecommunication traffic;Routing;Multicast algorithms;Internet;Traffic control;Stochastic processes;Load management;Cost function;Network coding;Approximation algorithms},
doi={10.1109/INFCOM.2005.1498566},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498567,
author={L. Lao and J. -. Cui and M. Gerla and D. Maggiorini},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A comparative study of multicast protocols: top, bottom, or in the middle?},
year={2005},
volume={4},
number={},
pages={2809-2814 vol. 4},
abstract={Multicast solutions have been evolving from "bottom" to "top", i.e., from IP layer (called IP multicast) to application layer (referred to as application layer multicast). Recently, there are some new proposals (named as overlay multicast) using certain "infrastructure" (composed of proxies) in the middle. Although it is well accepted that application layer multicast and overlay multicast are easier to deploy while sacrificing bandwidth efficiency compared with IP multicast, little research has been done to systematically evaluate and compare their performance. In this paper, we conduct a comparative study of different types of multicast routing protocols. We first present a qualitative comparison of three types of protocols, and then we provide a quantitative study of four representative protocols, namely, PIM-SSM, NARADA, NICE, and POM by extensive simulations. Our studies will help to answer some of the most important questions, such as which way to go: top, bottom, or in the middle?.},
keywords={IP networks;routing protocols;multicast protocols;IP layer;application layer;comparative study;multicast routing protocol;quantitative study;PIM-SSM;NARADA;NICE;POM;Multicast protocols;Computer science;Application software;Bandwidth;Routing protocols;Proposals;Pricing;Guidelines},
doi={10.1109/INFCOM.2005.1498567},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498568,
author={M. Yang and J. Ru and X. R. Li and H. Chen and A. Bashi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Predicting Internet end-to-end delay: a multiple-model approach},
year={2005},
volume={4},
number={},
pages={2815-2819 vol. 4},
abstract={This paper presents a novel approach to predict the Internet end-to-end delay using multiple-model (MM) methods. The basic idea of the MM method is to assume the system dynamics can be described by a set of models rather than a single one; by running a bank of filters (each corresponds to a certain model in the set) in parallel at the same time, the MM output is given by a combination of the estimates from these filters. Based on collected end-to-end delay data and preliminary data analysis, we propose an off-line model set design procedure using vector quantization (VQ) and short-term time series analysis so that MM methods can be applied to predict on-line measurement data. Numerical results show that the proposed MM predictor outperforms two widely used adaptive filters in terms of prediction accuracy and robustness.},
keywords={Internet;delays;channel bank filters;data analysis;vector quantisation;time series;adaptive filters;Internet;end-to-end delay;multiple-model method;bank of filters;data analysis;off-line model set;vector quantization;short-term time series analysis;adaptive filters;Internet;Filter bank;Information filtering;Information filters;Delay effects;Data analysis;Predictive models;Vector quantization;Time series analysis;Time measurement},
doi={10.1109/INFCOM.2005.1498568},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498569,
author={B. Al-Duwairi and G. Manimaran},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Intentional dropping: a novel scheme for SYN flooding mitigation},
year={2005},
volume={4},
number={},
pages={2820-2824 vol. 4},
abstract={This paper presents a novel scheme to mitigate the effect of SYN flooding attacks. The scheme, called intentional dropping based filtering, is based on the observation of client's persistence (i.e., client's reaction to packet loss by subsequent retransmissions) which is very widespread as it is built in TCP's connection setup. The main idea is to intentionally drop the first SYN packet of each connection request. Subsequent SYN packet from a request is passed only if it adheres to the TCP's timeout mechanism. Our analysis shows that the proposed scheme reduces attacker's effective attack rate significantly with an acceptable increase in connection establishment latency.},
keywords={transport protocols;telecommunication security;telecommunication congestion control;Internet;routing protocols;SYN flooding attack;intentional dropping based filtering;TCP connection;transmission control protocol;Floods;Traffic control;Web and internet services;Bandwidth;Access protocols;Computer crime;TCPIP;Computer networks;Filtering;Delay},
doi={10.1109/INFCOM.2005.1498569},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498570,
author={D. Stutzbach and R. Rejaie},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Capturing accurate snapshots of the Gnutella network},
year={2005},
volume={4},
number={},
pages={2825-2830 vol. 4},
abstract={A common approach for measurement-based characterization of peer-to-peer (P2P) systems is to capture overlay snapshots using a crawler. The accuracy of captured snapshots by P2P crawlers directly depends on both the crawling speed and the fraction of unreachable peers. This in turn affects the accuracy of the conducted characterization based on these captured snapshots. Prior studies frequently rely on crawling the network over an hour or more, during which time the overlay may change substantially. Moreover, none of the previous measurement-based studies on P2P systems have examined the accuracy of their captured snapshots or the impact on conducted characterization.},
keywords={peer-to-peer computing;telecommunication network topology;measurement-based characterization;peer-to-peer system;P2P;snapshots capturing;crawler;Gnutella network;cruiser;Crawlers;Peer to peer computing;Topology;Web pages;Information science;Error correction;Internet;Bandwidth;Sun},
doi={10.1109/INFCOM.2005.1498570},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498571,
author={Y. Zhang and M. Ahmed},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A control theoretic analysis of XCP},
year={2005},
volume={4},
number={},
pages={2831-2835 vol. 4},
abstract={Prior studies have shown that XCP D. Katabi et al., (2002), while showing high potential for effective congestion control, may have significant performance problems if it misestimates the bottleneck link capacity Y. Zhang et al., (2005). To explore the magnitude of this implication and ultimately to contain it, we have conducted a control theoretic analysis of the XCP protocol and have studied its properties in the presence of capacity estimation errors. Under such conditions, by using a revised fluid model, we have discovered that XCP will not settle at zero steady-state error. However, we found that the steady-state error is bounded by the estimation error, and this bound can be exploited in XCP router queue size planning. This preliminary analysis explains what we have observed experimentally in an implementation study of XCP.},
keywords={telecommunication links;telecommunication congestion control;queueing theory;telecommunication network planning;routing protocols;control theory;control theoretic analysis;explicit control protocol;XCP router queue size planning;congestion control;link capacity estimation error;revised fluid model;Feedback;Fluid flow control;Protocols;Estimation error;Control systems;Steady-state;Internet;Bandwidth;Optimal control;Delay},
doi={10.1109/INFCOM.2005.1498571},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498572,
author={W. Zhao and H. Schulzrinne},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={DotSlash: handling Web hotspots at dynamic content Web sites},
year={2005},
volume={4},
number={},
pages={2836-2840 vol. 4},
abstract={We propose DotSlash, a self-configuring and scalable rescue system, for handling web hotspots at dynamic content Web sites. To support load migration for dynamic content, an origin Web server sets up needed rescue servers drafted from other Web sites on the fly, and those rescue servers retrieve the scripts dynamically from the origin Web server, cache the scripts locally, and access the corresponding database server directly. We have implemented a prototype of DotSlash for the LAMP configuration, and tested our implementation using the RUBBoS bulletin board benchmark. Experiments show that by using DotSlash a dynamic content web site can completely remove its web server bottleneck, and can support a request rate constrained only by the capacity of its database server.},
keywords={electronic mail;hobby computing;data handling;Web sites;computer network reliability;file servers;safety systems;content management;DotSlash;Web hotspot handling;scalable rescue system;dynamic content Web site;load migration;database server;LAMP configuration;RUBBoS bulletin board benchmark;Web server;Databases;Lamps;Java;Information retrieval;Prototypes;Benchmark testing;Web pages;Service oriented architecture;Computer science},
doi={10.1109/INFCOM.2005.1498572},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498573,
author={D. -. Pham and S. Sugawara and T. Miki},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A new scheduler for real-time applications in differentiated services networks},
year={2005},
volume={4},
number={},
pages={2841-2846 vol. 4},
abstract={In this paper we propose a new scheduler. Deadline fair sharing (DFS), which consists of link scheduling and dropping mechanisms to provide absolute delay and loss guarantees in DiffServ networks. The scheduling mechanism uses dynamic weight associated with each class to schedule the packets and to make a dropping decision when an absolute delay guarantee violation occurs. The dropping mechanism drops packets and detects the onset of an early violation for absolute loss guarantee. When an early violation for the absolute loss guarantee of a class is detected, the scheduling mechanism gives that class more priority for transmitting its packets to prevent that violation. The simulation results show that the proposed scheduler can provide a wide range of absolute loss and delay bounds under various traffic load conditions without controlling the traffic.},
keywords={real-time systems;DiffServ networks;dynamic scheduling;resource allocation;telecommunication links;delays;telecommunication traffic;telecommunication congestion control;real-time application;differentiated services network;DiffServ network;deadline fair sharing;DFS;link scheduling;dropping decision mechanism;absolute delay guarantee;dynamic weight;packet transmission;traffic load condition;Intelligent networks;Diffserv networks;Dynamic scheduling;Delay;Telecommunication traffic;Communication system traffic control;IP networks;Scheduling algorithm;Propagation losses;Traffic control},
doi={10.1109/INFCOM.2005.1498573},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498574,
author={S. Schmid and L. Eggert and M. Brunner and J. Quittek},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Towards autonomous network domains},
year={2005},
volume={4},
number={},
pages={2847-2852 vol. 4},
abstract={The Internet is currently evolving beyond what its architecture can support. Often, the mechanisms that allow the Internet to adapt to increasingly conflicting sets of new requirements break some of its basic design principles and can thus severely interfere with end-to-end communication. This paper recognizes that increased autonomy of network regions is a key requirement for future internetworking. It outlines a new internetworking architecture that enables interoperation among a set of autonomous, heterogeneous network domains. The architecture is based on a global identity space and does not require global addressing or a shared internetworking protocol. It integrates the new concept of dynamic network composition with other recent architectural concepts, such as decoupling locators from identifiers.},
keywords={Internet;internetworking;transport protocols;open systems;autonomous network domain;Internet;end-to-end communication;internetworking protocol;heterogeneous network;identity space;dynamic network composition;Network address translation;Internet;IP networks;Protocols;Routing;National electric code;Europe;Laboratories;Internetworking;Cultural differences},
doi={10.1109/INFCOM.2005.1498574},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498575,
author={Y. Drougas and V. Kalogeraki},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A fair resource allocation algorithm for peer-to-peer overlays},
year={2005},
volume={4},
number={},
pages={2853-2858 vol. 4},
abstract={Over the past few years, peer-to-peer (P2P) systems have become very popular for constructing overlay networks of many nodes (peers) that allow users geographically distributed to share data and resources. One non-trivial question is how to distribute the data in a fair and fully decentralized manner among the peers. This is important because it can improve resource usage, minimize network latencies and reduce the volume of unnecessary traffic incurred in large-scale P2P systems. In this paper we present a technique for fair resource allocation in unstructured peer-to-peer systems. Our technique uses the fairness index of a distribution as a measure of fairness and shows how to optimize the fairness of the distribution using only local decisions. Load balancing is achieved by replicating documents across multiple nodes in the system. Our experimental results demonstrate that our technique is scalable, has low overhead and achieves good load balance even under skewed demand.},
keywords={resource allocation;peer-to-peer computing;telecommunication traffic;fair resource allocation algorithm;peer-to-peer overlay;P2P system;network latency minimization;fairness index;load balancing;document replication;network traffic;Resource management;Peer to peer computing;Large-scale systems;Sea measurements;Information retrieval;Protocols;Computer science;Data engineering;Delay;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1498575},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498576,
author={Z. Zhong and Z. Nelakuditi and Y. Yu and S. Lee and J. Wang and C. -. Chuah},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Failure inferencing based fast rerouting for handling transient link and node failures},
year={2005},
volume={4},
number={},
pages={2859-2863 vol. 4},
abstract={With the emergence of voice over IP and other real-time business applications, there is a growing demand for an IP network with high service availability. Unfortunately, in today's Internet, transient failures occur frequently due to faulty interfaces, router crashes, etc., and current IP networks lack the resiliency needed to provide high availability. To enhance availability, we proposed failure inferencing based fast rerouting (FIFR) approach that exploits the existence of a forwarding table per line-card, for lookup efficiency in current routers, to provide fast rerouting similar to MPLS, while adhering to the destination-based forwarding paradigm. In our previous work, we have shown that the FIFR approach can deal with single link failures. In this paper, we extend the FIFR approach to ensure loop-free packet delivery in case of single router failures also, thus mitigating the impact of many scenarios of failures. We demonstrate that the proposed approach not only provides high service availability but also incurs minimal routing overhead.},
keywords={Internet telephony;IP networks;computer network reliability;telecommunication links;real-time systems;telecommunication network routing;network interfaces;table lookup;transient link handling;node failure;voice over IP;real-time business application;IP network;Internet;faulty interface;router crash;failure inferencing based fast rerouting;FIFR;table per line-card forwarding;lookup efficiency;destination-based forwarding;loop-free packet delivery;minimal routing overhead;IP networks;Availability;Multiprotocol label switching;Routing;Internet telephony;Computer crashes;Web and internet services;Mission critical systems;Virtual private networks;Banking},
doi={10.1109/INFCOM.2005.1498576},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498577,
author={A. Dumitrescu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Efficient distributed admission control for core-stateless networks},
year={2005},
volume={4},
number={},
pages={2864-2869 vol. 4},
abstract={Providing service guarantees requires strict admission control to ensure that the resources are not over-allocated. On another hand, limiting the core nodes' role has been recognized as a key aspect in providing scalable quality of service (QoS) solutions. This paper presents a scalable multiple-token mechanism that ensures a distributed and coordinated resource allocation along the logical ring of the ingress/edge nodes. The proposed mechanism alleviates the scalability problem by keeping all the admission control operations in the ingress/edge nodes while preserving guaranteed service semantics. By distributing the available bandwidth of the links over multiple tokens, increased robustness and low latency under light load conditions are achieved, while the zero-false positives property is maintained. The erroneous connection denials, which could be due to the distribution of available bandwidth information, are avoided by an accumulation procedure that concentrates the available bandwidth information whenever necessary.},
keywords={resource allocation;telecommunication congestion control;quality of service;telecommunication network reliability;token networks;bandwidth allocation;admission control;distributed resource allocation;quality of service;scalable QoS;multiple-token mechanism;coordinated resource allocation;logical ring;ingress-edge node;guaranteed service semantics;zero-false positive property;accumulation procedure;bandwidth information;core stateless network;Admission control;Quality of service;Bandwidth;Delay;Resource management;Scalability;Robustness;Testing;Aggregates;State estimation},
doi={10.1109/INFCOM.2005.1498577},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498578,
author={A. Kapoor and A. Falk and T. Faber and Y. Pryadkin},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Achieving faster access to satellite link bandwidth},
year={2005},
volume={4},
number={},
pages={2870-2875 vol. 4},
abstract={TCP with Van Jacobson congestion control (VJCC) is known to have poor performance over large bandwidth-delay product paths. Long delay paths, in particular, can display very poor behavior with VJCC slowly probing to acquire available capacity. TCP performance enhancing proxies (PEPs) constitute one mechanism for ameliorating poor VJCC end-to-end performance by splitting TCP connections around a long-delay link or network, and using alternate congestion control dynamics across the troublesome portion. Previous congestion control techniques for use over satellite links have typically constituted either tweaks to the Van Jacobson algorithms, Vegas-style congestion control or disabling congestion control altogether in favor of a manual send-rate. This paper analyzes results from measurements of a new congestion control mechanism, the explicit Control protocol or XCP, between PEPs with a simulated geosynchronous satellite link in the path. We show that connections using an XCP PEP acquire their share of expensive satellite bandwidth up to 70 times faster than end-to-end TCP with VJCC.},
keywords={transport protocols;satellite links;telecommunication congestion control;delays;transport control protocol;TCP;Van Jacobson congestion control;VJCC;bandwidth-delay product path;performance enhancing proxies;PEP;explicit control protocol;XCP;geosynchronous satellite link;satellite bandwidth;end-to-end performance;Satellites;Bandwidth;Jacobian matrices;Delay;Internet;Displays;Indium phosphide;Algorithm design and analysis;Protocols;Resilience},
doi={10.1109/INFCOM.2005.1498578},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498579,
author={R. Fonseca and P. Sharma and S. Banerjee and S. -. Lee and S. Basu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Distributed querying of Internet distance information},
year={2005},
volume={4},
number={},
pages={2876-2881 vol. 4},
abstract={Estimation of network proximity among nodes is an important building block in several applications like service selection and composition, multicast tree formation, and overlay construction. Recently, scalable techniques have been proposed to estimate inter-node latencies, including network coordinate systems like GNP and Vivaldi. However, existing mechanisms for querying such information do not scale well to a very large number of nodes, when one wants to accurately find a set of nodes globally closest to a given node. In this paper we are concerned with distributing the position data among a set of infrastructure nodes, and propose ways of partitioning and querying this data. The trade-offs between accuracy and overhead in this distributed infrastructure are explored. We evaluate our solution through simulations with real and synthetic network measurement data.},
keywords={query processing;Internet;computer network reliability;distributed databases;distributed query;Internet distance information;network proximity estimation;scalable technique;internode latency;synthetic network measurement data;real network measurement data;Network servers;Delay;Databases;Position measurement;Economic indicators;Web and internet services;Bandwidth;Error analysis;Resource management;Size measurement},
doi={10.1109/INFCOM.2005.1498579},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498434,
author={Xin Chen and Shansi Ren and Haining Wang and Xiaodong zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={SCOPE: scalable consistency maintenance in structured P2P systems},
year={2005},
volume={3},
number={},
pages={1502-1513 vol. 3},
abstract={While current peer-to-peer (P2P) systems facilitate static file sharing, newly developed applications demand that P2P systems be able to manage dynamically changing files. Maintaining consistency between frequently updated files and their replicas is a fundamental reliability requirement for a P2P system. In this paper, we present SCOPE, a structured P2P system supporting consistency among a large number of replicas. By building a replica-partition-tree (RPT) for each key, SCOPE keeps track of the locations of replicas and then propagates update notifications. Our theoretical analyses and experimental results demonstrate that SCOPE can effectively maintain replica consistency while preventing hot spot and node-failure problems. Its efficiency in maintenance and failure-recovery is particularly attractive to the deployment of large-scale P2P systems.},
keywords={peer-to-peer computing;file organisation;maintenance engineering;computer network reliability;trees (mathematics);scalable consistency maintenance;structured P2P systems;peer-to-peer systems;dynamically-changing files management;replica-partition-tree;failure-recovery;Computer science;Educational institutions;Peer to peer computing;Maintenance;Buildings;Broadcasting;Privacy;Application software;Large-scale systems;Publishing},
doi={10.1109/INFCOM.2005.1498434},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498435,
author={Rongmei Zhang and Y. C. Hu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Assisted peer-to-peer search with partial indexing},
year={2005},
volume={3},
number={},
pages={1514-1525 vol. 3},
abstract={This paper proposes to improve search in unstructured peer-to-peer (P2P) overlay networks by building a partial index of shared data. The index maintains two types of information: the top interests of peers and globally unpopular data, both characterized by data properties. The proposed search protocol, assisted search with partial indexing, makes use of the index to improve search in three ways. First, the index assists peers to find other peers with similar interests and the unstructured search overlay is formed to reflect peer interests. Second, the index also provides search hints for those data difficult to locate by exploring peer interest locality, and these hints can be used for second-chance search. Third, the index helps to locate unpopular data items. Experiments based on both the Web and P2P file sharing traces show that the assisted search with a lightweight partial indexing service can significantly improve the success rate and search speed in locating data, while inducing less traffic overhead than Gnutella and a hit-rate based protocol in unstructured P2P systems.},
keywords={peer-to-peer computing;search problems;protocols;indexing;assisted peer-to-peer search;search protocol;partial indexing;peer interest locality;Web;P2P file sharing;Peer to peer computing;Indexing;Protocols;Network servers;Intelligent networks;Robustness;Network topology;File servers},
doi={10.1109/INFCOM.2005.1498435},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498436,
author={C. Gkantsidis and M. Mihail and A. Saberi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Hybrid search schemes for unstructured peer-to-peer networks},
year={2005},
volume={3},
number={},
pages={1526-1537 vol. 3},
abstract={We study hybrid search schemes for unstructured peer-to-peer networks. We quantify performance in terms of number of hits, network overhead, and response time. Our schemes combine flooding and random walks, look ahead and replication. We consider both regular topologies and topologies with supernodes. We introduce a general search scheme, of which flooding and random walks are special instances, and show how to use locally maintained network information to improve the performance of searching. Our main findings are: (a) a small number of supernodes in an otherwise regular topology can offer sharp savings in the performance of search, both in the case of search by flooding and search by random walk, particularly when it is combined with 1-step replication. We quantify, analytically and experimentally, that the reason of these savings is that the search is biased towards nodes that yield more information. (b) There is a generalization of search, of which flooding and random walk are special instances, which may take further advantage of locally maintained network information, and yield better performance than both flooding and random walk in clustered topologies. The method determines edge critically and is reminiscent of fundamental heuristics from the area of approximation algorithms.},
keywords={search problems;peer-to-peer computing;telecommunication network topology;hybrid search schemes;unstructured peer-to-peer networks;flooding;random walks;look ahead;replication;network topology;Peer to peer computing;Floods;Network topology;Delay;Performance analysis;Computer networks;Educational institutions;Computer network management;Technology management;Engineering management},
doi={10.1109/INFCOM.2005.1498436},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498437,
author={M. Adler and R. Kumar and K. Ross and D. Rubenstein and T. Suel and D. D. Yao},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Optimal peer selection for P2P downloading and streaming},
year={2005},
volume={3},
number={},
pages={1538-1549 vol. 3},
abstract={In a P2P system, a client peer may select one or more server peers to download a specific file. In a P2P resource economy, the server peers charge the client for the downloading. A server peer's price would naturally depend on the specific object being downloaded, the duration of the download, and the rate at which the download is to occur. The optimal peer selection problem is to select, from the set of peers that have the desired object, the subset of peers and download rates that minimizes cost. In this paper we examine a number of natural peer selection problems for both P2P downloading and P2P streaming. For downloading, we obtain the optimal solution for minimizing the download delay subject to a budget constraint, as well as the corresponding Nash equilibrium. For the streaming problem, we obtain a solution that minimizes cost subject to continuous playback while allowing for one or more server peers to fail during the streaming process. The methodologies developed in this paper are applicable to a variety of P2P resource economy problems.},
keywords={peer-to-peer computing;client-server systems;optimal peer selection;P2P downloading;P2P streaming;client peer;server peers;Nash equilibrium;P2P resource economy problems;Peer to peer computing;Bandwidth;Information science;File servers;Distributed computing;Computer science;Cost function;Nash equilibrium;Application software;Biotechnology},
doi={10.1109/INFCOM.2005.1498437},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498438,
author={A. Kumar and E. Altman and D. Miorandi and M. Goyal},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={New insights from a fixed point analysis of single cell IEEE 802.11 WLANs},
year={2005},
volume={3},
number={},
pages={1550-1561 vol. 3},
abstract={We study a fixed point formalisation of the well known analysis of Bianchi. We provide a significant simplification and generalisation of the analysis. In this more general framework, the fixed point solution and performance measures resulting from it are studied. Uniqueness of the fixed point is established. Simple and general throughput formulas are provided. It is shown that the throughput of any flow will be bounded by the one with the smallest transmission rate. The aggregate throughput is bounded by the reciprocal of the harmonic mean of the transmission rates. In an asymptotic regime with a large number of nodes, explicit formulas for the collision probability, the aggregate attempt rate and the aggregate throughput are provided. The results from the analysis are compared with ns2 simulations, and also with an exact Markov model of the back-off process. It is shown how the saturated network analysis can be used to obtain TCP transfer throughputs in some cases.},
keywords={wireless LAN;Markov processes;transport protocols;cellular radio;single cell IEEE 802.11 WLAN;throughput formulas;aggregate throughput;Markov model;back-off process;saturated network analysis;TCP transfer throughputs;Wireless LAN;Throughput;Aggregates;Equations;Analytical models;Wireless networks;Media Access Protocol;Wireless application protocol;Transmitters;Stochastic processes},
doi={10.1109/INFCOM.2005.1498438},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498439,
author={A. Vasan and R. Ramjee and T. Woo},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={ECHOS - enhanced capacity 802.11 hotspots},
year={2005},
volume={3},
number={},
pages={1562-1572 vol. 3},
abstract={The total number of hotspot users around the world is expected to grow from 9.3 million at the end of 2003 to 30 million at the end of 2004 according to researcher Gartner. Given the explosive growth in hotspot wireless usage, enhancing capacity of 802.11-based hot-spot wireless networks is an important problem. In this paper, we make two important contributions. We first present the AP-CST algorithm that dynamically adjusts the carrier sense threshold (CST) in order to allow more flows to coexist in current 802.11 architectures. We then extend the current hotspot engineering paradigm by allowing every cell and AP access to all available channels. These cells are then managed by the RNC-SC algorithm running in a centralized radio network controller. This algorithm assigns mobile stations to appropriate cells/channels and adjusts transmit power values dynamically, thereby exploiting spatial heterogeneity in distribution of users at the hotspots. Through detailed and extensive simulations, we show that the performance of 802.11-based hotspots can be improved by up to 195% per-cell and 70% overall.},
keywords={cellular radio;wireless LAN;telecommunication channels;centralised control;telecommunication control;carrier sense multiple access;enhanced capacity 802.11;hot-spot wireless networks;carrier sense threshold;channels;centralized radio network controller;mobile stations;spatial heterogeneity;Hardware;Explosives;Wireless networks;Computer science;Educational institutions;Wireless sensor networks;Heuristic algorithms;Power engineering and energy;Centralized control;Delay},
doi={10.1109/INFCOM.2005.1498439},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498440,
author={D. Qiao and K. G. Shin},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Smart power-saving mode for IEEE 802.11 wireless LANs},
year={2005},
volume={3},
number={},
pages={1573-1583 vol. 3},
abstract={Static PSM (power-saving mode) schemes employed in the current IEEE 802.11 implementations could not provide any delay-performance guarantee because of their fixed wakeup intervals. In this paper, we propose a smart PSM (SPSM) scheme, which directs a wireless station to sleep/wake up according to an "optimal" sequence, such that the desired delay performance is guaranteed with minimum energy consumption. Instead of constructing the sequence directly, SPSM takes a unique two-step approach. First, it translates an arbitrary user-desired delay performance into a generic penalty function. Second, it provides a generic algorithm that takes the penalty function as the input and produces the optimal station action sequence automatically. This way, the potentially-complicated energy-consumption-minimization problem subject to delay-performance constraints is simplified and solved systematically. Our simulation results show that, with a two-stair penalty function, SPSM achieves delay performance similar to the BSD (bounded slowdown) protocol under various scenarios, but always with less energy consumption, thanks to its capability to adapt to changes in the response-time distribution. Moreover, because of SPSM's two-step design feature, it is more flexible than BSD in the sense of being able to meet arbitrary user-desired delay requirement, e.g., providing soft delay-bound guarantees with power penalty functions.},
keywords={wireless LAN;power consumption;telecommunication power supplies;smart power-saving mode;IEEE 802.11 wireless LAN;wireless station;minimum energy consumption;energy-consumption-minimization problem;delay-performance constraints;response-time distribution;Wireless LAN;Local area networks;Delay;Wireless sensor networks;Energy consumption;Portable computers;Personal digital assistants;Batteries;Energy management;Protocols},
doi={10.1109/INFCOM.2005.1498440},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498441,
author={Chun-Ting Chou and S. N. Shankar and K. G. Shin},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Achieving per-stream QoS with distributed airtime allocation and admission control in IEEE 802.11e wireless LANs},
year={2005},
volume={3},
number={},
pages={1584-1595 vol. 3},
abstract={To support the transmission of (high-rate and oftenbursty) multimedia data with performance guarantees in an IEEE 802.11e wireless local area network (LAN), it is crucial to design judicious algorithms for admission control and resource allocation. The traffic specification element (TSPEC) of the new IEEE 802.11e standard is used to facilitate the design of the admission control. Based on the traffic profile given in the TSPEC and the dual-token bucket regulation, a guaranteed rate is derived for our airtime-based admission control. The admission control is integrated with the contention-based enhanced distributed channel access (EDCA), which together can provide so-called "parameterized QoS" - as in the polling-based HCF controlled channel access (HCCA) - via a new distributed, quantitative control of stations' airtime usage. We also extend the current QoS signaling of HCCA defined in IEEE 802.11e to perform admission control for this enhanced EDCA. Furthermore, we extend the integrated scheme for QoS provisioning in ad hoc wireless LANs and design appropriate signaling procedures. We evaluate via simulation the effectiveness of this parameterized QoS-capable EDCA scheme, and demonstrate its advantages over the centralized, polling-based HCCA scheme.},
keywords={quality of service;wireless LAN;multimedia communication;telecommunication congestion control;resource allocation;telecommunication traffic;telecommunication channels;telecommunication signalling;ad hoc networks;access protocols;multi-access systems;per-stream QoS;distributed airtime allocation;IEEE 802.11e wireless LAN;multimedia data;wireless local area network;admission control;resource allocation;traffic specification element;dual-token bucket regulation;airtime-based admission control;contention-based enhanced distributed channel access;parameterized QoS;polling-based HCF controlled channel access;quantitative control;QoS signaling;ad hoc wireless LAN;Admission control;Wireless LAN;Local area networks;Streaming media;Multimedia systems;USA Councils;Telecommunication traffic;Communication system traffic control;Resource management;Laboratories},
doi={10.1109/INFCOM.2005.1498441},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498442,
author={WeiZhao Wang and Xiang-Yang Li and Zheng Sun and Yu Wang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Design multicast protocols for non-cooperative networks},
year={2005},
volume={3},
number={},
pages={1596-1607 vol. 3},
abstract={Conventionally, most network protocols assume that the network entities that participate in the network activities will always behave as instructed. However, in practice, most network entities will try to maximize their own benefits instead of altruistically contribute to the network by following the prescribed protocols, which is known as selfish. Thus, new protocols should be designed for the non-cooperative network, which is composed of selfish entities. In this paper, we specifically show how to design strategyproof multicast protocols for non-cooperative networks such that these selfish entities will follow the protocols out of their own interests. By assuming that a group of receivers is willing to pay to receive the multicast service, we specifically give a general framework to decide whether it is possible, and how if possible to transform an existing multicast protocol to a strategyproof multicast protocol. We then show how the payments to those relay entities are shared fairly among all receivers so that it encourages collaboration among receivers. As a running example, we show how to design the strategyproof multicast protocol for the currently used core-based multicast structure. We also conduct extensive simulations to study the relations between payment and cost of the multicast structure.},
keywords={multicast protocols;telecommunication services;multicast protocols;noncooperative networks;receivers;multicast service;core-based multicast structure;Multicast protocols;Costs;Computer science;Network topology;Unicast;Algorithm design and analysis;Frame relay;Collaboration;Combinatorial mathematics;Resource management},
doi={10.1109/INFCOM.2005.1498442},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498443,
author={D. S. Lun and N. Ratnakar and R. Koetter and M. Medard and E. Ahmed and Hyunjoo Lee},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Achieving minimum-cost multicast: a decentralized approach based on network coding},
year={2005},
volume={3},
number={},
pages={1607-1617 vol. 3},
abstract={We present decentralized algorithms that compute minimum-cost subgraphs for establishing multicast connections in networks that use coding. These algorithms, coupled with existing decentralized schemes for constructing network codes, constitute a fully decentralized approach for achieving minimum-cost multicast. Our approach is in sharp contrast to the prevailing approach based on approximation algorithms for the directed Steiner tree problem, which is suboptimal and generally assumes centralized computation with full network knowledge. We also give extensions beyond the basic problem of fixed-rate multicast in networks with directed point-to-point links, and consider the case of elastic rate demand as well as the problem of minimum-energy multicast in wireless networks.},
keywords={multicast communication;encoding;approximation theory;trees (mathematics);radio links;minimum-cost multicast;decentralized approach;network coding;minimum-cost subgraphs;approximation algorithms;directed Steiner tree problem;fixed-rate multicast;point-to-point links;elastic rate demand;minimum-energy multicast;wireless networks;Network coding;Multicast algorithms;Approximation algorithms;Cost function;Computer networks;Relays;Electronic mail;Laboratories;Wireless networks;Tree graphs},
doi={10.1109/INFCOM.2005.1498443},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498444,
author={Zongpeng Li and Baochun Li},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Efficient and distributed computation of maximum multicast rates},
year={2005},
volume={3},
number={},
pages={1618-1628 vol. 3},
abstract={The transmission of information within a data network is constrained by network topology and link capacities. In this paper, we study the fundamental upper bound of information multicast rates with these constraints, given the unique replicable and encodable property of information flows. Based on recent information theory advances in coded multicast rates, we are able to formulate the maximum multicast rate problem as a linear network optimization problem, assuming the general undirected network model. We then proceed to apply Lagrangian relaxation techniques to obtain (1) a necessary and sufficient condition for multicast rate feasibility, and (2) a subgradient solution for computing the maximum rate and the optimal routing strategy to achieve it. The condition we give is a generalization of the well-known conditions for the unicast and broadcast cases. Our subgradient solution takes advantage of the underlying network flow structure of the problem, and therefore outperforms general linear programming solving techniques. It also admits a natural intuitive interpretation, and is amenable to fully distributed implementations.},
keywords={multicast communication;telecommunication network topology;telecommunication network routing;linear programming;gradient methods;maximum multicast rates;data network;network topology;link capacities;information theory;linear network optimization problem;Lagrangian relaxation techniques;subgradient solution;optimal routing strategy;network flow structure;linear programming solving techniques;Distributed computing;Network topology;Upper bound;Information theory;Lagrangian functions;Sufficient conditions;Routing;Unicast;Broadcasting;Linear programming},
doi={10.1109/INFCOM.2005.1498444},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498445,
author={F. Baccelli and A. Chaintreau and Zhen Liu and A. Riabov},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The one-to-many TCP overlay: a scalable and reliable multicast architecture},
year={2005},
volume={3},
number={},
pages={1629-1640 vol. 3},
abstract={We consider reliable multicast in overlay networks where nodes have finite-size buffers and are subject to failures. We address issues of end-to-end reliability and throughput scalability in this framework. We propose a simple architecture which consists of using distinct point-to-point TCP connections between adjacent pairs of end-systems, together with a back-pressure control mechanism regulating the transfers of adjacent TCP connections, as well as a back-up buffering system handling node failures. This architecture, that we call the one-to-many TCP overlay, is a natural extension of TCP to the one-to-many case, in that it adapts the rate of the group communication to local congestion in a decentralized way via the window back-pressure mechanism. Using theoretical investigations, experimentations in the Internet, and large network simulations, we show that this architecture provides end-to-end reliability and can tolerate multiple simultaneous node failures, provided the backup buffers are sized appropriately. We also show that under random perturbations caused by cross traffic described in the paper, the throughput of this reliable group communication is always larger than a positive constant, that does not depend on the group size. This scalability result contrasts with known results about the non-scalability of IP-supported multicast for reliable group communication.},
keywords={transport protocols;computer network reliability;Internet;IP networks;telecommunication traffic;multicast protocols;one-to-many TCP overlay;reliable multicast architecture;scalable multicast architecture;overlay networks;end-to-end reliability;throughput scalability;point-to-point TCP connections;back-pressure control mechanism;back-up buffering system handling node failures;group communication;window back-pressure mechanism;Internet;cross traffic;random perturbations;IP-supported multicast;Throughput;Scalability;Telecommunication network reliability;Multicast protocols;Streaming media;Communication system control;Control systems;IP networks;Reliability theory;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1498445},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498446,
author={M. Sundstron and L. -. Larzon},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={High-performance longest prefix matching supporting high-speed incremental updates and guaranteed compression},
year={2005},
volume={3},
number={},
pages={1641-1652 vol. 3},
abstract={Longest prefix matching is frequently used for IP forwarding in the Internet. Data structures used must be not only efficient, hut also robust against pathological entries caused by an adversary or misconfiguration. In this paper, we attack the longest prefix matching problem by presenting a new algorithm supporting high lookup performance, fast incremental updates and guaranteed compression ratio. High lookup performance is achieved by using only four memory accesses. Guaranteed compression ratio is achieved by combining direct indexing with an implicit tree structure and carefully choosing which construct to use when updating the forwarding table. Fast incremental updates are achieved by a new memory management technique featuring fast variable size allocation and deallocation while maintaining zero fragmentation. An IPv4 forwarding table data structure can be implemented in software or hardware within 2.7 Mb of memory to represent 2/sup 18/ routing entries. Incremental updates require only 752 memory accesses in worst case for the current guaranteed compression ratio. For a hardware implementation, we can use 300 MHz SRAM organized in four memory banks and four pipeline stages to achieve a guaranteed performance of 300 million lookups per second, corresponding to /spl sim/ 100 Gbit/s wire speed forwarding, and 400,000 incremental updates per second. In measurements performed on a 3.0 GHz Pentium 4 machine using a routing table with more than 2/sup 17/ entries, we can forward over 27 million IPv4 packets per second, which is equivalent to wire speeds exceeding 10 Gbit/s. On the same machine and with the same routing table, we can perform over 230,000 incremental updates/second.},
keywords={IP networks;Internet;tree data structures;storage management;telecommunication network routing;high-performance longest prefix matching;high-speed incremental updates;guaranteed compression;IP forwarding;Internet;direct indexing;tree structure;forwarding table;memory management technique;fast variable size allocation;IPv4 forwarding table data structure;SRAM;routing table;Routing;Data structures;Hardware;Wire;Internet;Robustness;Pathology;Indexing;Tree data structures;Memory management},
doi={10.1109/INFCOM.2005.1498446},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498447,
author={S. Boyd and A. Ghosh and B. Prabhakar and D. Shah},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Gossip algorithms: design, analysis and applications},
year={2005},
volume={3},
number={},
pages={1653-1664 vol. 3},
abstract={Motivated by applications to sensor, peer-to-peer and ad hoc networks, we study distributed asynchronous algorithms, also known as gossip algorithms, for computation and information exchange in an arbitrarily connected network of nodes. Nodes in such networks operate under limited computational, communication and energy resources. These constraints naturally give rise to "gossip" algorithms: schemes which distribute the computational burden and in which a node communicates with a randomly chosen neighbor. We analyze the averaging problem under the gossip constraint for arbitrary network, and find that the averaging time of a gossip algorithm depends on the second largest eigenvalue of a doubly stochastic matrix characterizing the algorithm. Using recent results of Boyd, Diaconis and Xiao (2003), we show that minimizing this quantity to design the fastest averaging algorithm on the network is a semi-definite program (SDP). In general, SDPs cannot be solved distributedly; however, exploiting problem structure, we propose a subgradient method that distributedly solves the optimization problem over the network. The relation of averaging time to the second largest eigenvalue naturally relates it to the mixing time of a random walk with transition probabilities that are derived from the gossip algorithm. We use this connection to study the performance of gossip algorithm on two popular networks: wireless sensor networks, which are modeled as geometric random graphs, and the Internet graph under the so-called preferential connectivity model.},
keywords={eigenvalues and eigenfunctions;matrix algebra;stochastic processes;gradient methods;optimisation;wireless sensor networks;Internet;graph theory;gossip algorithms;asynchronous algorithms;arbitrarily connected network;averaging problem;gossip constraint;eigenvalue;stochastic matrix;semidefinite program;subgradient method;optimization problem;random walk;transition probability;wireless sensor networks;geometric random graphs;Internet graph;preferential connectivity model;Algorithm design and analysis;Peer to peer computing;Computer networks;Distributed computing;Eigenvalues and eigenfunctions;Solid modeling;Ad hoc networks;Energy resources;Stochastic processes;Optimization methods},
doi={10.1109/INFCOM.2005.1498447},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498448,
author={U. Irmak and S. Mihaylov and T. Suel},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Improved single-round protocols for remote file synchronization},
year={2005},
volume={3},
number={},
pages={1665-1676 vol. 3},
abstract={Given two versions of a file, a current version located on one machine and an outdated version known only to another machine, the remote file synchronization problem is how to update the outdated version over a network with a minimal amount of communication. In particular, when the versions are very similar, the total data transmitted should be significantly smaller than the file size. File synchronization problems arise in many application scenarios such as Web site mirroring, file system backup and replication, and Web access over slow links. An open source tool for this problem, called rsync and included in many Linux distributions, is widely used in such scenarios, rsync uses a single round of messages between the two machines. While recent research has shown that significant additional savings in bandwidth consumption are possible through the use of optimized multi-round protocols, there are many scenarios where multiple rounds are undesirable. In this paper, we study single-round protocols for file synchronization that offer significant improvements over rsync. Our main contribution is a new approach to file synchronization based on the use of erasure codes. Using this approach, we design a single-round protocol that is provably efficient with respect to common measures of file distance, and another optimized practical protocol that shows promising improvements over rsync on our data sets. In addition, we show how to obtain moderate improvements by engineering the rsync approach.},
keywords={protocols;file organisation;synchronisation;Linux;single-round protocols;remote file synchronization;open source tool;rsync;Linux distributions;bandwidth consumption;Protocols;File systems;Linux;Bandwidth;Web pages;Computational Intelligence Society;Design optimization;Maintenance engineering;Open source software;Software algorithms},
doi={10.1109/INFCOM.2005.1498448},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498449,
author={Dongsheng Li and Xicheng Lu and Jie Wu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={FISSIONE: a scalable constant degree and low congestion DHT scheme based on Kautz graphs},
year={2005},
volume={3},
number={},
pages={1677-1688 vol. 3},
abstract={The distributed hash table (DHT) scheme has become the core component of many large-scale peer-to-peer networks. Degree, diameter, and congestion are important measures of DHT schemes. Many proposed DHT schemes are based on traditional interconnection topologies, one being the Kautz graph, which is a static topology with many good properties such as optimal diameter, optimal fault-tolerance, and low congestion. In this paper, we propose FISSIONE: the first effective DHT scheme based on Kautz graphs. FISSIONE is constant degree, O(log N) diameter, and (1 + o(1))-congestion-free. FISSIONE shows that a DHT scheme with constant degree and constant congestion can still achieve O(log N) diameter, which is better than the lower bound /spl Omega/(N/sup 1/d/) conjectured before. The average degree of FISSIONE is 4, the diameter is less than 2 log N, and the maintenance message cost is less than 3 log N. The average routing path length is about log N and is shorter than CAN or Koorde with the same degree when the peer-to-peer network is large-scale. FISSIONE can achieve good load balance, high performance, and low congestion and these properties are carefully evaluated by formal proofs or simulations in the paper.},
keywords={graph theory;file organisation;peer-to-peer computing;telecommunication network routing;telecommunication network topology;Kautz graphs;distributed hash table;large-scale peer-to-peer networks;interconnection topologies;static topology;maintenance message;average routing path length;FISSIONE;Peer to peer computing;Routing;Large-scale systems;Topology;Internet;Fault tolerance;Costs;Computational modeling;Computer industry;Memory},
doi={10.1109/INFCOM.2005.1498449},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498450,
author={Ningning Hu and Li Li and Z. M. Mao and P. Steenkiste and Jia Wang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A measurement study of Internet bottlenecks},
year={2005},
volume={3},
number={},
pages={1689-1700 vol. 3},
abstract={Recent advances in Internet measurement tools have made it possible to locate bottleneck links that constrain the available bandwidth of Internet paths. In this paper, we provide a detailed study of Internet path bottlenecks. We focus on the following four aspects: the persistence of bottleneck location, the sharing of bottlenecks among destination clusters, the packet loss and queueing delay of bottleneck links, and the relationship with router and link properties, including router CPU load, router memory load, link traffic load, and link capacity. We find that 20% - 30% of the source-destination pairs in our measurement have a persistent bottleneck; fewer than 10% of the destinations in a prefix cluster share a bottleneck more than half of the time; 60% of the bottlenecks on lossy paths can be correlated with a loss point no more than 2 hops away; and bottlenecks can be clearly correlated with link load, while presenting no strong relationship with link capacity, router CPU and memory load.},
keywords={Internet;queueing theory;telecommunication links;telecommunication network routing;telecommunication traffic;Internet bottlenecks;destination clusters;packet loss;queueing delay;bottleneck links;router CPU load;router memory load;link traffic load;link capacity;Telecommunication traffic;Loss measurement;Time measurement;Traffic control;Routing;Bandwidth;Delay effects;Web and internet services;Network servers;Web server},
doi={10.1109/INFCOM.2005.1498450},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498451,
author={D. B. Chua and E. D. Kolaczyk and M. Crovella},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Efficient monitoring of end-to-end network properties},
year={2005},
volume={3},
number={},
pages={1701-1711 vol. 3},
abstract={It is often desirable to monitor end-to-end properties, such as loss rates or packet delays, across an entire network. However, active end-to-end measurement in such settings does not scale well, and so complete network-wide measurement quickly becomes infeasible. More efficient measurement strategies are therefore needed. Previous work, examining this problem from a linear algebraic perspective, has shown that for exact recovery of complete end-to-end network properties, the number of paths that need to be monitored can be reduced to approximately the number of links in the network. In this paper we ask whether measurement strategies of even greater efficiency are possible. We recast the problem as one of statistical prediction and show that end-to-end network properties may be accurately predicted in many cases using a significantly smaller set of carefully chosen paths than needed for exact recovery. We formulate a general framework for the prediction problem, propose a simple class of predictors for standard quantities of interest (e.g., averages, totals, differences), and show that linear algebraic methods of subset selection may be used to make effective choice of which paths to measure. We explore the accuracy of the resulting methods both analytically and numerically, in the context of real network topologies of varying size. The feasibility of our methods derives from the low effective rank of routing matrices as encountered in practice, which appears to be a new observation of interest in its own right. The resulting framework, which is quite general, appears to hold promise for studying and improving the efficiency of monitoring of end-to-end-network properties.},
keywords={monitoring;telecommunication network routing;telecommunication network reliability;linear algebra;statistical analysis;end-to-end network properties monitoring;statistical prediction;linear algebraic methods;routing matrices;Routing;Computerized monitoring;Mathematics;Statistics;Delay;Condition monitoring;Computer science;Measurement standards;Network topology;Aggregates},
doi={10.1109/INFCOM.2005.1498451},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498452,
author={I. Keslassy and Cheng-Shang Chang and N. McKeown and Duan-Shin Lee},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Optimal load-balancing},
year={2005},
volume={3},
number={},
pages={1712-1722 vol. 3},
abstract={This paper is about load-balancing packets across multiple paths inside a switch, or across a network. It is motivated by the recent interest in load-balanced switches. Load-balanced switches provide an appealing alternative to crossbars with centralized schedulers. A load-balanced switch has no scheduler, is particularly amenable to optics, and - most relevant here -guarantees 100% throughput. A uniform mesh is used to load-balance packets uniformly across all 2-hop paths in the switch. In this paper we explore whether this particular method of load-balancing is optimal in the sense that it achieves the highest throughput for a given capacity of interconnect. The method we use allows the load-balanced switch to be compared with ring, torus and hypercube interconnects, too. We prove that for a given interconnect capacity, the load-balancing mesh has the maximum throughput. Perhaps surprisingly, we find that the best mesh is slightly non-uniform, or biased, and has a throughput of N/(2N - 1), where N is the number of nodes.},
keywords={resource allocation;packet switching;telecommunication network routing;Internet;optimal load-balancing;multiple paths;load-balanced switch;load-balance packets;interconnect capacity;maximum throughput;load-balanced routing network;Switches;Throughput;Telecommunication traffic;Packet switching;Routing;Traffic control;Hypercubes;Argon;Fabrics;Stochastic processes},
doi={10.1109/INFCOM.2005.1498452},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498453,
author={M. J. Neely and E. Modiano and Chih-Ping Li},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Fairness and optimal stochastic control for heterogeneous networks},
year={2005},
volume={3},
number={},
pages={1723-1734 vol. 3},
abstract={We consider optimal control for general networks with both wireless and wireline components and time varying channels. A dynamic strategy is developed to support all traffic whenever possible, and to make optimally fair decisions about which data to serve when inputs exceed network capacity. The strategy is decoupled into separate algorithms for flow control, routing, and resource allocation, and allows each user to make decisions independent of the actions of others. The combined strategy is shown to yield data rates that are arbitrarily close to the optimal operating point achieved when all network controllers are coordinated and have perfect knowledge of future events. The cost of approaching this fair operating point is an end-to-end delay increase for data that is served by the network. Analysis is performed at the packet level and considers the full effects of queueing.},
keywords={stochastic systems;time-varying channels;telecommunication congestion control;telecommunication network routing;resource allocation;delays;queueing theory;radio networks;data communication;optimal control;optimal stochastic control;heterogeneous networks;time varying channels;network capacity;flow control;routing;resource allocation;network controllers;end-to-end delay;queueing;wireless network;wireline network;data networks;Stochastic processes;Optimal control;Resource management;Traffic control;Routing;Wireless sensor networks;Sensor systems;World Wide Web;Communication system traffic control;Costs},
doi={10.1109/INFCOM.2005.1498453},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498454,
author={Jun Luo and J. -. Hubaux},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Joint mobility and routing for lifetime elongation in wireless sensor networks},
year={2005},
volume={3},
number={},
pages={1735-1746 vol. 3},
abstract={Although many energy efficient/conserving routing protocols have been proposed for wireless sensor networks, the concentration of data traffic towards a small number of base stations remains a major threat to the network lifetime. The main reason is that the sensor nodes located near a base station have to relay data for a large part of the network and thus deplete their batteries very quickly. The solution we propose in this paper suggests that the base station be mobile; in this way, the nodes located close to it change over time. Data collection protocols can then be optimized by taking both base station mobility and multi-hop routing into account. We first study the former, and conclude that the best mobility strategy consists in following the periphery of the network (we assume that the sensors are deployed within a circle). We then consider jointly mobility and routing algorithms in this case, and show that a better routing strategy uses a combination of round routes and short paths. We provide a detailed analytical model for each of our statements, and corroborate it with simulation results. We show that the obtained improvement in terms of network lifetime is in the order of 500%.},
keywords={mobile radio;routing protocols;wireless sensor networks;data communication;lifetime elongation;wireless sensor network;routing protocol;data traffic;base station;data collection protocol;base station mobility;multi-hop routing;mobility strategy;mathematical optimization;Intelligent networks;Wireless sensor networks;Base stations;Analytical models;Telecommunication traffic;Batteries;Routing protocols;Computer networks;Energy efficiency;Relays},
doi={10.1109/INFCOM.2005.1498454},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498455,
author={C. Buragohain and D. Agrawal and S. Suri},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Power aware routing for sensor databases},
year={2005},
volume={3},
number={},
pages={1747-1757 vol. 3},
abstract={Wireless sensor networks offer the potential to span and monitor large geographical areas inexpensively. Sensor network databases like TinyDB [S. Madden et al., 2002] are the dominant architectures to extract and manage data in such networks. Since sensors have significant power constraints (battery life), and high communication costs, design of energy efficient communication algorithms is of great importance. The data flow in a sensor database is very different from data flow in an ordinary network and poses novel challenges in designing efficient routing algorithms. In this work we explore the problem of energy efficient routing for various different types of database queries and show that in general, this problem is NP-complete. We give a constant factor approximation algorithm for one class of query, and for other queries give heuristic algorithms. We evaluate the efficiency of the proposed algorithms by simulation and demonstrate their near optimal performance for various network sizes.},
keywords={telecommunication network routing;wireless sensor networks;data communication;query processing;optimisation;graph theory;power aware routing;sensor database;wireless sensor network;energy efficient communication algorithm;routing algorithm;energy efficient routing;NP-complete problem;constant factor approximation algorithm;heuristic algorithm;graph theory;mathematical programming;mathematical optimization;Routing;Databases;Algorithm design and analysis;Energy efficiency;Approximation algorithms;Wireless sensor networks;Monitoring;Data mining;Batteries;Costs},
doi={10.1109/INFCOM.2005.1498455},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498456,
author={Yu He and C. S. Raghavendra},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={XVR: X visiting-pattern routing for sensor networks},
year={2005},
volume={3},
number={},
pages={1758-1769 vol. 3},
abstract={This paper proposes a new routing paradigm for sensor networks called X visiting-pattern routing (XVR) that decouples visiting-patterns of packets from the routing core. Visiting-patterns indicate where to forward packets as next hops in a network and are essential to any routing service. With XVR, the visiting-patterns are defined in a separate module from the routing core, thus enabling them to be changed independently. The overhead of changing routing behavior is further reduced significantly by parameterizing usual visiting-patterns; different routing services can be obtained by simply changing the visiting-pattern parameters. In addition, with the extensive routing behavior space and the separate visiting-pattern module, XVR furnishes a desirable base to realize automatic and concurrent routing services that adapt to application and network dynamics. Discussions and extensive simulations show that by systematically testing different visiting-patterns XVR provides a unique environment and a comprehensive approach to study both existing and new routing algorithms.},
keywords={telecommunication network routing;wireless sensor networks;XVR;sensor network;X visiting-pattern routing;concurrent routing service;Routing;Chemical sensors;Intelligent sensors;Condition monitoring;Costs;Helium;System testing;Chemical technology;Wireless communication;Soil},
doi={10.1109/INFCOM.2005.1498456},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498457,
author={D. Ferrara and L. Galluccio and A. Leonardi and G. Morabito and S. Palazzo},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={MACRO: an integrated MAC/routing protocol for geographic forwarding in wireless sensor networks},
year={2005},
volume={3},
number={},
pages={1770-1781 vol. 3},
abstract={Sensor networks are characterized by limited battery supplies. Due to this feature, communication protocols specifically designed for these networks should be aimed at minimizing energy consumption. To this purpose, the sensor's capability of transmitting with different power levels can be exploited. With this in mind, in this paper an integrated MAC/routing protocol, called MACRO, which exploits the capability of sensor devices to tune their transmission power is introduced. The proposed protocol requires that each node only knows its own coordinates and the coordinates of the destination, but does not require any exchange of location information. In order to select the next relay node, a competition is triggered at each hop, so that the most energy efficient relay node is chosen. This is achieved through maximization of a newly introduced parameter, called weighted progress factor, which represents the progress towards the destination per unit of transmitted power. To this aim, an analytical framework which guarantees that MACRO performs the best choice is derived. MACRO performance is evaluated through ns-2 simulation and compared to other relevant routing schemes. Performance results show that the proposed protocol outperforms other solutions in terms of energy efficiency and boosts data aggregation.},
keywords={access protocols;routing protocols;wireless sensor networks;data communication;MACRO;integrated MAC-routing protocol;geographic forwarding;wireless sensor network;energy consumption;relay node;weighted progress factor;transmitted power;data aggregation;Media Access Protocol;Routing protocols;Intelligent networks;Wireless sensor networks;Energy consumption;Energy efficiency;Relays;Performance analysis;Telecommunications;Batteries},
doi={10.1109/INFCOM.2005.1498457},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498458,
author={A. K. Das and R. J. Marks and P. Arabshahi and A. Gray},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Power controlled minimum frame length scheduling in TDMA wireless networks with sectored antennas},
year={2005},
volume={3},
number={},
pages={1782-1793 vol. 3},
abstract={We consider the problem of power controlled minimum frame length scheduling for TDMA wireless networks. Given a set of one-hop transmission requests, our objective is to schedule them in a minimum number of time slots, so that each slot schedule is free of self-interferences and meets desired SINR constraints. Additionally, the transmit power vector corresponding to each slot schedule should be minimal. We consider two different versions of the problem, a per-slot version and a per-frame version, and develop mixed integer linear programming models which can be used for solving the problems optimally. In addition, we propose a heuristic algorithm for the per-slot version.},
keywords={power control;telecommunication control;scheduling;time division multiple access;antennas;integer programming;linear programming;radio networks;power controlled minimum frame length scheduling;TDMA wireless network;sectored antenna;one-hop transmission;self-interference;transmit power vector;per-slot version;per-frame version;integer linear programming model;heuristic algorithm;Intelligent networks;Time division multiple access;Wireless networks;Power control;Signal to noise ratio;Scheduling algorithm;Mixed integer linear programming;Heuristic algorithms;Ad hoc networks;Slot antennas},
doi={10.1109/INFCOM.2005.1498458},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498459,
author={A. Eryilmaz and R. Srikant},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Fair resource allocation in wireless networks using queue-length-based scheduling and congestion control},
year={2005},
volume={3},
number={},
pages={1794-1803 vol. 3},
abstract={We consider the problem of allocating resources (time slots, frequency, power, etc.) at a base station to many competing flows, where each flow is intended for a different receiver. The channel conditions may be time-varying and different for different receivers. It is well-known that appropriately chosen queue-length based policies are throughput-optimal while other policies based on the estimation of channel statistics can be used to allocate resources fairly (such as proportional fairness) among competing users. In this paper, we show that a combination of queue-length-based scheduling at the base station and congestion control implemented either at the base station or at the end users can lead to fair resource allocation and queue-length stability.},
keywords={resource allocation;radio networks;queueing theory;scheduling;telecommunication congestion control;channel estimation;time-varying channels;fair resource allocation;wireless network;queue-length-based scheduling;congestion control;time-varying channel;radio receivers;channel estimation;proportional fairness;queue-length stability;Resource management;Intelligent networks;Wireless networks;Base stations;Statistics;Proportional control;Land mobile radio cellular systems;Radio spectrum management;Stability;Helium},
doi={10.1109/INFCOM.2005.1498459},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498460,
author={Xiaojun Lin and N. B. Shroff},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The impact of imperfect scheduling on cross-layer rate control in wireless networks},
year={2005},
volume={3},
number={},
pages={1804-1814 vol. 3},
abstract={In this paper, we study cross-layer design for rate control in multihop wireless networks. In our previous work, we have developed an optimal cross-layered rate control scheme that jointly computes both the rate allocation and the stabilizing schedule that controls the resources at the underlying layers. However, the scheduling component in this optimal cross-layered rate control scheme has to solve a complex global optimization problem at each time, and hence is too computationally expensive for online implementation. In this paper, we study how the performance of cross-layer rate control can be impacted if the network can only use an imperfect (and potentially distributed) scheduling component that is easier to implement. We study both the case when the number of users in the system is fixed and the case with dynamic arrivals and departures of the users, and we establish desirable results on the performance bounds of cross-layered rate control with imperfect scheduling. Compared with a layered approach that does not design rate control and scheduling together, our cross-layered approach has provably better performance bounds, and substantially outperforms the layered approach. The insights drawn from our analyses also enable us to design a fully distributed cross-layered rate control and scheduling algorithm for a restrictive interference model.},
keywords={scheduling;telecommunication control;radio networks;distributed algorithms;radiofrequency interference;queueing theory;imperfect scheduling;cross-layer rate control;rate control;multihop wireless network;cross-layered rate control scheme;rate allocation;global optimization problem;distributed cross-layered rate control;restrictive interference model;mathematical programming;mathematical optimization;queueing theory;Wireless networks;Processor scheduling;Optimal control;Algorithm design and analysis;Cross layer design;Spread spectrum communication;Resource management;Control systems;Dynamic scheduling;Distributed control},
doi={10.1109/INFCOM.2005.1498460},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498461,
author={P. Gupta and Y. Sankarasubramaniam and A. Stolyar},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Random-access scheduling with service differentiation in wireless networks},
year={2005},
volume={3},
number={},
pages={1815-1825 vol. 3},
abstract={Recent years have seen tremendous growth in the deployment of wireless local area networks (WLANs). An important design issue in such networks is that of distributed scheduling. The lack of centralized control leads to multiple users competing for channel access. This leads to significant throughput degradation. Existing approaches, such as the slotted Aloha protocol and IEEE 802.11 DCF, also fail to provide differentiated service to users. The upcoming IEEE 802.11e enhanced DCF incorporates additional mechanisms to provide support for service differentiation. However, the level of differentiation achieved with these mechanisms is difficult to quantify. In this paper, we propose a class of distributed scheduling algorithms, regulated contention medium access control (RCMAC), which provides dynamic prioritized access to users for service differentiation in a quantifiable manner. Furthermore, by regulating multi-user contention, RCMAC achieves higher throughput when traffic is bursty, as is typically the case. In addition to WLANs, the basic concepts of RCMAC have applications in ad hoc networks and emerging sensor networks.},
keywords={scheduling;DiffServ networks;distributed algorithms;access protocols;wireless LAN;random-access scheduling;service differentiation;wireless local area network;distributed scheduling;channel access;slotted Aloha protocol;distributed scheduling algorithm;regulated contention medium access control;dynamic prioritized access;multi-user contention;ad hoc network;sensor network;Wireless networks;Throughput;Wireless LAN;Centralized control;Degradation;Access protocols;Scheduling algorithm;Media Access Protocol;Communication system traffic control;Ad hoc networks},
doi={10.1109/INFCOM.2005.1498461},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498462,
author={N. Fonseca and M. Crovella},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Bayesian packet loss detection for TCP},
year={2005},
volume={3},
number={},
pages={1826-1837 vol. 3},
abstract={One of TCP's critical tasks is to determine which packets are lost in the network, as a basis for control actions (flow control and packet retransmission). Modern TCP implementations use two mechanisms: timeout, and fast retransmit. Detection via timeout is necessarily a time-consuming operation; fast retransmit, while much quicker, is only effective for a small fraction of packet losses. In this paper we consider the problem of packet loss detection in TCP more generally. We concentrate on the fact that TCP's control actions are necessarily triggered by inference of packet loss, rather than conclusive knowledge. This suggests that one might analyze TCP's packet loss detection in a standard inferencing framework based on probability of detection and probability of false alarm. This paper makes two contributions to that end: first, we study an example of more general packet loss inference, namely optimal Bayesian packet loss detection based on round trip time. We show that for long-lived flows, it is frequently possible to achieve high detection probability and low false alarm probability based on measured round trip time. Second, we construct an analytic performance model that incorporates general packet loss inference into TCP. We show that for realistic detection and false alarm probabilities (as are achievable via our Bayesian detector) and for moderate packet loss rates, the use of more general packet loss inference in TCP can improve throughput by as much as 25%.},
keywords={transport protocols;queueing theory;probability;Bayes methods;Bayesian packet loss detection;TCP;flow control;packet retransmission;timeout mechanism;fast retransmit mechanism;round trip time;detection probability;false alarm probability;queuing theory;Bayesian methods;Detectors;Performance loss;Event detection;Time measurement;Performance analysis;Throughput;Queueing analysis;Loss measurement;Helium},
doi={10.1109/INFCOM.2005.1498462},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498463,
author={R. King and R. Baraniuk and R. Riedi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={TCP-Africa: an adaptive and fair rapid increase rule for scalable TCP},
year={2005},
volume={3},
number={},
pages={1838-1848 vol. 3},
abstract={High capacity data transfers over the Internet routinely fail to meet end-to-end performance expectations. The default transport control protocol for best effort data traffic is currently TCP, which does not scale well to 100 Mbps and higher networks over long distances. In congestion avoidance, TCP is not swift enough to fully utilize resources over paths with a high delay bandwidth product. First attempts to alleviate this problem by equipping TCP with increased aggressiveness have shown the disadvantage of poor fairness with the ubiquitous standard TCP-Reno, or in some cases, even among two connections running over the same path. We propose a new delay sensitive-congestion avoidance mode (TCP-Africa) that allows for scalable, aggressive behavior in large underutilized links, yet falls back to the more conservative TCP-Reno algorithm once links become well utilized and congestion is imminent. Through ns2 simulations we argue for the safety, efficiency, and fairness of TCP-Africa.},
keywords={transport protocols;Internet;telecommunication links;TCP-Africa;rapid increase rule;scalable TCP;Internet;transport control protocol;best effort data traffic;congestion avoidance;ubiquitous standard;delay sensitive-congestion avoidance mode;TCP-Reno algorithm;Delay;Internet;Bandwidth;Statistics;World Wide Web;Transport protocols;Communication system traffic control;Computer hacking;Product safety;Proposals},
doi={10.1109/INFCOM.2005.1498463},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498464,
author={J. Ott and D. Kutscher},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A disconnection-tolerant transport for drive-thru Internet environments},
year={2005},
volume={3},
number={},
pages={1849-1862 vol. 3},
abstract={Today's mobile, wireless, and ad-hoc communications often exhibit extreme characteristics challenging assumptions underlying the traditional way of end-to-end communication protocol design in the Internet. One specific scenario is Internet access from moving vehicles on the road as we are researching in the drive-thru Internet project. Using wireless LAN as a broadly available access technology leads to intermittent - largely unpredictable and usually short-lived - connectivity, yet providing high performance while available. To allow Internet applications to deal reasonably well with such intermittent connectivity patterns, we have introduced a supportive drive-thru architecture. A key component is a "session" protocol offering persistent end-to-end communications even in the presence of interruptions. In this paper, we present the design of the persistent connectivity management protocol (PCMP) and report on findings from our implementation.},
keywords={Internet;mobile radio;protocols;computer network management;mobile computing;disconnection-tolerant transport;drive-thru Internet;ad-hoc communication;wireless communication;mobile communication;end-to-end communication protocol;wireless LAN;connectivity pattern;session protocol;persistent connectivity management protocol;Internet;Access protocols;Mobile communication;Transport protocols;Road vehicles;Wireless LAN;Wireless networks;Performance loss;Wireless application protocol;Vehicle driving},
doi={10.1109/INFCOM.2005.1498464},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498465,
author={R. de Oliveira and T. Braun},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A dynamic adaptive acknowledgment strategy for TCP over multihop wireless networks},
year={2005},
volume={3},
number={},
pages={1863-1874 vol. 3},
abstract={Multihop wireless networks based on the IEEE 802.11 MAC protocol are promising for ad hoc networks in small scale today. The 802.11 protocol minimizes the well-known hidden node problem but does not eliminate it completely. Consequently, the end-to-end bandwidth utilization may be quite poor if the involved protocols do not interact smoothly. In particular, the TCP protocol does not manage to obtain efficient bandwidth utilization because its congestion control mechanism is not tailored to such a complex environment. The main problems with TCP in such networks are the excessive amount of both spurious retransmissions and contention between data and acknowledgment (ACK) packets for the transmission medium. In this paper, we propose a dynamic adaptive strategy for minimizing the number of ACK packets in transit and mitigating spurious retransmissions. Using this strategy, the receiver adjusts itself to the wireless channel condition by delaying more ACK packets when the channel is in good condition and less otherwise. Our technique not only improves bandwidth utilization but also reduces power consumption by retransmitting much less than a regular TCP does. Extensive simulation evaluations show that our scheme provides very good enhancements in a variety of scenarios.},
keywords={transport protocols;wireless LAN;telecommunication channels;dynamic adaptive acknowledgment strategy;TCP;multihop wireless network;MAC protocol;ad hoc network;hidden node problem;end-to-end bandwidth utilization;congestion control mechanism;data and acknowledgment packet;spurious retransmission;wireless channel;power consumption;Spread spectrum communication;Wireless networks;Media Access Protocol;Bandwidth;Transport protocols;Wireless application protocol;Ad hoc networks;Degradation;Access protocols;Performance loss},
doi={10.1109/INFCOM.2005.1498465},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498466,
author={Jiangzhuo Chen and Lujun Jia and Xin Liu and G. Noubir and R. Sundaram},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Minimum energy accumulative routing in wireless networks},
year={2005},
volume={3},
number={},
pages={1875-1886 vol. 3},
abstract={In this paper, we propose to address the energy efficient routing problem in multi-hop wireless networks with accumulative relay. In the accumulative relay model, partially overheard signals of previous transmissions for the same packet are used to decode it using a maximal ratio combiner technique [J.G. Proakis, 2001]. Therefore, additional energy saving can be achieved over traditional energy efficient routing. The idea of accumulative relay originates from the study of relay channel in information theory with a main focus on network capacity. It has been independently applied to minimum-energy broadcasting in L.G. Manish Agrawal et al. (2004), I. Maric and R. Yates (2002). We formulate the minimum energy accumulative routing problem (MEAR) and study it. We obtain hardness of approximation results counterbalanced with good heuristic solutions which we validate using simulations. Without energy accumulation, the classic shortest path (SP) algorithm finds the minimum energy path for a source-destination pair. However, we show that with energy accumulation, the SP can be arbitrarily bad. We turn our attention to heuristics and show that any optimal solution of MEAR can be converted to a canonical form - wave path. Armed with this insight, we develop a polynomial time heuristic to efficiently search over the space of all wavepaths. Simulation results show that our heuristic can provide more than 30% energy saving over minimum energy routing without accumulative relay. We also discuss the implementation issues of such a scheme.},
keywords={wireless sensor networks;telecommunication network routing;ad hoc networks;graph theory;minimum energy accumulative routing;multihop wireless networks;accumulative relay model;maximal ratio combiner technique;relay channel;information theory;minimum-energy broadcasting;minimum energy accumulative routing problem;shortest path algorithm;source-destination pair;ad hoc network;wireless sensor network;optimization;graph theory;Routing;Intelligent networks;Wireless networks;Relays;Wireless sensor networks;Energy efficiency;Decoding;Spread spectrum communication;Radio frequency;Batteries},
doi={10.1109/INFCOM.2005.1498466},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498467,
author={Jinhua Zhu and Xin Wang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={PEER: a progressive energy efficient routing protocol for wireless ad hoc networks},
year={2005},
volume={3},
number={},
pages={1887-1896 vol. 3},
abstract={Many minimum energy (energy efficient) routing protocols have been proposed so far. However, a few effort has been spent on the routing overhead, route setup time, and route maintenance issues associated with such protocols. This paper first shows that the minimum energy routing schemes in the literature could fail without considering the routing overhead involved and the node mobility. It then proposes a more accurate analytical model to track the energy consumption and the impact of packets errors, and a simple energy-efficient routing scheme to improve the performance in mobility scenarios. The simulation results indicate that the PEER-based energy efficient routing has significantly higher performance than that of a normal energy-based routing scheme.},
keywords={routing protocols;ad hoc networks;mobile radio;PEER;progressive energy efficient routing protocol;wireless ad hoc network;routing overhead;route maintenance;minimum energy routing scheme;energy consumption;Energy efficiency;Routing protocols;Ad hoc networks;Costs;Energy consumption;Mobile ad hoc networks;Batteries;Peer to peer computing;Mobile communication;Wireless application protocol},
doi={10.1109/INFCOM.2005.1498467},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498468,
author={P. Nain and D. Towsley and Benyuan Liu and Zhen Liu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Properties of random direction models},
year={2005},
volume={3},
number={},
pages={1897-1907 vol. 3},
abstract={A number of mobility models have been proposed for the purpose of either analyzing or simulating the movement of users in a mobile wireless network. Two of the more popular are the random waypoint and the random direction models. The random waypoint model is physically appealing but difficult to understand. Although the random direction model is less appealing physically, it is much easier to understand. User speeds are easily calculated, unlike for the waypoint model, and, as we observe, user positions and directions are uniformly distributed. The contribution of this paper is to establish this last property for a rich class of random direction models that allow future movements to depend on past movements. To this end, we consider finite oneand two-dimensional spaces. We consider two variations, the random direction model with wrap around and with reflection. We establish a simple relationship between these two models and, for both, show that positions and directions are uniformly distributed for a class of Markov movement models regardless of initial position. In addition, we establish a sample path property for both models, namely that any piecewise linear movement applied to a user preserves the uniform distribution of position and direction provided that users were initially uniformly throughout the space with equal likelihood of being pointed in any direction.},
keywords={mobile radio;Markov processes;piecewise linear techniques;random direction model;mobile wireless network;random waypoint model;two-dimensional space;one-dimensional space;Markov movement model;path property;piecewise linear movement;Reflection;Piecewise linear techniques;Space exploration;Electronic mail;Analytical models;Wireless networks;Space stations},
doi={10.1109/INFCOM.2005.1498468},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498469,
author={Yingqun Yu and G. B. Giannakis},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={SICTA: a 0.693 contention tree algorithm using successive interference cancellation},
year={2005},
volume={3},
number={},
pages={1908-1916 vol. 3},
abstract={Contention tree algorithms have provable stability properties, and are known to achieve stable throughput as high as 0.487 for the infinite population Poisson model. A common feature in all these random access protocols is that collided packets at the receive-node are always discarded. In this paper, we derive a novel tree algorithm (TA) that we naturally term SICTA because it relies on successive interference cancellation to resolve collided packets. Performance metrics including throughput and delay are analyzed to establish that SICTA outperforms existing contention tree algorithms reaching 0.693 in stable throughput.},
keywords={interference suppression;stochastic processes;access protocols;trees (mathematics);0.693 contention tree algorithm;successive interference cancellation;Poisson model;random access protocol;packet collision;Interference cancellation;Access protocols;Throughput;Signal resolution;Telecommunication traffic;Stability;Multiaccess communication;Delay;Land mobile radio cellular systems;Road accidents},
doi={10.1109/INFCOM.2005.1498469},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498470,
author={S. Capkun and J. -. Hubaux},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Secure positioning of wireless devices with application to sensor networks},
year={2005},
volume={3},
number={},
pages={1917-1928 vol. 3},
abstract={So far, the problem of positioning in wireless networks has been mainly studied in a non-adversarial setting. In this work, we analyze the resistance of positioning techniques to position and distance spoofing attacks. We propose a mechanism for secure positioning of wireless devices, that we call verifiable multilateration. We then show how this mechanism can be used to secure positioning in sensor networks. We analyze our system through simulations.},
keywords={telecommunication security;wireless sensor networks;secure wireless device positioning;wireless sensor network;positioning technique;distance spoofing attack;verifiable multilateration;Wireless sensor networks;Communication system security;Proposals;Sensor systems;Application software;Protocols;Virtual manufacturing;Radio frequency;Computer networks;Analytical models},
doi={10.1109/INFCOM.2005.1498470},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498471,
author={Heesook Choi and Hui Song and Guohong Cao and T. La Porta},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Mobile multi-layered IPsec},
year={2005},
volume={3},
number={},
pages={1929-1939 vol. 3},
abstract={To achieve high throughput in wireless networks, smart forwarding and processing of packets in access routers are critical for overcoming the effects of the wireless links. However, these services cannot be provided if data sessions are protected using end-to-end encryption as with IPsec, because the information needed by these algorithms resides inside the portion of the packet that is encrypted, and can therefore not be used by the access routers. A previously proposed protocol, called multi-layered IPsec (ML-IPsec) modifies IPsec in a way so that certain portions of the datagram may be exposed to intermediate network elements, enabling these elements to provide performance enhancements. In this paper we extend ML-IPsec to deal with mobility and make it suitable for wireless networks. We define and present performance measurements of an efficient key distribution protocol to enable fast ML-IPsec session initialization, and two mobility protocols that are compatible with mobile IP and maintain ML-IPsec sessions. Our measurements show that, depending on the mobility protocol chosen, integrated mobile IP/ML-IPsec handoffs result in a pause of 56-105 milliseconds, of which only 31-85 milliseconds may be attributed to ML-IPsec. Further, we provide detailed discussion and performance measurements of our ML-IPsec implementation. We find the resulting protocol only marginally reduces throughput compared to scenarios in which IPsec is used (4%), and when coupled with SNOOP, greatly increases throughput over scenarios using standard TCP over IPsec (165% on average).},
keywords={mobile radio;IP networks;transport protocols;mobile computing;mobile multilayered IPsec;wireless network;smart forwarding;wireless link;end-to-end encryption;key distribution protocol;mobility protocol;mobile IP network;56 to 105 ms;31 to 85 ms;Cryptography;Measurement;Throughput;Wireless networks;Wireless application protocol;Computer science;Protection;Access protocols;Telecommunication traffic;Virtual private networks},
doi={10.1109/INFCOM.2005.1498471},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498472,
author={Yanchao Zhang and Wei Liu and Wenjing Lou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Anonymous communications in mobile ad hoc networks},
year={2005},
volume={3},
number={},
pages={1940-1951 vol. 3},
abstract={Due to the broadcast nature of radio transmissions, communications in mobile ad hoc networks (MANETs) are more susceptible to malicious traffic analysis. In this paper we propose a novel anonymous on-demand routing protocol, termed MASK, to enable anonymous communications thereby thwarting possible traffic analysis attacks. Based on a new cryptographic concept called pairing, we first propose an anonymous neighborhood authentication protocol which allows neighboring nodes to authenticate each other without revealing their identities. Then utilizing the secret pairwise link identifiers and keys established between neighbors during the neighborhood authentication process, MASK fulfills the routing and packet forwarding tasks nicely without disclosing the identities of participating nodes under a rather strong adversarial model. MASK provides the desirable sender and receiver anonymity, as well as the relationship anonymity of the sender and receiver. It is also resistant to a wide range of adversarial attacks. Moreover, MASK preserves the routing efficiency in contrast to previous proposals. Detailed anonymity analysis and simulation studies are carried out to validate and justify the effectiveness of MASK.},
keywords={mobile radio;ad hoc networks;routing protocols;telecommunication traffic;cryptography;anonymous communication;mobile ad hoc network;malicious traffic analysis;on-demand routing protocol;pairing cryptographic concept;anonymous neighborhood authentication protocol;pairwise link identifier;Mobile communication;Mobile ad hoc networks;Telecommunication traffic;Authentication;Radio broadcasting;Routing protocols;Cryptography;Cryptographic protocols;Proposals;Analytical models},
doi={10.1109/INFCOM.2005.1498472},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498473,
author={P. P. C. Lee and V. Misra and D. Rubenstein},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Distributed algorithms for secure multipath routing},
year={2005},
volume={3},
number={},
pages={1952-1963 vol. 3},
abstract={To proactively defend against intruders from readily jeopardizing single-path data sessions, we propose a distributed secure multipath solution to route data across multiple paths so that intruders require much more resources to mount successful attacks. Our work exhibits several crucial properties that differentiate itself from previous approaches. They include (1) distributed routing decisions: routing decisions are made without the centralized information of the entire network topology, (2) bandwidth-constraint adaptation: the worst-case link attack is mitigated for any feasible session throughput subject to the link-bandwidth constraints, and (3) lexicographic protection: severe link attacks are suppressed based on lexicographic optimization. We devise two algorithms for the solution, termed the bound-control algorithm and the lex-control algorithm, and prove their convergence to the respective optimal solutions. Experiments show that the bound-control algorithm is more effective to prevent the worst-case single-link attack when compared to the single-path approach, and that the lex-control algorithm further enhances the bound-control algorithm by countering severe single-link attacks and various models of multi-link attacks. Moreover, the lex-control algorithm offers prominent protection after only a few execution rounds. Thus, system designers can sacrifice minimal routing security for significantly improved algorithm performance when deploying the distributed secure multipath solution.},
keywords={distributed algorithms;telecommunication security;telecommunication network routing;data communication;telecommunication links;convergence;multipath channels;minimax techniques;graph theory;secure multipath routing;single-path data session;distributed secure multipath solution;distributed routing decision;network topology;bandwidth-constraint adaptation;worst-case link attack;link-bandwidth constraint;lexicographic protection;lexicographic optimization;bound-control algorithm;lex-control algorithm;convergence;minimal routing security;minimax optimization;graph theory;Distributed algorithms;Data security;Routing protocols;Computer crime;Computer science;Network topology;Throughput;Bandwidth;Constraint optimization;Optimal control},
doi={10.1109/INFCOM.2005.1498473},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498474,
author={R. Madan and Shuguang Cui and S. Lall and A. Goldsmith},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Cross-layer design for lifetime maximization in interference-limited wireless sensor networks},
year={2005},
volume={3},
number={},
pages={1964-1975 vol. 3},
abstract={We consider the joint optimal design of physical, medium access control (MAC), and routing layers to maximize the lifetime of energy-constrained wireless sensor networks. The problem of computing a lifetime-optimal routing flow, link schedule, and link transmission powers is formulated as a non-linear optimization problem. We first restrict the link schedules to the class of interference-free time division multiple access (TDMA) schedules. In this special case we formulate the optimization problem as a mixed integer-convex program, which can be solved using standard techniques. For general non-orthogonal link schedules, we propose an iterative algorithm that alternates between adaptive link scheduling and computation of optimal link rates and transmission powers for a fixed link schedule. The performance of this algorithm is compared to other design approaches for several network topologies. The results illustrate the advantages of load balancing, multihop routing, frequency reuse, and interference mitigation in increasing the lifetime of energy-constrained networks. We also describe a partially distributed algorithm to compute optimal rates and transmission powers for a given link schedule.},
keywords={wireless sensor networks;routing protocols;radiofrequency interference;time division multiple access;integer programming;radio links;convex programming;cross-layer design;lifetime maximization;interference-limited networks;medium access control;wireless sensor networks;lifetime-optimal routing flow;nonlinear optimization problem;time division multiple access;TDMA schedules;mixed integer-convex program;iterative algorithm;network topologies;load balancing;multihop routing;energy-constrained networks;Cross layer design;Interference;Wireless sensor networks;Processor scheduling;Routing;Time division multiple access;Iterative algorithms;Media Access Protocol;Adaptive scheduling;Algorithm design and analysis},
doi={10.1109/INFCOM.2005.1498474},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498475,
author={M. Cardei and M. T. Thai and Yingshu Li and Weili Wu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Energy-efficient target coverage in wireless sensor networks},
year={2005},
volume={3},
number={},
pages={1976-1984 vol. 3},
abstract={A critical aspect of applications with wireless sensor networks is network lifetime. Power-constrained wireless sensor networks are usable as long as they can communicate sensed data to a processing node. Sensing and communications consume energy, therefore judicious power management and sensor scheduling can effectively extend network lifetime. To cover a set of targets with known locations when ground access in the remote area is prohibited, one solution is to deploy the sensors remotely, from an aircraft. The lack of precise sensor placement is compensated by a large sensor population deployed in the drop zone, that would improve the probability of target coverage. The data collected from the sensors is sent to a central node (e.g. cluster head) for processing. In this paper we propose un efficient method to extend the sensor network life time by organizing the sensors into a maximal number of set covers that are activated successively. Only the sensors from the current active set are responsible for monitoring all targets and for transmitting the collected data, while all other nodes are in a low-energy sleep mode. By allowing sensors to participate in multiple sets, our problem formulation increases the network lifetime compared with related work [M. Cardei et al], that has the additional requirements of sensor sets being disjoint and operating equal time intervals. In this paper we model the solution as the maximum set covers problem and design two heuristics that efficiently compute the sets, using linear programming and a greedy approach. Simulation results are presented to verify our approaches.},
keywords={wireless sensor networks;greedy algorithms;linear programming;power-constrained wireless sensor networks;power management;sensor scheduling;network lifetime;heuristics design;greedy approach;linear programming;energy consumption;Energy efficiency;Intelligent networks;Wireless sensor networks;Sensor phenomena and characterization;Computer science;Scheduling;Energy management;Monitoring;Transceivers;Application software},
doi={10.1109/INFCOM.2005.1498475},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498476,
author={Wook Choi and S. K. Das},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A novel framework for energy - conserving data gathering in wireless sensor networks},
year={2005},
volume={3},
number={},
pages={1985-1996 vol. 3},
abstract={Achievable energy conservation rate in wireless sensor networks can further be enhanced depending on application-specific requirements such as data reporting latency and sensing coverage area. In this paper, we propose a novel framework for energy-conserving data gathering which exploits a trade-off between coverage and data reporting latency. The ultimate goal is to extend the network lifetime by offering only the application/user-specific quality of service (e.g., sensing coverage) in each data reporting round using (approximately) k sensors. The selection of these k sensors is based on a geometric probability theory and a randomization technique with constant computational complexity. The selected k sensors form a data gathering tree (DGT) rooted at the data gathering point. To improve on energy-savings, only the sensors on the DGT are scheduled to remain active (with transceiver on) during a reporting round so that the DGT is used as a backbone to reach the data gathering point. We present a probabilistic model for estimating the connectivity of the selected k sensors and also a recursive algorithm which derives the number of additional sensors required to probabilistically guarantee the connectivity. The immediate data reporting capability of sensors is also analyzed since the group of active sensors forming a DGT (backbone) in each round may not be able to serve as a dominating set. Simulation results show that the proposed framework leads to a significant conservation of energy with a small trade-off.},
keywords={wireless sensor networks;quality of service;probability;random processes;computational complexity;wireless sensor networks;energy-conserving data gathering tree;quality of service;geometric probability theory;randomization technique;computational complexity;energy-savings;recursive algorithm;active sensors;Intelligent networks;Wireless sensor networks;Sensor phenomena and characterization;Intelligent sensors;Data communication;Delay;Monitoring;Routing;Energy consumption;Computer science},
doi={10.1109/INFCOM.2005.1498476},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498477,
author={K. Kar and A. Krishnamurthy and N. Jaggi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Dynamic node activation in networks of rechargeable sensors},
year={2005},
volume={3},
number={},
pages={1997-2007 vol. 3},
abstract={We consider a network of rechargeable sensors, deployed redundantly in a random sensing environment, and address the problem of how sensor nodes should be activated dynamically so as to maximize a generalized system performance objective. The optimal sensor activation problem is a very difficult decision question, and under Markovian assumptions on the sensor discharge/recharge periods, it represents a complex semi-Markov decision problem. With the goal of developing a practical, distributed but efficient solution to this complex, global optimization problem, we first consider the activation question for a set of sensor nodes whose coverage areas overlap completely. For this scenario, we show analytically that there exists a simple threshold activation policy that achieves a performance within a factor of 3/4 of the optimum over all possible policies. We extend this threshold policy to a general network setting where the coverage areas of different sensors could have partial or no overlap with each other, and show by simulations that the performance of our policy is very close to that of the globally optimal policy. Our policy is fully distributed, and requires the sensor nodes to only keep track of the node activation states in its immediate neighborhood. We also consider the effects of spatial correlation on the performance of the threshold activation policy, and the choice of the optimal threshold.},
keywords={sensors;Markov processes;dynamic node activation;rechargeable sensors networks;random sensing environment;optimal sensor activation problem;Markovian assumptions;global optimization problem;globally optimal policy;spatial correlation;Intelligent networks;Batteries;Sensor systems;System performance;Performance analysis;Technological innovation;Monitoring;Systems engineering and theory},
doi={10.1109/INFCOM.2005.1498477},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498478,
author={Linn Cai and Xuemin Shen and J. W. Mark and Jianping Pan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A QoS-aware AIMD protocol for time-sensitive applications in wired/wireless networks},
year={2005},
volume={3},
number={},
pages={2008-2019 vol. 3},
abstract={A TCP-friendly additive increase and multiplicative decrease (AIMD) protocol is proposed to support time-sensitive applications in hybrid wired/wireless networks. By analyzing the performance of AIMD-controlled flows in hybrid networks, we propose a cross-layer procedure to select the AIMD protocol parameters with consideration of wireless link characteristics and application QoS requirements, in terms of delay, loss, and throughput. Since the cross-layer interaction only exchanges parameters among the application, the transport layer protocol, and the link layer protocol, our approach preserves the end-to-end semantics of the transport protocol and the layered structure of the Internet, and it is applicable to supporting various multimedia applications over heterogeneous wireless links. With appropriate parameters, AIMD-controlled flows can fairly share network resources with TCP flows, efficiently utilize wireless resources, and statistically guarantee end-to-end delay for time-sensitive applications. Extensive simulations are performed to validate the analytical results, evaluate the protocol performance, and demonstrate that the AIMD protocol can outperform the unresponsive UDP protocol when transporting multimedia traffic in hybrid networks. With satisfactory QoS, end systems have more incentives to voluntarily regulate multimedia traffic with an AIMD-based congestion controller, which is vital for network stability, integrity, and future proliferation.},
keywords={transport protocols;quality of service;telecommunication congestion control;statistical analysis;cellular radio;Internet;time-sensitive applications;hybrid wireless networks;hybrid wired networks;additive increase and multiplicative decrease protocol;TCP protocol;wireless link characteristics;QoS requirements;delay;transport layer protocol;link layer protocol;end-to-end semantics;Internet;multimedia applications;end-to-end delay;network stability;multimedia traffic;Wireless application protocol;Wireless networks;Transport protocols;Performance analysis;Communication system traffic control;Traffic control;Performance loss;Throughput;Internet;Analytical models},
doi={10.1109/INFCOM.2005.1498478},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498479,
author={J. Chesterfield and R. Chakravorty and I. Pratt and S. Banerjee and P. Rodriguez},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Exploiting diversity to enhance multimedia streaming over cellular links},
year={2005},
volume={3},
number={},
pages={2020-2031 vol. 3},
abstract={Wireless wide area networks (WWANs) are becoming ubiquitous across most geographic regions, enabling simultaneous coverage from multiple providers. WWAN channels exhibit both uncorrelated and correlated behaviour on a variety of levels. In this paper we examine the statistical properties of WWAN links, and illustrate the benefits in heterogeneity that can be exploited to improve statistical throughput and multimedia quality. Our results are based on real network measurements. We describe the design and implementation of a high quality multimedia streaming application that implements WWAN streaming optimisations utilising unequal error protection coding techniques, and we evaluate the performance over an operational WWAN network.},
keywords={cellular radio;radio links;wide area networks;error correction codes;statistical analysis;multimedia communication;multimedia streaming;cellular links;wireless wide area networks;geographic regions;unequal error protection coding techniques;Streaming media;Delay;Cellular networks;Land mobile radio cellular systems;Wide area networks;Ground penetrating radar;Multiaccess communication;Fading;Pervasive computing;Laboratories},
doi={10.1109/INFCOM.2005.1498479},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498480,
author={P. Hosein},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Capacity of packetized voice services over time-shared wireless packet data channels},
year={2005},
volume={3},
number={},
pages={2032-2043 vol. 3},
abstract={In traditional CDMA wireless networks, real-time services, such as circuit-switched voice, are transported over the air via synchronous channels because of their stringent delay requirements. In the third generation networks (3G), IxEV-DV [A.Soong et al., 2003] and HSDPA [E. Dahlman et al., 1998], an additional time shared channel was introduced on the forward link to support data services for which delay requirements are less stringent. The IxEV-DO [P. Bender et al., 2000] standard provides a single time-shared forward link channel and no synchronous channels since it was designed primarily for data services. It has recently been suggested that certain voice services (e.g.. Voice over IP (VoIP) and push-to-talk (PTT)), can be efficiently transported over such time-shared channels since they have less stringent delay requirements compared to circuit-switched voice. In this paper we investigate the capacity of VoIP users over these time-shared channels and investigate the sensitivity to various base station (BS) and mobile station (MS) design parameters, algorithms and features. Note that detailed simulations of each standard is not provided but rather a comparative approach is used whereby we investigate specific features of each standard. Our focus is on the forward channel since code division multiplexing is performed in the reverse link and hence comparable user capacities are achieved.},
keywords={channel capacity;radio links;mobile radio;code division multiplexing;Internet telephony;mobile computing;packetized voice services;time-shared wireless packet data channels;CDMA wireless networks;real-time services;delay requirements;third generation networks;3G networks;forward link channel;push-to-talk;circuit-switched voice;VoIP users;code division multiplexing;forward channel;Multiaccess communication;Bit rate;Wireless networks;Codecs;Delay effects;Base stations;Algorithm design and analysis;Circuit simulation;Code division multiplexing;Switching circuits},
doi={10.1109/INFCOM.2005.1498480},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498481,
author={J. Muller and S. Gorlatch},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={GSM: a game scalability model for multiplayer real-time games},
year={2005},
volume={3},
number={},
pages={2044-2045 vol. 3},
abstract={Current commercial real-time computer games increasingly provide game designs suitable for a high number of players, forming the class of massive multiplayer games (MMG). To support MMG, the scalability of network topologies becomes critically important, i.e., their ability to maintain the game service for an increasing number of players. This paper presents GSM - an analytical scalability model for a detailed investigation of massively multiplayer capabilities of different networking topologies. We use the GSM to discuss the suitability of the client-server and peer-to-peer topology, as well as our own concept of a multi-server topology, for the important classes of first person shooter (FPS) and real-time strategy (RTS) games whose designs are still rarely adopted in MMGs. We verify our analytical model in scalability experiments in which we were able to forecast the maximum numbers of players in a non-congested game session with un error of less than 7 %.},
keywords={computer games;telecommunication network topology;cellular radio;client-server systems;peer-to-peer computing;game scalability model;multiplayer real-time computer games;massive multiplayer games;network topologies;GSM;analytical scalability model;client-server topology;peer-to-peer topology;first person shooter;real-time strategy games;GSM;Scalability;Network topology;Analytical models;Peer to peer computing;Delay;Network servers;Military aircraft;Computer errors;Fault tolerance},
doi={10.1109/INFCOM.2005.1498481},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498482,
author={Seong Soo Kim and A. L. N. Reddy},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A study of analyzing network traffic as images in real-time},
year={2005},
volume={3},
number={},
pages={2056-2067 vol. 3},
abstract={This paper presents NetViewer, a network measurement approach that can simultaneously detect, identify and visualize attacks and anomalous traffic in real-time by passively monitoring packet headers. We propose to represent samples of network packet header data as frames or images. With such a formulation, a series of samples can be seen as a sequence of frames or video. This enables techniques from image processing and video compression to be applied to the packet header data to reveal interesting properties of traffic. We show that "scene change analysis" can reveal sudden changes in traffic behavior or anomalies. We also show that "motion prediction" techniques can be employed to understand the patterns of some of the attacks. We show that it may be feasible to represent multiple pieces of data as different colors of an image enabling a uniform treatment of multidimensional packet header data. We compare NetViewer with classical detection theory based Neyman-Pearson test and an IDS tool.},
keywords={telecommunication traffic;image coding;data compression;visual communication;network traffic;real-time images;NetViewer;network measurement approach;image processing;video compression;scene change analysis;motion prediction techniques;multidimensional packet header data;Neyman-Pearson test;Image analysis;Telecommunication traffic;Video compression;Data visualization;Monitoring;Image processing;Layout;Multidimensional systems;Testing;Intrusion detection},
doi={10.1109/INFCOM.2005.1498482},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498483,
author={D. E. Taylor and J. S. Turner},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={ClassBench: a packet classification benchmark},
year={2005},
volume={3},
number={},
pages={2068-2079 vol. 3},
abstract={Packet classification is an enabling technology for next generation network services and often the primary bottleneck in high-performance routers. The performance and capacity of many algorithms and classification devices, including TCAMs, depend upon properties of the filter set and query patterns. Despite the pressing need, no standard filter sets or performance evaluation tools are publicly available. In response to this problem, we present ClassBench, a suite of tools for benchmarking packet classification algorithms and devices. ClassBench includes a filter set generator that produces synthetic filter sets that accurately model the characteristics of real filter sets. Along with varying the size of the filter sets, we provide high-level control over the composition of the filters in the resulting filter set. The tool suite also includes a trace generator that produces a sequence of packet headers to exercise packet classification algorithms with respect to a given filter set. Along with specifying the relative size of the trace, we provide a simple mechanism for controlling locality of reference. While we have already found ClassBench to be very useful in our own research, we seek to eliminate the significant access barriers to realistic test vectors for researchers und initiate a broader discussion to guide the refinement of the tools and codification of a formal benchmarking methodology.},
keywords={telecommunication network routing;Internet;information filters;next generation network services;high-performance routers;ClassBench;TCAM;query patterns;performance evaluation tools;benchmarking packet classification algorithms;filter set generator;synthetic filter sets;realistic test vectors;packet classification filter sets;Character generation;Classification algorithms;Matched filters;Next generation networking;Size control;Information filtering;Information filters;Laboratories;Pressing;Testing},
doi={10.1109/INFCOM.2005.1498483},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498484,
author={Fang Hao and M. Kodialam and T. V. Lakshman and Hui Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Fast, memory-efficient traffic estimation by coincidence counting},
year={2005},
volume={3},
number={},
pages={2080-2090 vol. 3},
abstract={We consider the problem of fast, estimation of flow rates in backbone network links with possibly millions of flows. Accurate flow rate estimation is necessary for network traffic management, network planning, measuring compliance to service level agreements, and network security. Ideally, a rate estimation scheme should have short estimation times with provable bounds on estimation error, be low in memory usage, and be easily implementable in hardware for operation at high speeds. We develop such a scheme, and achieve up to two orders of magnitude speed-up in estimation time over the previously proposed two-runs-based RATE scheme [Kodialam, M et al., 2004]. The speedups are achieved without a significant increase in memory usage, by using coincidences instead of runs. Counting coincidences has a higher processing overhead than detecting two-runs, but this higher overhead is not significant for a hardware implementation. We show that the proposed scheme is faster and more accurate than other recently proposed schemes such as ACCEL-RATE [Hao, F et al., 2004] and smart sampling [Duffield, N et al., 2004]. The faster estimation time of the new scheme has many benefits including quicker detection of incipient denial of service attacks. We prove bounds on the scheme's accuracy, memory needs, and also show that it performs well by simulations that use both synthetic and real traffic traces.},
keywords={telecommunication traffic;telecommunication links;IP networks;telecommunication network routing;memory-efficient traffic estimation;coincidence counting;flow rates estimation;network links;network traffic management;network planning;hardware implementation;smart sampling;service attacks;IP networks;Sampling methods;Telecommunication traffic;IP networks;Statistics;Computer crime;Spine;Counting circuits;Bones;Monitoring;Event detection},
doi={10.1109/INFCOM.2005.1498484},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498485,
author={T. Okumura and D. Mosse},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The Netnice packet filter: bridging the structural mismatches in end-host network control},
year={2005},
volume={3},
number={},
pages={2091-2101 vol. 3},
abstract={There have been increasing demands for proper monitoring and control in end-host systems, mainly for security and QoS purposes. Nevertheless, existing technologies are insufficient as primitives for end-host security. For example, Berkeley packet filter (BPF), the most popular monitoring infrastructure for many Unix systems, is intended for packet capturing at physical interfaces, and thus, not appropriate for monitoring of applications, which is sometimes critical for system security. This paper presents a simple solution to the problem, utilizing hierarchical virtual network interface (VIF) mechanism. VIF is a new OS abstraction that can be hierarchically structured and attached to OS entities to control their network I/O. We extend VIFs to allow filtering and monitoring of their traffic, and show that it has desirable properties for end-host monitoring and control of traffic. We present our prototype implementation on FreeBSD, and evaluate it qualitatively and quantitatively. Demonstrated advantages include: i) ability to monitor terminating entities at arbitrary granularity, ii) a single consistent framework for both network security and network quality of service, iii) OS independence, iv) efficiency as a control primitive, v) compatibility with BPF interface and its applications, and vi) flexibility for future functional expansion.},
keywords={telecommunication security;telecommunication control;quality of service;telecommunication traffic;network interfaces;computer networks;information filters;Netnice packet filter;end-host network control;QoS;Berkeley packet filter;Unix systems;system security;virtual network interface mechanism;network quality of service;telecommunication traffic;Intelligent networks;Communication system traffic control;Traffic control;Band pass filters;Peace technology;Control systems;Computerized monitoring;Quality of service;Application software;Inspection},
doi={10.1109/INFCOM.2005.1498485},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498486,
author={Xinyan Zhang and Jiangchuan Liu and Bo Li and Y. -. P. Yum},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={CoolStreaming/DONet: a data-driven overlay network for peer-to-peer live media streaming},
year={2005},
volume={3},
number={},
pages={2102-2111 vol. 3},
abstract={This paper presents DONet, a data-driven overlay network for live media streaming. The core operations in DONet are very simple: every node periodically exchanges data availability information with a set of partners, and retrieves unavailable data from one or more partners, or supplies available data to partners. We emphasize three salient features of this data-driven design: 1) easy to implement, as it does not have to construct and maintain a complex global structure; 2) efficient, as data forwarding is dynamically determined according to data availability while not restricted by specific directions; and 3) robust and resilient, as the partnerships enable adaptive and quick switching among multi-suppliers. We show through analysis that DONet is scalable with bounded delay. We also address a set of practical challenges for realizing DONet, and propose an efficient member and partnership management algorithm, together with an intelligent scheduling algorithm that achieves real-time and continuous distribution of streaming contents. We have extensively evaluated the performance of DONet over the PlanetLab. Our experiments, involving almost all the active PlanetLab nodes, demonstrate that DONet achieves quite good streaming quality even under formidable network conditions. Moreover, its control overhead and transmission delay are both kept at low levels. An Internet-based DONet implementation, called CoolStreaming v.0.9, was released on May 30, 2004, which has attracted over 30000 distinct users with more than 4000 simultaneously being online at some peak times. We discuss the key issues toward designing CoolStreaming in this paper, and present several interesting observations from these large-scale tests; in particular, the larger the overlay size, the better the streaming quality it can deliver.},
keywords={multimedia communication;delays;Internet;peer-to-peer computing;computer network management;scheduling;peer-to-peer live media streaming;data-driven overlay network;CoolStreaming;member management algorithm;partnership management algorithm;intelligent scheduling algorithm;PlanetLab;streaming quality;transmission delay;control overhead delay;Internet;Streaming media;Peer to peer computing;Availability;Delay;Scheduling algorithm;Information retrieval;Robustness;Content management;Internet;Large-scale systems},
doi={10.1109/INFCOM.2005.1498486},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498487,
author={S. Q. Zhuang and D. Geels and I. Stoica and R. H. Katz},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On failure detection algorithms in overlay networks},
year={2005},
volume={3},
number={},
pages={2112-2123 vol. 3},
abstract={One of the key reasons overlay networks are seen as an excellent platform for large scale distributed systems is their resilience in the presence of node failures. This resilience rely on accurate and timely detection of node failures. Despite the prevalent use of keep-alive algorithms in overlay networks to detect node failures, their tradeoffs and the circumstances in which they might best he suited is not well understood. In this paper, we study how the design of various keep-alive approaches affect their performance in node failure detection time, probability of false positive, control overhead, and packet loss rate via analysis, simulation, and implementation. We find that among the class of keep-alive algorithms that share information, the maintenance of backpointer state substantially improves detection time and packet loss rate. The improvement in detection time between baseline and sharing algorithms becomes more pronounced as the size of neighbor set increases. Finally, sharing of information allows a network to tolerate a higher churn rate than baseline.},
keywords={telecommunication network reliability;failure analysis;large-scale systems;overlay networks;failure detection algorithms;large scale distributed systems;keep-alive algorithms;node failures;detection time;packet loss rate;Detection algorithms;Intelligent networks;Routing;Resilience;Telecommunication traffic;Large-scale systems;Probes;Performance loss;Failure analysis;Performance analysis},
doi={10.1109/INFCOM.2005.1498487},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498488,
author={Wenjie Wang and Cheng Jin and Sugih Jamin},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Network overlay construction under limited end-to-end reachability},
year={2005},
volume={3},
number={},
pages={2124-2134 vol. 3},
abstract={Network-overlay construction today assumes two-way communication capability - each host can initiate outgoing connections as well as accepting incoming connections. This is often not true on the current Internet due to several reasons, for example, the use of network address translation (NAT) and firewalls. Our experiments with eDonkey and Gnutella file-sharing systems reveal that as many as 36% of the hosts may be guarded - not accepting incoming connections. This presents a challenge to overlay construction because not all hosts are capable of receiving and forwarding requests. We propose an overlay optimization called e* to help existing overlay protocols overcome the reachability problem. Furthermore, e* builds very efficient overlay networks in terms of latency. Under realistic scenarios involving guarded hosts, e* can reduce the average overlay latency by 28-61% compared with existing protocols.},
keywords={reachability analysis;optimisation;protocols;peer-to-peer computing;limited end-to-end reachability;network overlay construction;eDonkey file-sharing systems;Gnutella file-sharing systems;e* overlay optimization;overlay protocols;Delay;Network address translation;Internet;Multicast protocols;Access protocols;Nominations and elections;Network topology;IP networks;Peer to peer computing;Bandwidth},
doi={10.1109/INFCOM.2005.1498488},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498489,
author={Selwyn Yuen and Baochun Li},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Strategyproof mechanisms for dynamic tree formation in overlay networks},
year={2005},
volume={3},
number={},
pages={2135-2146 vol. 3},
abstract={In overlay multicast, every end host forwards multicast data to other end hosts in order to disseminate data. However, this cooperative behavior cannot be taken for granted, since each overlay node is now a strategic end host. Ideally, a strategyproof mechanism should be provided to motivate cooperations among overlay nodes so that a mutually beneficial multicast tree topology results. In this paper, we apply mechanism design to the overlay multicast problem. We model the overlay network using the two scenarios of variable and single rate sessions, and further design distributed algorithms that motivate each node towards a better multicast tree. Since network parameters and constraints change dynamically in reality, our protocol dynamically adapts to form a better multicast tree. The correctness and performance of each distributed algorithm are verified by extensive implementation results on PlanetLab.},
keywords={telecommunication network topology;multicast protocols;overlay networks;dynamic tree formation;strategyproof mechanisms;overlay multicast;multicast tree topology;protocol;PlanetLab;Intelligent networks;Peer to peer computing;Algorithm design and analysis;Distributed algorithms;Multicast algorithms;Throughput;Buffer storage;Multicast protocols;Microeconomics;Costs},
doi={10.1109/INFCOM.2005.1498489},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498490,
author={S. Gollapudi and D. Sivakumar and Aidong Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Exploiting anarchy in networks: a game-theoretic approach to combining fairness and throughput},
year={2005},
volume={3},
number={},
pages={2147-2158 vol. 3},
abstract={We propose a novel mechanism for routing and bandwidth allocation that exploits the selfish and rational behavior of flows in a network. Our mechanism leads to allocations that simultaneously optimize throughput and fairness criteria. We analyze the performance of our mechanism in terms of the induced Nash equilibrium. We compare the allocations at the Nash equilibrium with throughput-optimal allocations as well as with fairness-optimal allocations. Our mechanism offers a smooth trade-off between these criteria, and allows us to produce allocations that are approximately optimal with respect to both. Our mechanism is also fairly simple and admits an efficient distributed implementation.},
keywords={game theory;bandwidth allocation;telecommunication network routing;game-theoretic approach;routing;bandwidth allocation;fairness criteria;throughput criteria;Nash equilibrium;throughput-optimal allocations;fairness-optimal allocations;Intelligent networks;Throughput;Routing;Bandwidth;Game theory;Algorithm design and analysis;Performance analysis;Nash equilibrium;Telecommunication traffic;Stability},
doi={10.1109/INFCOM.2005.1498490},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498491,
author={K. K. Ramachandran and B. Sikdar},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={An analytic framework for modeling peer to peer networks},
year={2005},
volume={3},
number={},
pages={215-269 vol. 3},
abstract={This paper presents an analytic framework to evaluate the performance of peer to peer (P2P) networks. Using the time to download or replicate an arbitrary file as the metric, we present a model which accurately captures the impact of various network and peer level characteristics on the performance of a P2P network. We propose a queueing model which evaluates the delays in the routers using a single class open queueing network and the peers as M/G/1/K processor sharing queues. The framework takes into account the underlying physical network topology and arbitrary file sizes, the search time, load distribution at peers and number of concurrent downloads allowed by a peer. The model has been validated using extensive simulations with campus level, power law AS level and ISP level topologies. The paper also describes the impact of various parameters associated with the network and peers including external traffic rates, service variability, file popularity etc. on the download times. We also show that in scenarios with multi-part downloads from different peers, a rate proportional allocation strategy minimizes the download times.},
keywords={peer-to-peer computing;queueing theory;delays;telecommunication network topology;telecommunication network routing;peer to peer networks;queueing model;delays;routers;single class open queueing network;M/G/1/K processor sharing queues;network topology;proportional allocation strategy;multipart downloads;Peer to peer computing;Network servers;Delay;Performance analysis;Network topology;Telecommunication traffic;Traffic control;Web server;Computer networks;Systems engineering and theory},
doi={10.1109/INFCOM.2005.1498491},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498492,
author={G. G. Xie and Jibin Zhan and D. A. Maltz and Hui Zhang and A. Greenberg and G. Hjalmtysson and J. Rexford},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On static reachability analysis of IP networks},
year={2005},
volume={3},
number={},
pages={2170-2183 vol. 3},
abstract={The primary purpose of a network is to provide reachability between applications running on end hosts. In this paper, we describe how to compute the reachability a network provides from a snapshot of the configuration state from each of the routers. Our primary contribution is the precise definition of the potential reachability of a network and a substantial simplification of the problem through a unified modeling of packet filters and routing protocols. In the end, we reduce a complex, important practical problem to computing the transitive closure to set union and intersection operations on reachability set representations. We then extend our algorithm to model the influence of packet transformations (e.g., by NATs or ToS remapping) along the path. Our technique for static analysis of network reachability is valuable for verifying the intent of the network designer, troubleshooting reachability problems, and performing "what-if" analysis of failure scenarios.},
keywords={reachability analysis;IP networks;routing protocols;failure analysis;computer network reliability;IP networks;static reachability analysis;routers;packet filters;routing protocols;packet transformations;failure analysis;Reachability analysis;IP networks;Filters;Routing protocols;Failure analysis;Performance analysis;Probes;Telecommunication traffic;Computer networks;Bones},
doi={10.1109/INFCOM.2005.1498492},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498493,
author={Zongpeng Li and Baochun Li and Dan Jiang and Lap Chi Lau},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On achieving optimal throughput with network coding},
year={2005},
volume={3},
number={},
pages={2184-2194 vol. 3},
abstract={With the constraints of network topologies and link capacities, achieving the optimal end-to-end throughput in data networks has been known as a fundamental but computationally hard problem. In this paper, we seek efficient solutions to the problem of achieving optimal throughput in data networks, with single or multiple unicast, multicast and broadcast sessions. Although previous approaches lead to solving NP-complete problems, we show the surprising result that, facilitated by the recent advances of network coding, computing the strategies to achieve the optimal end-to-end throughput can be performed in polynomial time. This result holds for one or more communication sessions, as well as in the overlay network model. Supported by empirical studies, we present the surprising observation that in most topologies, applying network coding may not improve the achievable optimal throughput; rather, it facilitates the design of significantly more efficient algorithms to achieve such optimality.},
keywords={optimisation;encoding;telecommunication network topology;network coding;optimal throughput;optimal end-to-end throughput;NP-complete problems;polynomial time;overlay network model;multicast sessions;broadcast sessions;Throughput;Network coding;Routing;Network topology;Unicast;Broadcasting;Decoding;Computer networks;Information theory;Algorithm design and analysis},
doi={10.1109/INFCOM.2005.1498493},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498494,
author={M. Durvy and P. Thiran},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Reaction-diffusion based transmission patterns for ad hoc networks},
year={2005},
volume={3},
number={},
pages={2195-2205 vol. 3},
abstract={We present a new scheme that mimics pattern formation in biological systems to create transmission patterns in multi-hop ad hoc networks. Our scheme is decentralized and relies exclusively on local interactions between the network nodes to create global transmission patterns. A transmission inhibits other transmissions in its immediate surrounding and encourages nodes located further away to transmit. The transmission patterns created by our medium access control scheme combine the efficiency of allocation-based schemes at high traffic loads and the flexibility of random access schemes. Moreover, we show that with appropriately chosen parameters our scheme converges to collision free transmission patterns that guarantee some degree of spatial reuse.},
keywords={ad hoc networks;access protocols;telecommunication traffic;reaction-diffusion based transmission patterns;multihop ad hoc networks;medium access control scheme;allocation-based schemes;traffic loads;random access schemes;Ad hoc networks;Media Access Protocol;Access protocols;Biological systems;Telecommunication traffic;Biology computing;Computer networks;Spread spectrum communication;Wireless application protocol;Time division multiple access},
doi={10.1109/INFCOM.2005.1498494},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498495,
author={Xiaohua Jia and Dongsoo Kim and S. Makki and Peng-Jun Wan and Chih-Wei Yi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Power assignment for k-connectivity in wireless ad hoc networks},
year={2005},
volume={3},
number={},
pages={2206-2211 vol. 3},
abstract={The problem min-power k-connectivity seeks a power assignment to the nodes in a given wireless ad hoc network such that the produced network topology is k-connected and the total power is the lowest. In this paper, we present several approximation algorithms for this problem. Specifically, we propose a 3k-approximation algorithm for any k /spl ges/ 3, a (k + 12H (k))-approximation algorithm for k(2k - 1) /spl les/ n where n is the network size, a (k + 2 [(k + 1)/2])-approximation algorithm for 2 /spl les/ k /spl les/ 7, a 6-approximation algorithm for k = 3, and a 9-approximation algorithm for k = 4.},
keywords={ad hoc networks;telecommunication network topology;approximation theory;wireless ad hoc networks;k-connectivity;power assignment;network topology;approximation algorithms;Intelligent networks;Ad hoc networks;Approximation algorithms;Network topology;Computer science;Mobile ad hoc networks;Wireless sensor networks;Energy consumption;Batteries;Energy conservation},
doi={10.1109/INFCOM.2005.1498495},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498496,
author={Lijun Chen and S. H. Low and J. C. Doyle},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Joint congestion control and media access control design for ad hoc wireless networks},
year={2005},
volume={3},
number={},
pages={2212-2222 vol. 3},
abstract={We present a model for the joint design of congestion control and media access control (MAC) for ad hoc wireless networks. Using contention graph and contention matrix, we formulate resource allocation in the network as a utility maximization problem with constraints that arise from contention for channel access. We present two algorithms that are not only distributed spatially, but more interestingly, they decompose vertically into two protocol layers where TCP and MAC jointly solve the system problem. The first is a primal algorithm where the MAC layer at the links generates congestion (contention) prices based on local aggregate source rates, and TCP sources adjust their rates based on the aggregate prices in their paths. The second is a dual subgradient algorithm where the MAC sub-algorithm is implemented through scheduling link-layer flows according to the congestion prices of the links. Global convergence properties of these algorithms are proved. This is a preliminary step towards a systematic approach to jointly design TCP congestion control algorithms and MAC algorithms, not only to improve performance, but more importantly, to make their interaction more transparent.},
keywords={telecommunication congestion control;access protocols;transport protocols;ad hoc networks;graph theory;resource allocation;matrix algebra;telecommunication channels;ad hoc wireless networks;media access control;congestion control;MAC;contention graph;contention matrix;resource allocation;utility maximization problem;channel access;TCP;dual subgradient algorithm;link-layer flows;global convergence;Media Access Protocol;Wireless networks;Aggregates;Matrix decomposition;Resource management;Access protocols;Scheduling algorithm;Convergence;Algorithm design and analysis;Control systems},
doi={10.1109/INFCOM.2005.1498496},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498497,
author={A. Raniwala and Tzi-cker Chiueh},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Architecture and algorithms for an IEEE 802.11-based multi-channel wireless mesh network},
year={2005},
volume={3},
number={},
pages={2223-2234 vol. 3},
abstract={Even though multiple non-overlapped channels exist in the 2.4 GHz and 5 GHz spectrum, most IEEE 802.11-based multi-hop ad hoc networks today use only a single channel. As a result, these networks rarely can fully exploit the aggregate bandwidth available in the radio spectrum provisioned by the standards. This prevents them from being used as an ISP's wireless last-mile access network or as a wireless enterprise backbone network. In this paper, we propose a multi-channel wireless mesh network (WMN) architecture (called Hyacinth) that equips each mesh network node with multiple 802.11 network interface cards (NICs). The central design issues of this multi-channel WMN architecture are channel assignment and routing. We show that intelligent channel assignment is critical to Hyacinth's performance, present distributed algorithms that utilize only local traffic load information to dynamically assign channels and to route packets, and compare their performance against a centralized algorithm that performs the same functions. Through an extensive simulation study, we show that even with just 2 NICs on each node, it is possible to improve the network throughput by a factor of 6 to 7 when compared with the conventional single-channel ad hoc network architecture. We also describe and evaluate a 9-node Hyacinth prototype that Is built using commodity PCs each equipped with two 802.11a NICs.},
keywords={ad hoc networks;channel allocation;telecommunication network routing;wireless LAN;multi-channel wireless mesh network;IEEE 802.11;radio spectrum;ISP;wireless enterprise backbone network;wireless last-mile access network;multihop ad hoc networks;network interface cards;channel assignment;routing;intelligent channel assignment;Hyacinth;network throughput;Wireless mesh networks;Ad hoc networks;Spread spectrum communication;Aggregates;Bandwidth;Spine;Mesh networks;Network interfaces;Routing;Distributed algorithms},
doi={10.1109/INFCOM.2005.1498497},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498309,
author={J. Ni and D. H. K. Tsang and S. Tatikonda and B. Bensaou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Threshold and reservation based call admission control policies for multiservice resource-sharing systems},
year={2005},
volume={2},
number={},
pages={773-783 vol. 2},
abstract={Many communications and networking systems can be modelled as resource-sharing systems with multiple classes of calls. Call admission control (CAC) is an essential component of such systems. For most practical systems it is prohibitively difficult to compute the optimal CAC policy that optimizes certain performance metrics because of the 'curse of dimensionality'. In this paper we study two families of structured CAC policies: threshold and reservation policies. These policies are easy to implement and have good performance in practice. However, since the number of structured policies grows exponentially with the number of call classes and the capacity of the system, finding the optimal structured policies is a complex unsolved problem. In this paper efficient search algorithms are proposed to find the coordinate optimal structured policies among all structured policies. Through extensive numerical experiments we show that the search algorithms converge quickly and work for systems with large capacity and many call classes. In addition, the returned structured policies have optimal or near-optimal performance, and outperform those structured policies with parameters chosen based on simple heuristics.},
keywords={resource allocation;search problems;telecommunication congestion control;combinatorial mathematics;optimisation;multiservice resource-sharing systems;call admission control;CAC;search algorithms;threshold policies;reservation policies;combinatorial optimization;Call admission control;Bandwidth;Streaming media;Telecommunication traffic;Water resources;Partial response channels;Measurement;Network servers;Computer science;Electronic mail},
doi={10.1109/INFCOM.2005.1498309},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498310,
author={K. Avrachenkov and U. Ayesta and P. Brown and R. Nunez-Queija},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Discriminatory processor sharing revisited},
year={2005},
volume={2},
number={},
pages={784-795 vol. 2},
abstract={As a natural multi-class generalization of the well-known (egalitarian) processor sharing (PS) service discipline, discriminatory processor sharing (DPS) is of great interest in many application areas, including telecommunications. Under DPS, the mean response time conditional on the service requirement is only known in closed form when all classes have exponential service requirement distributions. For generally distributed service requirements, Fayolle et al. (1980) showed that the expected conditional response times satisfy a system of integro-differential equations. In this paper, we exploit that result to prove that, provided the system is stable, for each class the expected unconditional response time is finite and that the expected conditional response time has an asymptote. The asymptotic bias of each class is found in closed form, involving the mean service requirements of all classes and the second moments of all classes but the one under consideration. In the course of the development we prove two other results that are of independent interest: we establish a conservation law for the time average unfinished work of all classes and, using a stochastic coupling argument, we show that the response times of different classes are stochastically ordered according to the DPS weights. Finally, we study DPS as a tool to achieve size based scheduling and we provide guidelines as to how the weights of DPS must be chosen such that DPS outperforms PS.},
keywords={time-sharing systems;processor scheduling;multiprocessing systems;multiclass generalization;processor sharing service discipline;discriminatory processor sharing;DPS;integro-differential equation;stochastic coupling;scheduling;Delay;Differential equations;Telecommunications;Research and development;Stochastic processes;Processor scheduling;Guidelines;Control systems;Quality of service;Internet},
doi={10.1109/INFCOM.2005.1498310},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498311,
author={L. Chu and K. Shen and H. Tang and T. Yang and J. Zhou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Dependency isolation for thread-based multi-tier Internet services},
year={2005},
volume={2},
number={},
pages={796-806 vol. 2},
abstract={Multi-tier Internet service clusters often contain complex calling dependencies among service components spreading across cluster nodes. Without proper handling, partial failure or overload at one component can cause cascading performance degradation in the entire system. While dependency management may not present significant challenges for even-driven services (particularly in the context of staged event-driven architecture), there is a lack of system support for thread-based online services to achieve dependency isolation automatically. To this end, we propose dependency capsule, a new mechanism that supports automatic recognition of dependency states and per-dependency management for thread-based services. Our design employs a number of dependency capsules at each service node: one for each remote service component. Dependency capsules monitor and manage threads that block on supporting services and isolate their performance impact on the capsule host and the rest of the system. In addition to the failure and overload isolation, each capsule can also maintain dependency-specific feedback information to adjust control strategies for better availability and performance. In our implementation, dependency capsules are transparent to application-level services and clustering middleware, which is achieved by intercepting dependency-induced system calls. Additionally, we employ two-level thread management so that only light-weight user-level threads block in dependency capsules. Using four applications on two different clustering middleware platforms, we demonstrate the effectiveness of dependency capsules in improving service availability and throughput during component failures and overload.},
keywords={Internet;multi-threading;middleware;fault tolerant computing;computer network management;multitier Internet service;thread-based online services;dependency capsule;automatic recognition;per-dependency management;remote service component;clustering middleware;two-level thread management;middleware platforms;Web and internet services;Yarn;Availability;Middleware;Power system faults;Power system protection;Degradation;Context-aware services;Condition monitoring;Remote monitoring},
doi={10.1109/INFCOM.2005.1498311},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498312,
author={J. Guo and J. Yao and L. Bhuyan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={An efficient packet scheduling algorithm in network processors},
year={2005},
volume={2},
number={},
pages={807-818 vol. 2},
abstract={Several companies have introduced powerful network processors (NPs) that can be placed in routers to execute various tasks in the network. These tasks can range from IP level table lookup algorithm to application level multimedia transcoding applications. An NP consists of a number of on-chip processors to carry out packet level parallel processing operations. Ensuring good load balancing among the processors increases throughput. However, such multiprocessing also gives rise to increased out-of-order departure of processed packets. In this paper, we first propose a dynamic batch co-scheduling (DBCS) scheme to schedule packets in a heterogeneous network processor assuming that the workload is perfectly divisible. The processed loads from the processors are ordered perfectly. We analyze the throughput and derive expressions for the batch size, scheduling time and maximum number of schedulable processors. To effectively schedule variable length packets in an NP, we propose a packetized dynamic batch-coscheduling (P-DBCS) scheme by applying a combination of deficit round robin (DRR) and surplus round robin (SRR) schemes. We extend the algorithm to handle multiple flows based on a fair scheduling of flows depending on their reservations. Extensive sensitivity results are provided through analysis and simulation to show that the proposed algorithms satisfy both the load balancing and in-order requirements in packet processing.},
keywords={telecommunication network routing;multiprocessing systems;parallel processing;resource allocation;processor scheduling;IP level table lookup algorithm;application level multimedia transcoding application;on-chip processors;packet level parallel processing;load balancing;heterogeneous network processor;packetized dynamic batch-coscheduling;P-DBCS scheme;deficit round robin;DRR;surplus round robin;SRR;fair scheduling;Scheduling algorithm;Processor scheduling;Round robin;Load management;Throughput;Dynamic scheduling;Table lookup;Transcoding;Parallel processing;Out of order},
doi={10.1109/INFCOM.2005.1498312},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498313,
author={E. Leonardi and M. Mellia and M. A. Marsan and F. Neri},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Joint optimal scheduling and routing for maximum network throughput},
year={2005},
volume={2},
number={},
pages={819-830 vol. 2},
abstract={In this paper we consider packet networks loaded by admissible traffic patterns, i.e. by traffic patterns that, if optimally routed, do not overload network resources. In these conditions, we study the combined behavior of distributed dynamic routing and scheduling algorithms based upon link state information, with no knowledge of the average traffic pattern, and we prove that simple schemes can achieve the same network throughput as optimal centralized routing and scheduling algorithms with complete information on the traffic pattern. Our study is based on a flow-level abstract model of the network, and considers elastic traffic, i.e., we assume that flows can adapt their transmission rates to network conditions. As a result, our model captures some of the main features of Internet traffic and of quality-of-service routing approaches being currently proposed for IP networks. We show that efficient dynamic routing and scheduling algorithms can be implemented in a distributed way, and we prove that maximum throughput is achieved also in case of temporary mismatches between the actual link metrics and those used by the routing algorithm. This is a particularly relevant aspect, since any distributed implementation of a routing algorithm requires a periodic exchange of link state information among nodes, and this implies delays, and thus time periods in which the actual link state is not known.},
keywords={Internet;quality of service;IP networks;telecommunication traffic;telecommunication network routing;packet radio networks;scheduling;packet network;distributed dynamic routing;scheduling algorithms;link state information;optimal centralized routing;flow-level abstract model;Internet traffic;quality-of-service routing;IP networks;Optimal scheduling;Throughput;Telecommunication traffic;Traffic control;Quality of service;IP networks;Heuristic algorithms;Scheduling algorithm;Routing protocols;Network topology},
doi={10.1109/INFCOM.2005.1498313},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498314,
author={X. Yuan and Z. Duan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={FRR: a proportional and worst-case fair round robin scheduler},
year={2005},
volume={2},
number={},
pages={831-842 vol. 2},
abstract={In this paper, we propose an O(1) complexity round robin scheduler, called fair round robin (FRR), that provides good fairness and delay properties. Unlike existing O(1) complexity round robin schedulers that can only achieve long term fairness, FRR not only provides proportional fairness, but also maintains a constant normalized worst-case fair index as defined in Bennett and Zhang's work. This means that FRR guarantees both short term and long term fairness among all backlogged flows.},
keywords={data communication;scheduling;packet switching;quality of service;round robin scheduler;fair round robin;FRR;backlogged flows;deterministic network calculus;Round robin;Scheduling algorithm;Delay;Processor scheduling;Quality of service;Bandwidth;High-speed networks;Computer science;Calculus},
doi={10.1109/INFCOM.2005.1498314},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498315,
author={D. Pan and Y. Yang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Credit based fair scheduling for packet switched networks},
year={2005},
volume={2},
number={},
pages={843-854 vol. 2},
abstract={With the rapid development of Internet multimedia applications, the next generation of networks is required to schedule not only the best effort traffic but also the traffic with bandwidth and delay guarantees. Currently, there are two types of fair scheduling algorithms in the literature. The time stamp based schedulers achieve very good fairness and delay guarantees but have high O(logN) time complexity, where N is the number of flows. While the round robin based schedulers reach O(1) time complexity, their delay guarantees are O(N). This paper aims at a fair scheduling algorithm with constant time complexity as well as good fairness and delay guarantees. We first present a credit/balance based fair scheduling algorithm called most credit first (MCF). We theoretically prove that MCF can provide O(logN) fairness, delay and delay jitter guarantees, and demonstrate experimentally that it actually can achieve O(1) guarantees. In order to reduce the O(logN) time complexity of MCF, we further present a more efficient variant of MCF, called fast most credit first (FMCF). FMCF achieves O(1) time complexity by utilizing approximation and synchronization, and at the same time preserves the O(logN) theoretical fairness, delay and delay jitter guarantees of MCF. We also implemented MCF and FMCF in NS/sub 2/ simulator to compare the end to end delay performance with other fair scheduling algorithms. Our experimental results demonstrate that MCF outperforms two commonly used fair schedulers, and FMCF is able to closely match the performance of MCF with reduced time complexity.},
keywords={Internet;multimedia communication;scheduling;computational complexity;delays;telecommunication traffic;packet switching;Internet multimedia application;round robin based schedulers;constant time complexity;credit-balance based fair scheduling algorithm;delay jitter;fast most credit first;FMCF;gateways;generalized processor sharing;GPS;packet switched networks;Packet switching;Processor scheduling;Scheduling algorithm;Telecommunication traffic;Bandwidth;Delay effects;Traffic control;Jitter;IP networks;Next generation networking},
doi={10.1109/INFCOM.2005.1498315},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498316,
author={J. Naor and A. Rosen and G. Scalosub},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Online time-constrained scheduling in linear networks},
year={2005},
volume={2},
number={},
pages={855-865 vol. 2},
abstract={We consider the problem of scheduling a sequence of packets over a linear network, where every packet has a source and a target, as well as a release time and a deadline by which it must arrive at its target. The model we consider is bufferless, where packets are not allowed to be buffered in nodes along their paths other than at their source. This model applies to optical networks where opto-electronic conversion is costly, and packets mostly travel through bufferless hops. The offline version of this problem was previously studied in M. Adler et al. (2002). In this paper we study the online version of the problem, where we are required to schedule the packets without knowledge of future packet arrivals. We use competitive analysis to evaluate the performance of our algorithms. We present the first deterministic online algorithms for several versions of the problem. For the problem of throughput maximization, where all packets have uniform weights, we give an algorithm with a logarithmic competitive ratio, and present some lower bounds. For other weight functions, we show algorithms that achieve optimal competitive ratios. We complete our study with several experimental results.},
keywords={linear network analysis;packet switching;wavelength division multiplexing;scheduling;deterministic algorithms;optoelectronic devices;optimisation;optical fibre networks;packet scheduling;linear network;optical networks;opto-electronic conversion;deterministic online algorithms;maximization;Intelligent networks;Delay;Optical buffering;Job shop scheduling;Processor scheduling;Optical fiber networks;Quality of service;Buffer storage;Computer science;Performance analysis},
doi={10.1109/INFCOM.2005.1498316},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498317,
author={F. Stann and J. Heidemann},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={BARD: Bayesian-assisted resource discovery in sensor networks},
year={2005},
volume={2},
number={},
pages={866-877 vol. 2},
abstract={Data dissemination in sensor networks requires four components: resource discovery, route establishment, packet forwarding, and route maintenance. Resource discovery can be the most costly aspect if meta-data does not exist to guide the search. Geographic routing can minimize search cost when resources are defined by location, and hash-based techniques like data-centric storage can make searching more efficient, subject to increased storage cost. In general, however, flooding is required to locate all resources matching a specification. In this paper, we propose BARD, Bayesian-assisted resource discovery, an approach that optimizes resource discovery in sensor networks by modeling search and routing as a stochastic process. BARD exploits the attribute structure of diffusion and prior routing history to avoid flooding for similar queries. BARD models attributes as random variables and finds routes to arbitrary value sets via Bayesian estimation. Results of occasional flooded queries establish a baseline probability distribution, which is used to focus additional queries. Since this process is probabilistic and approximate, even partial matches from prior searches can still reduce the scope of search. We evaluate the benefits of BARD by extending directed diffusion and examining control overhead with and without our Bayesian filter. These simulations demonstrate a 28% to 73% reduction in control traffic, depending on the number and locations of sources and sinks.},
keywords={information dissemination;wireless sensor networks;routing protocols;belief networks;stochastic processes;probability;telecommunication traffic;data dissemination;wireless sensor networks;resource discovery;route establishment;packet forwarding;geographic routing;hash-based techniques;resources matching;BARD;Bayesian-assisted resource discovery;stochastic process;flooded query;baseline probability distribution;network measurements;network traffic;Bayesian methods;Routing;Costs;Floods;Sensor phenomena and characterization;Stochastic processes;History;Random variables;Probability distribution;Filters},
doi={10.1109/INFCOM.2005.1498317},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498318,
author={M. Yarvis and N. Kushalnagar and H. Singh and A. Rangarajan and Y. Liu and S. Singh},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Exploiting heterogeneity in sensor networks},
year={2005},
volume={2},
number={},
pages={878-890 vol. 2},
abstract={The presence of heterogeneous nodes (i.e., nodes with an enhanced energy capacity or communication capability) in a sensor network is known to increase network reliability and lifetime. However, questions of where how many, and what types of heterogeneous resources to deploy remain largely unexplored. We focus on energy and link heterogeneity in ad hoc sensor networks and consider resource-aware MAC and routing protocols to utilize those resources. Using analysis, simulation, and real testbed measurements, we evaluate the impact of number and placement of heterogeneous resources on performance in networks of different sizes and densities. While we prove that optimal deployment is very hard in general, we also show that only a modest number of reliable, long-range backhaul links and line-powered nodes are required to have a significant impact. Properly deployed, heterogeneity can triple the average delivery rate and provide a 5-fold increase in the lifetime (respectively) of a large batten-powered network of simple sensors.},
keywords={ad hoc networks;wireless sensor networks;telecommunication network reliability;access protocols;routing protocols;radio links;heterogeneous nodes;wireless sensor network;network reliability;ad hoc network;resource-aware MAC protocol;routing protocol;long-range backhaul links;line-powered nodes;Intelligent networks;Mechanical sensors;Testing;Analytical models;Hardware;Costs;Fabrication;Application software;Power engineering computing;Research and development},
doi={10.1109/INFCOM.2005.1498318},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498319,
author={G. Zhou and T. He and J. A. Stankovic and T. Abdelzaher},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={RID: radio interference detection in wireless sensor networks},
year={2005},
volume={2},
number={},
pages={891-901 vol. 2},
abstract={In wireless sensor networks, many protocols assume that if node A is able to interfere with node B's packet reception, node B is within node A's communication range. It is also assumed that if node B is within node A's communication range, node A is able to interfere with node B's packet reception from any transmitter. While these assumptions may be useful in protocol design, they are not valid, according to the real experiments we conducted in MICA2 platform. For a strong link that has a high packet delivery ratio, the interference range is observed smaller than the communication range, while for a weak link that has a low packet delivery ratio, the interference range is larger than the communication range. So using communication range information alone is not enough to design real collision-free media access control protocols. This paper presents a radio interference detection protocol (RID) and its variation (RID-B) to detect run-time radio interference relations among nodes. The interference detection results are used to design real collision-free TDMA protocols. With extensive simulations in GlomoSim, and with sensor network application scenarios, we observe that the TDMA which uses the interference detection results has 100% packet delivery ratio, while the traditional TDMA has packet loss up to 60%, in heavy load. In addition to the scheduling-based TDMA protocols, we also explore the application of interference detection on contention-based MAC protocols.},
keywords={wireless sensor networks;time division multiple access;radiofrequency interference;interference suppression;telecommunication control;wireless sensor networks;MICA2 platform;collision-free media access control protocols;radio interference detection protocol;RID;collision-free TDMA protocol;GlomoSim;contention-based MAC protocol;Electromagnetic interference;Intelligent networks;Wireless sensor networks;Media Access Protocol;Time division multiple access;Radio transmitters;Mobile communication;Receivers;Access protocols;Runtime},
doi={10.1109/INFCOM.2005.1498319},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498320,
author={M. Ding and D. Chen and K. Xing and X. Cheng},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Localized fault-tolerant event boundary detection in sensor networks},
year={2005},
volume={2},
number={},
pages={902-913 vol. 2},
abstract={This paper targets the identification of faulty sensors and detection of the reach of events in sensor networks with faulty sensors. Typical applications include the detection of the transportation front line of a contamination and the diagnosis of network health. We propose and analyze two novel algorithms for faulty sensor identification and fault-tolerant event boundary detection. These algorithms are purely localized and thus scale well to large sensor networks. Their computational overhead is low, since only simple numerical operations are involved. Simulation results indicate that these algorithms can clearly detect the event boundary and can identify faulty sensors with a high accuracy and a low false alarm rate when as many as 20% sensors become faulty. Our work is exploratory in that the proposed algorithms can accept any kind of scalar values as inputs, a dramatic improvement over existing works that take only 0/1 decision predicates. Therefore, our algorithms are generic. They can be applied as long as the "events" can be modelled by numerical numbers. Though designed for sensor networks, our algorithms can be applied to the outlier detection and regional data analysis in spatial data mining.},
keywords={wireless sensor networks;fault diagnosis;fault tolerance;data mining;data analysis;sensor networks;transportation front line detection;network health diagnosis;fault-tolerant event boundary detection;regional data analysis;spatial data mining;Fault tolerance;Event detection;Fault detection;Fault diagnosis;Algorithm design and analysis;Transportation;Contamination;Computational modeling;Discrete event simulation;Numerical models},
doi={10.1109/INFCOM.2005.1498320},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498321,
author={M. Chen and J. Zhang and M. N. Murthi and Kamal Premaratne},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={TCP congestion avoidance: a network calculus interpretation and performance improvements},
year={2005},
volume={2},
number={},
pages={914-925 vol. 2},
abstract={TCP congestion avoidance mechanisms determine methods by which a source adjusts its window size according to network conditions. Although network calculus has been utilized to study window flow control, the use of network calculus to determine an optimal window controller and to provide analytical guidance to TCP congestion avoidance has persisted as an open problem. For the first time within a network calculus setting, we determine an optimal window size control method for general flow control problems. We also show that the basic TCP congestion avoidance mechanisms in TCP Vegas, enhanced TCP Vegas and fast TCP can be viewed as different approaches to approximating the optimal NC controller, with each TCP variant making different assumptions in terms of parameter estimation and control implementation strategy. Therefore, the network calculus controller reveals the inherent underlying structure in TCP congestion avoidance. Furthermore, we demonstrate through ns-2 simulations that an approximation of a particular NC controller achieves performance gains in terms of link throughput and source node throughput fairness with respect to TCP Vegas, enhanced TCP Vegas and fast TCP.},
keywords={transport protocols;telecommunication congestion control;parameter estimation;Internet;TCP congestion avoidance mechanism;network calculus;window flow control;enhanced TCP Vegas;parameter estimation;ns-2 simulations;Calculus;Size control;Throughput;Optimal control;Parameter estimation;Delay estimation;Bandwidth;Transport protocols;Performance gain;Internet},
doi={10.1109/INFCOM.2005.1498321},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498322,
author={S. Ebrahimi-Taghizadeh and A. Helmy and S. Gupta},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={TCP vs. TCP: a systematic study of adverse impact of short-lived TCP flows on long-lived TCP flows},
year={2005},
volume={2},
number={},
pages={926-937 vol. 2},
abstract={This paper describes systematical development of TCP adversarial scenarios where we use short-lived TCP flows to adversely influence long-lived TCP flows. Our scenarios are interesting since, (a) they point out the increased vulnerabilities of recently proposed scheduling, AQM and routing techniques that further favor short-lived TCP flows and (b) they are more difficult to detect when intentionally found to target long-lived TCP flows. We systematically exploit the ability of TCP flows in slow-start to rapidly capture greater proportion of bandwidth compared to long-lived TCP flows in congestion avoidance phase, to a point where they drive long-lived TCP flows into timeout. We use simulations, analysis and experiments to systematically study the dependence of the severity of impact on long-lived TCP flows on key parameters of short-lived TCP flows-including their locations, durations and numbers, as well as the intervals between consecutive flows. We derive characteristics of pattern of short-lived flows that exhibit extreme adverse impact on long-lived TCP flows. Counter to common beliefs, we show that targeting bottleneck links does not always cause maximal performance degradation for the long-lived flows. In particular, our approach illustrates the interactions between TCP flows and multiple bottleneck links and their sensitivities to correlated losses in the absence of 'non-TCP friendly' flows and paves the way for a systematic synthesis of worst-case congestion scenarios. While randomly generated sequences of short-lived TCP flows may provide some reductions (up to 10%) in the throughput of the long-lived flows, the scenarios we generate cause much greater reductions (>85%) for several TCP variants and for different packet drop policies (DropTail, RED).},
keywords={transport protocols;scheduling;routing protocols;telecommunication congestion control;telecommunication links;correlation theory;random sequences;telecommunication network management;queueing theory;telecommunication services;TCP adversarial scenario;short-lived TCP flows;vulnerability;scheduling;AQM;routing technique;congestion avoidance;targeting bottleneck links;correlation;randomly generated sequence;packet drop policies;DoS;denial of service;Throughput;Mice;Bandwidth;Internet;Routing;Analytical models;Counting circuits;Degradation;NASA;Performance loss},
doi={10.1109/INFCOM.2005.1498322},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498323,
author={J. Wang and D. X. Wei and S. H. Low},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Modelling and stability of FAST TCP},
year={2005},
volume={2},
number={},
pages={938-948 vol. 2},
abstract={We introduce a discrete-time model of FAST TCP that fully captures the effect of self-clocking and compare it with the traditional continuous-time model. While the continuous-time model predicts instability for homogeneous sources sharing a single link when feedback delay is large, experiments suggest otherwise. Using the discrete-time model, we prove that FAST TCP is locally asymptotically stable in general networks when all sources have a common round-trip feedback delay, no matter how large the delay is. We also prove global stability for a single bottleneck link in the absence of feedback delay. The techniques developed here are new and applicable to other protocols.},
keywords={discrete time systems;transport protocols;delay systems;telecommunication links;telecommunication congestion control;resource allocation;Internet;discrete-time model;FAST TCP;transmission control protocol;self-clocking;continuous-time model;homogeneous sources;feedback delay;global stability;single bottleneck link;congestion control;Feedback;Delay;Stability analysis;Internet;Size control;Pi control;Proportional control;Predictive models;Protocols;Asymptotic stability},
doi={10.1109/INFCOM.2005.1498323},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498324,
author={E. Brosh and G. Lubetzky-Sharon and Y. Shavitt},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Spatial-temporal analysis of passive TCP measurements},
year={2005},
volume={2},
number={},
pages={949-959 vol. 2},
abstract={In this paper we look at TCP data which was passively collected from an edge ISP, and analyze it to obtain some new results and deeper understanding of TCP loss process. The focus of our study is to identify the 'root cause' links, i.e., the links that are responsible for the majority of the losses or reorders found on the end-to-end TCP connection. We suggest a new root cause criterion and a cost-effective algorithm to identify the root cause links. The algorithm incorporates a new out-of-sequence packet classification technique which is interesting by itself. We test our algorithm on the collected and simulated data and analytically justify its correctness. The simulation results show that the algorithm has a 95% detection rate with 10% false detection rate. We also analyze TCP temporal loss process, and found that the burst loss size is geometrically distributed. We analyze the TCP time-out loss indication under the Bernoulli loss model, which is the simplest model that can cause a geometric distribution, and show that the behavior of the TCP loss process is not different than when tail drop is assumed.},
keywords={Internet;telecommunication services;telecommunication links;transport protocols;spatiotemporal phenomena;ISP;Internet service provider;network links;end-to-end TCP connection;transmission control protocol;out-of-sequence packet classification technique;geometric distribution;Bernoulli loss model;spatial-temporal analysis;Solid modeling;TCPIP;Analytical models;Algorithm design and analysis;Protocols;Probes;Telecommunication traffic;Electric variables measurement;Computer science;Testing},
doi={10.1109/INFCOM.2005.1498324},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498325,
author={Cheng-Shang Chang and Duan-Shin Lee and Chao-Lin Yu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Generalization of the Pollaczek-Khinchin formula for throughput analysis of input-buffered switches},
year={2005},
volume={2},
number={},
pages={960-970 vol. 2},
abstract={Many switch architectures with buffers placed at input ports suffer from the head-of-line blocking (HOL) problem and thus can not achieve 100% throughput. For an input-buffered switch, the number of HOL packets is often characterized by the Lindley equation for a discrete-time queue, i.e. q(t+1)=(q(t)-F)/sup +/+a(t), where q(t) is the number of HOL packets at time t, a(t) is the number of new HOL packets at time t, and F is the maximum number of HOL packets that can depart per unit of time. As the total number of HOL packets is bounded in a switch, it places an upper limit on the expected number of HOL packets. Thus, the maximum throughput is the utilization that makes the expected HOL packets equal to the upper limit. For the case with F=1, the expected number of HOL packets can be found via the Pollaczek-Khinchin formula and the maximum throughput can be solved by a quadratic equation as reported in [M.J. Karol et al. (1987), C. Kolias et al. (1996), G. Thomas (1997)]. One of the main contributions of this paper is that we derive a generalized Pollaczek-Khinchin formula for the case F>1. Such a formula is then used for finding the maximum throughput of several input-buffered switches. For the case F/spl Gt/1, numerical computation of the maximum throughput becomes difficult. For large F, we present several bounds and approximations for the throughput. Numerical studies and simulation results confirm that our approximation methods work well.},
keywords={discrete time systems;queueing theory;packet switching;approximation theory;buffer storage;head-of-line blocking problem;HOL packet;Lindley equation;discrete-time queue;Pollaczek-Khinchin formula;quadratic equation;input-buffered switches;approximation method;Throughput;Optical switches;Packet switching;Optical buffering;Communication switching;Optical packet switching;Equations;Optical fibers;High speed optical techniques;Buffer storage},
doi={10.1109/INFCOM.2005.1498325},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498326,
author={P. Giaccone and E. Leonardi and D. Shah},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On the maximal throughput of networks with finite buffers and its application to buffered crossbars},
year={2005},
volume={2},
number={},
pages={971-980 vol. 2},
abstract={The advent of packet networks has motivated many researchers to study the performance of networks of queues in the last decade or two. However, most of the previous work assumes the availability of infinite queue-size. Instead, in this paper, we study the maximal achievable throughput in a flow-controlled lossless network with finite-queue size. In such networks, throughput depends on the packet scheduling policy utilized. As the main of this paper, we obtain a dynamic scheduling policy that achieves the maximal throughput (equal to the maximal throughput in the presence of infinite queue-size) with a minimal finite queue-size at the internal nodes of the network. Though the performance of the policy is ideal, it is quite complex and hence difficult to implement. This leads us to a design of simpler and possibly implementable policy. We obtain a natural trade-off between throughput and queue-size for this policy. We apply our results to the packet switches with buffered crossbar architecture. We propose a simple, implementable, distributed scheduling policy which provides high throughput in the presence of minimal internal buffer. We also obtain a natural trade-off between throughput, internal speedup and buffer-size providing a switch designer with a gamut of designs. To the best of authors' knowledge, this is one of the first attempts to study the throughput for general networks with finite queue-size. We believe that our methods are general and can be useful in other contexts.},
keywords={queueing theory;telecommunication congestion control;packet switching;dynamic scheduling;buffer storage;computer networks;network performance;availability;flow-controlled lossless network;finite-queue size;dynamic scheduling policy;packet switches;buffered crossbar architecture;gamut;Throughput;Switches;Packet switching;Availability;Computer architecture;Performance loss;Queueing analysis;Scheduling algorithm;Dynamic scheduling;Asynchronous transfer mode},
doi={10.1109/INFCOM.2005.1498326},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498327,
author={S. -. Chuang and S. Iyer and N. McKeown},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Practical algorithms for performance guarantees in buffered crossbars},
year={2005},
volume={2},
number={},
pages={981-991 vol. 2},
abstract={This paper is about high capacity switches and routers that give guaranteed throughput, rate and delay guarantees. Many routers are built using input queueing or combined input and output queueing (CIOQ), using crossbar switching fabrics. But such routers require impractically complex scheduling algorithms to provide the desired guarantees. We explore how a buffered crossbar-a crossbar switch with a packet buffer at each crosspoint-can provide guaranteed performance (throughput, rate, and delay), with less complex, practical scheduling algorithms. We describe scheduling algorithms that operate in parallel on each input and output port, and hence are scalable. With these algorithms, buffered crossbars with a speedup of two can provide 100% throughput, rate, and delay guarantees.},
keywords={telecommunication network routing;queueing theory;scheduling;electronic switching systems;buffer storage;telecommunication computing;telecommunication network reliability;high capacity switches;network routers;delay;combined input-output queueing;CIOQ;scheduling algorithm;buffered crossbar switching fabrics;scalability;Switches;Throughput;Delay;Scheduling algorithm;Fabrics;Packet switching;High performance computing;Laboratories;Pipelines;Spine},
doi={10.1109/INFCOM.2005.1498327},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498328,
author={S. Kaxiras and G. Keramidas},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={IPStash: a set-associative memory approach for efficient IP-lookup},
year={2005},
volume={2},
number={},
pages={992-1001 vol. 2},
abstract={IP-lookup is a challenging problem because of the increasing routing table sizes, increased traffic and higher speed links. These characteristics lead to the prevalence of hardware solutions such as TCAMs (ternary content addressable memories), despite their high power consumption, low update rate and increased board area requirements. We propose a memory architecture called IPStash to act as a TCAM replacement, offering at the same time, high update rate, higher performance and significant power savings. The premise of our work is that full associativity is not necessary for IP-lookup. Rather, we show that the required associativity is simply a function of the routing table size, Thus, we propose a memory architecture similar to set-associative caches but enhanced with mechanisms to facilitate IP-lookup and in particular longest prefix match (LPM). To reach a minimum level of required associativity we introduce an iterative method to perform LPM in a small number of iterations. This allows us to insert route prefixes of different lengths in IPStash very efficiently, selecting the most appropriate index in each case. Orthogonal to this, we use skewed associativity to increase the effective capacity of our devices. We thoroughly examine different choices in partitioning routing tables for the iterative LPM and the design space for the IPStash devices. The proposed architecture is also easily expandable. Using the Cacti 3.2 access time and power consumption simulation tool we explore the design space for IPStash devices and we compare them with the best blocked commercial TCAMs.},
keywords={IP networks;table lookup;telecommunication network routing;telecommunication links;iterative methods;memory architecture;cache storage;power consumption;content-addressable storage;IP-lookup;routing table;network link;power consumption;memory architecture;IPStash;set-associative caches;longest prefix match;LPM;iterative method;Cacti 3.2 access time;Routing;Delay;Space exploration;IP networks;Random access memory;Hardware;Energy consumption;Iterative methods;Information security;Tree data structures},
doi={10.1109/INFCOM.2005.1498328},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498329,
author={S. Liu and T. Basar and R. Srikant},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Pitfalls in the fluid modeling of RTT variations in window-based congestion control},
year={2005},
volume={2},
number={},
pages={1002-1012 vol. 2},
abstract={Deterministic delay differential equation models, where the packet traffic is modeled as a fluid, are widely used to study congestion control algorithms in the Internet. In this paper, we point out some pitfalls in such fluid modeling of window flow control algorithms. Specifically, we argue that the modeling assumptions used to capture the variability in the RTT (due to queue length fluctuations) may play a critical role in our ability to design stable algorithms. We study two scenarios to illustrate the dramatic impact of RTT modeling. We first consider TCP-Reno with RED, and show that assuming that the RTT is a constant (when it is actually time-varying) leads to conservative parameter choices, i.e., the system continues to be stable even with variable RTT. On the other hand, for the recently proposed stabilized Vegas, we show the following result: while the network can be stabilized under the constant RTT assumption, there is no choice of parameters that would stabilize the system when the RTT variations are taken into account. Interestingly, such problems do not arise if the congestion-control mechanisms at the end-users are rate-based.},
keywords={telecommunication traffic;telecommunication congestion control;delays;Internet;transport protocols;random processes;differential equations;deterministic delay differential equation model;packet traffic;congestion control algorithm;Internet;pitfalls;fluid modeling;window flow control;RTT;TCP-Reno;transmission control protocol;RED;randomly early detection;stabilized Vegas;Delay;Fluid flow control;Mathematical model;Differential equations;Internet;Stability;Performance analysis;Traffic control;Fluctuations;Algorithm design and analysis},
doi={10.1109/INFCOM.2005.1498329},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498330,
author={Q. Wu and N. S. V. Rao},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A class of reliable UDP-based transport protocols based on stochastic approximation},
year={2005},
volume={2},
number={},
pages={1013-1024 vol. 2},
abstract={The capacities of Internet backbone links have been continuously improving over the last decade, but such improvements have not been fully realized at the application level, particularly in high-performance applications. The complicated and monolithic TCP-AIMD dynamics are responsible to a large degree for low throughputs as a result of the difficulty in optimally configuring its parameters such as buffer sizes, AIMD coefficients, and slow-start transition points. In this paper, we propose a new class of UDP-based transport protocols that utilize a rate control scheme founded on the stochastic approximation method to achieve high throughputs at the application level. These protocols operate around a local maximum of the throughput regression curve by dynamically adjusting the source rate in response to acknowledgements and losses based on the statistical behavior of the network connection. We analytically show that this protocol generates a TCP-friendly flow, and also stochastically converges to the maximum throughput under a monotone loss rate condition. Our implementation achieved very robust performance over diverse Internet connections with different characteristics: it tracked the peak throughput in presence of time-varying cross traffic and consistently achieved 2-5 times the throughput of default TCP without significantly affecting the concurrent regular traffic.},
keywords={telecommunication congestion control;transport protocols;Internet;telecommunication links;regression analysis;approximation theory;telecommunication network reliability;reliable UDP;transport protocol;stochastic approximation;Internet backbone link;monolithic TCP-AIMD dynamics;rate control scheme;stochastic approximation method;throughput regression curve;monotone loss rate condition;time-varying cross traffic;congestion control;Transport protocols;Stochastic processes;Throughput;Internet;Bandwidth;Spine;Application software;Communication system traffic control;Telecommunication traffic;Traffic control},
doi={10.1109/INFCOM.2005.1498330},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498331,
author={S. H. Low and L. L. H. Andrew and B. P. Wydrowski},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Understanding XCP: equilibrium and fairness},
year={2005},
volume={2},
number={},
pages={1025-1036 vol. 2},
abstract={We prove that the XCP equilibrium solves a constrained max-min fairness problem by identifying it with the unique solution of a hierarchy of optimization problems, namely those solved by max-min fair allocation, but solved by XCP under an additional constraint. We describe an algorithm to compute this equilibrium and derive a lower and upper bound on link utilization. While XCP reduces to max-min allocation at a single link, in a network the additional constraint can cause a flow to receive an arbitrarily small fraction of its max-min allocation. We present simulation results to confirm our analytical findings.},
keywords={mathematical programming;resource allocation;telecommunication congestion control;telecommunication traffic;constraint theory;transport protocols;explicit control protocol;XCP equilibrium;max-min fair allocation;mathematical programming;optimization problem;flow control;additional constraint;Network topology;Australia;Constraint optimization;Upper bound;Computational modeling;Analytical models;Mathematical programming;Internet;Explosives;Grid computing},
doi={10.1109/INFCOM.2005.1498331},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498332,
author={Y. Zhang and T. R. Henderson},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={An implementation and experimental study of the explicit control protocol (XCP)},
year={2005},
volume={2},
number={},
pages={1037-1048 vol. 2},
abstract={The explicit control protocol (XCP) has been proposed as a multi-level network feedback mechanism for congestion control of Internet transport protocols. Theoretical and simulation results have suggested that the protocol is stable and efficient over high bandwidth-delay product paths, while being more scalable to deploy than mechanisms that require per-flow state in routers. However, there is little operational experience with the approach. Since the deployment of XCP would require changes to both the end hosts and routers, it is important to study the implications of this new architecture before advocating such wide scale changes to Internets. This paper presents the results of an experimental study of XCP. We first implemented XCP in the Linux kernel and solved various systems issues. After validating previously reported simulation results, we studied the sensitivity of XCP's performance to various environmental factors, and discovered issues with TCP/IP configuration, capacity misestimation due to link sharing, handling of non-congestion losses, and the partial deployment of XCP queues in the network. These sensitivities can significantly reduce XCP's ability to control congestion and achieve fairness. Our contributions are twofold. First, through implementation we have revealed the challenges in platforms that lack large native data types or floating point arithmetic, and the need to keep fractions in the XCP protocol header. Second, through experiment and analysis we have identified several possibilities for XCP to enter into incorrect feedback control loops and adversely affect the performance. The challenges identified are deployment challenges intrinsic to the XCP design, and they suggest that the current proposal requires additional development and extension.},
keywords={telecommunication congestion control;Internet;transport protocols;queueing theory;floating point arithmetic;Linux;operating system kernels;IP networks;telecommunication links;explicit control protocol;XCP queue;multilevel network feedback mechanism;congestion control;Internet transport protocol;bandwidth-delay product path;per-flow state;Linux kernel system;TCP-IP configuration;capacity misestimation;link sharing;noncongestion loss handling;floating point arithmetic;Transport protocols;Feedback;IP networks;Internet;Linux;Kernel;Performance loss;Environmental factors;TCPIP;Floating-point arithmetic},
doi={10.1109/INFCOM.2005.1498332},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498333,
author={Pankaj Risbood and Swarup Acharya and Bhawna Gupta},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The BEST challenge for next-generation Ethernet services},
year={2005},
volume={2},
number={},
pages={1049-1059 vol. 2},
abstract={Service providers are starting to offer next-generation E-Line (point-to-point) and E-LAN (multipoint-to-multipoint) Ethernet services over their existing SONET/SDH networks. While Ethernet typically is "best-effort", these emerging services are expected to be "carrier-class" with strict bandwidth guarantees. Consequently, spanning tree creation, critical to any Ethernet network is fundamentally changed; each tree hop now needs to have sufficient capacity to meet the requisite bandwidth demands. In this paper, we introduce the bandwidth-endowed spanning tree (BEST) problem. Unlike the polynomial complexity of standard spanning tree algorithms, BEST is NP-complete, raising questions about the scalability of these services. We propose offline and online algorithms and study their performance using extensive simulations. We show that leveraging the Virtual Concatenation protocol (ITU-T G.707) is key to practical algorithms that are both effective and efficient. Inspite of the theoretical hardness, the online algorithms we propose are a good match to "optimal", offline integer programming benchmarks, demonstrating the viability of next-generation Ethernet services.},
keywords={computational complexity;SONET;integer programming;synchronous digital hierarchy;trees (mathematics);optical fibre LAN;next-generation Ethernet service;E-LAN;SONET-SDH network;bandwidth-endowed spanning tree;BEST challenge;polynomial complexity;NP-complete;online algorithm;virtual concatenation protocol;ITU-T G.707;optimal offline integer programming;Ethernet networks;Bandwidth;Protocols;Local area networks;Polynomials;Scalability;Virtual private networks;Frame relay;SONET;Next generation networking},
doi={10.1109/INFCOM.2005.1498333},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498334,
author={W. Wei and B. Wang and C. Zhang and J. Kurose and D. Towsley},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Classification of access network types: Ethernet wireless LAN, ADSL, cable modem or dialup?},
year={2005},
volume={2},
number={},
pages={1060-1071 vol. 2},
abstract={Ethernet, wireless LAN, ADSL, cable modem and dialup are common access networks, but have dramatically different characteristics. Fast and accurate classification of access network type can improve protocol or application performance significantly. In this paper, we propose a simple and efficient end-end scheme to classify the type of an access network into three categories: Ethernet, wireless LAN and low-bandwidth connection. Our scheme is based on the intrinsic characteristics of the various access networks and utilizes the median and entropy of packet pair inter-arrival times. Extensive experiments show that our scheme obtains accurate classification results in a very short time (10 to 100 seconds).},
keywords={wireless LAN;digital subscriber lines;modems;inter-computer links;radio access networks;access network;Ethernet;wireless LAN;asymmetric digital subscriber line;ADSL;cable modem;dialup;low-bandwidth connection;packet pair interarrival time;Ethernet networks;Wireless LAN;Modems;Bandwidth;Peer to peer computing;Computer science;Access protocols;Application software;Joining processes;Hybrid fiber coaxial cables},
doi={10.1109/INFCOM.2005.1498334},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498335,
author={A. Dhamdhere and H. Jiang and C. Dovrolis},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Buffer sizing for congested Internet links},
year={2005},
volume={2},
number={},
pages={1072-1083 vol. 2},
abstract={Packet buffers in router/switch interfaces constitute a central element of packet networks. The appropriate sizing of these buffers is an important and open research problem. Much of the previous work on buffer sizing modeled the traffic as an exogenous process, i.e., independent of the network state, ignoring the fact that the offered load from TCP flows depends on delays and losses in the network. In TCP-aware work, the objective has often been to maximize the utilization of the link, without considering the resulting loss rate. Also, previous TCP-aware buffer sizing schemes did not distinguish between flows that are bottlenecked at the given link and flows that are bottlenecked elsewhere, or that are limited by their size or advertised window. In this work, we derive the minimum buffer requirement for a drop-tail link, given constraints on the minimum utilization, maximum loss rate, and maximum queueing delay, when it is feasible to achieve all three constraints. Our results are applicable when most of the traffic (80-90%) at the given link is generated by large TCP flows that are bottlenecked at that link. For heterogeneous flows, we show that the buffer requirement depends on the harmonic mean of their round-trip times, and on the degree of loss synchronization. To limit the maximum loss rate, the buffer should be proportional to the number of flows that are bottlenecked at that link, when that number exceeds a certain threshold. The maximum queueing delay constraint, on the other hand, provides a simple upper bound on the buffer requirement. We also describe how to estimate the parameters of our buffer sizing formula from packet and loss traces, evaluate the proposed model with simulations, and compare it with two other buffer provisioning schemes.},
keywords={telecommunication congestion control;Internet;telecommunication traffic;queueing theory;transport protocols;delays;constraint theory;routing protocols;parameter estimation;synchronisation;telecommunication links;packet switching;network interfaces;packet buffer sizing;congested Internet link;router-switch interface;TCP flow;drop-tail link;heterogeneous flow;harmonic mean;round-trip time;synchronization loss;queueing delay constraint;parameter estimation;congestion control;buffer management;telecommunication traffic;Internet;Delay;Traffic control;Switches;Packet switching;Telecommunication traffic;Upper bound;Parameter estimation;Communication system traffic control;Engineering profession},
doi={10.1109/INFCOM.2005.1498335},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498336,
author={J. -. Guillaume and M. Latapy},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Relevance of massively distributed explorations of the Internet topology: simulation results},
year={2005},
volume={2},
number={},
pages={1084-1094 vol. 2},
abstract={Internet maps are generally constructed using the traceroute tool from a few sources to many destinations. It appeared recently that this exploration process gives a partial and biased view of the real topology, which leads to the idea of increasing the number of sources to improve the quality of the maps. In this paper, we present a set of experiments we have conduced to evaluate the relevance of this approach. It appears that the statistical properties of the underlying network have a strong influence on the quality of the obtained maps, which can be improved using massively distributed explorations. Conversely, we show that the exploration process induces some properties on the maps. We validate our analysis using real-world data and experiments and we discuss its implications.},
keywords={Internet;telecommunication network topology;graph theory;telecommunication network routing;massively distributed exploration;Internet topology;traceroute tool;network measurement;graph theory;Internet;Network topology;Data analysis;Graph theory;Shape;Robustness;Protocols;IP networks},
doi={10.1109/INFCOM.2005.1498336},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498337,
author={L. Pavel},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Power control for OSNR optimization in optical networks: a distributed algorithm via a central cost approach},
year={2005},
volume={2},
number={},
pages={1095-1105 vol. 2},
abstract={This paper addresses the problem of optical signal-to-noise ratio (OSNR) optimization in optical networks. An analytical OSNR network model is developed for a general multi-link configuration, that includes the contribution of amplified spontaneous emission and crosstalk accumulation. An network OSNR optimization problem is formulated such that all channels maintain a desired individual OSNR level, while input optical power is minimized. An iterative, distributed algorithm for channel power control is proposed, which is shown to converge geometrically to the optimal solution. Convergence is proved for both synchronous and asynchronous operation.},
keywords={iterative methods;power control;distributed algorithms;optical fibre networks;crosstalk;superradiance;telecommunication links;optimisation;telecommunication channels;channel power control;OSNR;optical network optimization;iterative distributed algorithm;central cost approach;multilink configuration;spontaneous emission amplification;crosstalk accumulation;synchronous-asynchronous operation;Power control;Signal to noise ratio;Optical noise;Optical fiber networks;Distributed algorithms;Cost function;Stimulated emission;Optical crosstalk;Analytical models;Spontaneous emission},
doi={10.1109/INFCOM.2005.1498337},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498338,
author={M. Kurant and P. Thiran},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On survivable routing of mesh topologies in IP-over-WDM networks},
year={2005},
volume={2},
number={},
pages={1106-1116 vol. 2},
abstract={Failure restoration at the IP layer in IP-over-WDM networks requires to map the IP topology on the WDM topology in such a way that a failure at the WDM layer leaves the IP topology connected. Such a mapping is called survivable. Finding a survivable mapping is known to be NP-complete E. Modiano et al., (2002), making it impossible in practice to assess the existence or absence of such a mapping for large networks, (i) We first introduce a new concept of piecewise survivability, which makes the problem much easier, and allows us to formally prove that a given survivable mapping does or does not exist, (ii) Secondly, we show how to trace the vulnerable areas in the topology, and how to strengthen them to enable a survivable mapping, (iii) Thirdly, we give an efficient and scalable algorithm that finds a survivable mapping. In contrast to the heuristics proposed in the literature to date, our algorithm exhibits a number of provable properties that are crucial for (i) and (ii). We consider both link and node failures at the physical layer.},
keywords={telecommunication network routing;telecommunication network topology;mesh generation;IP networks;optimisation;computational complexity;wavelength division multiplexing;computer network reliability;survivable routing;mesh topology;IP-over-WDM network;failure restoration;survivable mapping;NP-complete;scalable algorithm;Routing;Network topology;Intelligent networks;Wavelength division multiplexing;Protection;Physical layer;Computer science;Optical switches},
doi={10.1109/INFCOM.2005.1498338},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498339,
author={Anurag Srivastava and Swarup Acharya and Mamoor Alicherry and Bhawna Gupta and Pankaj Risbood},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Differential delay aware routing for Ethernet over SONET/SDH},
year={2005},
volume={2},
number={},
pages={1117-1127 vol. 2},
abstract={The virtual concatenation protocol in SONET/SDH has ushered in a novel routing paradigm that enables a circuit to be "split" and routed over multiple paths. However, this diverse routing causes differential delay among the paths which can impact service if not accounted for in the routing. In this paper, we introduce the differential delay aware routing problem and show that it is not only NP-complete but is also provably hard to approximate within a constant factor. However, by transforming it into a flow routing formulation, we can derive effective, practical solutions. We present various algorithms and use extensive simulations to show that they are a good match to an "ideal" integer linear programming formulation. We also highlight how the differential delay data allows individual link delays to be reverse-engineered. We propose three algorithms to derive link delays including one that leverages the flexibility in the virtual concatenation protocol bits. Given the rise of next-generation applications such as online games where latency information is key, this knowledge of link delays, heretofore only loosely approximated, enables the telecom infrastructure to be more effective in supporting these applications.},
keywords={optical fibre LAN;computational complexity;integer programming;linear programming;synchronous digital hierarchy;SONET;protocols;delays;differential delay aware routing;Ethernet;SONET;SDH;virtual concatenation protocol;NP-complete problem;constant factor;integer linear programming formulation;next-generation application;telecom infrastructure;Delay;Routing;Ethernet networks;SONET;Synchronous digital hierarchy;Protocols;Telecommunication traffic;Virtual colonoscopy;Circuits;Costs},
doi={10.1109/INFCOM.2005.1498339},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498340,
author={H. Q. Ngo and D. Pan and Y. Yang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Optical switching networks with minimum number of limited range wavelength converters},
year={2005},
volume={2},
number={},
pages={1128-1138 vol. 2},
abstract={We study the problem of determining the minimum number of limited range wavelength converters needed to construct strictly, wide-sense, and rearrangeably nonblocking optical cross-connects for both unicast and multicast traffic patterns. We give the exact formula to compute this number for rearrangeably and wide-sense nonblocking cross-connects under both the unicast and multicast cases. We also give optimal cross-connect constructions with respect to the number of limited-range wavelength converters.},
keywords={photonic switching systems;optical wavelength conversion;telecommunication traffic;multicast communication;wavelength division multiplexing;optical fibre networks;wavelength converters;nonblocking optical cross-connect;unicast traffic pattern;multicast traffic pattern;wavelength-division-multiplexing;WDM;optical switching networks;Optical fiber networks;Optical wavelength conversion;Wavelength division multiplexing;High speed optical techniques;WDM networks;Optical fiber communication;Communication switching;Unicast;Costs;Optical interconnections},
doi={10.1109/INFCOM.2005.1498340},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498341,
author={A. Sharma and A. Bestavros and I. Matta},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={dPAM: a distributed prefetching protocol for scalable asynchronous multicast in P2P systems},
year={2005},
volume={2},
number={},
pages={1139-1150 vol. 2},
abstract={We leverage the buffering capabilities of end-systems to achieve scalable, asynchronous delivery of streams in a peer-to-peer environment. Unlike existing cache-and-relay schemes, we propose a distributed prefetching protocol where peers prefetch and store portions of the streaming media ahead of their playout time, thus not only turning themselves to possible sources for other peers but their prefetched data can allow them to overcome the departure of their source-peer. This stands in sharp contrast to existing cache-and-relay schemes where the departure of the source-peer forces its peer children to go the original server, thus disrupting their service and increasing server and network load. Through mathematical analysis and simulations, we show the effectiveness of maintaining such asynchronous multicasts from several source-peers to other children peers, and the efficacy of prefetching in the face of peer departures. We confirm the scalability of our dPAM protocol as it is shown to significantly reduce server load.},
keywords={peer-to-peer computing;multicast protocols;mathematical analysis;computer network reliability;peer-to-peer environment;distributed prefetching protocol;media streaming;mathematical analysis;dPAM protocol scalability;asynchronous multicast;Multicast protocols;Prefetching;Peer to peer computing;Feeds;Network servers;Computer science;Distributed computing;Time sharing computer systems;Data engineering;Buffer storage},
doi={10.1109/INFCOM.2005.1498341},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498342,
author={M. Zhong and K. Shen and J. Seiferas},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Non-uniform random membership management in peer-to-peer networks},
year={2005},
volume={2},
number={},
pages={1151-1161 vol. 2},
abstract={Existing random membership management algorithms provide each node with a small, uniformly random subset of global participants. However, many applications would benefit more from non-uniform random member subsets. For instance, non-uniform gossip algorithms can provide distance-based propagation bounds and thus information can reach nearby nodes sooner. In another example, Kleinberg shows that networks with random long-links following distance-based non-uniform distributions exhibit better routing performance than those with uniformly randomized topologies. In this paper, we propose a scalable non-uniform random membership management algorithm, which provides each node with a random membership subset with application-specified probability e.g., with probability inversely proportional to distances. Our algorithm is the first non-uniform random membership management algorithm with proved convergence and bounded convergence time. Moreover, our algorithm does not put specific restrictions on the network topologies and thus has wide applicability.},
keywords={peer-to-peer computing;computer network management;probability;scalable random membership management algorithm;nonuniform random member subset;nonuniform gossip algorithm;probability distributions;peer-to-peer networks;Intelligent networks;Peer to peer computing;Sampling methods;Network topology;Computer network management;Broadcasting;Load management;Probability distribution;Delay;Computer science},
doi={10.1109/INFCOM.2005.1498342},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498343,
author={A. Kumar and J. Xu and E. W. Zegura},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Efficient and scalable query routing for unstructured peer-to-peer networks},
year={2005},
volume={2},
number={},
pages={1162-1173 vol. 2},
abstract={Searching for content in peer-to-peer networks is an interesting and challenging problem. Queries in Gnutella-like unstructured systems that use flooding or random walk to search must visit O(n) nodes in a network of size n, thus consuming significant amounts of bandwidth. In this paper, we propose a query routing protocol that allows low bandwidth consumption during query forwarding using a low cost mechanism to create and maintain information about nearby objects. To achieve this, our protocol maintains a lightweight probabilistic routing table at each node that suggests the location of each object in the network. Following the corresponding routing table entries, a query can reach the destination in a small number of hops with high probability. However, maintaining routing tables in a large and highly dynamic network requires non-traditional mechanisms. We design a novel data structure called an exponentially decaying bloom filter (EDBF) that encodes such probabilistic routing tables in a highly compressed manner, and allows for efficient aggregation and propagation. The search primitives provided by our system can be used to search for single keys or multiple keywords with equal ease. Analytical modeling of our design predicts significant improvements in search efficiency, verified through extensive simulations in which we observed an order of magnitude reduction in query path length over previous proposals.},
keywords={peer-to-peer computing;tree searching;query processing;routing protocols;probability;Internet;information filters;peer-to-peer network;Gnutella unstructured system;random walk search;query routing protocol;lightweight probabilistic routing table;exponentially decaying bloom filter;EDBF;Query processing;Peer to peer computing;Bandwidth;Routing protocols;Analytical models;Predictive models;Costs;Data structures;Filters;Proposals},
doi={10.1109/INFCOM.2005.1498343},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498344,
author={J. Liang and R. Kumar and Y. Xi and K. W. Ross},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Pollution in P2P file sharing systems},
year={2005},
volume={2},
number={},
pages={1174-1185 vol. 2},
abstract={One way to combat P2P file sharing of copyrighted content is to deposit into the file sharing systems large volumes of polluted files. Without taking sides in the file sharing debate, in this paper we undertake a measurement study of the nature and magnitude of pollution in the FastTrack P2P network, currently the most popular P2P file sharing system. We develop a crawling platform which crawls the majority of the FastTrack Network's 20,000+ supernodes in less than 60 minutes. From the raw data gathered by the crawler for popular audio content, we obtain statistics on the number of unique versions and copies available in a 24-hour period. We develop an automated procedure to detect whether a given version is polluted or not, and we show that the probabilities of false positives and negatives of the detection procedure are very small. We use the data from the crawler and our pollution detection algorithm to determine the fraction of versions and fraction of copies that are polluted for several recent and old songs. We observe that pollution is pervasive for recent popular songs. We also identify and describe a number of anti-pollution mechanisms.},
keywords={peer-to-peer computing;copyright;Internet;ubiquitous computing;copy protection;P2P file sharing;copyrighted content;FastTrack P2P network;pollution detection algorithm;antipollution mechanism;Internet;Peer to peer computing;Information science;Pollution measurement;Internet;Telecommunication traffic;Crawlers;Marketing and sales;Current measurement;Statistics;Probability},
doi={10.1109/INFCOM.2005.1498344},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498345,
author={Z. Naor},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On-line search for mobile users},
year={2005},
volume={2},
number={},
pages={1186-1195 vol. 2},
abstract={The problem of searching for mobile users in cellular networks is addressed in this study. Previous studies addressing this issue have focused on the problem of searching for a single user. The underlying assumption for this approach is that some straightforward strategy of searching for multiple users can be easily derived from a single user search strategy. Unfortunately, this assumption is violated very often in practice. As it is shown in this study, the problem of maximizing the expected rate of successful searches under delay and bandwidth constraints is NP-hard. Given the conditions that each search for a single user must be over during a pre-defined time period, and that the bandwidth available for search operations is bounded from above by a pre-defined constant, when the potential locations of different users overlap, the derivation of an optimal concurrent search for many independent users from a set of optimal single user searches is NP-hard. Unfortunately, very often the potential locations of different users overlap. In reality, a cellular network has to serve many competing search requests sharing a limited bandwidth. Since the problem of maximizing the expected rate of successful searches under delay and bandwidth constraints is NP-hard, this study proposes an approximation algorithm, that is optimal for most probable cases, and nearly optimal for the worst case condition. Even under the worst case condition, the proposed method can potentially increase the expected rate of successful searches by 100%. Moreover, the proposed search strategy outperforms a greedy search strategy, that considers only the users' location probabilities and ignores their deadline constraints. Under certain conditions, the expected rate of successful searches generated by the proposed method is twice the equivalent rate generated by the greedy search strategy. In addition, the proposed search strategy outperforms a heuristic algorithm that searches around the user last known location.},
keywords={cellular radio;mobility management (mobile radio);optimisation;approximation theory;query formulation;cellular networks;mobile user search strategy;NP-hard;approximation algorithm;heuristic algorithm;location management;on-line search;Bandwidth;Land mobile radio cellular systems;Delay;Mathematics;Physics;Computer science;Mobile computing;Approximation algorithms;Heuristic algorithms;Technology management},
doi={10.1109/INFCOM.2005.1498345},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498346,
author={Y. Mao and B. Knutsson and H. Lu and J. M. Smith},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={DHARMA: distributed home agent for robust mobile access},
year={2005},
volume={2},
number={},
pages={1196-1206 vol. 2},
abstract={Mobile wireless devices have intermittent connectivity, sometimes intentional. This is a problem for conventional Mobile IP, beyond its well-known routing inefficiencies and deployment issues. DHARMA selects a location-optimized instance from a distributed set of home agents to minimize routing overheads; set management and optimization are done using the PlanetLab overlay network. DHARMA's session support overcomes both transitions between home agent instances and intermittent connectivity. Cross-layer information sharing between the session layer and the overlay network are used to exploit multiple wireless links when available. The DHARMA prototype supports intermittently connected legacy TCP applications in a variety of scenarios and is largely portable across host operating systems. Experiments with DHARMA deployed on more than 200 PlanetLab nodes demonstrate routing performance consistently better than that for best-case Mobile IP.},
keywords={mobile agents;mobile computing;transport protocols;computer network management;telecommunication network routing;mobile wireless devices;location-optimized instance;PlanetLab overlay network;cross-layer information sharing;multiple wireless link;TCP application;mobile IP;DHARMA;distributed home agent;robust mobile access;network management;network routing;Robustness;Routing;DH-HEMTs;Circuits;Portable computers;Personal digital assistants;TCPIP;Internet;Delay;Space exploration},
doi={10.1109/INFCOM.2005.1498346},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498347,
author={J. Li and A. Kubota and H. Kameda},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Location management for PCS networks with consideration of mobility patterns},
year={2005},
volume={2},
number={},
pages={1207-1216 vol. 2},
abstract={This paper addresses the dynamic location management for personal communication service (PCS) networks with consideration of mobility patterns. The popular hexagonal cellular architecture is considered. In this paper, we first introduce a coordinate system for the hexagonal cellular architectures. Then, we develop an all-direction mobility model based on the coordinate system for the hexagonal cellular architecture to cope with the mobility patterns of mobile terminals (MTs). The shape and size of the local area (LA) in the dynamic location management scheme is determined by minimizing the total location management cost with bounding the paging cost The optimization problem is transferred to maximize expected number of cells traversed by the MT in the LA with a given size of the LA. The analytic model of calculating the probabilities of any MT's moving is established. An algorithm is proposed to solve the optimization problem efficiently.},
keywords={mobility management (mobile radio);personal communication networks;cellular radio;dynamic location management;personal communication service;PCS network;coordinate system;hexagonal cellular architecture;all-direction mobility model;optimization;Personal communication networks;Costs;Shape;Base stations;Telephony;Databases;Paging strategies;Computer network management;Cities and towns;Mobile computing},
doi={10.1109/INFCOM.2005.1498347},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498348,
author={D. Madigan and E. Einahrawy and R. P. Martin and W. -. Ju and P. Krishnan and A. S. Krishnakumar},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Bayesian indoor positioning systems},
year={2005},
volume={2},
number={},
pages={1217-1227 vol. 2},
abstract={In this paper, we introduce a new approach to location estimation where, instead of locating a single client, we simultaneously locate a set of wireless clients. We present a Bayesian hierarchical model for indoor location estimation in wireless networks. We demonstrate that our model achieves accuracy that is similar to other published models and algorithms. By harnessing prior knowledge, our model eliminates the requirement for training data as compared with existing approaches, thereby introducing the notion of a fully adaptive zero profiling approach to location estimation.},
keywords={wireless LAN;indoor radio;belief networks;Bayesian hierarchical model;indoor location estimation;fully adaptive zero profiling approach;WLAN;wireless local area network;indoor positioning systems;Bayesian methods;Wireless networks;Hospitals;Handheld computers;Airports;Hardware;World Wide Web;Supervised learning;Training data;Predictive models},
doi={10.1109/INFCOM.2005.1498348},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498349,
author={S. M. Das and H. Pucha and Y. C. Hu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Performance comparison of scalable location services for geographic ad hoc routing},
year={2005},
volume={2},
number={},
pages={1228-1239 vol. 2},
abstract={Geographic routing protocols allow stateless routing in mobile ad hoc networks (MANETs) by taking advantage of the location information of mobile nodes and thus are highly scalable. A central challenge in geographic routing protocols is the design of scalable distributed location services that track mobile node locations. A number of location services have been proposed, but little is known about the relative performance of these location services. In this paper, we perform a detailed performance comparison of three rendezvous-based location services that cover a range of design choices: a quorum-based protocol (XYLS) which disseminates each node's location to O(/spl radic/N) nodes, a hierarchical protocol (GLS) which disseminates each node's location to O(logN) nodes, and a geographic hashing based protocol (GHLS) which disseminates each node's location to O(1) nodes. We present a quantitative model of protocol overheads for predicting the performance tradeoffs of the protocols for static networks. We then analyze the performance impact of mobility on these location services. Finally, we compare the performance of routing protocols equipped with the three location services with two topology-based routing protocols, AODV and DSR, for a wide range of network sizes. Our study demonstrates that when practical MANET sizes are considered, robustness to mobility and the constant factors matter more than the asymptotic costs of location service protocols. In particular, while GLS scales better asymptotically, GHLS is far simpler, transmits fewer control packets, and delivers more data packets than GLS when used with geographic routing in MANETs of sizes considered practical today and in the near future. Similarly, although XYLS scales worse asymptotically than GLS, it transmits fewer control packets and delivers more data packets than GLS in large mobile networks.},
keywords={mobile radio;ad hoc networks;routing protocols;telecommunication network topology;mobile ad hoc network;MANET;scalable distributed location services;quorum-based protocol;hierarchical protocol;GLS;geographic hashing based protocol;GHLS;topology-based routing protocol;AODV;DSR;Routing protocols;Mobile ad hoc networks;Performance analysis;Robustness;Scalability;Computer networks;Intelligent networks;Mobile computing;Predictive models;Robust control},
doi={10.1109/INFCOM.2005.1498349},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498350,
author={N. Zhou and A. A. Abouzeid},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Routing in ad hoc networks: a theoretical framework with practical implications},
year={2005},
volume={2},
number={},
pages={1240-1251 vol. 2},
abstract={In this paper, information theoretic techniques are used to derive analytic expressions for the minimum expected length of control messages exchanged by proactive routing in a two-level hierarchical ad hoc network. Several entropy measures are introduced and used to bound the memory size necessary for the storage of the routing tables. The entropy rates of the topology sequences are used to bound the communication routing overhead-both the interior routing overhead within a cluster and the exterior routing overhead across clusters. A scalability analysis of the routing overheads with regard to the number of nodes and the cluster size is provided under three different network scaling modes. Finally, practical design issues are studied by providing the optimal cluster sizes that asymptotically minimize (i) the memory requirement for each cluster head; (ii) the total control message routing overhead.},
keywords={ad hoc networks;entropy;routing protocols;telecommunication network topology;telecommunication network reliability;sequences;proactive routing;two-level hierarchical ad hoc network;entropy measures;routing tables;topology sequences;scalability analysis;routing overhead;control message routing;Routing;Ad hoc networks;Entropy;Information analysis;Communication system control;Size measurement;Network topology;Scalability;Optimal control;Size control},
doi={10.1109/INFCOM.2005.1498350},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498351,
author={W. Yu and Y. Sun and K. J. R. Liu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={HADOF: defense against routing disruptions in mobile ad hoc networks},
year={2005},
volume={2},
number={},
pages={1252-1261 vol. 2},
abstract={HADOF is a set of mechanisms to protect mobile ad hoc networks against routing disruption attacks launched by inside attackers. First, each node launches a route traffic observer to monitor the behavior of each valid route in its route cache, and to collect the packet forwarding statistics submitted by the nodes on this route. Since malicious nodes may submit false reports, each node also keeps cheating records for other nodes. If a node is detected as dishonest, this node will be excluded from future routes, and the other nodes will stop forwarding packets for it. Third, each node will try to build friendship with other nodes to speed up malicious node detection. Route diversity will be explored by each to discover multiple routes to the destination, which can increase the chance of defeating malicious nodes who aim to prevent good routes from being discovered. In addition, adaptive route rediscovery will be applied to determine when new routes should be discovered. HADOF can handle various attacks and introduces little overhead to the existing protocols. Both analysis and simulation studies have confirmed the effectiveness of HADOF.},
keywords={mobile radio;ad hoc networks;routing protocols;telecommunication traffic;diversity reception;statistical analysis;telecommunication congestion control;HADOF;mobile ad hoc networks;routing disruption attack;network traffic;packet forwarding statistics;route diversity;protocols;Intelligent networks;Mobile ad hoc networks;Protection;Computer networks;Communication system security;Ad hoc networks;Routing protocols;Educational institutions;Computerized monitoring;Statistics},
doi={10.1109/INFCOM.2005.1498351},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498352,
author={L. Lin and N. B. Shroff and R. Srikant},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Asymptotically optimal power-aware routing for multihop wireless networks with renewable energy sources},
year={2005},
volume={2},
number={},
pages={1262-1272 vol. 2},
abstract={In this paper, we model and characterize the performance of multihop radio networks in the presence of energy constraints and design routing algorithms to optimally utilize the available energy. The energy model allows vastly different energy sources in heterogeneous environments. The proposed algorithm is shown to achieve a competitive ratio (i.e., the ratio of the performance of any off-line algorithm that has knowledge of all past and future packet arrivals to the performance of our online algorithm) that is asymptotically optimal with respect to the number of nodes in the network. The algorithm assumes no statistical information on packet arrivals and can easily be incorporated into existing routing frameworks (e.g., proactive or on-demand methodologies) in a distributed fashion. Simulation results confirm that the algorithm performs very well in terms of maximizing the throughput of an energy-constrained network. Further, a new threshold-based scheme is proposed to reduce the routing overhead while incurring only minimum performance degradation.},
keywords={telecommunication network routing;optimisation;telecommunication congestion control;wireless sensor networks;multihop radio network;routing algorithm;optimization;packet arrival;maximization;renewable energy sources;Routing;Spread spectrum communication;Wireless networks;Renewable energy resources;Cost function;Wireless sensor networks;Energy management;Multicast algorithms;Circuits;Radio network},
doi={10.1109/INFCOM.2005.1498352},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498353,
author={S. Racz and T. Jakabfy and J. Farkas and C. Antal},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Connection admission control for flow level QoS in bufferless models},
year={2005},
volume={2},
number={},
pages={1273-1282 vol. 2},
abstract={Admission control algorithms used in access networks for multiplexed voice sources are typically based on aggregated system characteristics, such as aggregate loss probability. Even though the relation of these aggregate performance measures to the performance of specific flows is not trivial, it has gained limited attention so far. We propose an admission control method that provides flow level QoS guarantees. The proposed method is based on Gaussian approximation applied for the bufferless multiplexing model. We show that the flow level packet loss violation probability can be approximated as the quantile of a normal distribution and we give a method to calculate its mean and variance. The obtained admission control formula includes the moments of the activity factor distribution.},
keywords={telecommunication congestion control;quality of service;Gaussian distribution;multiplexing;radio access networks;connection admission control algorithm;access networks;multiplexed voice sources;QoS guarantees;Gaussian approximation;bufferless model;probability;normal distribution;Admission control;Traffic control;Aggregates;Communication system traffic control;Probability;Jitter;Intelligent networks;Performance analysis;Laboratories;Gain measurement},
doi={10.1109/INFCOM.2005.1498353},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498354,
author={W. Wang and X. Wang and A. Nilsson},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A new admission control scheme under energy and QoS constraints for wireless networks},
year={2005},
volume={2},
number={},
pages={1283-1294 vol. 2},
abstract={Battery capacity of mobile terminals and radio bandwidth are both limited and precious resources in wireless networks. In this paper, we present a thorough performance study of energy-based admission control scheme to make the best use of these two resources for effective mobile communications. In order to reduce energy consumption of each terminal, we introduce a victim selection algorithm (VSA) and a beneficiary selection algorithm (BSA) for acquiring bandwidth and releasing bandwidth, respectively. To avoid potential compromise of quality of service (QoS) due to the concern of energy consumption in connection admission control, we further propose an adjustment algorithm to statistically meet the demands for QoS. The performance of the proposed schemes is evaluated with respect to energy consumption rate of each successfully transmitted bit, throughput and call blocking probabilities for a variety of traffic such as Poisson and self-similar, multi-class traffic.},
keywords={mobile radio;telecommunication terminals;quality of service;telecommunication congestion control;probability;telecommunication traffic;mobile terminals;wireless networks;mobile communication;victim selection algorithm;VSA;beneficiary selection algorithm;BSA;quality of service;QoS;connection admission control;energy consumption;call blocking probability;network traffic;Admission control;Wireless networks;Bandwidth;Quality of service;Batteries;Communication system traffic control;Mobile communication;Energy consumption;Throughput;Data communication},
doi={10.1109/INFCOM.2005.1498354},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498355,
author={E. Altman},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On stochastic recursive equations and infinite server queues},
year={2005},
volume={2},
number={},
pages={1295-1302 vol. 2},
abstract={The purpose of this paper is to investigate some performance measures of the discrete time infinite server queue under a general arrival process. We assume, more precisely, that at each time unit a batch with a random size may arrive, where the sequence of batch sizes need not be i.i.d. All we request is that it would be stationary ergodic and that the service duration has a phase type distribution. Our goal is to obtain explicit expressions for the first two moments of number of customers in steady state. We obtain this by computing the first two moments of some generic stochastic recursive equations that our system satisfies. We then show that this class of recursive equations allow to solve not only the G/PH//spl infin/ queue but also a network of such queues. We finally investigate the process of residual activity time in a G/G//spl infin/ queue under general stationary ergodic assumptions, obtain the unique stationary solution and establish coupling convergence to it from any initial state.},
keywords={discrete time systems;queueing theory;stochastic processes;convergence;correlation theory;network servers;discrete time infinite server queue;arrival process;service duration;phase type distribution;stochastic recursive equation;G-PH-/spl infin/ queue;G-G-/spl infin/ queue;unique stationary solution;coupling convergence;Stochastic processes;Equations;Time measurement;Stochastic systems;Distributed computing;Steady-state;Queueing analysis;Network servers;Telecommunication traffic;Traffic control},
doi={10.1109/INFCOM.2005.1498355},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498356,
author={S. Ayyorgun and S. Vanichpun and W. Feng},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Q-Composer and CpR: a probabilistic synthesizer and regulator of traffic (a probabilistic control of buffer occupancy)},
year={2005},
volume={2},
number={},
pages={1303-1315 vol. 2},
abstract={We present and show the correctness of two algorithms called Q-Composer and CpR. Q-Composer is a probabilistic traffic-synthesizer and CpR is a probabilistic traffic-regulator. Given a cumulative distribution function F, Q-Composer synthesizes a flow that when fed into a single-input single-output network element, the distribution of the queue-size probability at the element closely follows F. CpR regulates an arbitrary traffic so that when the regulated traffic (i.e. the output of CpR) is fed into a single-input single-output network element, the distribution of the queue-size probability at the element closely follows a pre-specified cdf F. CpR can be viewed as a probabilistic generalization of deterministic Leaky-bucket regulators. Q-Composer and CpR are straightforward algorithms to implement and have applications in providing end-to-end probabilistic quality-of-service guarantees, multimedia encoding/decoding, and resource allocation and in simulation studies, beside other areas.},
keywords={controllers;probabilistic logic;telecommunication traffic;queueing theory;probability;multimedia communication;encoding;decoding;quality of service;resource allocation;Q-Composer;CpR;composer-powered-regulator;probabilistic traffic-synthesizer;probabilistic traffic-regulator;cumulative distribution function;single-input single-output network element;queue-size probability;deterministic Leaky-bucket regulator;multimedia encoding;decoding;resource allocation;Synthesizers;Regulators;Traffic control;Communication system traffic control;Telecommunication traffic;Distribution functions;Network synthesis;Quality of service;Encoding;Decoding},
doi={10.1109/INFCOM.2005.1498356},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498357,
author={E. Altman and K. E. Avrachenkov and A. A. Kherani and B. J. Prabhu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Performance analysis and stochastic stability of congestion control protocols},
year={2005},
volume={2},
number={},
pages={1316-1327 vol. 2},
abstract={We study an adaptive window protocol (AWP) with a general increase and decrease profile in the presence of window dependent random losses. We derive a steady-state Kolmogorov equation and obtain its solution in analytic form. We obtain some stochastic ordering relations for a protocol with different bounds on window. A closed form necessary and sufficient stability condition using the stochastic ordering for the window process is established. Finally, we apply the general results to particular TCP versions such as NEW Reno TCP, scalable TCP and Highspeed TCP. We observe that Highspeed TCP can be used to approximate almost any kind of window behavior by varying only one design parameter.},
keywords={transport protocols;stochastic processes;telecommunication congestion control;stability;queueing theory;adaptive window protocol;AWP;steady-state Kolmogorov equation;stochastic stability;highspeed TCP;transmission control protocol;performance analysis;congestion control protocol;Performance analysis;Stochastic processes;Stability analysis;Protocols;Equations;Signal processing;Queueing analysis;Electronic mail;Proposals},
doi={10.1109/INFCOM.2005.1498357},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498358,
author={B. Miller and K. Avrachenkov and K. Stepanyan and G. Miller},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Flow control as stochastic optimal control problem with incomplete information},
year={2005},
volume={2},
number={},
pages={1328-1337 vol. 2},
abstract={The nonlinear stochastic control problem related with flow control is considered. The state of the link is described by controlled hidden Markov process while the loss flow is described by the counting process with the intensity depending on the current transmission rate and unobserved link state. The control is the transmission rate and have to be chosen as non-anticipating process depending on the observation of the loss process. The aim of the control is to achieve the maximum of some utility function taking into account the losses of transmitted information. Originally the problem belongs to a class of stochastic control with incomplete information, however, the optimal filtering equations giving the estimation of the current link state based on the observation of the loss process give the opportunity to reduce the problem to the standard stochastic control problem with full observations. Then, a necessary optimality condition is derived in the form of stochastic maximum principle which allows us to obtain explicit analytic expressions for the optimal control in some particular cases. The optimal and suboptimal controls are investigated and compared with the flow control schemes which is used in TCP/IP networks. In particular, the optimal control demonstrates a much smoother behavior than the currently used TCP/IP congestion control.},
keywords={telecommunication congestion control;hidden Markov models;filtering theory;telecommunication links;transport protocols;IP networks;Internet;maximum principle;nonlinear stochastic control problem;flow control;hidden Markov process;counting process;information transmission rate;nonanticipating process;optimal filtering equation;link estimation;maximum principle;TCP-IP networks;transmission control protocol;Internet protocol;congestion control;Optimal control;Stochastic processes;Propagation losses;TCPIP;Process control;Hidden Markov models;Information filtering;Information filters;Equations;State estimation},
doi={10.1109/INFCOM.2005.1498358},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498359,
author={A. Tang and J. Wang and S. H. Low and M. Chiang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Network equilibrium of heterogeneous congestion control protocols},
year={2005},
volume={2},
number={},
pages={1338-1349 vol. 2},
abstract={When heterogeneous congestion control protocols that react to different pricing signals share the same network, the resulting equilibrium may no longer be interpreted as a solution to the standard utility maximization problem. We prove the existence of equilibrium under mild assumptions. Then we show that multi-protocol networks whose equilibria are locally non-unique or infinite in number can only form a set of measure zero. Multiple locally unique equilibria can arise in two ways. First, unlike in the single-protocol case, the set of bottleneck links can be non-unique with heterogeneous protocols even when the routing matrix has full row rank. The equilibria associated with different sets of bottleneck links are necessarily distinct. Second, even when there is a unique set of bottleneck links, network equilibrium can still be non-unique, but is always finite and odd in number. They cannot all be locally stable unless it is globally unique. Finally, we provide various sufficient conditions for global uniqueness. Numerical examples are used throughout the paper to illustrate these results.},
keywords={telecommunication congestion control;routing protocols;matrix algebra;telecommunication links;optimisation;Internet;heterogeneous congestion control protocol;pricing signal;network equilibrium;maximization problem;multiprotocol network;bottleneck links;routing matrix;Pricing;Algorithm design and analysis;Delay;Routing protocols;Sufficient conditions;Signal analysis;Network topology;Queueing analysis;Feedback;Large-scale systems},
doi={10.1109/INFCOM.2005.1498359},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498360,
author={E. Altman and K. E. Avrachenkov and B. J. Prabhu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Fairness in MIMD congestion control algorithms},
year={2005},
volume={2},
number={},
pages={1350-1361 vol. 2},
abstract={The multiplicative increase multiplicative decrease (MIMD) congestion control algorithm in the form of scalable TCP has been proposed for high speed networks. We study fairness among sessions sharing a common bottleneck link, where one or more sessions use the MIMD algorithm. Losses, or congestion signals, occur when the capacity is reached but could also be initiated before that. Both synchronous as well as asynchronous losses are considered. In the asynchronous case, only one session suffers a loss at a loss instant. Two models are then considered to determine which source looses a packet: a rate dependent model in which the packet loss probability of a session is proportional to its rate at the congestion instant, and the independent loss rate model. We first study how two MIMD sessions share the capacity in the presence of general combinations of synchronous and asynchronous losses. We show that, in the presence of rate dependent losses, the capacity is fairly shared whereas rate independent losses provide high unfairness. We then study inter protocol fairness: how the capacity is shared in the presence of synchronous losses among sessions some of which use additive increase multiplicative decrease (AIMD) protocols whereas the others use MIMD protocols.},
keywords={telecommunication congestion control;telecommunication links;transport protocols;probability;Internet;computer network reliability;multiplicative increase multiplicative decrease;MIMD congestion control algorithm;scalable TCP;transmission control protocol;high speed networks;bottleneck link;rate dependent model;packet loss probability;inter protocol fairness;additive increase multiplicative decrease;AIMD protocols;Protocols;High-speed networks;Convergence;Internet;Algorithm design and analysis;Analytical models;Feedback},
doi={10.1109/INFCOM.2005.1498360},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498361,
author={M. Guirguis and A. Bestavros and I. Matta and Y. Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Reduction of quality (RoQ) attacks on Internet end-systems},
year={2005},
volume={2},
number={},
pages={1362-1372 vol. 2},
abstract={Current computing systems depend on adaptation mechanisms to ensure that they remain in quiescent operating regions. These regions are often defined using efficiency, fairness, and stability properties. To that end, traditional research works in scalable server architectures and protocols have focused on promoting these properties by proposing even more sophisticated adaptation mechanisms, without the proper attention to security implications. In this paper, we exemplify such security implications by exposing the vulnerabilities of admission control mechanisms that are widely deployed in Internet end systems to reduction of quality (RoQ) attacks. RoQ attacks target the transients of a system's adaptive behavior as opposed to its limited steady-state capacity. We show that a well orchestrated RoQ attack on an end-system admission control policy could introduce significant inefficiencies that could potentially deprive an Internet end-system from much of its capacity, or significantly reduce its service quality, while evading detection by consuming an unsuspicious, small fraction of that system's hijacked capacity. We develop a control theoretic model for assessing the impact of RoQ attacks on an end-system's admission controller. We quantify the damage inflicted by an attacker through deriving appropriate metrics. We validate our findings through real Internet experiments performed in our lab.},
keywords={computer network reliability;computer network management;Internet;transport protocols;telecommunication security;telecommunication congestion control;performance evaluation;quality of service;personal computing;network servers;scalable server architectures;protocols;stability;sophisticated adaptation mechanisms;security;vulnerability;admission control mechanisms;Internet end system;reduction of quality attacks;RoQ;steady-state capacity;systems hijacked capacity;denial-of-service;Web service;resource management;performance evaluation;Internet;Admission control;Web server;Resource management;Delay;Computer science;Stability;Computer architecture;Protocols;Mechanical factors},
doi={10.1109/INFCOM.2005.1498361},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498362,
author={Q. Li and E. -. Chang and M. C. Chan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On the effectiveness of DDoS attacks on statistical filtering},
year={2005},
volume={2},
number={},
pages={1373-1383 vol. 2},
abstract={Distributed denial of service (DDoS) attacks pose a serious threat to service availability of the victim network by severely degrading its performance. Recently, there has been significant interest in the use of statistical-based filtering to defend against and mitigate the effect of DDoS attacks. Under this approach, packet statistics are monitored to classify normal and abnormal behaviour. Under attack, packets that are classified as abnormal are dropped by the filter that guards the victim network. We study the effectiveness of DDoS attacks on such statistical-based filtering in a general context where the attackers are "smart". We first give an optimal policy for the filter when the statistical behaviours of both the attackers and the filter are static. We next consider cases where both the attacker and the filter can dynamically change their behaviour, possibly depending on the perceived behaviour of the other party. We observe that while an adaptive filter can effectively defend against a static attacker, the filter can perform much worse if the attacker is more dynamic than perceived.},
keywords={adaptive filters;Internet;statistical analysis;quality of service;distributed denial of service attacks;DDoS;service availability;statistical-based filtering;normal classification;victim network;optimal policy;adaptive filter;Computer crime;Adaptive filters;Telecommunication traffic;Filtering;Computer science;Degradation;Context-aware services;Humans;Availability;Statistical distributions},
doi={10.1109/INFCOM.2005.1498362},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498363,
author={Y. Tang and S. Chen},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Defending against Internet worms: a signature-based approach},
year={2005},
volume={2},
number={},
pages={1384-1394 vol. 2},
abstract={With the capability of infecting hundreds of thousands of hosts, worms represent a major threat to the Internet. The defense against Internet worms is largely an open problem. This paper investigates two important problems. Can a localized defense system detect new worms that were not seen before and moreover, capture the attack packets? How to identify polymorphic worms from the normal background traffic? We have two major contributions here. The first contribution is the design of a novel double-honeypot system, which is able to automatically detect new worms and isolate the attack traffic. The second contribution is the proposal of a new type of position-aware distribution signatures (PADS), which fit in the gap between the traditional signatures and the anomaly-based systems. We propose two algorithms based on expectation-maximization (EM) and Gibbs sampling for efficient computation of PADS from polymorphic worm samples. The new signature is capable of handling certain polymorphic worms. Our experiments show that the algorithms accurately separate new variants of the MSBlaster worm from the normal-traffic background.},
keywords={Internet;computer viruses;telecommunication traffic;optimisation;sampling methods;digital signatures;Internet worms;double-honeypot system;network traffic;position-aware distribution signatures;PADS;anomaly-based system;expectation-maximization;Gibbs sampling;polymorphic worm sample;MSBlaster worm;Internet;Computer worms;Intrusion detection;Atherosclerosis;Information science;Proposals;Sampling methods;Humans;IP networks;Protection},
doi={10.1109/INFCOM.2005.1498363},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498364,
author={A. Yaar and A. Perrig and D. Song},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={FIT: fast Internet traceback},
year={2005},
volume={2},
number={},
pages={1395-1406 vol. 2},
abstract={Traceback mechanisms are a critical part of the defense against IP spoofing and DoS attacks, as well as being of forensic value to law enforcement. Currently proposed IP traceback mechanisms are inadequate to address the traceback problem for the following reasons: they require DDoS victims to gather thousands of packets to reconstruct a single attack path; they do not scale to large scale distributed DoS attacks; and they do not support incremental deployment. We propose fast Internet traceback (FIT), a new packet marking approach that significantly improves IP traceback in several dimensions: (1) victims can identify attack paths with high probability after receiving only tens of packets, a reduction of 1-3 orders of magnitude compared to previous packet marking schemes; (2) FIT performs well even in the presence of legacy routers, allowing every FIT-enabled router in path to be identified; and (3) FIT scales to large distributed attacks with thousands of attackers. Compared with previous packet marking schemes, FIT represents a step forward in performance and deployability.},
keywords={IP networks;quality of service;Internet;probability;telecommunication network routing;large-scale systems;IP spoofing;large scale distributed DoS attacks;law enforcement;IP traceback mechanism;fast Internet traceback;FIT;packet marking approach;probability;legacy routers;Internet;Computer crime;Law enforcement;Large-scale systems;Costs;Forensics;Frequency;Domain Name System;Environmental economics;Protection},
doi={10.1109/INFCOM.2005.1498364},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498365,
author={W. Zhao and M. Ammar and E. Zegura},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Controlling the mobility of multiple data transport ferries in a delay-tolerant network},
year={2005},
volume={2},
number={},
pages={1407-1418 vol. 2},
abstract={As technology rapidly progresses, more devices will combine both communication and mobility capabilities. With mobility in devices, we envision a new class of proactive networks that are able to adapt themselves, via physical movement, to meet the needs of applications. To fully realize these opportunities, effective control of device mobility and the interaction between devices is needed. In this paper, we consider the message ferrying (MF) scheme which exploits controlled mobility to transport data in delay-tolerant networks, where end-to-end paths may not exist between nodes. In the MF scheme, a set of special mobile nodes called message ferries are responsible for carrying data for nodes in the network. We study the use of multiple ferries in such networks, which may be necessary to address performance and robustness concerns. We focus on the design of ferry routes. With the possibilities of interaction between ferries, the route design problem is challenging. We present algorithms to calculate routes such that the traffic demand is met and the data delivery delay is minimized. We evaluate these algorithms under a variety of network conditions via simulations. Our goal is to guide the design of MF systems and understand the tradeoff between the incurred cost of multiple ferries and the improved performance. We show that the performance scales well with the number of ferries in terms of throughput, delay and resource requirements in both ferries and nodes.},
keywords={delays;telecommunication network routing;tolerance analysis;telecommunication traffic;mobility management (mobile radio);data communication;minimisation;message ferrying scheme;mobility control;multiple data transportation;delay-tolerant network;end-to-end path;ferry routes design;network interaction;traffic demand;minimization;resource requirement;Intelligent networks;Communication system control;Mobile communication;Delay;Mobile robots;Legged locomotion;Educational institutions;Computer networks;Robustness;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1498365},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498366,
author={J. Ledlie and M. Seltzer},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Distributed, secure load balancing with skew, heterogeneity and churn},
year={2005},
volume={2},
number={},
pages={1419-1430 vol. 2},
abstract={Numerous proposals exist for load balancing in peer-to-peer (p2p) networks. Some focus on namespace balancing, making the distance between nodes as uniform as possible. This technique works well under ideal conditions, but not under those found empirically. Instead, researchers have found heavy-tailed query distributions (skew), high rates of node join and leave (churn) and wide variation in node network and storage capacity (heterogeneity). Other approaches tackle these less-than-ideal conditions, but give up on important security properties. We propose an algorithm that both facilitates good performance and does not dilute security. Our algorithm, k-choices, achieves load balance by greedily matching nodes' target workloads with actual applied workloads through limited sampling and limits any fundamental decrease in security by basing each nodes' set of potential identifiers on a single certificate. Our algorithm compares favorably to four others in trace-driven simulations. We have implemented our algorithm and found that it improved aggregate throughput by 20% in a widely heterogeneous system in our experiments.},
keywords={resource allocation;peer-to-peer computing;query processing;security of data;telecommunication security;sampling methods;load balancing;peer-to-peer network;namespace balancing;heavy-tailed query distribution;storage capacity;security property;k-choices algorithm;greedily matching node;target workload;sampling;trace-driven simulations;heterogeneous system;Load management;Peer to peer computing;Intrusion detection;Proposals;Computer vision;Variable structure systems;Sampling methods;Security;Computational modeling;Aggregates},
doi={10.1109/INFCOM.2005.1498366},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498369,
author={W. Chen and L. Clarke and J. Kurose and D. Towsley},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Optimizing cost-sensitive trust-negotiation protocols},
year={2005},
volume={2},
number={},
pages={1431-1442 vol. 2},
abstract={Trust negotiation is a process that establishes mutual trust by the exchange of digital credentials and/or guiding policies among entities who may have no pre-existing knowledge about each other. Motivated by the desire to disclose as little sensitive information as possible in practice, this paper investigates the problem of minimizing the "cost" of the credentials exchanged by a trust-negotiation protocol. A credential or a policy is assigned a weighted cost, referred to as its sensitivity cost. We formalize an optimization problem, namely the minimum sensitivity cost problem, whose objective is to minimize the total sensitivity costs of the credentials and policies disclosed during trust negotiation. We study the complexity of the minimal sensitivity cost problem and propose algorithms to solve the problem efficiently, for the cases that policies are cost-sensitive and cost-insensitive. A simple finite state machine model of trust-negotiation protocols is presented to model various trust-negotiation protocols, and to provide a quantitative evaluation of the number of exchange rounds needed to achieve a successful negotiation, and the probability of achieving a successful negotiation under various credential disclosure strategies.},
keywords={protocols;minimisation;finite state machines;authorisation;Internet;probability;digital credentials;guiding policies;trust-negotiation protocol;optimization problem;minimum sensitivity cost problem;minimization;finite state machine model;quantitative evaluation;probability;Protocols;Automata;Security;Telephony;Computer science;Cost function;Internet;Electronic commerce;Government;Employment},
doi={10.1109/INFCOM.2005.1498369},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498371,
author={Y. Matias and R. Refua},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Delayed-dictionary compression for packet networks},
year={2005},
volume={2},
number={},
pages={1443-1454 vol. 2},
abstract={This paper considers compression in packet networks. Since data packets may be dropped or arrive reordered, streaming compression algorithms result in a considerable decoding latency. On the other hand, standard stateless packet compression algorithms that compress each packet independently, give a relatively poor compression ratio. We introduce a novel compression algorithm for packet networks: delayed-dictionary compression. By allowing delay in the dictionary construction, the algorithm handles effectively the problems of packet drops and packet reordering, while resulting with a compression quality which is often substantially better than standard stateless packet compression and has a smaller decoding latency than that of streaming compression. We conducted extensive experiments to establish the potential improvement for packet compression techniques, using many data files including the Calgary corpus and the Canterbury corpus. Experimental results of the new delayed-dictionary compression show that its main advantage is in low to medium speed links.},
keywords={data compression;decoding;delays;packet radio networks;radio links;data packet network;streaming compression algorithm;decoding;delay;dictionary construction;Calgary corpus;Canterbury corpus;medium speed links;Decoding;Dictionaries;Compression algorithms;Payloads;Computer science;Data structures;Boolean functions;Delay effects;Data compression;Bandwidth},
doi={10.1109/INFCOM.2005.1498371},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498374,
author={A. Ganesh and L. Massoulie and D. Towsley},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The effect of network topology on the spread of epidemics},
year={2005},
volume={2},
number={},
pages={1455-1466 vol. 2},
abstract={Many network phenomena are well modeled as spreads of epidemics through a network. Prominent examples include the spread of worms and email viruses, and, more generally, faults. Many types of information dissemination can also be modeled as spreads of epidemics. In this paper we address the question of what makes an epidemic either weak or potent. More precisely, we identify topological properties of the graph that determine the persistence of epidemics. In particular, we show that if the ratio of cure to infection rates is larger than the spectral radius of the graph, then the mean epidemic lifetime is of order log n, where n is the number of nodes. Conversely, if this ratio is smaller than a generalization of the isoperimetric constant of the graph, then the mean epidemic lifetime is of order e/sup na/, for a positive constant a. We apply these results to several network topologies including the hypercube, which is a representative connectivity graph for a distributed hash table, the complete graph, which is an important connectivity graph for BGP, and the power law graph, of which the AS-level Internet graph is a prime example. We also study the star topology and the Erdos-Renyi graph as their epidemic spreading behaviors determine the spreading behavior of power law graphs.},
keywords={telecommunication network topology;hypercube networks;graph theory;network servers;internetworking;routing protocols;table lookup;telecommunication security;security of data;information dissemination;network topological property;hypercube network;distributed hash table;BGP;border gateway protocol;star topology;Erdos-Renyi graph;epidemic spreading;power law graph;Network topology;Viruses (medical);Hypercubes;Computer worms;Sufficient conditions;Computer science;Graph theory;Stochastic processes;Impedance;Power system faults},
doi={10.1109/INFCOM.2005.1498374},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498380,
author={S. Raghunath and S. Kalyanaraman and K. K. Ramakrishnan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Trade-offs in resource management for virtual private networks},
year={2005},
volume={2},
number={},
pages={1467-1477 vol. 2},
abstract={Virtual private networks (VPNs) feature notable characteristics in structure and traffic patterns that can be exploited by the service provider to achieve significant capacity savings. Efficient provisioning of point-to-point connections using statistical admission control is well understood. However, provisioning a VPN involves provisioning a set of point-to-multipoint connections and features an additional dimension in the form of a traffic matrix. Consequently we have multiple network mechanisms that are important for efficient operation: a) admission control, b) signaling-based per-link reservations, c) traffic matrix estimation. In this paper we examine the relative importance of mechanisms that positively affect the operational efficiency in the context of VPN provisioning. Using insights from our extensive measurement based study on the structural properties usually observed in VPNs, we build a simulation framework to quantify the trade-offs in opting for one mechanism over the other. We arrive at our conclusions with the help of simulations featuring a variety of VPN structures and network topologies. We find that the structural characteristics of VPNs cause traffic matrix estimation to be a dominant factor in determining the utilization gains. Consequently, we find that deploying statistical techniques might not be worth the effort if the traffic matrix is not incorporated. While signaling-based reservation mechanisms lead to higher utilization, edge-based techniques prove to be lot more scalable and simpler to realize. We explore the means to reduce the performance penalty associated with such simpler techniques.},
keywords={virtual private networks;telecommunication traffic;quality of service;telecommunication congestion control;statistical analysis;telecommunication signalling;telecommunication network topology;telecommunication network reliability;telecommunication network management;telecommunication links;matrix algebra;virtual private network;VPN provisioning;traffic pattern;service provider;statistical admission control;point-to-multipoint connection;traffic matrix estimation;multiple network mechanism;signaling-based per-link reservation;network topologies;edge-based technique;scalability;resource management;Intelligent networks;Resource management;Virtual private networks;Traffic control;Communication system traffic control;Admission control;Telecommunication traffic;Quality of service;Bandwidth;Network topology},
doi={10.1109/INFCOM.2005.1498380},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498383,
author={W. Liang and W. Wang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A quantitative study of authentication and QoS in wireless IP networks},
year={2005},
volume={2},
number={},
pages={1478-1489 vol. 2},
abstract={With the increasing demand for secure and high-quality communications in public access wireless IP networks, it is very important to have an in-depth understanding of the relationship between the security and quality of service (QoS). In wireless networks, authentication can provide secure communications by preventing unauthorized usage and negotiating the credentials for data transmission. Nevertheless, it induces heavy overhead to data transmission, further deteriorating overall system performance. Thus, we analyze the impact of authentication on the security and QoS quantitatively in this paper. First, we introduce a system model based on a challenge/response authentication, which is widely used in many mobile environments. Then, a concept of security level is proposed to describe the protection of communications according to the nature of security, i.e., information secrecy, data integrity, and resource availability. By taking traffic and mobility patterns into account, our approach establishes a direct and quantitative connection between the security and QoS through the authentication. Finally, numerical results are provided to demonstrate the impact of security levels, mobility and traffic patterns on overall system performance in terms of authentication delay and call dropping probability.},
keywords={telecommunication security;message authentication;radio access networks;IP networks;quality of service;telecommunication traffic;delays;probability;mobility management (mobile radio);secure communication;high-quality communication;public access wireless IP networks;quality of service;QoS;data transmission;system performance;mobile environment;data integrity;resource availability;traffic pattern;mobility pattern;authentication delay;call dropping probability;quantitative study;Authentication;IP networks;Communication system security;Data security;Quality of service;Information security;Data communication;System performance;Wireless networks;Protection},
doi={10.1109/INFCOM.2005.1498383},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1498384,
author={Hsinping Wang and Tsungnan Lin},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On efficiency in searching networks},
year={2005},
volume={2},
number={},
pages={1490-1501 vol. 2},
abstract={This paper deliberates on various critical aspects in evaluating searching networks. Existing metrics either draw biased conclusions regarding search performance or provide wrong guidelines for algorithm design. We, therefore, define a unified criterion, search efficiency (SE), to objectively address search performance in a comprehensive manner. The goal of SE is to better characterize performance of searching networks than existing metrics do as well as to guide the design of future ones. We first validate the correctness of SE in performance evaluation in an ideal graph, strictly binary tree, by analyzing SE for two typical search methods, breadth first search and random walk. We further show its strength in performance characterization in the real-world topology, power-law random graph, under various network conditions. We finally design an algorithm, dynamic search, based on SE analysis. Its proved outstanding performance demonstrates the strength of SE to provide guidance for the future design of searching networks.},
keywords={tree searching;performance evaluation;telecommunication network topology;peer-to-peer computing;trees (mathematics);searching networks;performance evaluation;binary tree;real-world topology;power-law random graph;peer-to-peer network;Intelligent networks;Algorithm design and analysis;Costs;Performance analysis;Network topology;Search methods;Humans;Guidelines;Tree graphs;Heuristic algorithms},
doi={10.1109/INFCOM.2005.1498384},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497873,
author={G. Tan and J. Guttag},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={The 802.11 MAC protocol leads to inefficient equilibria},
year={2005},
volume={1},
number={},
pages={1-11 vol. 1},
abstract={Wireless local area networks (WLANs) based on the family of 802.11 technologies are becoming ubiquitous. These technologies support multiple data transmission rates. Transmitting at a lower data rate (by using a more resilient modulation scheme) increases the frame transmission time but reduces the hit error rate. In non-cooperative environments such as public hot-spots or WLANs operated by different enterprises that are physically close to each other, individual nodes attempt to maximize their achieved throughput by adjusting the data rate or frame size used, irrespective of the impact of this on overall system performance. In this paper, we show both analytically using a game theoretic model and through simulation that the existing 802.11 distributed MAC protocol, DCF (for distributed coordination function), as well as its enhanced version, which is being standardized at part of 802.11e, can lead non-cooperative nodes to undesirable Nash equilibriums, in which the wireless channel is inefficiently used. We show that by establishing independence between the allocation of the shared channel resource and the transmission strategies used by individual nodes, an ideal MAC protocol can lead rational nodes to arrive at equilibriums in which all competing nodes achieve higher throughputs tan with DCF.},
keywords={wireless LAN;access protocols;data communication;modulation;telecommunication channels;resource allocation;802.11 MAC protocol;wireless local area networks;WLAN;multiple data transmission rates;resilient modulation scheme;distributed coordination function;Nash equilibriums;wireless channel;shared channel resource allocation;Media Access Protocol;Throughput;Wireless LAN;Data communication;Error analysis;System performance;Game theory;Analytical models;Wireless application protocol;Nash equilibrium},
doi={10.1109/INFCOM.2005.1497873},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497874,
author={Hao Zhu and Guohong Cao},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={rDCF: a relay-enabled medium access control protocol for wireless ad hoc networks},
year={2005},
volume={1},
number={},
pages={12-22 vol. 1},
abstract={It is well known that IEEE 802.11 provides a physical layer multi-rate capability, and hence MAC layer mechanisms are needed to exploit this capability. Several solutions have been proposed to achieve this goal. However, these solutions only consider how to exploit good channel quality for the direct link between the sender and the receiver. Since IEEE 802.11 supports multiple transmission rates in response to different channel conditions, data packets may be delivered faster through a relay node than through the direct link if the direct link has low quality and low rate. In this paper, we propose a novel MAC layer relay-enabled distributed coordination function (DCF) protocol, called rDCF, to further exploit the physical layer multi-rate capability. We design a protocol to assist the sender, the relay node and the receiver to reach an agreement on which data rate to use and whether to transmit the data through a relay node. Considering various issues such as bandwidth utilization and channel errors, we propose techniques to further improve the performance of rDCF. Simulation results show that rDCF can significantly improve the system performance when the channel quality of the direct link is poor.},
keywords={access protocols;multi-access systems;ad hoc networks;wireless LAN;telecommunication channels;radio links;bandwidth allocation;mobile radio;relay-enabled medium access control protocol;wireless ad hoc networks;IEEE 802.11;physical layer multirate capability;MAC layer mechanisms;channel quality;multiple transmission rates;data packets;direct link;distributed coordination function protocol;relay node;receiver;bandwidth utilization;Relays;Media Access Protocol;Wireless application protocol;Access protocols;Ad hoc networks;Physical layer;Bandwidth;Computer science;System performance;Costs},
doi={10.1109/INFCOM.2005.1497874},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497875,
author={Xin Wang and K. Kar},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Throughput modelling and fairness issues in CSMA/CA based ad-hoc networks},
year={2005},
volume={1},
number={},
pages={23-34 vol. 1},
abstract={In this paper, we consider the throughput modelling and fairness provisioning in CSMA/CA based ad-hoc networks. The main contributions are: firstly, a throughput model based on Markovian analysis is proposed for the CSMA/CA network with a general topology. Simulation investigations are presented to verify its performance. Secondly, fairness issues in CSMA/CA networks are discussed based on the throughput model. The origin of unfairness is explained and the trade-off between throughput and fairness is illustrated. Thirdly, throughput approximations based on local topology information are proposed and their performances are investigated. Fourthly, three different fairness metrics are presented and their distributed implementations, based on the throughput approximation, are proposed.},
keywords={carrier sense multiple access;ad hoc networks;Markov processes;telecommunication network topology;approximation theory;throughput modelling;CSMA-CA based ad-hoc networks;Markovian analysis;general topology;throughput approximations;Throughput;Intelligent networks;Multiaccess communication;Ad hoc networks;Network topology;Wireless networks;Media Access Protocol;Bandwidth;Wireless application protocol;Broadcasting},
doi={10.1109/INFCOM.2005.1497875},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497877,
author={Yaling Yang and Jun Wang and R. Kravets},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Distributed optimal contention window control for elastic traffic in wireless LANs},
year={2005},
volume={1},
number={},
pages={35-46 vol. 1},
abstract={This paper presents a theoretical study on distributed contention window control algorithms for achieving arbitrary bandwidth allocation policies and efficient channel utilization. By modeling different bandwidth allocation policies as an optimal contention window assignment problem, we design a general and fully distributed contention window control algorithm, called GCA (general contention window adaptation), and prove that it converges to the solution of the contention window assignment problem. By examining the stability of GCA, we identify the optimal stable point that maximizes channel utilization and provide solutions to control the stable point of GCA near the optimal point. Due to the generality of GCA, our work provides a theoretical foundation to analyze existing and design new contention window control algorithms.},
keywords={optimal control;distributed control;telecommunication traffic;wireless LAN;telecommunication congestion control;bandwidth allocation;channel allocation;control system synthesis;distributed optimal contention window control;elastic traffic;wireless LAN;arbitrary bandwidth allocation;channel utilization;contention window assignment problem;control algorithms design;Optimal control;Wireless LAN;Local area networks;Bandwidth;Channel allocation;Telecommunication traffic;Algorithm design and analysis;Computer science;Application software;Distributed control},
doi={10.1109/INFCOM.2005.1497877},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497878,
author={T. Ren and R. J. La},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Downlink beamforming algorithms with inter-cell interference in cellular networks},
year={2005},
volume={1},
number={},
pages={47-57 vol. 1},
abstract={We study the application of antenna arrays at the base stations in a multi-cell environment. Simulation results demonstrate that the inter-cell interference significantly degrades the system performance in terms of packet loss probability (PLP) and total throughput. In order to cope with the presence of inter-cell interference in multi-cell networks we propose two algorithms: the first algorithm replaces the noise term in the beamforming algorithm by the sum of average inter-cell interference and noise, and is shown to perform well for certain type of link curves. We derive an expression for the average PLP as a function of the target SINR value corresponding to the target PLP. This expression tells us that the average PLP does not equal the target PLP in general, and offers an explanation for the good performance of the first algorithm for some link curves. Based on this expression, the second proposed algorithm makes use of more than just the mean of the SINR distribution in the beamforming algorithm. The experimental results demonstrate that this algorithm achieves the target PLP with general link curves and different scheduling algorithms under various wireless channel models. We characterize the inter-cell interference distribution for different scheduling and beamforming algorithms under various channel models. It is shown that the inter-cell interference can be well approximated by a log-normal random variable and exhibits weak temporal correlation.},
keywords={radio links;radiofrequency interference;cellular radio;antenna arrays;probability;scheduling;packet switching;telecommunication channels;log normal distribution;interference suppression;downlink beamforming algorithms;intercell interference;cellular networks;antenna arrays;base stations;multicell environment;packet loss probability;total throughput;beamforming algorithm;link curves;SINR;scheduling algorithms;wireless channel models;log-normal random variable;weak temporal correlation;Downlink;Array signal processing;Interference;Land mobile radio cellular systems;Scheduling algorithm;Signal to noise ratio;Antenna arrays;Base stations;Degradation;System performance},
doi={10.1109/INFCOM.2005.1497878},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497879,
author={F. Baccelli and B. Blaszczyszyn and M. K. Karray},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Blocking rates in large CDMA networks via a spatial Erlang formula},
year={2005},
volume={1},
number={},
pages={58-67 vol. 1},
abstract={This paper builds upon the scalable admission control schemes for CDMA networks developed in F. Baccalli et al. (2003, December 2004). These schemes are based on an exact representation of the geometry of both the downlink and the uplink channels and ensure that the associated power allocation problems have solutions under constraints on the maximal power of each station/user. These schemes are decentralized in that they can be implemented in such a way that each base station only has to consider the load brought by its own users to decide on admission. By load we mean here some function of the configuration of the users and of their bit rates that is described in the paper. When implemented in each base station, such schemes ensure the global feasibility of the power allocation even in a very large (infinite number of cells) network. The estimation of the capacity of large CDMA networks controlled by such schemes was made in these references. In certain cases, for example for a Poisson pattern of mobiles in an hexagonal network of base stations, this approach gives explicit formulas for the infeasibility probability, defined as the fraction of cells where the population of users cannot be entirely admitted by the base station. In the present paper we show that the notion of infeasibility probability is closely related to the notion of blocking probability, defined as the fraction of users that are rejected by the admission control policy in the long run, a notion of central practical importance within this setting. The relation between these two notions is not bound to our particular admission control schemes, but is of more general nature, and in a simplified scenario it can be identified with the well-known Erlang loss formula. We prove this relation using a general spatial birth-and-death process, where customer locations are represented by a spatial point process that evolves over time as users arrive or depart. This allows our model to include the exact representation of the geometry of inter-cell and intra-cell interferences, which play an essential role in the load indicators used in these cellular network admission control schemes.},
keywords={code division multiple access;radio links;telecommunication channels;stochastic processes;probability;radiofrequency interference;cellular radio;telecommunication congestion control;blocking rates;CDMA networks;spatial Erlang formula;downlink channels;uplink channels;base station;power allocation;Poisson pattern;hexagonal network;infeasibility probability;blocking probability;Erlang loss formula;spatial birth-and-death process;intracell interferences;intercell interferences;cellular network admission control schemes;Intelligent networks;Multiaccess communication;Admission control;Base stations;Geometry;Steady-state;Probability;Research and development;Downlink;Bit rate},
doi={10.1109/INFCOM.2005.1497879},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497880,
author={Tian Bu and Mun Choon Chan and R. Ramjee},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Designing wireless radio access networks for third generation cellular networks},
year={2005},
volume={1},
number={},
pages={68-78 vol. 1},
abstract={In third generation (3G) cellular networks, base stations are connected to base station controllers by point-to-point (usually T1/E1) links. However, today's T1/E1 based buck haul network is not a good match for next generation wireless networks because symmetric T1s is not an efficient way to carry bursty and asymmetric data traffic. In this paper, we propose designing an IEEE 802.16-based wireless radio access network to carry the traffic from the base station to the radio network controller. 802.16 has several characteristics that make it a better match for 3G radio access networks including its support for time division duplex mode that supports asymmetry efficiently. In this paper, we tackle the following question; given a layout of base stations and base station controllers, how do we design the topology of the 802.16 radio access network connecting the base stations to the base station controller that minimizes the number of 802.16 links used while meeting the expected demands of traffic from/to the base stations? We make three contributions: we first show that finding the optimal solution to the problem is NP-hard. We then provide heuristics that perform close to the optimal solution. Finally, we address the reliability issue of failure of 802.16 links or nodes by designing algorithms to create topologies that can handle single failures effectively.},
keywords={radio access networks;3G mobile communication;cellular radio;radio links;data communication;telecommunication traffic;telecommunication control;time division multiplexing;telecommunication network topology;telecommunication network reliability;computational complexity;wireless radio access networks;third generation cellular networks;base stations;point-to-point links;asymmetric data traffic;IEEE 802.16;radio network controller;3G radio access networks;time division duplex mode;network topology;NP-hard;network reliability;Radio access networks;Land mobile radio cellular systems;Base stations;Communication system traffic control;Radio control;Next generation networking;Wireless networks;Radio network;Network topology;Joining processes},
doi={10.1109/INFCOM.2005.1497880},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497881,
author={Z. Rosberg},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Asymptotically optimal transmission power and rate control for CDMA channels with multiple user classes},
year={2005},
volume={1},
number={},
pages={79-89 vol. 1},
abstract={An asymptotically combined optimal transmission power and rate control policy is derived for a DS-CDMA time varying fading channel with multiple user classes, random spreading codes and a linear MMSE multiuser detector. The rigorous optimization problem is presented as a non-convex constrained program explicitly solved in a closed-form given by a function of a single Lagrangian multiplier. The optimal multiplier is derived by a low number of independent bisection searches for a zero, where each search is done in a single-valued function. The optimal control policy is demonstrated by an application, where the transmission power is adapted to the channel fade variations, and the transmission rates are adapted to the tier in which the mobile is located. The effect of the number of tiers on the optimal transmission rate is presented in an environment with lognormal and Rayleigh fading.},
keywords={optimal control;multiuser detection;code division multiple access;spread spectrum communication;time-varying channels;least mean squares methods;optimisation;telecommunication congestion control;mobile radio;Rayleigh channels;log normal distribution;asymptotically optimal transmission power;rate control;multiple user classes;DS-CDMA time varying fading channel;random spreading codes;linear MMSE multiuser detector;optimization problem;nonconvex constrained program;Lagrangian multiplier;single-valued function;optimal control policy;mobile radio;Rayleigh fading;lognormal;Optimal control;Multiaccess communication;Power control;Communication system control;Iterative algorithms;Fading;Control systems;Detectors;Rayleigh channels;Bandwidth},
doi={10.1109/INFCOM.2005.1497881},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497882,
author={J. Dorsey and D. Siewiorek},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Exchange power management for mobile ad hoc networks},
year={2005},
volume={1},
number={},
pages={90-101 vol. 1},
abstract={We present an incentive compatible mechanism for negotiated power management in mobile ad hoc networks. Using power measurements of real wireless interfaces, we show that a cost model for this environment must account for energy complementarity between overlapping traffic flows. We introduce the combinatorial exchange, a generalization of the route selection method already implemented in source routing networks, as a model which accounts for overlap. No previous mechanism for networks is incentive compatible in the power managing environment. We have developed a distributed procedure for exchange-based route selection, which we evaluate using realistic simulation. Our results show significant improvements in energy consumption variability, route setup latency, and application message delivery latency.},
keywords={mobile radio;ad hoc networks;telecommunication traffic;telecommunication network routing;exchange power management;mobile ad hoc networks;power measurements;wireless interfaces;overlapping traffic flows;combinatorial exchange;route selection method;source routing networks;exchange-based route selection;energy consumption variability;route setup latency;application message delivery latency;Energy management;Mobile ad hoc networks;Delay;Power measurement;Costs;Telecommunication traffic;Traffic control;Routing;Environmental management;Energy consumption},
doi={10.1109/INFCOM.2005.1497882},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497883,
author={A. Behzad and I. Rubin},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Impact of power control on the performance of ad hoc wireless networks},
year={2005},
volume={1},
number={},
pages={102-113 vol. 1},
abstract={An ad hoc wireless network with n nodes and m source-destination pairs, using a scheduling based medium access control (MAC) protocol such as time division multiple access (TDMA), and a routing mechanism that may be unicast or multicast based, is considered. Under a given nodal transmit power vector, we define the source-destination throughput vector to be achievable if there exists an associated temporal (based on the channel sharing MAC protocol) and spatial (based on the underlying routing mechanism) joint scheduling-routing scheme that yields the throughput vector. In this paper, we analyze and investigate the effect of nodal transmit power vector on the maximum (or supreme) level of a general (real-valued) function of the source-destination throughput levels. We represent the latter supreme level attained under power vector. We also derive a linear programming (LP) formulation for obtaining the exact solution to the optimization problem that yields the throughput capacity of finite ad hoc wireless networks. Our LP based performance evaluation results identify the magnitude of capacity upgrade that can be realized for networks with random topologies and traffic patterns.},
keywords={power control;telecommunication congestion control;ad hoc networks;multicast protocols;time division multiple access;routing protocols;telecommunication channels;scheduling;linear programming;telecommunication network topology;telecommunication traffic;power control;ad hoc wireless networks;source-destination pairs;medium access control protocol;time division multiple access;TDMA;routing mechanism;multicast;nodal transmit power vector;source-destination throughput vector;channel sharing MAC protocol;underlying routing mechanism;joint scheduling-routing scheme;linear programming;optimization problem;random topologies;traffic patterns;Power control;Wireless networks;Throughput;Media Access Protocol;Vectors;Multicast protocols;Routing protocols;Access protocols;Time division multiple access;Wireless application protocol},
doi={10.1109/INFCOM.2005.1497883},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497884,
author={R. Mangharam and R. Rajkumar and S. Pollin and F. Catthoor and B. Bougard and L. Van der Perre and I. Moeman},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Optimal fixed and scalable energy management for wireless networks},
year={2005},
volume={1},
number={},
pages={114-125 vol. 1},
abstract={In many devices, wireless network interfaces consume upwards of 30% of scarce portable system energy. Extending the system lifetime by minimizing communication power consumption has therefore become a priority. Conventional energy management techniques focus independently on minimizing the fixed energy consumption of the transceiver circuit or on scalable transmission control. Fixed energy consumption is reduced by maximizing the transceiver shutdown interval. In contrast, variable transmission rate, coding and power can be leveraged to minimize energy costs. These two energy management approaches present a tradeoff in minimizing the overall system energy. For example, variable energy costs are minimized by transmitting at a lower modulation rate and transmission power, but this also shortens the sleep duration thereby increasing fixed energy consumption. We present a methodology for energy-efficient resource allocation across the physical layer, communications layer and link layer. Our methodology is aimed at providing QoS for multiple users with bursty MPEG-4 video over a time-varying channel. We evaluate our scheme by exploiting control knobs of actual RF components over a modified IEEE 802.11 MAC. Our results indicate that the system lifetime is increased by a factor of 2 to 5 compared to the gains of conventional techniques.},
keywords={radio networks;telecommunication congestion control;radio links;resource allocation;time-varying channels;access protocols;wireless LAN;quality of service;energy management;wireless networks;communication power consumption;transceiver circuit;scalable transmission control;variable transmission rate;overall system energy;energy-efficient resource allocation;link layer;MPEG-4 video;time-varying channel;IEEE 802.11 MAC;QoS;Energy management;Wireless networks;Energy consumption;Transceivers;Communication system control;Costs;Circuits;Sleep;Energy efficiency;Resource management},
doi={10.1109/INFCOM.2005.1497884},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497885,
author={S. J. Baek and G. de Veciana},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Spatial energy balancing in large-scale wireless multihop networks},
year={2005},
volume={1},
number={},
pages={126-137 vol. 1},
abstract={In this paper we investigate the use of proactive multipath routing to achieve energy efficient operation of ad hoc wireless networks. The focus is on optimizing trade-offs between the energy cost of spreading traffic and the improved spatial balance of energy burdens. We first propose a simple scheme for multipath routing based on node proximity. Then combining stochastic geometric and queuing models we develop a continuum model for such networks, permitting consideration of different types of designs, i.e., with and without energy replenishing and storage capabilities. We propose a parameterized family of energy balancing strategies for grids and approximate the spatial distributions of energy burdens based on their associated second order statistics. Our analysis and simulations show the fundamental importance of the tradeoff explored in this paper, and how its optimization depends on the relative values of the energy reserves/storage, replenishing rates, and network load characteristics. Simulation results show that proactive multipath routing decreases the probability of energy depletion by orders of magnitude versus that of shortest path routing scheme when the initial energy reserve is high.},
keywords={telecommunication network routing;stochastic processes;queueing theory;statistical analysis;optimisation;mobile radio;spatial energy balancing;large-scale wireless multihop networks;multipath routing;ad hoc wireless networks;spatial balance;node proximity;stochastic geometric;queuing models;continuum model;energy balancing strategies;second order statistics;optimization;network load characteristics;shortest path routing scheme;Large-scale systems;Spread spectrum communication;Routing;Solid modeling;Energy storage;Energy efficiency;Wireless networks;Cost function;Telecommunication traffic;Traffic control},
doi={10.1109/INFCOM.2005.1497885},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497886,
author={Hyuk Lim and J. C. Hou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Localization for anisotropic sensor networks},
year={2005},
volume={1},
number={},
pages={138-149 vol. 1},
abstract={In this paper, we consider the issue of localization in anisotropic sensor networks. Anisotropic networks are differentiated from isotropic networks in that they possess properties that vary according to the direction of measurement. Anisotropic characteristics result from various factors such as the geographic shape of the region (non-convex region), the different node densities, the irregular radio patterns, and the anisotropic terrain conditions. In order to characterize anisotropic features, we devise a linear mapping method that transforms proximity measurements between sensor nodes into a geographic distance embedding space by using the truncated singular value decomposition-based (TSVD-based) pseudo-inverse technique. This transformation retains as much topological information as possible and reduces the effect of measurement noises on the estimates of geographic distances. We show via simulation that the proposed localization method outperforms DV-hop, DV-distance (D. Niculescu, 2001), and MDS-map (Y. Shang et al., 2003), and makes robust and accurate estimates of sensor locations in both isotropic and anisotropic sensor networks.},
keywords={wireless sensor networks;singular value decomposition;telecommunication network topology;anisotropic sensor networks;anisotropic terrain conditions;linear mapping method;geographic distance embedding space;truncated singular value decomposition;pseudo-inverse technique;topological information;Anisotropic magnetoresistance;Wireless sensor networks;Shape;Sensor phenomena and characterization;Communication system security;Monitoring;Sensor systems;Global Positioning System;Position measurement;Computer science},
doi={10.1109/INFCOM.2005.1497886},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497887,
author={A. Caruso and S. Chessa and S. De and A. Urpi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={GPS free coordinate assignment and routing in wireless sensor networks},
year={2005},
volume={1},
number={},
pages={150-160 vol. 1},
abstract={In this paper we consider the problem of constructing a coordinate system in a sensor network where location information is not available. To this purpose we introduce the virtual coordinate assignment protocol (VCap) which defines a virtual coordinate system based on hop distances. As compared to other approaches, VCap is simple and have very little requirements in terms of communication and memory overheads. We compare by simulations the performances of greedy routing using our virtual coordinate system with the one using the physical coordinates. Results show that the virtual coordinate system can be used to efficiently support geographic routing.},
keywords={routing protocols;radionavigation;greedy algorithms;wireless sensor networks;GPS free coordinate assignment;wireless sensor networks;virtual coordinate assignment protocol;virtual coordinate system;greedy routing;geographic routing;Global Positioning System;Intelligent networks;Wireless sensor networks;Routing protocols;Costs;Mobile ad hoc networks;Monitoring;Data processing;Databases;Sensor systems},
doi={10.1109/INFCOM.2005.1497887},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497888,
author={Lei Fang and Wenliang Du and Peng Ning},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A beacon-less location discovery scheme for wireless sensor networks},
year={2005},
volume={1},
number={},
pages={161-171 vol. 1},
abstract={In wireless sensor networks (WSNs), sensor location plays a critical role in many applications. Having a GPS receiver on every sensor node is costly. In the past, a number of location discovery schemes have been proposed. Most of these schemes share a common feature: they use some special nodes, called beacon nodes, which are assumed to know their own locations (e.g., through GPS receivers or manual configuration). Other sensors discover their locations based on the information provided by these beacon nodes. In this paper, we show that efficient location discovery can be achieved in sensor networks without using beacons. We propose a beacon-less location discovery scheme, based on the following observations: in practice, it is quite common that sensors are deployed in groups, i.e., sensors are put into n groups, and sensors in the same group are deployed together at the same deployment point (the deployment point is different from the sensors' final resident location). Sensors from the same group can land in different locations, and those locations usually follow a probability distribution that can be known a priori. With this prior deployment knowledge, we show that sensors can discover their locations by observing the group memberships of its neighbors. We model the location discovery problem as a statistical estimation problem, and we use the maximum likelihood estimation method to estimate the location. We have conducted experiments to evaluate our scheme.},
keywords={wireless sensor networks;radionavigation;statistical distributions;maximum likelihood estimation;beacon-less location discovery scheme;wireless sensor networks;GPS receiver;sensor node;probability distribution;maximum likelihood estimation method;statistical estimation problem;Wireless sensor networks;Global Positioning System;Costs;Sensor systems;Satellites;Application software;Probability distribution;Maximum likelihood estimation;Personnel;Routing protocols},
doi={10.1109/INFCOM.2005.1497888},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497889,
author={N. B. Priyantha and H. Balakrishnan and E. D. Demaine and S. Teller},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Mobile-assisted localization in wireless sensor networks},
year={2005},
volume={1},
number={},
pages={172-183 vol. 1},
abstract={The localization problem is to determine an assignment of coordinates to nodes in a wireless ad-hoc or sensor network that is consistent with measured pairwise node distances. Most previously proposed solutions to this problem assume that the nodes can obtain pairwise distances to other nearby nodes using some ranging technology. However, for a variety of reasons that include obstructions and lack of reliable omnidirectional ranging, this distance information is hard to obtain in practice. Even when pairwise distances between nearby nodes are known, there may not be enough information to solve the problem uniquely. This paper describes MAL, a mobile-assisted localization method which employs a mobile user to assist in measuring distances between node pairs until these distance constraints form a "globally rigid'* structure that guarantees a unique localization. We derive the required constraints on the mobile's movement and the minimum number of measurements it must collect; these constraints depend on the number of nodes visible to the mobile in a given region. We show how to guide the mobile's movement to gather a sufficient number of distance samples for node localization. We use simulations and measurements from an indoor deployment using the Cricket location system to investigate the performance of MAL, finding in real-world experiments that MAL's median pairwise distance error is less than 1.5% of the true node distance.},
keywords={mobile radio;wireless sensor networks;ad hoc networks;telecommunication network reliability;indoor radio;mobile-assisted localization;wireless sensor networks;pairwise node distances;localization problem;wireless ad-hoc;reliable omnidirectional ranging;node localization;indoor deployment;Cricket location system;Intelligent networks;Wireless sensor networks;Coordinate measuring machines;Reflection;Computer science;Artificial intelligence;Laboratories;Intelligent sensors;Distance measurement;Rotation measurement},
doi={10.1109/INFCOM.2005.1497889},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497890,
author={S. Shakkottai and R. Srikant},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Economics of network pricing with multiple ISPs},
year={2005},
volume={1},
number={},
pages={184-194 vol. 1},
abstract={In this paper we examine how transit and customer prices are set in a network consisting of multiple ISPs. Some ISPs may be geographically co-located so that they compete for the same set of end users. We examine the existence of equilibrium price strategies in this situation and show how positive profit can be achieved using threat strategies. It is shown that if the number of ISPs competing for the same customers is large then it can lead to price wars. ISPs that are not geographically co-located may not directly compete for users, but are nevertheless involved in a non-cooperative game of setting access and transit prices for each other. We study how such ISPs are linked economically through transit ISPs by considering a multi-stage game. We also consider the economics of private exchange points and show that they could become far more wide spread then they currently are.},
keywords={Internet;pricing;economics;network pricing;multiple ISP;equilibrium price strategies;multistage game;private exchange point economics;Internet service provider;Pricing;Internet telephony;Web and internet services;Traffic control;Computer networks;Protocols;IP networks;Telecommunication traffic;Clouds;Joining processes},
doi={10.1109/INFCOM.2005.1497890},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497891,
author={Linhai He and J. Walrand},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Pricing differentiated Internet services},
year={2005},
volume={1},
number={},
pages={195-204 vol. 1},
abstract={One of the critical challenges facing the networking industry today is to increase the profitability of Internet services. One well-known method in economics for increasing the revenues of a service is to segment its market through differentiation. However, special characteristics of Internet services, such as congestion externality, may complicate the design and provisioning of such offerings. In this paper, we study how a provider should price its services differentially based on their characteristics. By using a game-theoretic approach, we show that even with a simple two-class differentiated service model, if prices are not properly matched with service qualities, then the system may settle into an undesirable equilibrium similar to that in the classical "prisoner's dilemma" game. In addition, there may not even be a stable equilibrium under certain conditions. We then show that dynamic pricing approaches, in which prices are chosen according to users' relative preferences over different service classes, may be used to avoid such types of problems.},
keywords={pricing;DiffServ networks;Internet;game theory;pricing differentiated Internet services;congestion externality;game-theoretic approach;two-class differentiated service model;dynamic pricing approaches;Pricing;Web and internet services;Helium;Computer networks;Computer industry;Industrial economics;Profitability;Game theory;Streaming media},
doi={10.1109/INFCOM.2005.1497891},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497892,
author={Linhai He and J. Walrand},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Pricing and revenue sharing strategies for Internet service providers},
year={2005},
volume={1},
number={},
pages={205-216 vol. 1},
abstract={One of the challenges facing the networking industry today is to increase the profitability of Internet services. This calls for economic mechanisms that can enable providers to charge more for better services and collect a fair share of the increased revenues. In this papery we present a generic model for pricing Internet services that are jointly offered by a group of providers. We show that non-cooperative pricing strategies between providers may lead to unfair distribution of profit and may even discourage future upgrades to the network. As an alternative, we propose a fair revenue-sharing policy based on the weighted proportional fairness criterion. We show that this fair allocation policy encourages collaboration among providers and hence can produce higher profits for all providers. Based on the analysis, we suggest a scalable algorithm for providers to implement this policy in a distributed way and study its convergence property.},
keywords={Internet;pricing;game theory;revenue sharing strategies;Internet service providers;noncooperative pricing strategies;weighted proportional fairness criterion;fair allocation policy;collaboration;Pricing;Web and internet services;Profitability;Protocols;Helium;Computer networks;Collaboration;Convergence;Game theory;IP networks},
doi={10.1109/INFCOM.2005.1497892},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497893,
author={M. Andrews},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Maximizing profit in overloaded networks},
year={2005},
volume={1},
number={},
pages={217-224 vol. 1},
abstract={We consider the problem of scheduling data in overloaded networks. We wish to maximize the total profit of data that is served. We first consider a single server that has to schedule data over time-varying channels. This model is motivated by scheduling in wireless networks. Our objective is to maximize the total amount of data scheduled to user by time. In contrast to most previous work we assume that the channel conditions are defined by an adversary rather than a stationary, stochastic process. We give lower bounds on how competitive an online algorithm can be and show that the hounds are nearly matched by a simple randomized algorithm. We also consider a situation in which packets with associated profits are injected into a network of servers. We wish to schedule the packets in the network and maximize the profit of data that reaches its destination. We show that if the servers are allowed to exchange control packets that inform each other of the congestion in the network then we can approximate the optimum profit arbitrarily closely. We also show that without these control packets this is not possible. Our results are motivated by recent work on primal-dual algorithms for flow control in networks. The key difference between our approach and this previous work is that we take into account the scheduling dynamics in the network.},
keywords={dynamic scheduling;time-varying channels;packet radio networks;stochastic processes;network servers;random processes;telecommunication congestion control;overloaded networks;scheduling data;time-varying channels;wireless networks;stochastic process;randomized algorithm;servers;primal-dual algorithms;flow control;Intelligent networks;Network servers;Wireless networks;Time-varying channels;Scheduling algorithm;Traffic control;Data communication;Stochastic processes;Dynamic scheduling;Stochastic systems},
doi={10.1109/INFCOM.2005.1497893},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497894,
author={Jinyang Li and J. Stribling and R. Morris and M. F. Kaashoek and T. M. Gil},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A performance vs. cost framework for evaluating DHT design tradeoffs under churn},
year={2005},
volume={1},
number={},
pages={225-236 vol. 1},
abstract={Protocols for distributed hash tables (DHTs) incorporate features to achieve low latency for lookup requests in the face of churn, continuous changes in membership. These protocol features can include a directed identifier space, parallel lookups, pro-active flooding of membership changes, and stabilization protocols for maintaining accurate routing. In addition, DHT protocols have parameters that can be tuned to achieve different tradeoffs between lookup latency and communication cost due to maintenance traffic. The relative importance of the features and parameters is not well understood, because most previous work evaluates protocols on static networks. This paper presents a performance versus cost framework (PVC) that allows designers to compare the effects of different protocol features and parameter values. PVC views a protocol as consuming a certain amount of network bandwidth in order to achieve a certain lookup latency, and helps reveal the efficiency with which protocols use additional network resources to improve latency. To demonstrate the value of PVC, this paper simulates Chord, Kademlia, Kelips, OneHop, and Tapestry under different workloads and uses PVC to understand which features are more important under churn. PVC analysis shows that the key to efficiently using additional bandwidth is for a protocol to adjust its routing table size. It also shows that routing table stabilization is wasteful and can be replaced with opportunistic learning through normal lookup traffic. These insights combined demonstrate that PVC is a valuable tool for DHT designers.},
keywords={file organisation;table lookup;routing protocols;telecommunication traffic;bandwidth allocation;maintenance engineering;distributed hash tables;proactive flooding;stabilization protocols;routing protocols;maintenance traffic;performance versus cost framework;network bandwidth;routing table stabilization;lookup traffic;Costs;Delay;Routing protocols;Telecommunication traffic;Bandwidth;Gas insulated transmission lines;Computer science;Artificial intelligence;Laboratories;Floods},
doi={10.1109/INFCOM.2005.1497894},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497895,
author={P. Francois and O. Bonaventure},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Avoiding transient loops during IGP convergence in IP networks},
year={2005},
volume={1},
number={},
pages={237-247 vol. 1},
abstract={When the topology of an IP network changes due to a link failure or a link metric modification, the routing tables of all the routers must be updated. Each of those updates may cause transient loops. In this paper, we prove that by ordering the updates of the routing tables on the routers, it is possible to avoid all transient loops during the convergence of ISIS or OSPF after a planned link failure, an unplanned failure of a protected link and after a link metric modification. We then propose a protocol that allows the routers to order the update of their routing tables to avoid transient loops without requiring any complex computation.},
keywords={IP networks;telecommunication links;telecommunication network topology;routing protocols;computer network reliability;telecommunication network planning;transient loops;IP network topology;link failure;link metric modification;routing tables;planned link failure;protected link;routing protocol;Convergence;Intelligent networks;IP networks;Protection;Network topology;Spine;Routing protocols;Telecommunication traffic;Computer networks;Costs},
doi={10.1109/INFCOM.2005.1497895},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497896,
author={R. Gummadi and R. Govindan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Practical routing-layer support for scalable multihoming},
year={2005},
volume={1},
number={},
pages={248-259 vol. 1},
abstract={The recent trend of rapid increase in routing table sizes at routers comprising the Internet's core is posing a serious challenge to the current Internet's scalability, availability, and stability. Multihoming is a prime contributor to this table size explosion. This paper argues that it is possible to a) scale the Internet's routing table sub-linearly with degree of multihoming, and b) improve routing convergence times even under pervasive multihoming using simple and incrementally deployable extensions to today's routing protocols. We present an addressing and routing protocol called SIMPLER (scalable IP multihoming protocol leveraging routing), which is designed to minimize and contain the propagation in space and time of non-aggregatable routes. SIMPLER's prefix containment property results in lower lookup and route processing costs (promotes scalability), and faster convergence time (helps network availability and stability). SIMPLER vastly diminishes the number of non-aggregatable prefixes appearing in the Internet core due to multihoming (to zero in the absence of network faults, and O(number of faults) otherwise), and always leaks fewer non-aggregatable prefixes than today's dominant multihoming strategy of "hole punching". Additionally, SIMPLER provides transport-layer survivability (TLS) and better routing policy management, while offering the same routing robustness as today's multihoming. The main cost of SIMPLER is the increased use of address space (O(log(network size)) in the average case). SIMPLER is carefully designed to be useful to both multihomed transit providers and multihomed leaf sites.},
keywords={routing protocols;Internet;IP networks;computer network reliability;computer network management;practical routing-layer support;Internet;routing convergence;routing protocols;scalable IP multihoming protocol leveraging routing;network availability;network stability;network faults;hole punching;transport-layer survivability;routing policy management;Internet;Routing protocols;Scalability;Stability;Convergence;Costs;Explosions;IP networks;Punching;Robustness},
doi={10.1109/INFCOM.2005.1497896},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497897,
author={G. Retvari and J. J. Biro and T. Ciinkler and T. Henk},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A precomputation scheme for minimum interference routing: the least-critical-path-first algorithm},
year={2005},
volume={1},
number={},
pages={260-268 vol. 1},
abstract={This paper focuses on the selection of bandwidth-guaranteed channels for communication sessions that require it. The basic idea comes from minimum interference routing: select a feasible path that puts the least possible restriction on the available transmission capacity of other communicating parties. This is achieved by circumventing some critical bottleneck links. The main contribution of the paper is a novel characterization of link criticality, the criticality threshold, which can be readily precompiled for routing dozens of subsequent calls. Based on this finding we define a generic precomputation framework for minimum interference routing, the least-critical-path-first routing algorithm. We show by means of extensive simulations that efficient route precomputation is possible even in the case, when accurate resource availability information is not immediately available.},
keywords={telecommunication network routing;bandwidth allocation;telecommunication channels;telecommunication links;interference (signal);minimum interference routing;least-critical-path-first algorithm;bandwidth-guaranteed channels;transmission capacity;critical bottleneck links;subsequent calls routing;Interference;Routing;Bandwidth;Telecommunication traffic;High-speed networks;Laboratories;Informatics;Availability;Network address translation;Propagation losses},
doi={10.1109/INFCOM.2005.1497897},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497898,
author={D. E. Taylor and J. S. Turner},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Scalable packet classification using distributed crossproducing of field labels},
year={2005},
volume={1},
number={},
pages={269-280 vol. 1},
abstract={A wide variety of packet classification algorithms and devices exist in the research literature and commercial market. The existing solutions exploit various design tradeoffs to provide high search rates, power and space efficiency, fast incremental updates, and the ability to scale to large numbers of filters. There remains a need for techniques that achieve a favorable balance among these tradeoffs and scale to support classification on additional fields beyond the standard 5-tuple. We introduce distributed crossproducing of field labels (DCFL), a novel combination of new and existing packet classification techniques that leverages key observations of the structure of real filter sets and takes advantage of the capabilities of modern hardware technology. Using a collection of real and synthetic filter sets, we provide analyses of DCFL performance and resource requirements on filter sets of various sizes and compositions. An optimized implementation of DCFL can provide over 100 million searches per second and storage for over 200 thousand filters in a current generation FPGA or ASIC without the need for external memory devices.},
keywords={field programmable gate arrays;application specific integrated circuits;digital filters;packet classification algorithms;distributed crossproducing of field labels;filter sets;FPGA;ASIC;external memory devices;Matched filters;Quality of service;Monitoring;Laboratories;Classification algorithms;Hardware;Performance analysis;Field programmable gate arrays;Application specific integrated circuits;Transport protocols},
doi={10.1109/INFCOM.2005.1497898},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497899,
author={Xiliang Liu and K. Ravindran and D. Loguinov},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={What signals do packet-pair dispersions carry?},
year={2005},
volume={1},
number={},
pages={281-292 vol. 1},
abstract={Although packet-pair probing has been used as one of the primary mechanisms to measure bottleneck capacity, cross-traffic intensity, and available bandwidth of end-to-end Internet paths, there is still no conclusive answer as to what information about the path is contained in the output packet-pair dispersions and how it is encoded. In this paper, we address this issue by deriving closed-form expression of packet-pair dispersion in the context of a single-hop path and general bursty cross-traffic arrival. Under the assumptions of cross-traffic stationarity and ASTA sampling, we examine the statistical properties of the information encoded in inter-packet spacings and derive the asymptotic average of the output packet-pair dispersions as a closed-form function of the input dispersion. We show that this result is different from what was obtained in prior work using fluid cross-traffic models and that this discrepancy has a significant impact on the accuracy of packet-pair bandwidth estimation.},
keywords={telecommunication traffic;bandwidth allocation;Internet;statistical analysis;packet-pair dispersions;packet-pair probing;bottleneck capacity;cross-traffic intensity;available bandwidth;end-to-end Internet paths;single-hop path;bursty cross-traffic arrival;statistical properties;fluid cross-traffic models;packet-pair bandwidth estimation;Bandwidth;Dispersion;Traffic control;Stochastic processes;Delay estimation;Internet;Closed-form solution;Sampling methods;Queueing analysis;Estimation theory},
doi={10.1109/INFCOM.2005.1497899},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497900,
author={Kai Zheng and Hao Che and Zhijun Wang and Bin Liu},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={TCAM-based distributed parallel packet classification algorithm with range-matching solution},
year={2005},
volume={1},
number={},
pages={293-303 vol. 1},
abstract={Packet classification (PC) has been a critical data path function for many emerging networking applications. An interesting approach is the use of TCAM to achieve deterministic, high speed PC However, apart from high cost and power consumption, due to slow growing clock rate for memory technology in general, PC based on the traditional single TCAM solution has difficulty to keep up with fast growing line rates. Moreover, the TCAM storage efficiency is largely affected by the need to support rules with ranges, or range matching. In this paper, a distributed TCAM scheme that exploits chip-level-parallelism is proposed to greatly improve the PC throughput. This scheme seamlessly integrates with a range encoding scheme, which not only solves the range matching problem but also ensures a balanced high throughput performance. Using commercially available TCAM chips, the proposed scheme achieves PC performance of more than 100 million packets per second (Mpps), matching OC768 (40 Gbps) line rate.},
keywords={parallel algorithms;pattern classification;telecommunication traffic;storage allocation;distributed parallel packet classification algorithm;range-matching solution;critical data path function;ternary content addressable memory;chip-level-parallelism;encoding scheme;40 Gbit/s;Classification algorithms;Clocks;Throughput;Computer science;Quality of service;Delay;Data engineering;Application software;Costs;Energy consumption},
doi={10.1109/INFCOM.2005.1497900},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497901,
author={F. Geraci and M. Pellegrini and P. Pisati and L. Rizzo},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Packet classification via improved space decomposition techniques},
year={2005},
volume={1},
number={},
pages={304-312 vol. 1},
abstract={Packet classification is a common task in modern Internet routers. The goal is to classify packets into "classes" or "flows" according to some ruleset that looks at multiple fields of each packet. Differentiated actions can then be applied to the traffic depending on the result of the classification. Even though rulesets can be expressed in a relatively compact way by using high level languages, the resulting decision trees can partition the search space (the set of possible attribute values) in a potentially very large (106 and more) number of regions. This calls for methods that scale to such large problem sizes, though the only scalable proposal in the literature so far is the one based on a fat inverted segment tree (A. Feldmann and S. Muthukrishnan). In this paper we propose a new geometric technique called G-filter for packet classification on d dimensions. G-filter is based on an improved space decomposition technique. In addition to a theoretical analysis showing that classification in G-filter has O(1) time complexity and slightly super-linear space in the number of rules, we provide thorough experiments showing that the constants involved are extremely small on a wide range of problem sizes, and that G-filter improve the best results in the literature for large problem sizes, and is competitive for small sizes as well.},
keywords={information filtering;Internet;set theory;telecommunication network routing;space decomposition techniques;Internet routers;resulting decision trees;geometric technique;G-filter;packet classification;time complexity;Traffic control;Decision trees;Filters;Telecommunication traffic;Internet;High level languages;Marketing and sales;Filtering;Network address translation;Multidimensional systems},
doi={10.1109/INFCOM.2005.1497901},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497902,
author={D. K. Goldenberg and A. Krishnamurthy and W. C. Maness and Y. R. Yang and A. Young and A. S. Morse and A. Savvides},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Network localization in partially localizable networks},
year={2005},
volume={1},
number={},
pages={313-326 vol. 1},
abstract={Knowing the positions of the nodes in a network is essential to many next generation pervasive and sensor network functionalities. Although many network localization systems have recently been proposed and evaluated, there has been no systematic study of partially localizable networks, i.e., networks in which there exist nodes whose positions cannot be uniquely determined. There is no existing study which correctly identifies precisely which nodes in a network are uniquely localizable and which are not. This absence of a sufficient uniqueness condition permits the computation of erroneous positions that may in turn lead applications to produce flawed results. In this paper, in addition to demonstrating the relevance of networks that may not be fully localizable, we design the first framework for two dimensional network localization with an efficient component to correctly determine which nodes are localizable and which are not. Implementing this system, we conduct comprehensive evaluations of network localizability, providing guidelines for both network design and deployment. Furthermore, we study an integration of traditional geographic routing with geographic routing over virtual coordinates in the partially localizable network setting. We show that this novel cross-layer integration yields good performance, and argue that such optimizations will be likely be necessary to ensure acceptable application performance in partially localizable networks.},
keywords={telecommunication network routing;network localization;partially localizable networks;network design;network deployment;geographic routing;cross-layer integration;Intelligent networks;Global Positioning System;Routing;Satellites;Computer science;Australia;Sensor systems;Guidelines;Next generation networking;Pervasive computing},
doi={10.1109/INFCOM.2005.1497902},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497903,
author={Anxiao Jiang and J. Bruck},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Monotone percolation and the topology control of wireless networks},
year={2005},
volume={1},
number={},
pages={327-338 vol. 1},
abstract={This paper addresses the topology control problem for large wireless networks that are modelled by an infinite point process on a two-dimensional plane. Topology control is the process of determining the edges in the network by adjusting the transmission radii of the nodes. Topology control algorithms should be based on local decisions, be adaptive to changes, guarantee full connectivity and support efficient routing. We present a family of topology control algorithms that, respectively, achieve some or all of these requirements efficiently. The key idea in our algorithms is a concept that we call monotone percolation. In classical percolation theory, we are interested in the emergence of an infinitely large connected component. In contrast, in monotone percolation we are interested in the existence of a relatively short path that makes monotonic progress between any pair of source and destination nodes. Our key contribution is that we demonstrate how local decisions on the transmission radii can lead to monotone percolation and in turn to efficient topology control algorithms.},
keywords={telecommunication network topology;radio networks;graph theory;telecommunication congestion control;monotone percolation;wireless network;infinite point process;two-dimensional plane;topology control algorithm;destination node;source node;graph theory;Network topology;Wireless networks;Routing;Process control;Space technology;Programmable control;Adaptive control;Combinatorial mathematics;Graph theory;Euclidean distance},
doi={10.1109/INFCOM.2005.1497903},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497904,
author={Qing Fang and Jie Gao and L. J. Guibas and V. de Silva and Li Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={GLIDER: gradient landmark-based distributed routing for sensor networks},
year={2005},
volume={1},
number={},
pages={339-350 vol. 1},
abstract={We present gradient landmark-based distributed routing (GLIDER), a novel naming/addressing scheme and associated routing algorithm, for a network of wireless communicating nodes. We assume that the nodes are fixed (though their geographic locations are not necessarily known), and that each node can communicate wirelessly with some of its geographic neighbors - a common scenario in sensor networks. We develop a protocol which in a preprocessing phase discovers the global topology of the sensor field and, as a byproduct, partitions the nodes into routable tiles - regions where the node placement is sufficiently dense and regular that local greedy methods can work well. Such global topology includes not just connectivity but also higher order topological features, such as the presence of holes. We address each node by the name of the tile containing it and a set of local coordinates derived from connectivity graph distances between the node and certain landmark nodes associated with its own and neighboring tiles. We use the tile adjacency graph for global route planning and the local coordinates for realizing actual inter- and intra-tile routes. We show that efficient load-balanced global routing can be implemented quite simply using such a scheme.},
keywords={gradient methods;distributed algorithms;wireless sensor networks;telecommunication network topology;graph theory;routing protocols;GLIDER;gradient landmark-based distributed routing;wireless sensor network;naming-addressing scheme;associated routing algorithm;wireless communicating node;node placement;greedy method;tile adjacency graph;intratile route;intertile route;load-balanced global routing planning;graph theory;algebraic topology;topology discovery;Network topology;Tiles;Wireless sensor networks;Hardware;Routing protocols;Computer science;Land use planning;Graph theory;Combinatorial mathematics;IP networks},
doi={10.1109/INFCOM.2005.1497904},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497905,
author={Kyoungwon Suh and Yang Guo and J. Kurose and D. Towsley},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Locating network monitors: complexity, heuristics, and coverage},
year={2005},
volume={1},
number={},
pages={351-361 vol. 1},
abstract={There is increasing interest in concurrent passive monitoring of IP flows at multiple locations within an IP network. The common objective of such a distributed monitoring system is to sample packets belonging to a large fraction of IP flows in a cost-effective manner by carefully placing monitors and controlling their sampling rates. In this paper, we consider the problem of where to place monitors within the network and how to control their sampling. To address the tradeoff between monitoring cost and monitoring coverage, we consider minimum cost and maximum coverage problems under various budget constraints. We show that all of the defined problems are NP-hard. We propose greedy heuristics, and show that the heuristics provide solutions quite close to the optimal solutions through experiments using synthetic and real network topologies. In addition, our experiments show that a small number of monitors is often enough to monitor most of the traffic in an entire IP network.},
keywords={monitoring;IP networks;greedy algorithms;telecommunication network topology;telecommunication traffic;network monitoring;concurrent passive monitoring;IP network;distributed monitoring system;control their sampling;NP-hard problem;greedy heuristics;network topology;Costs;Sampling methods;Telecommunication traffic;IP networks;Network topology;Computer science;Computerized monitoring;Computer displays;Control systems;Resource management},
doi={10.1109/INFCOM.2005.1497905},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497906,
author={F. Baccelli and Ki Baek Kim and D. De Vleeschauwer},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Analysis of the competition between wired, DSL and wireless users in an access network},
year={2005},
volume={1},
number={},
pages={362-373 vol. 1},
abstract={This paper analyzes the performance of a large population composed of several classes of long lived TCP flows experiencing packet losses due to random transmission errors and to congestion created by the sharing of a common tail-drop or RED bottleneck router. Each class has a different transmission error rate. This setting is used to analyze the competition between wired and wireless users in an access network, where one class (the wired class) has no or small (like BER in DSL) transmission error losses whereas the other class has higher transmission error losses, or the competition between DSL flows using different coding schemes. We propose a natural and simple model for the joint throughput evolution of several classes of TCP flows under such a mix of losses. Two types of random transmission error losses are considered: one where losses are Poisson and independent of the rate of the flow, and one where the losses are still Poisson but with an intensity that is proportional to the rate of the source. We show that the large population model where the population tends to infinity has a threshold (given in closed form) below which there are no congestion losses at all in steady state, and above which there is a stationary limiting regime in which we can compute both the mean value and the distribution of the rate obtained by each class of flow. We also show that the maximum mean value for the aggregated rate is achieved at the threshold.},
keywords={digital subscriber lines;transport protocols;error statistics;telecommunication congestion control;synchronisation;IP networks;telecommunication traffic;Poisson distribution;radio access networks;wireless user;DSL user;wired user;access network;TCP flow;packet loss;RED bottleneck router;tail-drop router;coding scheme;random transmission error loss;Poisson loss;congestion control;flow control;IP traffic;synchronisation;bit error rate;BER;packet error;DSL;Propagation losses;Performance analysis;Performance loss;Error analysis;Bit error rate;Throughput;H infinity control;Steady-state;Distributed computing},
doi={10.1109/INFCOM.2005.1497906},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497907,
author={A. Blanc and Yi-Kai Liu and A. Vahdat},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Designing incentives for peer-to-peer routing},
year={2005},
volume={1},
number={},
pages={374-385 vol. 1},
abstract={In a peer-to-peer network, nodes are typically required to route packets for each other. This leads to a problem of "free-loaders", nodes that use the network but refuse to route other nodes' packets. In this paper we study ways of designing incentives to discourage free-loading. We model the interactions between nodes as a "random matching game", and describe a simple reputation system that provides incentives for good behavior. Under certain assumptions, we obtain a stable subgame-perfect equilibrium. We use simulations to investigate the robustness of this scheme in the presence of noise and malicious nodes, and we examine some of the design trade-offs. We also evaluate some possible adversarial strategies, and discuss how our results might apply to real peer-to-peer systems.},
keywords={incentive schemes;peer-to-peer computing;telecommunication network routing;incentive design;peer-to-peer network routing;problem of free-loader;random matching game;reputation system;subgame-perfect equilibrium;Peer to peer computing;Routing;Game theory;Noise robustness;Noise measurement;Waste materials;Bandwidth;National security;Research and development;Engineering profession},
doi={10.1109/INFCOM.2005.1497907},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497908,
author={A. Zemlianov and G. de Veciana},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Cooperation and decision-making in a wireless multi-provider setting},
year={2005},
volume={1},
number={},
pages={386-397 vol. 1},
abstract={In this paper we investigate network design for a wireless service provider using two orthogonal technologies: a WAN technology with uniform spatial coverage and set of LAN access points each with limited coverage. We assume that the system is designed so that users (or their agents) independently and greedily select among the two options based on maximizing a specified utility function which may be a function of the quality of the wireless link, distance to the access points, and/or congestion on system resources. We focus on two complementary aspects of this problem. On the one hand we study system performance under such decision-making strategies. We show convergence of decision-making process to an equilibrium, and that a congestion-sensitive utility can provide substantial (300%) performance improvements over natural proximity-based criterion. On the other hand, we consider various problems associated with dimensioning typically expensive backhaul links, for the WAN and set of LAN hotspots. Our results show how to best jointly exploit technologies with different coverage scales so as to statistically multiplex spatial load fluctuations in order to reduce backhaul costs.},
keywords={decision making;wide area networks;local area networks;convergence;radio links;radio networks;decision-making;wireless multi-provider setting;network design;orthogonal technology;WAN technology;LAN access point;utility function;decision-making strategy;convergence;proximity-based criterion;spatial load fluctuation;network cooperation;Decision making;Wide area networks;Local area networks;Wireless LAN;Costs;Wireless sensor networks;Convergence;Fluctuations;Intelligent networks;System performance},
doi={10.1109/INFCOM.2005.1497908},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497909,
author={B. Burns and O. Brock and B. N. Levine},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={MV routing and capacity building in disruption tolerant networks},
year={2005},
volume={1},
number={},
pages={398-408 vol. 1},
abstract={Disruption-tolerant networks (DTNs) differ from other types of networks in that capacity is exclusively created by the movements of participants. This implies that understanding and influencing the participants' motions can have a significant impact on network performance. In this paper, we introduce the routing protocol MV, which learns structure in the movement patterns of network participants and uses it to enable informed message passing. We also propose the introduction of autonomous agents as additional participants in DTNs. These agents adapt their movements in response to variations in network capacity and demand. We use multi-objective control methods from robotics to generate motions capable of optimizing multiple network performance metrics simultaneously. We present experimental evidence that these strategies, individually and in conjunction, result in significant performance improvements in DTNs.},
keywords={routing protocols;message passing;telecommunication control;MV routing protocol;disruption tolerant network;routing protocol;message passing;autonomous agent;multiobjective control method;Intelligent networks;Disruption tolerant networking;Routing protocols;Autonomous agents;Measurement;Bandwidth;Delay;Computer science;Message passing;Motion control},
doi={10.1109/INFCOM.2005.1497909},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497910,
author={M. Andrews and L. Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Bounds on fiber minimization in optical networks with fixed fiber capacity},
year={2005},
volume={1},
number={},
pages={409-419 vol. 1},
abstract={We consider the problem of minimizing the amount of deployed fiber in optical networks in which each fiber carries a fixed number of wavelengths. We are given a network of general topology to carry a set of demands. For each demand we wish to choose a route and a wavelength. Since only distinct wavelengths can be carried on the same fiber, each link e requires max/spl lambda/ Fe(/spl lambda/) fibers where Fe(/spl lambda/) is the number of demands along e that are assigned wavelength /spl lambda/. We wish to minimize the total amount of fiber deployed in order to carry all the demands. Most past work either assumed an unlimited number of wavelengths or else was restricted to specific topologies such as lines, rings and trees. We show that for general topologies the problem is hard to approximate. In particular, for a family of networks of size N, we show that there is no O(log/sup 1/4-/spl epsi//N) approximation algorithm for any /spl epsi/ > 0 unless all problems in NP can be solved by randomized algorithms with expected running time O(n/sup polylog n/). On the positive side we describe methods to choose routes and wavelengths in order to obtain a logarithmic approximation ratio. Lastly we present heuristics that have close-to-optimal performance on example problems on several US backbone networks.},
keywords={optical fibre networks;telecommunication network topology;fiber minimization;optical network;fixed fiber capacity;general network topology;ring topology;trees topology;approximation algorithm;randomized algorithm;logarithmic approximation ratio;Optical fiber networks;Intelligent networks;Optical fiber devices;Optical wavelength conversion;Network topology;Stimulated emission;Wavelength division multiplexing;Approximation algorithms;Spine;Bandwidth},
doi={10.1109/INFCOM.2005.1497910},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497911,
author={Zhenghao Zhang and Yuanyuan Yang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A novel analytical model for electronic and optical switches with shared buffer},
year={2005},
volume={1},
number={},
pages={420-431 vol. 1},
abstract={Switches with shared buffer have lower packet loss probabilities than other types of switches when the sizes of the buffers are the same. In the past, the performance analysis for electronic shared buffer switches has been carried out extensively. However, due to the strong dependencies of the output queues in the buffer, it is very difficult to find a good analytical model. Existing models are either accurate but have exponential complexities or not very accurate. In this paper, we propose a novel analytical model called the aggregation model for switches with shared buffer. This model can be used for analyzing both electronic and optical switches, and has perfect accuracies under all tested conditions and has polynomial time complexity. It is based on the idea of induction: first find the behavior of 2 queues, then aggregate them into one block; then find the behavior of 3 queues while regarding 2 of the queues as one block, then aggregate the 3 queues into one block; then aggregate 4 queues and so on. When a sufficient number of queues have been aggregated, the behavior of the entire switch is found. We believe that the new model represents the best analytical model for shared buffer switches so far.},
keywords={buffer circuits;computational complexity;probability;telecommunication switching;optical communication;queueing theory;analytical model;optical switch;packet loss probability;electronic shared buffer switch;aggregation model;time complexity;Analytical models;Optical switches;Optical buffering;Aggregates;Optical packet switching;Optical losses;Performance analysis;Queueing analysis;Electronic equipment testing;Polynomials},
doi={10.1109/INFCOM.2005.1497911},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497912,
author={A. Brzezinski and E. Modiano},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Dynamic reconfiguration and routing algorithms for IP-over-WDM networks with stochastic traffic},
year={2005},
volume={1},
number={},
pages={432-443 vol. 1},
abstract={We develop algorithms for joint IP layer routing and WDM logical topology reconfiguration in IP-over-WDM networks experiencing stochastic traffic. At the WDM layer, we associate a non-negligible tuning latency with WDM reconfiguration, during which time tuned transceivers cannot service backlogged data. The IP layer is modeled as a queueing system. We demonstrate that our algorithms achieve asymptotic throughput optimality by using frame-based maximum weight scheduling decisions. We study both deterministic and random frame durations. In addition to dynamically triggering WDM reconfiguration, our algorithms specify precisely how to route packets over the IP layer during the phases in which the WDM layer remains fixed. Our algorithms remain valid under a variety of optical layer constraints. We provide an analysis of the specific case of WDM networks with multiple ports per node. In order to gauge the delay properties of our algorithms, we conduct a simulation study and demonstrate an important tradeoff between WDM reconfiguration and IP layer routing. We find that multi-hop routing is extremely beneficial at low throughput levels, while single-hop routing achieves improved delay at high throughput levels. For a simple access network, we demonstrate through simulation the benefit of employing multi-hop IP layer routes.},
keywords={IP networks;wavelength division multiplexing;stochastic processes;telecommunication traffic;telecommunication network routing;telecommunication network topology;queueing theory;scheduling;optical fibre networks;dynamic reconfiguration;routing algorithm;IP-over-WDM network;stochastic traffic;IP layer routing;topology reconfiguration;radio transceiver;queueing system;frame-based maximum weight scheduling decision;random frame duration;deterministic frame duration;delay property;multihop routing;Routing;Stochastic processes;Telecommunication traffic;Wavelength division multiplexing;Delay;Throughput;Traffic control;Network topology;Transceivers;Scheduling algorithm},
doi={10.1109/INFCOM.2005.1497912},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497913,
author={Chunpeng Xiao and B. Bing and G. K. Chang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={An efficient reservation MAC protocol with preallocation for high-speed WDM passive optical networks},
year={2005},
volume={1},
number={},
pages={444-454 vol. 1},
abstract={Wavelength division multiplexing passive optical networks (WDM PONs) can dynamically offer each end user a unique optical wavelength for data transmission as well as the possibility of wavelength reuse and aggregation, thereby ensuring scalability in bandwidth assignment. In this paper, we propose a new byte size clock (BSC) reservation MAC scheme that not only arbitrates upstream transmission and prevents optical collisions, but also varies bandwidth according to demand and priority, reduces request delay using pre-allocation and delta compression, and handles the addition/reconfiguration of network nodes efficiently. The new access scheme exploits both WDM and TDM to cater for both light and heavy bandwidth requirements and supports both Ethernet and ATM packets without segmenting or aggregating them. Our proposed protocol is not only backward compatible with APON and EPON, but also provides a better utilization of the access link in terms of the throughput and delay. In addition, the amount of pre-allocated bandwidth can be minimized using delta compression, which in turns reduces the latency due to the request and grant mechanism. We analyzed, evaluated, and simulated the performance and practicality of the proposed scheme.},
keywords={access protocols;bandwidth allocation;wavelength division multiplexing;time division multiplexing;data compression;queueing theory;optical fibre LAN;reservation MAC protocol;high-speed WDM passive optical network;wavelength division multiplexing;data transmission;wavelength reuse;wavelength aggregation;bandwidth assignment;byte size clock reservation;upstream transmission;delta compression;Ethernet;ATM packet;access link;bandwidth allocation;request and grant mechanism;queueing theory;Media Access Protocol;Wavelength division multiplexing;WDM networks;Passive optical networks;Bandwidth;High speed optical techniques;Optical fiber networks;Delay;Data communication;Scalability},
doi={10.1109/INFCOM.2005.1497913},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497914,
author={Honghai Zhang and J. C. Hou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Capacity of wireless ad-hoc networks under ultra wide band with power constraint},
year={2005},
volume={1},
number={},
pages={455-465 vol. 1},
abstract={In this paper, we study how the achievable throughput scales in a wireless network with randomly located nodes as the number of nodes increases, under a communication model where (i) each node has a maximum transmission power W/sub O/ and is capable of utilizing B Hz of bandwidth and (ii) each link can obtain a channel throughput according to the Shannon capacity. Under the limit case that B tends to infinity, we show that each node can obtain a throughput of /spl theta/(n/sup (/spl alpha/-1)/2/) where n is the density of the nodes and /spl alpha/ > 1 is the path loss exponent. Both the upper bound and lower bound are derived through percolation theory. In order to derive the capacity bounds, we have also derived an important result on random geometric graphs: if the distance between two points in a Poisson point process with density n is non-diminishing, the minimum power route requires a power rate at least /spl Omega/(n/sup (1-/spl alpha/)/2/). Our results show that the most promising approach to improving the capacity bounds in wireless ad hoc networks is to employ unlimited bandwidth resources, such as the ultra wide band (UWB).},
keywords={channel capacity;ad hoc networks;ultra wideband communication;graph theory;stochastic processes;wireless ad-hoc networks;ultra wide band;power constraint;communication model;Shannon capacity;path loss exponent;percolation theory;random geometric graphs;Poisson point process;stochastic process;queuing theory;graph theory;information theory;Ad hoc networks;Ultra wideband technology;Bandwidth;Mobile ad hoc networks;Throughput;Upper bound;Wireless sensor networks;Wireless networks;FCC;Intelligent sensors},
doi={10.1109/INFCOM.2005.1497914},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497915,
author={Honghai Zhang and J. Hou},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On the critical total power for asymptotic k-connectivity in wireless networks},
year={2005},
volume={1},
number={},
pages={466-476 vol. 1},
abstract={In this paper, we investigate the minimum total power (termed as critical total power) required to ensure asymptotic k-connectivity in heterogeneous wireless networks where nodes may transmit using different levels of power. We show that under the assumption that wireless nodes form a homogeneous Poisson point process with density /spl lambda/ on a unit square region [0, 1]/sup 2/ and the Toroidal model [M.D. Penrose, 1997], the critical total power required for maintaining k-connectivity is /spl theta/((/spl Gamma/(e/2+k))/((k-1)l)/spl lambda//sup 1-e/2/) with probability approaching one as /spl lambda/ goes to infinity, where e is the path loss exponent. Compared with the results that all nodes use a common critical transmission power for maintaining k-connectivity [M.D. Penrose, 1999], [P.-J. Wan and C. Yi, 2004], we show that the critical total power can be reduced by an order of (log /spl lambda/)e/2 by allowing nodes to optimally choose different levels of transmission power. This result is not subject to any specific power/topology control algorithm, but rather a fundamental property in wireless networks.},
keywords={stochastic processes;queueing theory;graph theory;mobile radio;critical total power;asymptotic k-connectivity;heterogeneous wireless network;Poisson point process;Toroidal model;transmission power;stochastic process;queuing theory;graph theory;Intelligent networks;Wireless networks;Energy consumption;Computer science;Region 10;H infinity control;Propagation losses;Network topology;Centralized control;Stochastic processes},
doi={10.1109/INFCOM.2005.1497915},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497916,
author={A. Velayutham and K. Sundaresan and R. Sivakumar},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Non-pipelined relay improves throughput performance of wireless ad-hoc networks},
year={2005},
volume={1},
number={},
pages={477-490 vol. 1},
abstract={The communication model typically assumed in wireless ad-hoc networks is based on a traditional "pipelined relay" (PR} strategy. In PR, an end-to-end flow has multiple outstanding packets (or data units) along the path from the source to the destination. In this paper, we argue that due to several unique properties of wireless ad-hoc networks, PR can be fundamentally improved upon. We present a new non-pipelined relay (nPR) strategy, where end-to-end flows have exactly one outstanding packet (or data unit) along the end-to-end path. We show that nPR has the following properties: (i) under idealized network conditions, it provides performance improvement, in terms of end-to-end throughput capacity and network transport capacity over PR, and achieves proportional fairness; and (ii) under practical network conditions, it further increases the above performance improvements, both in terms of the throughput achieved, and in terms of the fairness between flows. Finally, we present a forwarding protocol that practically realizes nPR. Through analysis and ns2 based packet level simulations, we evaluate the performance of the proposed strategy, and that of the forwarding protocol.},
keywords={pipeline processing;ad hoc networks;protocols;wireless ad-hoc network;communication model;nonpipelined relay strategy;end-to-end flow;network transport capacity;forwarding protocol;Relays;Throughput;Ad hoc networks;Delay;Protocols;Computer networks;Performance analysis;Analytical models;Spread spectrum communication;Interference constraints},
doi={10.1109/INFCOM.2005.1497916},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497917,
author={D. Miorandi and E. Altman},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Coverage and connectivity of ad hoc networks presence of channel randomness},
year={2005},
volume={1},
number={},
pages={491-502 vol. 1},
abstract={In this paper, we present an analytical procedure for the computation of the node isolation probability in an ad hoc network in the presence of channel randomness, with applications to shadowing and fading phenomena. Such a probability coincides with the complement of the coverage probability, given that nodes are distributed according to a Poisson point process. These results are used to obtain an estimate of the connectivity features for very dense networks. For the case of superimposed lognormal shadowing and Rayleigh fading, the connectivity improvements achievable by means of diversity schemes are investigated.},
keywords={ad hoc networks;probability;Rayleigh channels;diversity reception;ad hoc network;channel randomness;node isolation probability;coverage probability;Poisson point process;lognormal shadowing;Rayleigh fading channel;diversity scheme;noisy channel;Ad hoc networks;Intelligent networks;Shadow mapping;Computer networks;Rayleigh channels;Fading;Spread spectrum communication;Packet radio networks;Wireless sensor networks;Radio communication},
doi={10.1109/INFCOM.2005.1497917},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497918,
author={Wensheng Zhang and Guohong Cao},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Group rekeying for filtering false data in sensor networks: a predistribution and local collaboration-based approach},
year={2005},
volume={1},
number={},
pages={503-514 vol. 1},
abstract={When a sensor network is deployed in hostile environments, the adversary may compromise some sensor nodes, and use the compromised nodes to inject false sensing reports or modify the reports sent by other nodes. In order to defend against the attacks with low cost, researchers have proposed symmetric group key-based en-route filtering schemes, such as SEF [F. Ye et al., March 2004] and I-LHAP [S. Zhu et al., 2004]. However, if the adversary has compromised a large number of nodes, many group keys can be captured, and the filtering schemes may become ineffective or even useless. To deal with node compromise, the compromised nodes should be identified and the innocent nodes should update their group keys. Some existing intruder identification schemes can be used to identify the compromised nodes, but most existing group rekeying schemes are not suitable for sensor networks since they have large overhead and are not scalable. To address the problem, we propose a family of predistribution and local collaboration-based group rekeying (PCGR) schemes. These schemes are designed based on the ideas that future group keys can be preloaded to the sensor nodes before deployment, and neighbors can collaborate to protect and appropriately use the preloaded keys. Extensive analyses and simulations are conducted to evaluate the proposed schemes, and the results show that the proposed schemes can achieve a good level of security, outperform most previous group rekeying schemes, and significantly improve the effectiveness of filtering false data.},
keywords={filtering theory;data communication;telecommunication networks;telecommunication security;wireless sensor networks;false data filtering;sensor network;local collaboration-based approach;key-based en-route filtering scheme;compromised node;intruder identification scheme;predistribution and local collaboration-based group rekeying scheme;network security;Filtering;Intelligent networks;Collaboration;Sensor systems;Data security;Monitoring;Computer science;Costs;Protection;Analytical models},
doi={10.1109/INFCOM.2005.1497918},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497919,
author={S. C. -. Huang and Ding-Zhu Du},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={New constructions on broadcast encryption key pre-distribution schemes},
year={2005},
volume={1},
number={},
pages={515-523 vol. 1},
abstract={This paper presents various new techniques on secure group communication schemes. We present a new broadcast encryption scheme RBE, being particularly efficient in multiple revocation, and a node-based key pre-distribution scheme, remedying the key overlapping problem of pool-based schemes. Starting with a detailed analysis on broadcast encryption and group key distribution schemes, we discuss the influence of join as well as the feasibility of including it in broadcast encryption schemes by means of performing full updating or overprovisioning.},
keywords={broadband networks;cryptography;telecommunication security;broadcast encryption;key predistribution scheme;secure group communication scheme;key overlapping problem;pool-based scheme;information theory;Cryptography;Communication system security;Information security;Internet;TV broadcasting;Wireless sensor networks;Performance analysis;Information theory;System analysis and design;IP networks},
doi={10.1109/INFCOM.2005.1497919},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497920,
author={Haowen Chan and A. Perrig},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={PIKE: peer intermediaries for key establishment in sensor networks},
year={2005},
volume={1},
number={},
pages={524-535 vol. 1},
abstract={The establishment of shared cryptographic keys between communicating neighbor nodes in sensor networks is a challenging problem due to the unsuitability of asymmetric key cryptography for these resource-constrained platforms. A range of symmetric-key distribution protocols exist, but these protocols do not scale effectively to large sensor networks. For a given level of security, each protocol incurs a linearly increasing overhead in either communication cost per node or memory per node. We describe peer intermediaries for key establishment (PIKE), a class of key-establishment protocols that involves using one or more sensor nodes as a trusted intermediary to facilitate key establishment. We show that, unlike existing key-establishment protocols, both the communication and memory overheads of PIKE protocols scale sub-linearly (O(/spl radic/n)) with the number of nodes in the network yet achieving higher security against node compromise than other protocols.},
keywords={peer-to-peer computing;cryptography;wireless sensor networks;protocols;telecommunication security;PIKE;peer intermediary;sensor network;asymmetric key cryptography;resource-constrained platform;symmetric-key distribution protocol;peer intermediaries for key establishment protocol;network security;Intelligent networks;Peer to peer computing;Elliptic curve cryptography;Base stations;Cryptographic protocols;Costs;Batteries;Sensor phenomena and characterization;Computer architecture;Energy consumption},
doi={10.1109/INFCOM.2005.1497920},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497921,
author={A. Bremler-Barr and H. Levy},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Spoofing prevention method},
year={2005},
volume={1},
number={},
pages={536-547 vol. 1},
abstract={A new approach for filtering spoofed IP packets, called spoofing prevention method (SPM), is proposed. The method enables routers closer to the destination of a packet to verify the authenticity of the source address of the packet. This stands in contrast to standard ingress filtering which is effective mostly at routers next to the source and is ineffective otherwise. In the proposed method a unique temporal key is associated with each ordered pair of source destination networks (AS's, autonomous systems). Each packet leaving a source network S is tagged with the key K(S, D), associated with (S, D), where D is the destination network. Upon arrival at the destination network the key is verified and removed. Thus the method verifies the authenticity of packets carrying the address s which belongs to network S. An efficient implementation of the method, ensuring not to overload the routers, is presented. The major benefits of the method are the strong incentive it provides to network operators to implement it, and the fact that the method lends itself to stepwise deployment, since it benefits networks deploying the method even if it is implemented only on parts of the Internet. These two properties, not shared by alternative approaches, make it an attractive and viable solution to the packet spoofing problem.},
keywords={Internet;telecommunication security;IP networks;information filtering;telecommunication network routing;spoofing prevention method;spoofed IP packet filtering;temporal key;source destination network;autonomous system;Internet;Telecommunication traffic;Information filtering;Information filters;Scanning probe microscopy;IP networks;Computer hacking;Computer crime;Web and internet services;Law enforcement;Costs},
doi={10.1109/INFCOM.2005.1497921},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497922,
author={M. A. Zafer and E. Modiano},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A calculus approach to minimum energy transmission policies with quality of service guarantees},
year={2005},
volume={1},
number={},
pages={548-559 vol. 1},
abstract={We consider a queueing system with controllable service rate; for example, a transmitter whose rate can be controlled by varying the transmission power. For such a system we obtain optimal data transmission policies that satisfy given quality of service (QoS) constraints and also minimize the total transmission energy expenditure. First, we consider the deterministic case of known arrivals and present a formulation based on a calculus approach using arrival and minimum departure curves. The problem is posed as a continuous time optimization and an optimal solution is obtained for general arrival curves and QoS constraints. In the latter half of the paper, we consider a stochastic arrival process (Poisson process) and a single deadline constraint. The objective is to obtain a transmission policy that minimizes the expected energy expenditure. The problem is formulated as a stochastic optimal control problem and an explicit solution is obtained with some relaxation. Finally, simulation results comparing various policies are presented.},
keywords={calculus of communicating systems;quality of service;queueing theory;telecommunication control;data communication;stochastic processes;optimal control;radio networks;calculus approach;minimum energy transmission policy;quality of service guarantee;queueing system;data transmission policy;QoS constraint;continuous time optimization;stochastic arrival process;Poisson process;single deadline constraint;energy expenditure;stochastic optimal control problem;Calculus;Quality of service;Optimal control;Control systems;Stochastic processes;Wireless sensor networks;Laboratories;Transmitters;Data communication;Constraint optimization},
doi={10.1109/INFCOM.2005.1497922},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497923,
author={S. Alouf and E. Altman and J. Galtier and J. -. Lalande and C. Touati},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Quasi-optimal bandwidth allocation for multi-spot MFTDMA satellites},
year={2005},
volume={1},
number={},
pages={560-571 vol. 1},
abstract={This paper presents an algorithm for resource allocation in satellite networks. It deals with planning a time/frequency plan for a set of terminals with a known geometric configuration under interference constraints. Our objective is to maximize the system throughput while guaranteeing that the different types of demands are satisfied, each type using a different amount of bandwidth. The proposed algorithm relies on two main techniques. The first generates admissible configurations for the interference constraints, whereas the second uses linear and integer programming with column generation. The obtained solution estimates a possible allocation plan with optimality guarantees, and highlights the frequency interferences which degrade the construction of good solutions.},
keywords={bandwidth allocation;time division multiple access;satellite communication;time-frequency analysis;radiofrequency interference;linear programming;integer programming;telecommunication network planning;quasioptimal bandwidth allocation;multispot MFTDMA satellite;resource allocation;satellite network;time-frequency analysis;geometric configuration;interference constraint;integer programming;linear programming;column generation;Channel allocation;Satellites;Interference constraints;Frequency estimation;Resource management;Throughput;Bandwidth;Linear programming;Radio spectrum management;Degradation},
doi={10.1109/INFCOM.2005.1497923},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497924,
author={M. J. Neely},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Energy optimal control for time varying wireless networks},
year={2005},
volume={1},
number={},
pages={572-583 vol. 1},
abstract={We develop a dynamic control strategy for minimizing energy expenditure in a time varying wireless network with adaptive transmission rates. The algorithm operates without knowledge of traffic rates or channel statistics, and yields average power that is arbitrarily close to the minimum possible value achieved by an algorithm optimized with complete knowledge of future events. Proximity to this optimal solution is shown to be inversely proportional to network delay. We then present a similar algorithm that solves the related problem of maximizing network throughput subject to peak and average power constraints. The techniques used in this paper are novel and establish a foundation for stochastic network optimization.},
keywords={optimal control;radio networks;telecommunication control;energy optimal control;time varying wireless network;dynamic control strategy;adaptive transmission rate;network delay;power constraint;stochastic network optimization;Optimal control;Wireless networks;Throughput;Wireless sensor networks;Ad hoc networks;Interference;Adaptive systems;Programmable control;Adaptive control;Communication system traffic control},
doi={10.1109/INFCOM.2005.1497924},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497925,
author={Yunnan Wu and Qian Zhang and Wenwu Zhu and Sun-Yuan Kung},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Bounding the power rate function of wireless ad hoc networks},
year={2005},
volume={1},
number={},
pages={584-595 vol. 1},
abstract={Given a wireless ad hoc network and an end-to-end traffic pattern, the power rate function refers to the minimum total power required to support different throughput under a layered model of wireless networks. A critical notion of the layered model is the realizable graphs, which describe possible hit-rate supplies on the links by the physical and medium access layers. Under the layered model, the problem of finding the power rate function can he transformed into finding the minimum-power realizable graph that can provide a given throughput. We introduce a usage conflict graph to represent the conflicts among different uses of the wireless medium. Testing the realizability of a given graph can be transformed into finding the (vertex) chromatic number, i.e., the minimum number of colors required in a proper vertex-coloring, of the associated usage conflict graph. Based on an upper bound of the chromatic number, we propose a linear program that outputs an upper bound of the power rate function. A lower bound of the chromatic number is the clique number. We propose a systematic way of identifying cliques based on a geometric analysis of the space sharing among active links. This leads to another linear program, which yields a lower bound of the power rate function. We further apply greedy vertex-coloring to fine tune the bounds. Simulations results demonstrate that the obtained bounds are tight in the low power and low rate regime.},
keywords={ad hoc networks;graph theory;linear programming;radio links;greedy algorithms;power rate function;wireless ad hoc network;end-to-end traffic pattern;medium access layer;minimum-power realizable graph;usage conflict graph;chromatic number;clique number;geometric analysis;greedy vertex-coloring;Ad hoc networks;Throughput;Wireless networks;Energy efficiency;Telecommunication traffic;Mobile ad hoc networks;Unicast;Traffic control;Asia;Testing},
doi={10.1109/INFCOM.2005.1497925},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497926,
author={P. B. Godfrey and I. Stoica},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Heterogeneity and load balance in distributed hash tables},
year={2005},
volume={1},
number={},
pages={596-606 vol. 1},
abstract={Existing solutions to balance load in DHTs incur a high overhead either in terms of routing state or in terms of load movement generated by nodes arriving or departing the system. In this paper, we propose a set of general techniques and use them to develop a protocol based on Chord, called Y/sub 0/, that achieves load balancing with minimal overhead under the typical assumption that the load is uniformly distributed in the identifier space. In particular, we prove that Y/sub 0/ can achieve near-optimal load balancing, while moving little load to maintain the balance and increasing the size of the routing tables by at most a constant factor. Using extensive simulations based on real-world and synthetic capacity distributions, we show that Y/sub 0/ reduces the load imbalance of Chord from O(log n) to a less than 3.6 without increasing the number of links that a node needs to maintain. In addition, we study the effect of heterogeneity on both DHTs, demonstrating significantly reduced average route length as node capacities become increasingly heterogeneous. For a real-word distribution of node capacities, the route length in Y/sub 0/ is asymptotically less than half the route length in the case of a homogeneous system.},
keywords={distributed algorithms;routing protocols;heterogeneity effect;distributed hash table;routing state;load movement;network protocol;load balancing;node capacity;homogeneous system;Peer to peer computing;Intrusion detection;Load management;Computer science;Query processing;Identity management systems;Routing protocols;Discrete wavelet transforms;Costs},
doi={10.1109/INFCOM.2005.1497926},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497927,
author={Chun Zhang and Yong Liu and Weibo Gong and J. Kurose and R. Moll and D. Towsley},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On optimal routing with multiple traffic matrices},
year={2005},
volume={1},
number={},
pages={607-618 vol. 1},
abstract={Routing optimization is used to find a set of routes that minimizes cost (delay, utilization). Previous work has addressed this problem for the case of a known, static end-to-end traffic matrix. In the Internet, it is difficult to accurately estimate a traffic matrix, and the constantly changing nature of Internet traffic makes it costly to maintain optimal routing by responding to traffic changes. Thus, it is of interest to maintain a set of routes that are "good" for a number of different possible traffic scenarios. In this paper, we explore ways to find an optimal set of routes with multiple traffic matrices to minimize expected cost. We focus on two general approaches, source-destination routing and destination routing. In the case of source-destination routing, we extend existing methods with a single traffic matrix to solve the optimization problem with multiple traffic matrices: we extend the convex optimization solution methods for a single traffic matrix to the multiple traffic matrix case; we also extend the gradient-based solution methods for a single traffic matrix to the multiple traffic matrix case. However, the multiple traffic matrix case requires many more control variables. In the case of destination routing, we encounter many more differences from the single traffic matrix case. The loop-free property, which is valid for the single traffic matrix case, is no longer valid for the multiple traffic matrix case, and it is difficult to extend existing methods for a single traffic matrix to solve the optimization problem with multiple traffic matrices. We show that it is NP-complete even to determine the feasibility of multiple traffic matrices. We thus propose and evaluate a heuristic algorithm for this case.},
keywords={telecommunication network routing;telecommunication traffic;Internet;gradient methods;optimisation;optimal routing;traffic matrix;routing optimization;Internet traffic;source-destination routing;destination routing;convex optimization;gradient method;NP-complete problem;heuristic algorithm;Routing;Cost function;Internet;Optimization methods;Delay;Computer science;Heuristic algorithms;Multiprotocol label switching;Distributed algorithms;Piecewise linear techniques},
doi={10.1109/INFCOM.2005.1497927},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497928,
author={A. D. Jaggard and V. Ramachandran},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Relating two formal models of path-vector routing},
year={2005},
volume={1},
number={},
pages={619-630 vol. 1},
abstract={This paper unifies two independently developed formalisms for path-vector routing protocols such as the border gateway protocol (BGP), the standard inter-domain routing protocol for the Internet. Sobrinho (2003) and Griffin, Jaggard, and Ramachandran (2003) proved conditions for guaranteed protocol convergence, but as these works operate at different levels of abstraction in modeling the protocols, the relationship between them is not obvious. Here we provide a rigorous translation between these two frameworks and use it to connect the convergence results, yielding a more complete set of analysis tools than in either framework alone. We motivate our discussion by presenting an example of applying both frameworks to analyze a set of protocols; in doing so, we show how the models, in conjunction, give important guidelines for protocol design.},
keywords={routing protocols;Internet;convergence;formal model;path-vector routing protocol;border gateway protocol;inter-domain routing protocol;Internet;protocol convergence;Routing protocols;Convergence;Robustness;Internet;Guidelines;Mathematical model;Mathematics;Standards development;Petroleum;Costs},
doi={10.1109/INFCOM.2005.1497928},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497929,
author={B. Awerbuch and D. Holmer and H. Rubens and R. Kleinberg},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Provably competitive adaptive routing},
year={2005},
volume={1},
number={},
pages={631-641 vol. 1},
abstract={An ad hoc wireless network is an autonomous self-organizing system of mobile nodes connected by wireless links where nodes not in direct range communicate via intermediary nodes. Routing in ad hoc networks is a challenging problem as a result of highly dynamic topology as well as bandwidth and energy constraints. In addition, security is critical in these networks due to the accessibility of the shared wireless medium and the cooperative nature of ad hoc networks. However, none of the existing routing algorithms can withstand a dynamic proactive adversarial attack. The routing protocol presented in this work attempts to provide throughput-competitive route selection against an adaptive adversary. A proof of the convergence time of our algorithm is presented as well as preliminary simulation results.},
keywords={routing protocols;ad hoc networks;mobile radio;convergence;competitive adaptive routing;ad hoc wireless network;autonomous self-organizing system;mobile node;wireless link;intermediary node;dynamic topology;proactive adversarial attack;routing protocol;convergence;Routing protocols;Ad hoc networks;Computer crime;Telecommunication traffic;Wireless networks;Communication system security;Algorithm design and analysis;Testing;Computer science;Organizing},
doi={10.1109/INFCOM.2005.1497929},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497930,
author={A. S. Krishnakumar and P. Krishnan},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On the accuracy of signal strength-based estimation techniques},
year={2005},
volume={1},
number={},
pages={642-650 vol. 1},
abstract={In this paper, we address the problem of finding the inherent uncertainty of signal strength-based location estimation techniques. We propose a mathematical model for mapping uncertainty in signal strength space to uncertainty in physical space. We then analyze this model to compute the minimum value of the uncertainty in location estimation using signal strength measurements. The results of this analysis are used to draw conclusions about the dependence of the minimum uncertainty of various factors such as the signal variance, number of APs, distance between the APs and the propagation constant. We provide an argument linking the minimum uncertainty with a lower limit on the median error in location estimation using classification techniques.},
keywords={signal processing;stochastic processes;radiocommunication;signal strength-based estimation technique;location estimation;signal variance;propagation constant;classification technique;stochastic process;optimization;Uncertainty;Mathematical model;Shadow mapping;Time difference of arrival;Signal mapping;Analysis of variance;Signal analysis;Propagation constant;Joining processes;Process design},
doi={10.1109/INFCOM.2005.1497930},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497931,
author={T. Nadeem and Lucheng Ji and A. Agrawala and J. Agre},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Location enhancement to IEEE 802.11 DCF},
year={2005},
volume={1},
number={},
pages={651-663 vol. 1},
abstract={In this paper, we propose an enhancement to the existing IEEE 802.11 distributed coordination function (DCF) MAC to improve channel spatial reuse efficiency, and thus improve overall network data throughput. Our modification, named the location enhanced DCF (LED) for IEEE 802.11, incorporates location information in DCF frame exchange sequences so that stations sharing the communication channel are able to make better interference predictions and blocking assessments. Utilizing an underlying physical layer design that supports frame capture, the LED enhanced interference estimation can increase overall network data throughput by permitting more concurrent transmissions. In this paper we also analytically study the potential performance enhancement of the LED over the original IEEE 802.11 DCF. The results are verified using the ns-2 simulator, which shows that up to 35% of DCF blocking decisions are unnecessary and our LED method can achieve up to 22% more throughput than the original DCF.},
keywords={wireless LAN;distributed algorithms;access protocols;channel estimation;location enhancement;IEEE 802.11 DCF;distributed coordination function;MAC;channel spatial reuse;location information;communication channel;blocking assessment;interference estimation;concurrent transmission;wireless LAN;Media Access Protocol;Throughput;Light emitting diodes;Interference;Wireless networks;Multiaccess communication;Educational institutions;Communication channels;Access protocols;Computer science},
doi={10.1109/INFCOM.2005.1497931},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497932,
author={C. Tuduce and T. Gross},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A mobility model based on WLAN traces and its validation},
year={2005},
volume={1},
number={},
pages={664-674 vol. 1},
abstract={The simulation of mobile networks calls for a mobility model to generate the trajectories of the mobile users (or nodes). It has been shown that the mobility model has a major influence on the behavior of the system. Therefore, using a realistic mobility model is important if we want to increase the confidence that simulations of mobile systems are meaningful in realistic settings. In this paper we present an executable mobility model that uses real-life mobility characteristics to generate mobility scenarios that can be used for network simulations. We present a structured framework for extracting the mobility characteristics from a WLAN trace, for processing the mobility characteristics to determine a parameter set for the mobility model, and for using a parameter set to generate mobility scenarios for simulations. To derive the parameters of the mobility' model, we measure the mobility' characteristics of users of a campus wireless network. Therefore, we call this model the WLAN mobility model Mobility-analysis confirms properties observed by other research groups. The validation shows that the WLAN model maps the real-world mobility' characteristics to the abstract world of network simulators with a very small error. For users that do not have the possibility to capture a WLAN trace, we explore the value space of the WLAN model parameters and show how different parameters sets influence the mobility of the simulated nodes.},
keywords={mobile radio;wireless LAN;mobile computing;mobile network;structured framework;WLAN trace;mobility characteristics;campus wireless network;WLAN mobility model;mobility analysis;Wireless LAN;Wireless networks;Wide area networks;Computational modeling;Character generation;Space exploration;Network topology;Availability;Wireless application protocol;Laboratories},
doi={10.1109/INFCOM.2005.1497932},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497933,
author={I. Ramani and S. Savage},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={SyncScan: practical fast handoff for 802.11 infrastructure networks},
year={2005},
volume={1},
number={},
pages={675-684 vol. 1},
abstract={Wireless access networks scale by replicating base stations geographically and then allowing mobile clients to seamlessly "hand off" from one station to the next as they traverse the network. However, providing the illusion of continuous connectivity requires selecting the right moment to handoff and the right base station to transfer to. Unfortunately, 802.11-based networks only attempt a handoff when a client's service degrades to a point where connectivity is threatened. Worse, the overhead of scanning for nearby base stations is routinely over 250 ms - during which incoming packets are dropped - far longer than what can be tolerated by highly interactive applications such as voice telephony. In this paper we describe SyncScan, a low-cost technique for continuously tracking nearby base stations by synchronizing short listening periods at the client with periodic transmissions from each base station. We have implemented this SyncScan algorithm using commodity 802.11 hardware and we demonstrate that it allows better handoff decisions and over an order of magnitude improvement in handoff delay. Finally, our approach only requires trivial implementation changes, is incrementally deployable and is completely backward compatible with existing 802.11 standards.},
keywords={wireless LAN;mobile radio;synchronisation;mobile computing;fast handoff;802.11 infrastructure network;wireless access network;voice telephony;low-cost technique;SyncScan algorithm;handoff delay;synchronization;250 ms;Base stations;Computer science;Degradation;Costs;Delay;Network topology;Monitoring;Femtocell networks;Telephony;Hardware},
doi={10.1109/INFCOM.2005.1497933},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497934,
author={N. Barakat and E. H. Sargent},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Dual-header optical burst switching: a new architecture for WDM burst-switched networks},
year={2005},
volume={1},
number={},
pages={685-693 vol. 1},
abstract={In this paper we introduce a new signalling architecture called dual-header optical burst switching (DOBS) for next generation burst-switching optical networks. Using DOBS, the functional offset size of every burst on a given link can be set to the same size without the use of fiber delay line buffers. This allows DOBS to realize lower burst-scheduling complexity, lower ingress delay, higher throughput and better fairness than conventional single-header OBS systems. We present a new burst-scheduling algorithm called free channel queue scheduling that requires only O(1) time to execute and that achieves optimal performance in constant-offset DOBS systems. Using simulation, we find that the blocking probability of a 16-channel DOBS system is 50% lower than that of a similar LAUC-VF JET OBS system. We also show that DOBS achieves better fairness than JET OBS with respect to burst length and with respect to the residual path length of bursts.},
keywords={optical fibre networks;wavelength division multiplexing;telecommunication signalling;telecommunication channels;queueing theory;scheduling;dual-header optical burst switching;WDM burst-switched network;signalling architecture;burst-scheduling complexity;ingress delay;free channel queue scheduling;blocking probability;Optical burst switching;Wavelength division multiplexing;WDM networks;Optical buffering;Throughput;Optical fiber networks;Optical control;Process control;Computer architecture;Next generation networking},
doi={10.1109/INFCOM.2005.1497934},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497935,
author={Zhenghao Zhang and Yuanyuan Yang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={On-line optimal wavelength assignment in WDM networks with shared wavelength converter pool},
year={2005},
volume={1},
number={},
pages={694-705 vol. 1},
abstract={In this paper we study on-line wavelength assignment in wavelength-routed WDM networks under both unicast and multicast traffic. We assume nodes in the networks have wavelength conversion ability. Since wavelength converters are still expensive and difficult to implement, we consider the networks that have only a limited number of converters in each node, and the converters are shared by all input channels at the node. We consider how to set up connections in such networks using as few wavelength converters as possible. For unicast traffic, we first study the problem of setting up a lightpath on a given link path with minimum number of conversions, and give a new algorithm that solves it in O(tk) time, where t is the number of links on the path and k is the number of wavelengths per fiber, as compared to the best known existing algorithm that runs in at least O(t/sup 2/k) time. We also consider the case when nodes have different conversion priorities, and give an O(tk) time algorithm for setting up a lightpath on a given link path while converting wavelength at higher priority nodes only when necessary. We then generalize this technique to WDM networks with arbitrary topologies and present an algorithm that sets up an optimal lightpath network-wide in O(Nk + Lk) time by checking the state of the entire network, where N and L are the number of nodes and links in the network, respectively. For multicast traffic, finding an optimal multicast light-tree is known to be NP-hard and is usually solved by first finding a link tree then finding a light tree on the link tree. Finding a link tree is also NP-hard and has been extensively studied. Thus, we focus on the second problem which is to set up a light tree on a given link tree with minimum number of conversions. We propose a new and more practical multicast conversion model, where the output of the wavelength converter can be split. As can be seen, the new model can save the usage of converters considerably. We first show that this problem is NP-hard and then give efficient heuristics to solve it approximately.},
keywords={wavelength division multiplexing;optical fibre networks;multicast communication;telecommunication traffic;telecommunication network topology;optical wavelength conversion;online optimal wavelength assignment;WDM network;shared wavelength converter pool;multicast traffic;unicast traffic;wavelength conversion;time algorithm;network topology;lightpath network;multicast light-tree;NP-hard problem;multicast conversion model;Wavelength assignment;Intelligent networks;WDM networks;Optical wavelength conversion;Telecommunication traffic;Wavelength converters;Wavelength conversion;Unicast;Multicast algorithms;Optical fiber networks},
doi={10.1109/INFCOM.2005.1497935},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497936,
author={M. Scheutzow and P. Seeling and M. Maier and M. Reisslein},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Multicast capacity of packet-switched ring WDM networks},
year={2005},
volume={1},
number={},
pages={706-717 vol. 1},
abstract={Packet-switched unidirectional and bidirectional ring wavelength division multiplexing (WDM) networks with destination stripping provide an increased capacity due to spatial wavelength reuse. Besides unicast traffic, future destination stripping ring WDM networks also need to support multicast traffic efficiently. In this paper, we provide a probabilistic analysis of the mean hop distances traveled by multicast packet copies on the wavelength channels, and based on the mean hop distances analyze the nominal transmission capacity, reception capacity, and multicast capacity of both unidirectional and bidirectional ring WDM networks with destination stripping. The developed analytical methodology accommodates not only multicast traffic with arbitrary multicast fanout but also unicast and broadcast traffic. In our numerical investigations we examine the impact of number of ring nodes and multicast fanout on the transmission, reception, and multicast capacity of both types of ring networks for different unicast, multicast, and broadcast traffic scenarios and different mixes of unicast and multicast traffic. Our analytical methodology provides a foundation for extended analyses of the multicast capacity of WDM ring networks and enables the evaluation and comparison of future multicast-capable medium access control (MAC) protocols for unidirectional and bidirectional ring WDM networks in terms of transmitter, receiver, and multicast throughput efficiency.},
keywords={multicast communication;packet switching;wavelength division multiplexing;optical fibre networks;telecommunication traffic;probability;channel capacity;multicast capacity;packet-switched ring WDM network;bidirectional network;unidirectional network;wavelength division multiplexing;destination stripping;wavelength reuse;unicast traffic;multicast traffic;probabilistic analysis;mean hop distance;multicast packet;wavelength channel;reception capacity;broadcast traffic;medium access control protocol;WDM networks;Unicast;Telecommunication traffic;Wavelength division multiplexing;Capacity planning;Multicast protocols;Broadcasting;Communication system traffic control;Media Access Protocol;Access protocols},
doi={10.1109/INFCOM.2005.1497936},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497937,
author={Huan Liu and F. A. Tobagi},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Traffic grooming in WDM SONET UPSR rings with multiple line speeds},
year={2005},
volume={1},
number={},
pages={718-729 vol. 1},
abstract={We consider the traffic grooming problem in WDM/SONET UPSR rings with multiple line speeds. This is motivated by the fact that when traffic demands are non-uniform and are spread over a relatively wide range, a ring using multiple line speeds would lead to a lower cost, owing to the economy of scale seen in devices, in particular, electronic ADMs, running at higher speeds. We give a novel integer linear programming (ILP) formulation for the problem. We also propose two techniques to exploit the symmetric problem structure resulting from the equivalency in the line speed assignments and the color assignments for wavelengths. The techniques reduce computation time, thus, allow many problem instances to be solved exactly. For large size problems, we propose efficient heuristic algorithms that achieve a similar cost using a fraction of the computation time. We show that, by allowing WDM/SONET rings to run at different line speeds, we can greatly reduce the ADM cost. We also show that allowing nodes to switch traffic can help to reduce the cost further.},
keywords={telecommunication traffic;wavelength division multiplexing;SONET;integer programming;linear programming;traffic grooming;WDM SONET UPSR ring;line speed;integer linear programming;color assignment;heuristic algorithm;Wavelength division multiplexing;SONET;Costs;Telecommunication traffic;Add-drop multiplexers;Switches;Optical add-drop multiplexers;Optical fiber devices;Economies of scale;Integer linear programming},
doi={10.1109/INFCOM.2005.1497937},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497938,
author={Xin Yu and Z. Kedem},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={A distributed adaptive cache update algorithm for the dynamic source routing protocol},
year={2005},
volume={1},
number={},
pages={730-739 vol. 1},
abstract={On-demand routing protocols use route caches to make routing decisions. Due to mobility, cached routes easily become stale. To address the cache staleness issue, prior work in DSR used heuristics with ad hoc parameters to predict the lifetime of a link or a route. However, heuristics cannot accurately predict timeouts because topology changes are unpredictable. In this paper, we propose to proactively disseminate the broken link information to the nodes that have that link in their caches. We define a new cache structure called a cache table and present a distributed cache update algorithm. Each node maintains in its cache table the information necessary for cache updates. When a link failure is detected, the algorithm notifies all reachable nodes that have cached the link in a distributed manner. The algorithm does not use any ad hoc parameters, thus making route caches fully adaptive to topology changes. We show that the algorithm outperforms DSR with path caches and with Link-MaxLife, an adaptive timeout mechanism for link caches. We conclude that proactive cache updating is the key to the adaptation of on-demand routing protocols to mobility.},
keywords={distributed algorithms;cache storage;routing protocols;telecommunication network topology;mobile communication;radio links;distributed adaptive cache update algorithm;dynamic source routing protocol;ad hoc parameter;network topology;broken link information;cache table;adaptive timeout mechanism;Heuristic algorithms;Routing protocols;Network topology;Delay;Computer science;Mobile ad hoc networks;Telecommunication traffic},
doi={10.1109/INFCOM.2005.1497938},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497939,
author={Shiwen Mao and Y. T. Hou and Xiaolin Cheng and H. D. Sherali and S. F. Midkiff},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Multipath routing for multiple description video in wireless ad hoc networks},
year={2005},
volume={1},
number={},
pages={740-750 vol. 1},
abstract={As developments in wireless ad hoc networks continue, there is an increasing expectation with regard to supporting content-rich multimedia communications (e.g., video) in such networks, in addition to simple data communications. The recent advances in multiple description (MD) video coding have made it highly suitable for multimedia applications in such networks. In this paper, we study the important problem of multipath routing for MD video in wireless ad hoc networks. We follow an application-centric cross-layer approach and formulate an optimal routing problem that minimizes the application layer video distortion. We show that the optimization problem has a highly complex objective function and an exact analytic solution is not obtainable. However, we find that a meta-heuristic approach such as genetic algorithms (GAs) is eminently effective in addressing this type of complex cross-layer optimization problems. We provide a detailed solution procedure for the GA-based approach, as well as a tight lower bound for video distortion. We use numerical results to demonstrate the superior performance of the GA-based approach and compare it to several other approaches. Our efforts in this work provide an important methodology for addressing complex cross-layer optimization problems, particularly those involving application and network layers.},
keywords={telecommunication network routing;ad hoc networks;multimedia communication;genetic algorithms;visual communication;multipath routing;wireless ad hoc network;multimedia communication;data communication;description video coding;application-centric cross-layer approach;application layer video distortion;meta-heuristic approach;genetic algorithm;cross-layer optimization problem;Routing;Intelligent networks;Ad hoc networks;Streaming media;Mobile ad hoc networks;Video coding;Data communication;Decoding;Computer industry;Systems engineering and theory},
doi={10.1109/INFCOM.2005.1497939},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497940,
author={Jian Tang and Guoliang Xue and C. Chandler and Weiyi Zhang},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Interference-aware routing in multihop wireless networks using directional antennas},
year={2005},
volume={1},
number={},
pages={751-760 vol. 1},
abstract={Recent research has shown that interference can make a significant impact on the performance of multihop wireless networks. Researchers have studied interference-aware topology control recently [M. Burkhart et al., 2004]. In this paper, we study routing problems in a multihop wireless network using directional antennas with dynamic traffic. We present new definitions of link and path interference that are suitable for designing better routing algorithms. We then formulate and optimally solve two power constrained minimum interference single path routing problems. Routing along paths found by our interference-aware algorithms tends to have less channel collisions and higher network throughput. Our simulation results show that, compared with the minimum power path routing algorithm, our algorithms can reduce average path interference by 40% or more at the cost of a minor power increase. We also extend our work towards survivable routing by formulating and solving the power constrained minimum interference node-disjoint path routing problem.},
keywords={radiofrequency interference;telecommunication network routing;directive antennas;radio networks;telecommunication traffic;interference-aware routing;multihop wireless network;directional antenna;interference-aware topology control;dynamic traffic;path interference;link interference;channel collision;power path routing algorithm;interference node-disjoint path routing problem;Routing;Spread spectrum communication;Wireless networks;Directional antennas;Interference constraints;Network topology;Communication system traffic control;Algorithm design and analysis;Road accidents;Throughput},
doi={10.1109/INFCOM.2005.1497940},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1497941,
author={Y. T. Hou and Yi Shi and H. D. Sherali and J. E. Wieselthier},
booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.},
title={Online lifetime-centric multicast routing for ad hoc networks with directional antennas},
year={2005},
volume={1},
number={},
pages={761-772 vol. 1},
abstract={We consider a wireless ad hoc network where each node employs a single-beam directional antenna and is provisioned with limited energy. We are interested in an online multicast routing algorithm for successive multicast communication requests with the aim of maximizing network lifetime. The beamforming property associated with single-beam directional antenna introduces some unique problems that do not exist for omnidirectional antennas and therefore significantly increases the design space for routing algorithms. The contributions of this paper are twofold. First, we provide some important theoretical understanding on various multicast problems and deduce that even an offline version of this problem is NP-hard. Second, we develop a highly competitive online heuristic algorithm that takes network lifetime consideration directly into iterative calculations and show that an algorithm designed under this methodology provides consistently better performance than the current state-of-the-art algorithm that takes remaining energy into iterative calculations. The theoretical results and heuristic algorithm in this paper offer some important insights on algorithmic design for energy-constrained wireless ad hoc networks with directional antennas.},
keywords={multicast communication;telecommunication network routing;ad hoc networks;directive antennas;iterative methods;online lifetime-centric multicast routing;directional antenna;wireless ad hoc network;single-beam directional antenna;multicast communication;network lifetime;omnidirectional antenna;NP-hard problem;heuristic algorithm;iterative calculation;Routing;Ad hoc networks;Directional antennas;Iterative algorithms;Multicast algorithms;Algorithm design and analysis;Mobile ad hoc networks;Heuristic algorithms;Iterative methods;Multicast communication},
doi={10.1109/INFCOM.2005.1497941},
ISSN={0743-166X},
month={March},}

