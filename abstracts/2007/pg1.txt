@INPROCEEDINGS{4215591,
author={Y. T. Hou and Y. Shi and H. D. Sherali},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Spectrum Sharing for Multi-Hop Software Defined Radio Networks},
year={2007},
volume={},
number={},
pages={1-9},
abstract={Software defined radio (SDR) capitalizes advances in signal processing and radio technology and is capable of reconfiguring RF and switching to desired frequency bands. It is a frequency-agile data communication device that is vastly more powerful than recently proposed multi-channel multi-radio (MC-MR) technology. In this paper, we investigate the important problem of multi-hop networking with SDR nodes. For such network, each node has a pool of frequency bands (not necessarily of equal size) that can be used for communication. The uneven size of bands in the radio spectrum prompts the need of further division into sub-bands for optimal spectrum sharing. We characterize behaviors and constraints for such multi-hop SDR network from multiple layers, including modeling of spectrum sharing and sub-band division, scheduling and interference constraints, and flow routing. We give a formal mathematical formulation with the objective of minimizing the required network-wide radio spectrum resource for a set of user sessions. Since such problem formulation falls into mixed integer non-linear programming (MINLP), which is NP-hard in general, we develop a lower bound for the objective by relaxing the integer variables and linearization. Subsequently, we develop a near-optimal algorithm to this MINLP problem. This algorithm is based on a novel sequential fixing procedure, where the integer variables are determined iteratively via a sequence of linear programming. Simulation results show that solutions obtained by this algorithm are very close to lower bounds obtained via relaxation, thus suggesting that the solution produced by the algorithm is near-optimal.},
keywords={computational complexity;integer programming;linear programming;nonlinear programming;radio spectrum management;resource allocation;software radio;wireless channels;optimal radio spectrum sharing;multihop software defined radio networks;frequency-agile data communication device;multi channel multi radio technology;network-wide radio spectrum resource minimisation;mixed integer nonlinear programming;NP-hard problem;sequential fixing procedure;linear programming;Spread spectrum communication;Software radio;Signal processing algorithms;Iterative algorithms;Interference constraints;Integer linear programming;Signal processing;Radio frequency;Communication switching;Data communication},
doi={10.1109/INFCOM.2007.9},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215592,
author={M. Fiore and C. Casetti and C. -. Chiasserini},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Efficient Retrieval of User Contents in MANETs},
year={2007},
volume={},
number={},
pages={10-18},
abstract={We consider a cooperative environment in wireless mobile networks where information is exchanged among nodes in a peer-to-peer fashion. We apply a pure peer-to-peer approach (i.e., without the intervention of servers) and we seek to devise an efficient query/response propagation algorithm. Our approach, called <i>Eureka</i>, identifies the regions of the network where the required information is more likely to be stored and steers the queries toward those regions. To discriminate among regions, we introduce the concept of <i>information density</i> and a procedure that allows nodes its estimation. The effectiveness of our scheme is evaluated through simulation in a vehicular environment with realistic mobility models.},
keywords={ad hoc networks;information networks;mobile communication;peer-to-peer computing;user contents retrieval;MANET;wireless mobile networks;information exchange;peer-to-peer fashion;query-response propagation algorithm;Eureka;information density;vehicular environment;mobility models;mobile ad hoc network;Content based retrieval;Peer to peer computing;Mobile ad hoc networks;Network servers;Information retrieval;Bandwidth;Global Positioning System;Communications Society;Wireless communication;Time varying systems},
doi={10.1109/INFCOM.2007.10},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215593,
author={C. Joo and N. B. Shroff},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Performance of Random Access Scheduling Schemes in Multi-Hop Wireless Networks},
year={2007},
volume={},
number={},
pages={19-27},
abstract={The performance of scheduling schemes in multi-hop wireless networks has attracted significant attention in the recent literature. It is well known that optimal scheduling solutions require centralized information and lead to impractical implementations due to their enormous complexity (high-degree polynomial or NP-hard, depending on the interference scenario). Further, multi-hop networks typically require distributed algorithms that operate on local information. Thus, in this paper, we develop a constant-time distributed random access algorithm for scheduling in multi-hop wireless networks. An important feature of this scheme is that it is guaranteed to achieve a fraction (efficiency factor) of the optimal performance. We show that this scheme theoretically achieves a superior efficiency factor as well as numerically achieves a significant performance improvement over the state-of-the-art. Simulation results also confirm that the performance of this scheme is close to a greedy centralized scheme.},
keywords={distributed algorithms;greedy algorithms;radio networks;scheduling;multihop wireless network;constant-time optimal distributed random access scheduling algorithm;greedy centralized scheme;Spread spectrum communication;Wireless networks;Optimal scheduling;Processor scheduling;Interference;Scheduling algorithm;Telecommunication traffic;Traffic control;Routing;Communications Society},
doi={10.1109/INFCOM.2007.11},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215594,
author={P. Djukic and S. Valaee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Link Scheduling for Minimum Delay in Spatial Re-Use TDMA},
year={2007},
volume={},
number={},
pages={28-36},
abstract={Time division multiple access (TDMA) based medium access control (MAC) protocols provide QoS with guaranteed access to wireless channel. However, in multihop wireless networks, these protocols may introduce delay when packets are forwarded from an inbound link to an outbound link on a node. Delay occurs if the outbound link is scheduled to transmit before the inbound link. The total round trip delay can be quite large since it accumulates at every hop in the path. This paper presents a method that finds schedules with minimum round trip scheduling delay. We show that the scheduling delay can be interpreted as a cost collected over a cycle on the conflict graph. We use this observation to formulate a min-max program for the delay across a set of multiple paths. The min-max delay program is NP-complete since the transmission order of links is a vector of binary integer variables. We design heuristics to select appropriate transmission orders. Once the transmission orders are known, a modified Bellman-Ford algorithm is used to find the schedules. The simulation results confirm that the proposed algorithm can find effective min-max delay schedules.},
keywords={delays;quality of service;telecommunication links;time division multiple access;link scheduling;minimum delay;spatial reuse TDMA;time division multiple access;medium access control protocols;QoS;wireless channel access;multihop wireless networks;scheduling delay;min-max delay program;binary integer variables;heuristics;Bellman-Ford algorithm;wireless multihop networks;Time division multiple access;Bandwidth;Access protocols;Media Access Protocol;Wireless application protocol;Scheduling algorithm;Delay effects;Spread spectrum communication;Mesh networks;Communications Society},
doi={10.1109/INFCOM.2007.12},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215595,
author={E. Altman and K. Avrachenkov and G. Miller and B. Prabhu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Discrete Power Control: Cooperative and Non-Cooperative Optimization},
year={2007},
volume={},
number={},
pages={37-45},
abstract={We consider an uplink power control problem where each mobile wishes to maximize its throughput (which depends on the transmission powers of all mobiles) but has a constraint on the average power consumption. A finite number of power levels are available to each mobile. The decision of a mobile to select a particular power level may depend on its channel state. We consider two frameworks concerning the state information of the channels of other mobiles: (i) the case of full state information and (ii) the case of local state information. In each of the two frameworks, we consider both cooperative as well as non-cooperative power control. We manage to characterize the structure of equilibria policies and, more generally, of best-response policies in the non-cooperative case. We present an algorithm to compute equilibria policies in the case of two non-cooperative players. Finally, we study the case where a malicious mobile, which also has average power constraints, tries to jam the communication of the other mobile. Our results are illustrated and validated through various numerical examples.},
keywords={mobile communication;optimisation;power control;telecommunication computing;telecommunication control;discrete power control;optimization;channel state;Power control;Base stations;Throughput;Batteries;Communications Society;Constraint optimization;Energy consumption;Mobile communication;Multiaccess communication;Wireless networks},
doi={10.1109/INFCOM.2007.13},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215596,
author={D. Avidor and S. Mukherjee and F. A. Onat},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Transmit Power Distribution of Wireless Ad Hoc Networks with Topology Control},
year={2007},
volume={},
number={},
pages={46-52},
abstract={We study the impact of several topology control schemes on the transmit power of nodes in a wireless packet data network, where the nodes are randomly distributed over a large area according to a Poisson point process, and the propagation channels are subject to fading. Topology control has been proposed as a technique to improve the performance of multi-hop networks, e.g. ad hoc networks and sensor networks. It amounts to adjusting the transmit power of each node independently so as to optimize certain performance measures, such as throughput, connectivity, lifespan of networks of battery-powered nodes, simplifying the routing algorithms, etc. Many such algorithms use the pattern of immediate neighbors observed by each node as the basis for power adjustment. Most published research on topology control is based on a simplistic radio propagation model, where the area covered by a transmitter is a perfect disk centered at the transmitter. Similarly, the self interference of the network, if considered, is caused only by transmitters located inside such a disk centered at the receiver. With this propagation model, the statistical properties of the communication range are easily derived from the desired number of one-hop neighbors (assuming that the latter is known, and is the only criterion to be satisfied). It is not always trivial to derive the resulting statistical properties of the node transmit power when a certain pattern of neighbors is desired in a fading environment. However, this is the information required when the lifespan of a network of battery-powered devices is of interest. In this paper we calculate the statistical properties of the nodes' transmit power in networks produced by several topology control algorithms, when the propagation channels are subject to fading.},
keywords={ad hoc networks;stochastic processes;telecommunication control;telecommunication network topology;transmit power distribution;wireless ad hoc network;topology control;Poisson point process;propagation channel;multihop network;Power distribution;Mobile ad hoc networks;Network topology;Fading;Radio transmitters;Wireless sensor networks;Spread spectrum communication;Ad hoc networks;Power measurement;Throughput},
doi={10.1109/INFCOM.2007.14},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215597,
author={M. Kodialam and T. V. Lakshman},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Achievable Rate Region for Wireless Systems with Time Varying Channels},
year={2007},
volume={},
number={},
pages={53-61},
abstract={We consider a wireless system comprising of multiple users that communicate with a base station. When there are a large number of users with time varying channels, it has been shown that multiuser diversity can be exploited to achieve high throughput in these systems. In a system employing multiuser diversity, the base station estimates the channel quality for each user during each time slot, and schedules the user with the best channel condition for that time slot. There has been a considerable amount of work towards developing scheduling mechanisms to provide quality of service guarantees to the individual users in addition to maximizing total throughput. In this paper, we consider the achievable rate region of a multiuser TDM system when the average transmit power is bounded. Our objective is to develop efficient algorithms to determine if a given rate vector is achievable within the average power bound. We characterize the achievable rate region when the channel behavior can be approximated by the on-off Gilbert-Elliot channel model. We first show that the problem of determining if a rate vector is achievable can be formulated as a convex optimization problem over a suitably denned polymatroid. We derive optimal waterfilling algorithms for solving the achievable rate region problem.},
keywords={convex programming;multiuser channels;quality of service;scheduling;time division multiplexing;time-varying channels;wireless channels;wireless system;time varying channel;scheduling;quality of service;achievable rate region;multiuser TDM system;Gilbert-Elliot channel;convex optimization;optimal waterfilling algorithm;Time varying systems;Base stations;Time division multiplexing;Throughput;Wireless communication;Communications Society;USA Councils;Quality of service;Power system modeling;Scheduling algorithm},
doi={10.1109/INFCOM.2007.15},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215598,
author={J. Tang and X. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={QoS-Driven Power Allocation Over Parallel Fading Channels With Imperfect Channel Estimations in Wireless Networks},
year={2007},
volume={},
number={},
pages={62-70},
abstract={We propose the quality-of-service (QoS) driven power allocation schemes for parallel fading channels when considering imperfect channel estimations. In particular, the parallel communication model plays a fundamental role in physical-layer evolutions of wireless networks. By integrating information theory with the concept of effective capacity, our proposed schemes aim at maximizing the system throughput subject to a given delay constraint. Solving the original non-convex problem by a 2-dimensional convex optimization approach, we develop the optimal allocation algorithms under different QoS and power constraints. Consistent with our previous work assuming perfect channel state information (CSI), our analyses considering imperfect CSI demonstrate that when the QoS constraint becomes more and more stringent, the optimal effective capacity decreases from the ergodic capacity to the zero-outage capacity. Moreover, our results indicate that the channel estimation error has a significant impact on QoS provisioning, especially when the delay constraint is stringent. Specifically, as long as the channel estimation is not perfect, a positive zero-outage capacity is unattainable. On the other hand, our simulations also suggest that a larger number of parallel channels can provide higher throughput and more stringent QoS, while offering better robustness against the imperfectness of CSI.},
keywords={channel allocation;channel capacity;channel estimation;convex programming;fading channels;quality of service;radio networks;wireless networks;QoS-driven power allocation;quality of service;parallel fading channels;imperfect channel estimation;information theory;2D convex optimization approach;channel state information;zero-outage channel capacity;Fading;Channel estimation;Wireless networks;Throughput;Quality of service;Power system modeling;Information theory;Delay effects;Constraint theory;Constraint optimization},
doi={10.1109/INFCOM.2007.16},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215599,
author={D. Xu and M. Chiang and J. Rexford},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={DEFT: Distributed Exponentially-Weighted Flow Splitting},
year={2007},
volume={},
number={},
pages={71-79},
abstract={Network operators control the flow of traffic through their networks by adapting the configuration of the underlying routing protocols. For example, they tune the integer link weights that interior gateway protocols like OSPF and ISIS use to compute shortest paths. The resulting optimization problem -to find the best link weights for a given topology and traffic matrix -is computationally intractable even for the simplest objective functions, forcing the use of local-search techniques. The optimization problem is difficult in part because these protocols split traffic evenly along shortest paths, with no ability to adjust the splitting percentages or direct traffic on other paths. In this paper, we propose an extension to these protocols, called Distributed Exponentially-weighted Flow SpliTting (DEFT), where the routers can direct traffic on non-shortest paths, with an exponential penalty on longer paths. DEFT leads not only to an easier-to-solve optimization problem, but also to weight settings that provably perform no worse than OSPF and IS-IS. Furthermore, in our optimization problem, both link weights and flows of traffic are integrated as optimization variables into the formulation and jointly solved by a two-stage iterative method. Our novel formulation leads to a much more efficient way to identify good link weights than the local-search heuristics used for OSPF and IS-IS today. DEFT retains the simplicity of having routers compute paths based on configurable link weights, while approaching the performance of more complex routing protocols that can split traffic arbitrarily over any paths.},
keywords={computer network management;internetworking;IP networks;iterative methods;mathematical programming;routing protocols;search problems;telecommunication network topology;telecommunication traffic;distributed exponentially-weighted traffic flow splitting;routing protocol;interior gateway protocol;optimization problem;network topology;local-search technique;shortest path problem;two-stage iterative method;mathematical programming;IP network management;Telecommunication traffic;Communication system traffic control;Routing protocols;Cost function;Design optimization;Network topology;Computer network management;Optimization methods;Computer networks;IP networks},
doi={10.1109/INFCOM.2007.17},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215600,
author={M. Babaioff and J. Chuang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Optimality and Interconnection of Valiant Load-Balancing Networks},
year={2007},
volume={},
number={},
pages={80-88},
abstract={The Valiant Load-Balancing (VLB) design has been proposed for a backbone network architecture that can efficiently provide predictable performance under changing traffic matrices [1]. In this paper we show that the VLB network has <i>optimal</i> performance when nodes can fail, in the sense that it can support the maximal homogeneous flow for any number of node failures. We generalize the VLB design to enable interconnection of multiple VLB networks, and study interconnection via bilateral peering agreements as well as transit agreements. We show that using VLB as a transit scheme yields the lowest possible network and interconnection capacities, while VLB peering can also achieve near-optimal use of capacity.},
keywords={Internet;matrix algebra;resource allocation;telecommunication traffic;valiant load-balancing interconnection network;traffic matrix;node failure;bilateral peering agreement;Internet;maximal homogeneous flow;Telecommunication traffic;Peer to peer computing;Spine;Routing;Robustness;Traffic control;Network topology;Communications Society;IP networks;Internet},
doi={10.1109/INFCOM.2007.18},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215601,
author={P. Francois and M. Shand and O. Bonaventure},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Disruption Free Topology Reconfiguration in OSPF Networks},
year={2007},
volume={},
number={},
pages={89-97},
abstract={A few modifications to software and/or hardware of routers have been proposed recently to avoid the transient micro loops that can occur during the convergence of link-state interior gateway protocols like IS-IS and OSPF. We1 propose in this paper a technique that does not require modifications to ISIS and OSPF, and that can be applied now by ISPs. Roughly, in the case of a manual modification of the state of a link, we progressively change the metric associated with this link to reach the required modification by ensuring that each step of the progression will be loop-free. The number of changes that are applied to a link to reach the targeted state by ensuring the transient consistency of the forwarding inside the network is minimized. Analysis performed on real regional and tier-1 ISP topologies show that the number of required transient changes is small. The solution can be applied in the case of link metric updates, manual set up, and shut down of links.},
keywords={Internet;internetworking;protocols;telecommunication network routing;telecommunication network topology;disruption free topology reconfiguration;OSPF network;network router;link-state interior gateway protocol;Internet service provider;Network topology;Telecommunication traffic;Hardware;Optical fiber networks;Multiprotocol label switching;Routing protocols;Communications Society;Convergence;Intersymbol interference;Performance analysis},
doi={10.1109/INFCOM.2007.19},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215602,
author={A. Kvalbein and T. Cicic and S. Gjessing},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Post-Failure Routing Performance with Multiple Routing Configurations},
year={2007},
volume={},
number={},
pages={98-106},
abstract={The slow convergence of IGP routing protocols after a topology change has led to several proposals for proactive recovery schemes in IP networks. These proposals are limited to guaranteeing loop-free connectivity after a link or node failure, and do not take into account the resulting load distribution in the network. This can lead to congestion and packet drops. In this work, we show how a good load distribution can be achieved in pure IP networks immediately after a link failure, when multiple routing configurations (MRC) is used as a fast recovery mechanism. This paper is the first attempt to improve the load balancing when a proactive recovery scheme is used. Unlike load balancing methods used with normal IP rerouting, our method does not compromise on the routing performance in the failure free case. Our method is evaluated using simulations on several real and synthetically generated network topologies. The evaluation shows that our method yields good routing performance, making it feasible to use MRC to handle transient network failures.},
keywords={failure analysis;IP networks;resource allocation;routing protocols;telecommunication network topology;post-failure routing performance;interior gateway routing protocol;IP network topology;loop-free connectivity;multiple routing configuration;load balancing;Telecommunication traffic;Routing protocols;IP networks;Network topology;Proposals;Load management;Communications Society;Laboratories;Convergence;Peer to peer computing},
doi={10.1109/INFCOM.2007.20},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215603,
author={R. Maheshwari and J. Gao and S. R. Das},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Detecting Wormhole Attacks in Wireless Networks Using Connectivity Information},
year={2007},
volume={},
number={},
pages={107-115},
abstract={We propose a novel algorithm for detecting worm-hole attacks in wireless multi-hop networks. The algorithm uses only connectivity information to look for forbidden substructures in the connectivity graph. The proposed approach is completely localized and, unlike many techniques proposed in literature, does not use any special hardware artifact or location information, making the technique universally applicable. The algorithm is independent of wireless communication models. However, knowledge of the model and node distribution helps estimate a parameter used in the algorithm. We present simulation results for three different communication models and two different node distributions, and show that the algorithm is able to detect wormhole attacks with a 100% detection and 0% false alarm probabilities whenever the network is connected with high probability. Even for very low density networks where chances of disconnection is very high, the detection probability remains very high.},
keywords={graph theory;probability;radio networks;telecommunication network topology;telecommunication security;wormhole attack detection algorithm;wireless multihop networks;connectivity information;forbidden substructures;connectivity graph;wireless communication models;probability;Wireless networks;Peer to peer computing;Wireless sensor networks;Telecommunication traffic;Protocols;Communications Society;Computer science;USA Councils;Spread spectrum communication;Hardware},
doi={10.1109/INFCOM.2007.21},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215604,
author={Z. Chen and C. Ji},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Measuring Network-Aware Worm Spreading Ability},
year={2007},
volume={},
number={},
pages={116-124},
abstract={This work investigates three aspects: (a) a network vulnerability as the non-uniform vulnerable-host distribution, (b) threats, i.e., intelligent worms that exploit such a vulnerability, and (c) defense, i.e., challenges for fighting the threats. We first study five data sets and observe consistent clustered vulnerable-host distributions. We then present a new metric, referred to as the non-uniformity factor, which quantifies the unevenness of a vulnerable-host distribution. This metric is essentially the Renyi information entropy and better characterizes the non-uniformity of a distribution than the Shannon entropy. We then analytically and empirically measure the infection rate and the propagation speed of network-aware worms. We show that a representative network-aware worm can increase the spreading speed by exactly or nearly a non-uniformity factor when compared to a random-scanning worm at the early stage of worm propagation. This implies that when a worm exploits an uneven vulnerable-host distribution as a network-wide vulnerability, the Internet can be infected much more rapidly. Furthermore, we analyze the effectiveness of defense strategies on the spread of network-aware worms. Our results demonstrate that counteracting network-aware worms is a significant challenge for the strategies that include host-based defense and IPv6.},
keywords={entropy;Internet;network-aware worm spreading ability;network vulnerability;Renyi information entropy;Shannon entropy;vulnerable-host distribution;Computer worms;Internet;Communications Society;Electric variables measurement;Computer networks;Distributed computing;Intelligent networks;Information entropy;Velocity measurement;IP networks},
doi={10.1109/INFCOM.2007.22},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215605,
author={N. S. Artan and H. J. Chao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={TriBiCa: Trie Bitmap Content Analyzer for High-Speed Network Intrusion Detection},
year={2007},
volume={},
number={},
pages={125-133},
abstract={Deep packet inspection (DPI) is often used in network intrusion detection and prevention systems (NIDPS), where incoming packet payloads are compared against known attack signatures. Processing every single byte in the incoming packet payload has a very stringent time constraint, e.g., 200 ps for a 40-Gbps line. Traditional DPI systems either need a large memory space or use special memory such as ternary content addressable memory (TCAM), limiting parallelism, or yielding high cost/power consumption. In this paper, we present a highspeed, single-chip DPI scheme that is scalable and configurable through memory updates. The scheme is based on a novel data structure called TriBiCa (trie bitmap content analyzer), which provides minimal perfect hashing functionality. It uses a trie structure with a hash function performed at each layer. Branching is determined by the hashing results with an objective to evenly partition attack signatures into multiple groups at each layer. During a query, as an input traverses the trie, an address to a table in the memory that stores all attack signatures is formed and is used to access the signature for an exact match. Due to the small space required, multiple copies of TriBiCa can be implemented on a single chip to perform pipelining and parallelism simultaneously, thus achieving high throughput. We have designed the TriBiCa on a modest FPGA chip, Xilinx Virtex II Pro, achieving 10-Gbps throughput without using any external memory. A proof-of-concept design is implemented and tested with 1-Gbps packet streams. By using today's state-of-the-art FPGAs, a throughput of 40 Gbps is believed to be achievable.},
keywords={computer networks;data structures;digital signatures;string matching;telecommunication security;high-speed network intrusion detection-prevention system;deep packet inspection;single-chip DPI scheme;trie bitmap content analyzer;TriBiCa-data structure;minimal perfect hashing functionality;attack signature;string matching;High-speed networks;Intrusion detection;Throughput;Payloads;Field programmable gate arrays;Inspection;Time factors;Associative memory;Costs;Energy consumption},
doi={10.1109/INFCOM.2007.23},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215606,
author={L. Huang and X. Nguyen and M. Garofalakis and J. M. Hellerstein and M. I. Jordan and A. D. Joseph and N. Taft},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Communication-Efficient Online Detection of Network-Wide Anomalies},
year={2007},
volume={},
number={},
pages={134-142},
abstract={There has been growing interest in building large-scale distributed monitoring systems for sensor, enterprise, and ISP networks. Recent work has proposed using principal component analysis (PCA) over global traffic matrix statistics to effectively isolate network-wide anomalies. To allow such a PCA-based anomaly detection scheme to scale, we propose a novel approximation scheme that dramatically reduces the burden on the production network. Our scheme avoids the expensive step of centralizing all the data by performing intelligent filtering at the distributed monitors. This filtering reduces monitoring bandwidth overheads, but can result in the anomaly detector making incorrect decisions based on a perturbed view of the global data set. We employ stochastic matrix perturbation theory to bound such errors. Our algorithm selects the filtering parameters at local monitors such that the errors made by the detector are guaranteed to lie below a user-specified upper bound. Our algorithm thus allows network operators to explicitly balance the tradeoff between detection accuracy and the amount of data communicated over the network. In addition, our approach enables real-time detection because we exploit continuous monitoring at the distributed monitors. Experiments with traffic data from Abilene backbone network demonstrate that our methods yield significant communication benefits while simultaneously achieving high detection accuracy.},
keywords={distributed processing;matrix algebra;principal component analysis;security of data;stochastic processes;telecommunication security;communication-efficient online detection;network-wide anomalies;distributed monitoring systems;principal component analysis;anomaly detection;intelligent filtering;stochastic matrix perturbation theory;realtime detection;Abilene backbone network;Monitoring;Filtering;Principal component analysis;Telecommunication traffic;Detectors;Large-scale systems;Sensor systems;Statistical analysis;Statistical distributions;Production},
doi={10.1109/INFCOM.2007.24},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215607,
author={P. Key and L. Massoulie and D. Towsley},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Path Selection and Multipath Congestion Control},
year={2007},
volume={},
number={},
pages={143-151},
abstract={In this paper we investigate the potential benefits of coordinated congestion control for multipath data transfers, and contrast with uncoordinated control. For static random path selections, we show the worst-case throughput performance of uncoordinated control behaves as if each user had but a single path (scaling like log(log(<i>N</i>))/log(<i>N</i>) where <i>N</i> is the system size, measured in number of resources). Whereas coordinated control gives a throughput allocation bounded away from zero, improving on both uncoordinated control and on the greedy-least loaded path selection of e.g. Mitzenmacher. We then allow users to change their set of routes and introduce the notion of a Nash equilibrium. We show that with RTT bias (as in TCP Reno), uncoordinated control can lead to inefficient equilibria. With no RTT bias, both uncoordinated or coordinated Nash equilibria correspond to desirable welfare maximising states. Moreover, simple path reselection polices that shift to paths with higher net benefit can find these states.},
keywords={game theory;telecommunication congestion control;telecommunication network routing;multipath congestion control;multipath data transfer;static random path selection;greedy-least loaded path selection;Nash equilibrium;uncoordinated control;Routing;Throughput;Transport protocols;Communications Society;Communication system control;USA Councils;Size control;Control systems;Size measurement;Nash equilibrium},
doi={10.1109/INFCOM.2007.25},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215608,
author={A. Mondal and A. Kuzmanovic},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={When TCP Friendliness Becomes Harmful},
year={2007},
volume={},
number={},
pages={152-160},
abstract={Short TCP flows may suffer significant response-time performance degradations during network congestion. Unfortunately, this creates an incentive for misbehavior by clients of <i>interactive</i> <i>applications</i> (e.g., gaming, telnet, Web): to send "dummy" packets into the network at a <i>TCP</i>-<i>fair</i> rate even when they have no data to send, thus improving their performance in moments when they do have data to send. Even though no "law" is violated in this way, a large-scale deployment of such an approach has the potential to seriously jeopardize one of the core Internet's principles - <i>statistical</i> <i>multiplexing</i>. We quantify, by means of analytical modeling and simulation, gains achievable by the above misbehavior. Further, we explore techniques that both misbehaving and regular clients can apply to optimize their performance. Our research indicates that easy-to-implement application-level techniques are capable of dramatically reducing incentives for conducting the above transgressions, still without compromising the idea of statistical multiplexing.},
keywords={Internet;statistical multiplexing;telecommunication congestion control;transport protocols;TCP friendliness;TCP flows;network congestion;Internet;statistical multiplexing;Internet;Degradation;Analytical models;Delay;Large-scale systems;Network servers;Communications Society;Mice;Bandwidth;Telecommunication traffic},
doi={10.1109/INFCOM.2007.26},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215609,
author={A. Tang and K. Jacobsson and L. L. H. Andrew and S. H. Low},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Accurate Link Model and Its Application to Stability Analysis of FAST TCP},
year={2007},
volume={},
number={},
pages={161-169},
abstract={This paper presents a link model which captures the queue dynamics when congestion windows of TCP sources change. By considering both the self-clocking and the link integrator effects, the model is a generalization of existing models and is shown to be more accurate by both open loop and closed loop packet level simulations. It reduces to the known static link model when flows' round trip delays are similar, and approximates the standard integrator link model when the heterogeneity of round trip delays is significant. We then apply this model to the stability analysis of FAST TCP. It is shown that FAST TCP flows over a single link are always linearly stable regardless of delay distribution. This result resolves the notable discrepancy between empirical observations and previous theoretical predictions. The analysis highlights the critical role of self-clocking in TCP stability and the scalability of FAST TCP with respect to delay. The proof technique is new and less conservative than the existing ones.},
keywords={delays;queueing theory;telecommunication congestion control;telecommunication links;transport protocols;accurate link model;stability analysis;FAST TCP;queue dynamics;congestion windows;TCP sources;self-clocking;link integrator effects;open loop simulations;closed loop simulations;packet level simulations;static link model;round trip delays;standard integrator link model;proof technique;Stability analysis;Predictive models;Protocols;Delay effects;Traffic control;Upper bound;Size control;Communications Society;Jacobian matrices;USA Councils},
doi={10.1109/INFCOM.2007.27},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215610,
author={B. Blaszczyszyn and M. K. Karray},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Performance Evaluation of Scalable Congestion Control Schemes for Elastic Traffic in Cellular Networks with Power Control},
year={2007},
volume={},
number={},
pages={170-178},
abstract={This paper deals with the performance evaluation of some congestion control schemes for elastic traffic in wireless cellular networks with power allocation/control. These schemes allow us to identify the feasible configurations of instantaneous up-and downlink bit-rates of users; i.e., such that can be obtained by allocating respective powers, taking into account in an exact way the interference created in the whole, multicellular network. We consider the bit-rate configurations identified by these schemes as feasible sets for some classical, maximal fair resource allocation policies, and study their performance in the long-term evolution of the system. Specifically, we assume Markovian arrivals, departures and mobility of customers, which transmit some given data-volumes, as well as some temporal channel variability (fading), and study the mean number of users, the mean throughput i.e., the mean bit-rates, and the mean delay that these policies offer in different parts of a given cell. Explicit formulas are obtained in the case of proportional fair policies, which may or may-not take advantage of the fading, for null or infinitely rapid customer mobility. This approach applies also to a channel shared by the elastic traffic and a streaming, with predefined customer bit-rates, regulated by the respective admission policy.},
keywords={cellular radio;Markov processes;telecommunication congestion control;telecommunication traffic;scalable congestion control;elastic traffic;wireless cellular network;power allocation;power control;bit-rate configuration;Markovian process;temporal channel variability;Communication system traffic control;Land mobile radio cellular systems;Power control;Fading;Geometry;Interference;Traffic control;Throughput;Downlink;Delay},
doi={10.1109/INFCOM.2007.28},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215611,
author={O. Gerstel and G. Sasaki and A. Balasubramanian},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Revenue Focused Protection for VOD in DWDM Rings},
year={2007},
volume={},
number={},
pages={179-187},
abstract={New protection schemes for video on demand (VOD) in a DWDM ring network are proposed that employ information per customer. Unlike prior schemes that rely on fixed priorities, the proposed scheme varies the priority to ensure the system best meets customer expected downtime, thereby ensuring revenues are maximized. The information used to determine current priorities includes <i>failure and revenue statistics</i>. Failure statistics is the number of VOD service interruptions a customer experiences, and revenue statistics is the rate that revenues are generated by a customer. To evaluate the schemes a simple model of traffic and customer behavior is used. They are evaluated over two network resource provisioning scenarios. There are cases when the lost revenue can be reduced from about 20% to zero by using failure and revenue statistics.},
keywords={telecommunication network topology;video on demand;wavelength division multiplexing;revenue focused protection;video on demand;DWDM ring network;revenue statistics;Protection;Wavelength division multiplexing;Statistics;Bandwidth;Telecommunication traffic;Video on demand;USA Councils;Traffic control;Switches;Network servers},
doi={10.1109/INFCOM.2007.29},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215612,
author={O. Turkcu and S. Subramaniam},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Blocking in Reconfigurable Optical Networks},
year={2007},
volume={},
number={},
pages={188-196},
abstract={In this paper, we investigate the blocking performance of all-optical ring and mesh networks with Reconfigurable Optical Add-Drop Multiplexers (ROADMs) and tunable transponders. The ROADMs and transponders together determine the number and set of wavelengths that can be added/dropped leading to a wavelength termination constraint in addition to the well-known wavelength continuity constraint. We develop an analytical model for the blocking probability by accounting for both constraints and validate the model using simulation results. Specifically, a model for computing the blocking probability in a reconfigurable network of arbitrary topology wherein the number and tunability of the transponders are given parameters is presented. It is found that narrowly tunable transponders with a tuning range of about 4 in a 32-wavelength network provides nearly as good a performance as widely tunable transponders (tunable over the entire range of wavelengths), for a wide range of loads and number of transponders. Moreover, waveband assignment to narrowly tunable transponders is found to be a factor in some cases, and we present some results for two different assignment schemes.},
keywords={multiplexing equipment;optical communication equipment;optical fibre networks;probability;telecommunication network topology;transponders;reconfigurable optical networks;all-optical ring networks;mesh networks;reconfigurable optical add-drop multiplexers;tunable transponders;wavelength termination constraint;wavelength continuity constraint;blocking probability;topology;Optical fiber networks;Transponders;Tunable circuits and devices;Analytical models;Optical add-drop multiplexers;Telecommunication traffic;Computer networks;Network topology;Optical filters;Costs},
doi={10.1109/INFCOM.2007.30},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215613,
author={S. R. Mohanty and L. N. Bhuyan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Lexicographic Fairness in WDM Optical Cross-Connects},
year={2007},
volume={},
number={},
pages={197-205},
abstract={We consider fair allocation of sessions at the outputs of optical cross-connects employing wavelength division multiplexing (WDM). Each session consists of traffic on one or more wavelengths (channels). We identify lexicographic fairness as the most appropriate fairness criterion that is relevant to this setting. Achieving a fair lexicographic solution, commonly referred to as lexicographic optimality (LEX), is trivial and polynomial-time computable when any incoming wavelength can be converted to any outgoing wavelength (full conversion). This is not apparent in the practical and realistic case of limited conversion. We prove that LEX is also polynomial-time computable for the limited conversion case by reducing the problem to a min-cost max-flow optimization objective in network flows. We also motivate, formulate and solve a stronger variant of lexicographic optimality that we refer to as worst-case fair lexicographic optimal (W-LEX). Although our effective setting is an optimization problem in bipartite graphs (the request graph is bipartite), the network-flow based algorithms are applicable to unit capacity graphs in general. Further, we provide fast polynomial-time algorithms that furnish solutions for LEX and the W-LEX optimality problems for arbitrary bipartite graphs (i.e. arbitrary wavelength-conversion rules) and are computationally less expensive than network-flow methods. Finally we report simulation results to validate our findings.},
keywords={graph theory;optimisation;wavelength division multiplexing;lexicographic fairness;WDM optical cross-connects;wavelength division multiplexing;worst-case fair lexicographic optimal;optimization problem;bipartite graphs;Wavelength division multiplexing;Throughput;Wavelength conversion;Optical network units;Polynomials;Optical fibers;Optical wavelength conversion;High speed optical techniques;Computer networks;Bipartite graph},
doi={10.1109/INFCOM.2007.31},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215614,
author={Y. Pan and L. Pavel},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Global Convergence of An Iterative Gradient Algorithm for The Nash Equilibrium in An Extended OSNR Game},
year={2007},
volume={},
number={},
pages={206-212},
abstract={This paper considers the problem of optical signal-to-noise ratio (OSNR) optimization with link capacity constraints within a Nash game framework. In optical wavelength-division multiplexed (WDM) networks, all wavelength-multiplexed channels share the optical fiber. Even when individually channel parameters are adjusted, the total launched power has to be limited below the nonlinearity threshold. This can be regarded as the optical link capacity constraint. In the previous work of Pan &amp; Pavel (2005), the authors have proposed an extended OSNR Nash game. Channel utility has been related to OSNR and the status of the optical link has been considered directly in channel cost function. The difficulty is that the unique Nash equilibrium (NE) solution of this OSNR Nash game is highly nonlinear and thus analytically intractable. The main contribution of this paper is to develop an iterative, distributed gradient algorithm towards finding the NE solution. The algorithm uses only local measurements and the current load of the network (or link). The authors proved that the iterative gradient algorithm converges globally to this NE solution under sufficient conditions.},
keywords={channel capacity;convergence of numerical methods;game theory;gradient methods;optical fibre networks;optimisation;wavelength division multiplexing;optical signal-to-noise ratio optimization problem;optical signal-to-noise ratio game;global convergence;Nash equilibrium;optical link capacity constraint;optical wavelength-division multiplexed network;wavelength-multiplexed channel;nonlinearity threshold;channel cost function;iterative distributed gradient algorithm;Convergence;Iterative algorithms;Nash equilibrium;Signal to noise ratio;Optical noise;Fiber nonlinear optics;Wavelength division multiplexing;Optical fiber communication;Nonlinear optics;Constraint optimization},
doi={10.1109/INFCOM.2007.32},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215615,
author={M. J. Neely},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Pricing in a Free Market Wireless Network},
year={2007},
volume={},
number={},
pages={213-221},
abstract={We consider an ad-hoc wireless network operating within a free market economic model. Users send data over a choice of paths, and scheduling and routing decisions are updated dynamically based on time varying channel conditions, user mobility, and current network prices charged by intermediate nodes. Each node sets its own price for relaying services, with the goal of earning revenue that exceeds its time average reception and transmission expenses. We first develop a greedy pricing strategy that maximizes social welfare while ensuring all participants make non-negative profit. We then construct a (non-greedy) policy that balances profits more evenly by optimizing a profit fairness metric. Both algorithms operate in a distributed manner and do not require knowledge of traffic rates or channel statistics. This work demonstrates that individuals can benefit from carrying wireless devices even if they are not interested in their own personal communication.},
keywords={ad hoc networks;greedy algorithms;mobile radio;optimisation;pricing;profitability;scheduling;telecommunication network routing;telecommunication traffic;wireless channels;optimal pricing;ad-hoc wireless network;free market economic model;time varying channel condition;user mobility;scheduling;routing decision;greedy pricing strategy;profit fairness metric;Pricing;Wireless networks;Peer to peer computing;Traffic control;Spread spectrum communication;Costs;Relays;Communication system traffic control;Stochastic processes;Communication system control},
doi={10.1109/INFCOM.2007.33},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215616,
author={J. Zhang and D. Zheng and M. Chiang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={The Impact of Stochastic Noisy Feedback on Distributed Network Utility Maximization},
year={2007},
volume={},
number={},
pages={222-230},
abstract={The implementation of distributed network utility maximization (NUM) algorithms hinges heavily on information feedback through message passing among network elements. In practical systems the feedback is often obtained using error-prone measurement mechanisms and suffers from random errors. There has been little work in this direction, and by and large the impact of noisy feedback remains unclear. A main objective of this study is to fill this void and to obtain a rigorous and systematic understanding of the impact of stochastic noisy feedback. In this paper, we consider distributed NUM in multi-hop wireless networks, and focus on the impact of noisy feedback on the distributed algorithms based on the Lagrangian dual method. These algorithms can in general be regarded as some form of gradient (or sub-gradient) based methods. Assuming strong duality, we study both cases when the stochastic gradients are unbiased or biased, and develop a general theory on the stochastic stability of these algorithms in the presence of noisy feedback. When the gradient estimator is unbiased, we establish, via a combination of the stochastic Lyapunov Stability Theorem and local analysis, that the iterates generated by distributed NUM algorithms converge with probability one to the optimal point, under standard technical conditions. In contrast, when the gradient estimator is biased, we show that the iterates converge to a contraction region around the optimal point, provided that the biased terms are asymptotically bounded by a scaled version of the true gradients. We also investigate the rate of convergence for the unbiased case, and find that, in general, the limit process of the interpolated process corresponding to the normalized iterate sequence is a stationary reflected linear diffusion process, not necessarily a Gaussian diffusion process. We also apply the above general theory to investigate stability of cross-layer rate control for joint congestion control and random access. Our numerical examples corroborate the theoretic findings well.},
keywords={convergence;distributed algorithms;duality (mathematics);gradient methods;Lyapunov methods;message passing;probability;radio networks;stability;stochastic processes;telecommunication congestion control;telecommunication network management;utility theory;stochastic noisy feedback;distributed network utility maximization algorithm;message passing;error-prone measurement mechanism;multihop wireless networks;Lagrangian dual method;gradient estimator method;stochastic Lyapunov stability;convergence probability;joint congestion control;distributed algorithm;Stochastic processes;Feedback;Utility programs;Stability;Diffusion processes;Fasteners;Message passing;Stochastic systems;Spread spectrum communication;Wireless networks},
doi={10.1109/INFCOM.2007.34},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215617,
author={Z. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Min-Cost Multicast of Selfish Information Flows},
year={2007},
volume={},
number={},
pages={231-239},
abstract={We study multicast in a non-cooperative environment where information flows selfishly route themselves through the cheapest paths available. The main challenge is to enforce such selfish multicast flows to stabilize at a socially optimal operating point incurring minimum total edge cost, through appropriate cost allocation and other economic measures, with replicable and encodable properties of information flows considered. We show that known cost allocation schemes are not sufficient. We provide a shadow-price based cost allocation for networks without capacity limits, and show it enforces minimum-cost multicast. This improves previous result where a 2-approximate multicast flow is enforced. For capacitied networks, computing cost allocation by ignoring edge capacities will not yield correct results. We show that an edge tax scheme can be combined with a cost allocation to strictly enforce optimal multicast flows in this more realistic case. If taxes are not desirable, they can be returned to flows while maintaining weak enforcement of the optimal flow. We relate the taxes to VCG payment schemes and discuss an efficient primal-dual algorithm that simultaneously computes the taxes, the cost allocation, and the optimal multicast flow.},
keywords={game theory;graph theory;minimisation;multicast communication;telecommunication network routing;selfish multicast information flow;shadow-price based cost allocation;minimum-cost multicast;capacitied network;graph theory;network routing;game theory;Cost function;Routing;Environmental economics;Computer networks;Finance;Game theory;Network topology;Network coding;Nash equilibrium;Multicast algorithms},
doi={10.1109/INFCOM.2007.35},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215618,
author={S. Majumdar and D. Kulkarni and C. V. Ravishankar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Addressing Click Fraud in Content Delivery Systems},
year={2007},
volume={},
number={},
pages={240-248},
abstract={Mechanisms for data access and payment are central to the success of content delivery systems. However, not much attention has been paid to the issues of dishonest intermediaries (brokers) or client collusion with dishonest brokers. We propose protocols to verify broker honesty for data accesses under standard security assumptions in such systems. Analytical and experimental results show that our protocols are robust against replay and fabrication attacks, and are consistently able to identify broker dishonesty.},
keywords={content management;fraud;information retrieval;protocols;security of data;content delivery system;data access;dishonest broker;client collusion;protocols;standard security assumption;payment scheme;Access protocols;Communications Society;Data security;Robustness;Fabrication;Stock markets;Web and internet services;Web server;Quality management;Subscriptions},
doi={10.1109/INFCOM.2007.36},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215619,
author={R. Zheng and R. Barton},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Toward Optimal Data Aggregation in Random Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={249-257},
abstract={Data gathering is one of the most important services provided by wireless sensor networks (WSNs). Since the predominant traffic pattern in data gathering services is many-to-one communication, it is critical to understand the limitations of many-to-one information flows and devise efficient data aggregation protocols to support prolonged operations in WSNs. In this paper, we provide a theoretical characterization of data aggregation processes under different communication modalities in WSNs. We demonstrate that data aggregation rates of Theta(log(n)/n) and Theta(1) are optimal when operating in fading environments with power path-loss exponents that satisfy 2 &lt; alpha &lt; 4 and alpha &gt; 4, respectively. Furthermore, the optimal rate can be achieved using a generalization of cooperative beam-forming called cooperative time-reversal communication. In contrast, the non-cooperative multihop relay strategies widely adopted in literature are shown to be suboptimal in the low-to-medium attenuation regime (for 2 &lt; alpha &lt; 4).},
keywords={telecommunication traffic;wireless sensor networks;optimal data aggregation protocol;random wireless sensor network;data gathering;fading environment;cooperative time-reversal communication;cooperative beam-forming;noncooperative multihop relay strategy;low-to-medium attenuation regime;Wireless sensor networks;Relays;Protocols;Telecommunication traffic;Unicast;Wireless networks;Upper bound;Topology;Communications Society;Computer science},
doi={10.1109/INFCOM.2007.37},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215620,
author={R. Cohen and B. Kapchits},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Optimal Algorithm for Minimizing Energy Consumption while Limiting Maximum Delay in a Mesh Sensor Network},
year={2007},
volume={},
number={},
pages={258-266},
abstract={This paper presents an algorithm for maximizing the lifetime of a sensor network while guaranteeing an upper bound on the end-to-end delay. We prove that the proposed algorithm is optimal, and that it requires simple computing operations that can be implemented by simple devices. To the best of our knowledge, this is the first paper to propose a sensor wake-up frequency that depends on the sensor's location in the routing paths. Using simulations, we show that the proposed algorithm significantly increases the lifetime of the network, while guaranteeing maximum end-to-end delay.},
keywords={telecommunication network routing;telecommunication network topology;wireless sensor networks;mesh sensor network topology;energy consumption minimization;maximum end-to-end delay;optimal energy-aware routing algorithm;Energy consumption;Routing;Frequency synchronization;Communications Society;Computer science;Upper bound;Computational modeling;Peer to peer computing;Hardware;Mesh networks},
doi={10.1109/INFCOM.2007.38},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215621,
author={J. Zhu and S. Chen and B. Bensaou and K. -. Hung},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Tradeoff Between Lifetime and Rate Allocation in Wireless Sensor Networks: A Cross Layer Approach},
year={2007},
volume={},
number={},
pages={267-275},
abstract={This paper studies the tradeoff between energy consumption and application performance in wireless sensor networks by investigating the interaction between network lifetime maximization and rate allocation problems. To guarantee the individual performance of sensor nodes, we adopt the network utility maximization (NUM) framework to ensure certain fairness on source rates of sensor nodes. We formulate the network lifetime maximization problem and fair rate allocation problem as constrained maximization problems, and combine them by introducing a system parameter, which characterizes the tradeoff between the two problems. Using Lagrange dual decomposition, the original problem is vertically decomposed into three subproblems: a rate control problem at the transport layer, a contention resolution problem at the MAC Layer, and a cross-layer energy conservation problem. The first and second subproblems jointly solve the congestion problem in sensor networks via congestion prices, and fully distributed algorithms are derived. Furthermore, they are coupled with the cross layer energy conservation problem to solve the network lifetime maximization problem via energy prices. For the third subproblem, we first propose a partially distributed algorithm where network lifetime is a global information, and then by exploring the similarity between max-min rate allocation and network lifetime maximization in sensor networks, we approximate the latter by the NUM framework, and hence formulate the tradeoff problem in the unified NUM framework. As a result, a fully distributed algorithm is derived for the energy conservation problem.},
keywords={distributed algorithms;optimisation;resource allocation;telecommunication congestion control;wireless sensor networks;network lifetime maximization problem;wireless sensor networks;energy consumption;network utility maximization;NUM framework;fair rate allocation problem;constrained maximization problems;Lagrange dual decomposition;rate control problem;transport layer;contention resolution problem;MAC layer;cross-layer energy conservation problem;congestion problem;partially distributed algorithms;max-min rate allocation;fully distributed algorithm;Wireless sensor networks;Cross layer design;Energy conservation;Batteries;Distributed algorithms;Sensor phenomena and characterization;Peer to peer computing;Utility programs;Delay;Resource management},
doi={10.1109/INFCOM.2007.39},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215622,
author={M. Rossi and N. Bui and M. Zorzi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Cost and Collision Minimizing Forwarding Schemes for Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={276-284},
abstract={The paper presents a novel integrated MAC/routing scheme for wireless sensor networking. Our design objective is to elect the next hop for data forwarding by minimizing the number of messages and, at the same time, maximizing the probability of electing the best candidate node. To this aim, we represent the suitability of a node to act as the relay by means of locally calculated and generic cost metrics. Based on these costs, we analytically model the access selection problem through dynamic programming techniques thereby devising the optimal access policy. We subsequently derive a contention-based MAC and forwarding scheme, named cost and collision minimizing routing (CCMR). Both analytical and simulation results are given to demonstrate the effectiveness of our technique by comparing its performance against state of the art solutions.},
keywords={access protocols;dynamic programming;minimisation;probability;telecommunication congestion control;telecommunication network routing;wireless sensor networks;collision minimizing data forwarding scheme;wireless sensor network;integrated contention-based MAC/routing scheme;probability maximization;optimal access selection problem;dynamic programming technique;cost minimization;Wireless sensor networks;Routing;Relays;Peer to peer computing;Nominations and elections;Cost function;Energy consumption;Topology;Communications Society;Dynamic programming},
doi={10.1109/INFCOM.2007.40},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215623,
author={Y. -. Nam and P. K. Gopala and H. El-Gamal},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Resolving Collisions Via Incremental Redundancy: ARQ Diversity},
year={2007},
volume={},
number={},
pages={285-293},
abstract={A cross-layer approach is adopted for the design of finite-user symmetric random access wireless systems. Instead of the traditional collision model, a more realistic physical layer model is adopted. An incremental redundancy automatic repeat request (IR-ARQ) scheme, tailored to jointly combat the effects of user collisions, multi-path fading, and channel noise, is proposed. The diversity-multiplexing-delay tradeoff of the proposed scheme is analyzed for fully-loaded queues, and compared with that of the Gallager tree algorithm for collision resolution and the network-assisted diversity multiple access (NDMA) protocol of Tsatsanis et at.. The fully-loaded queue model is then replaced by one with random arrivals, where the three protocols are compared in terms of the stability region and average delay. Overall, our analytical and numerical results establish the superiority of the proposed IR-ARQ scheme and reveal some important insights. For example, it turns out that the performance is optimized, for a given total throughput, by maximizing the probability that a certain user will send a new packet and minimizing the transmission rate employed by each user.},
keywords={access protocols;automatic repeat request;fading channels;multi-access systems;multipath channels;multiplexing;queueing theory;radio access networks;ARQ diversity;cross-layer approach;finite-user symmetric random access wireless system;incremental redundancy automatic repeat request;multipath fading;channel noise;diversity-multiplexing-delay tradeoff;fully-loaded queues;collision resolution;network-assisted diversity multiple access protocol;Automatic repeat request;Access protocols;Base stations;Physical layer;Throughput;Decoding;Fading;Cultural differences;Queueing analysis;Stability},
doi={10.1109/INFCOM.2007.41},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215624,
author={Y. Yi and G. de Veciana and S. Shakkottai},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Optimal MAC Scheduling With Physical Interference},
year={2007},
volume={},
number={},
pages={294-302},
abstract={We propose a general family of MAC scheduling algorithms that achieve any rate-point on a uniform discrete-lattice within the throughput-region (i.e., lattice-throughput-optimal) under a physical interference model. Under the physical interference model, a centralized algorithm requires information on node locations (and distance among nodes) to determine a schedule that is provably throughput-optimal. In this paper, we propose a distributed, synchronous contention-based scheduling algorithm that (i) is lattice-throughput-optimal, (ii) does not require node location information, and (iii) has a signaling complexity that does not depend on network size. Thus, it is amenable to simple implementation, and is robust to network dynamics such as topology and load changes.},
keywords={access protocols;ad hoc networks;interference (signal);scheduling;telecommunication signalling;optimal MAC scheduling algorithms;uniform discrete-lattice;throughput-region;physical interference model;node locations;synchronous contention-based scheduling algorithm;lattice-throughput-optimal;signaling complexity;Interference;Scheduling algorithm;Throughput;Optimal scheduling;Peer to peer computing;Network topology;Aggregates;Switches;Telecommunication traffic;Communications Society},
doi={10.1109/INFCOM.2007.42},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215625,
author={K. Sundaresan and R. Sivakumar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Cooperating with Smartness: Using Heterogeneous Smart Antennas in Ad-Hoc Networks},
year={2007},
volume={},
number={},
pages={303-311},
abstract={The ability of smart antennas to improve performance in a typically constrained ad-hoc network environment, has helped them garner significant attention over the last few years. However, not much light has been shed on wireless ad-hoc networks that have nodes with varying antenna capabilities. While homogeneous ad-hoc networks with all nodes having the same antenna capabilities will have certain applications, we argue that ad-hoc networks with nodes having heterogeneous antenna capabilities are more likely to be the norm due to a variety of motivating factors. In the context of such heterogeneous smart antenna networks (HSANs), we investigate and motivate the need for a simple form of node cooperation called retransmit diversity. We show that while such a simple form of node cooperation cannot bring significant benefits to homogeneous omni-directional and smart antenna networks, they can bring several folds improvement to heterogeneous smart antenna networks. We then present several key properties pertaining to node cooperation in HSANs. In the process, we identify a fundamental trade-off between exploiting smart antenna gain and cooperation gain, that undermines the ability of HSANs to leverage node cooperation to their maximum potential. To address this tradeoff, we then present an adaptive cooperation mechanism and incorporate this mechanism through the design of a simple but efficient MAC protocol. The performance of the MAC protocol is evaluated through <sub>ns</sub>2 simulations.},
keywords={access protocols;ad hoc networks;adaptive antenna arrays;heterogeneous smart antenna;wireless ad-hoc network;retransmit diversity;adaptive cooperation mechanism;MAC protocol;Ad hoc networks;Peer to peer computing;Media Access Protocol;Mesh networks;Communication system traffic control;Performance gain;Computer networks;Wireless networks;Communications Society;Environmental economics},
doi={10.1109/INFCOM.2007.43},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215626,
author={A. Sheth and S. Nedevschi and R. Patra and S. Surana and E. Brewer and L. Subramanian},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Packet Loss Characterization in WiFi-Based Long Distance Networks},
year={2007},
volume={},
number={},
pages={312-320},
abstract={Despite the increasing number of WiFi-based Long Distance (WiLD) network deployments, there is a lack of understanding of how WiLD networks perform in practice. In this paper, we perform a systematic study to investigate the commonly cited sources of packet loss induced by the wireless channel and by the 802.11 MAC protocol. The channel induced losses that we study are external WiFi, non-WiFi and multipath interference. The protocol induced losses that we study are protocol timeouts and the breakdown of CSMA over WiLD links. Our results are based on measurements performed on two real-world WiLD deployments and a wireless channel emulator. The two deployments allow us to compare measurements across rural and urban settings. The channel emulator allows us to study each source of packet loss in isolation in a controlled environment. Based on our experiments we observe that the presence of external WiFi interference leads to significant amount of packet loss in WiLD links. In addition to identifying the sources of packet loss, we analyze the loss variability across time. We also explore the solution space and propose a range of MAC and network layer adaptation algorithms to mitigate the channel and protocol induced losses. The key lessons from this study were also used in the design of a TDMA based MAC protocol for high performance long distance multihop wireless networks [12].},
keywords={access protocols;multipath channels;radio links;wireless channels;wireless LAN;packet loss characterization;WiFi-based long distance network;multipath interference;802.11 MAC protocol;CSMA;WiLD link;wireless channel emulator;TDMA;multihop wireless network;Media Access Protocol;Wireless application protocol;Interference;Space exploration;Electric breakdown;Multiaccess communication;Performance evaluation;Time division multiple access;Spread spectrum communication;Wireless networks},
doi={10.1109/INFCOM.2007.44},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215627,
author={L. Yuan and K. Kant and P. Mohapatra and C. -. Chuah},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Proxy View of Quality of Domain Name Service},
year={2007},
volume={},
number={},
pages={321-329},
abstract={The domain name system (DNS) provides a critical service for the Internet -mapping of user-friendly domain names to their respective IP addresses. Yet, there is no standard set of metrics quantifying the quality of domain name service or QoDNS, let alone a thorough evaluation of it. This paper attempts to fill this gap from the perspective of a DNS proxy/cache, which is the bridge between clients and authoritative servers. We present an analytical model of DNS proxy operations that offers insights into the design tradeoffs of DNS infrastructure and the selection of critical DNS parameters. After validating our model against simulation results, we extend it to study the impact of DNS cache poisoning attacks and evaluate various DNS proposals with respect to the QoDNS metrics. In particular, we compare the performance of two newly proposed DNS security solutions: one based on cryptography and one using collaborative overlays.},
keywords={cache storage;client-server systems;cryptography;Internet;quality of service;telecommunication security;domain name service quality;domain name system;QoDNS metrics;Internet;client-server system;DNS infrastructure design tradeoffs;DNS proxy operations;DNS cache poisoning attacks;DNS security solutions;cryptography;collaborative overlays;Computer crime;Analytical models;Peer to peer computing;Domain Name System;Security;Cryptography;Public key;Delay;Communications Society;Web and internet services},
doi={10.1109/INFCOM.2007.45},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215628,
author={G. Shrimali and A. Akella and A. Mutapcic},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Cooperative Inter-Domain Traffic Engineering Using Nash Bargaining and Decomposition},
year={2007},
volume={},
number={},
pages={330-338},
abstract={We present a new inter-domain traffic engineering protocol based on the concepts of Nash bargaining and dual decomposition. Under this scheme, ISPs use an iterative procedure to jointly optimize a social cost function, referred to as the Nash product. We show that the global optimization problem can be separated into sub-problems by introducing appropriate shadow prices on the inter-domain flows. These sub-problems can then be solved independently and in a decentralized manner by the individual ISPs. Our approach does not require the ISPs to share any sensitive internal information (such as network topology or link weights). More importantly, our approach is provably Pareto-efficient and fair. Therefore, we believe that our approach is highly amenable to adoption by ISPs when compared to past naive approaches. We conduct simulation studies of our approach over several real ISP topologies. Our evaluation shows that the approach converges quickly, offers equitable performance improvements to ISPs, is significantly better than unilateral approaches (e.g. hot potato routing) and offers the same performance as a centralized solution with full knowledge.},
keywords={computer network management;decision theory;game theory;Internet;iterative methods;Pareto optimisation;protocols;telecommunication network routing;telecommunication network topology;telecommunication traffic;cooperative inter-domain traffic engineering protocol;Nash bargaining;dual decomposition;ISP;iterative procedure;global pareto optimization;network topology;network link weight;Internet service provider;game theory;Tellurium;Communication system traffic control;Protocols;Telecommunication traffic;Network topology;Routing;Communications Society;Cost function;Service oriented architecture;Performance gain},
doi={10.1109/INFCOM.2007.46},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215629,
author={Y. Zhang and Z. M. Mao and J. Wang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Framework for Measuring and Predicting the Impact of Routing Changes},
year={2007},
volume={},
number={},
pages={339-347},
abstract={Routing dynamics heavily influence Internet data plane performance. Existing studies only narrowly focused on a few destinations and did not consider the predictability of the impact of routing changes on performance metrics such as reachability. In this work, we propose an efficient framework to capture coarse-grained but important performance degradation as a result of BGP routing events using light-weight probing. We deployed our framework across six vantage points for 11 weeks and found that the data plane experienced serious performance degradation in the form of reachability loss and forwarding loops following a significant fraction of updates affecting many destination prefixes and networks across all vantage points studied. Specifically, more than 39% of updates resulted in reachability loss, some lasting for more than 300 seconds, impacting more than 72% of probed prefixes and more than 35% of all the prefixes on the Internet. We identified that more than half of the prefixes have predictable routing behavior. Based on the stationarity of the correlation between routing changes and the data plane performance, we developed a model to accurately predict the severity of the impact due to routing changes. Such a model is directly helpful for making informed decisions for improved routing schemes such as overlay routing and backup path selection.},
keywords={Internet;telecommunication network routing;routing dynamics;Internet data plane performance;BGP routing event;reachability loss;Routing;Degradation;Predictive models;Performance loss;Delay;Convergence;Communications Society;Loss measurement;Internet telephony;Stability},
doi={10.1109/INFCOM.2007.47},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215630,
author={L. Wang and M. Saranu and J. M. Gottlieb and D. Pei},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Understanding BGP Session Failures in a Large ISP},
year={2007},
volume={},
number={},
pages={348-356},
abstract={The current global Internet routing frequently suffers from cascading routing changes and slow routing convergence. Such instability can significantly affect the performance of real-time Internet applications such as VoIP, multimedia conferencing and online gaming. One major cause of routing instability is the failure of BGP peering sessions, but there has been little understanding of the factors that contribute to the failures of operational BGP sessions. In this paper, we present a systematic study on the failures of a few hundred BGP sessions using data collected in a tier-1 ISP network over a 9-month period. We first quantify the impact of the session failures on both the control plane and the data plane. We then use syslog events to identify the direct triggers of session failures. Furthermore, we use several heuristics, including link failure information, session down time and traffic level, to identify the root problems that led to these session failures. We found that the major root causes are administrative session resets and link failures, each contributing to 46.1% and 30.4% of the observed session failures.},
keywords={Internet;routing protocols;telecommunication network reliability;telecommunication traffic;BGP peering session failure;Internet service provider;global Internet routing;VoIP;multimedia conferencing;online gaming;network traffic level;routing protocol;Failure analysis;Computer science;Internet;Convergence;Communications Society;Application software;Communication system traffic control;Streaming media;Routing protocols;Stability},
doi={10.1109/INFCOM.2007.48},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215631,
author={M. Garetto and P. Giaccone and E. Leonardi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Capacity of Ad Hoc Wireless Networks Under General Node Mobility},
year={2007},
volume={},
number={},
pages={357-365},
abstract={We revisit the problem of characterizing the capacity of an ad hoc wireless network with n mobile nodes. Grossglauser and Tse (2001) showed that, by exploiting user mobility, it is possible to maintain a constant per-node throughput as the number of nodes grows. Their scheme allows to overcome the throughput decay (at least as 1/radicn) that affects networks with static nodes, which was first pointed out by Gupta and Kumar (2000). Subsequent works have analyzed the delay-capacity trade-off that arises in mobile networks under various mobility models. Almost invariably, however, available asymptotic results strongly rely on the assumption that nodes are identical, and move according to some ergodic process that is equally likely to visit any portion of the network area. In this paper, we relax such 'homogeneous mixing' assumption on the node mobility process, and analyze the network capacity in the more realistic case in which nodes are heterogeneous, and the motion of a node does not necessarily cover uniformly the entire space. We propose a general framework to characterize the capacity of networks with arbitrary mobility patterns, considering both the case of finite number of nodes (also with the support of experimental traces), as well as asymptotic results when the number of nodes grows to infinity.},
keywords={ad hoc networks;mobile radio;ad hoc wireless network;delay-capacity trade-off;mobile network;ergodic process;arbitrary mobility pattern;Wireless networks;Peer to peer computing;Throughput;Communications Society;Motion analysis;H infinity control;Mobile communication;Optimal scheduling;Anisotropic magnetoresistance;Delay},
doi={10.1109/INFCOM.2007.49},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215632,
author={S. C. -. Huang and P. -. Wan and C. T. Vu and Y. Li and F. Yao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Nearly Constant Approximation for Data Aggregation Scheduling in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={366-372},
abstract={Data aggregation is a fundamental yet time-consuming task in wireless sensor networks. We focus on the latency part of data aggregation. Previously, the data aggregation algorithm of least latency [1] has a latency bound of (Delta - 1)<i>R</i>, where Delta is the maximum degree and R is the network radius. Since both Delta and <i>R</i> could be of the same order of the network size, this algorithm can still have a rather high latency. In this paper, we designed an algorithm based on maximal independent sets which has an latency bound of 23<i>R</i> + Delta - 18. Here Delta contributes to an additive factor instead of a multiplicative one; thus our algorithm is nearly constant approximation and it has a significantly less latency bound than earlier algorithms especially when Delta is large.},
keywords={approximation theory;scheduling;set theory;wireless sensor networks;wireless sensor network;data aggregation scheduling algorithm;maximal independent set;constant approximation;Wireless sensor networks;Delay;Algorithm design and analysis;Approximation algorithms;Broadcasting;Computer science;Base stations;Heuristic algorithms;Scheduling;Communications Society},
doi={10.1109/INFCOM.2007.50},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215633,
author={F. De Pellegrini and D. Miorandi and I. Carreras and I. Chlamtac},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Graph-Based Model for Disconnected Ad Hoc Networks},
year={2007},
volume={},
number={},
pages={373-381},
abstract={Recently, research on disconnected networks has been fostered by several studies on delay-tolerant networks, which are designed in order to sustain disconnected operations. We focus on the emerging notion of connectivity which exists in such networks, where the message exchange between nodes is enforced by leveraging storage capabilities at intermediate relays, with the aim of achieving connectivity over time. The problem, under the constraint of intermittent connectivity, is hence to devise efficient mechanisms for message delivery, and evaluate the performance thereof. In this paper, we introduce a graph-based model able to capture the evolution of the connectivity properties of such systems over time. We show that, for most networks of interest, such connectivity graphs can be modeled as Erdos-Renyi random graphs. Furthermore, we show that, under a uniformity assumption, the time taken for the connectivity graph to become connected scales as Theta((n log n)/lambda) with the number of nodes in the network. Hence we found that, using epidemic routing techniques, message delay is O((n log<sup>2</sup> n)/(lambda log log n)). The model is validated by numerical simulations and by a comparison with the connectivity patterns emerging from real experiments.},
keywords={ad hoc networks;communication complexity;graph theory;telecommunication network routing;graph-based model;disconnected ad hoc networks;delay-tolerant networks;network connectivity;message delivery;connectivity graphs;Erdos-Renyi random graphs;epidemic routing techniques;message delay;Ad hoc networks;Disruption tolerant networking;Delay;Peer to peer computing;Routing;Satellite broadcasting;Network topology;Resilience;Erbium;Communications Society},
doi={10.1109/INFCOM.2007.51},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215634,
author={A. Ozgur and O. Leveque and D. Tse},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Hierarchical Cooperation Achieves Linear Capacity Scaling in Ad Hoc Networks},
year={2007},
volume={},
number={},
pages={382-390},
abstract={n source and destination pairs randomly located in a fixed area want to communicate with each other. It is well known that classical multihop architectures that decode and forward packets can deliver at most a radicn-scaling of the aggregate throughput. The performance is limited by the mutual interference between communicating nodes. We show however that a linear scaling of the capacity with n can in fact be achieved by more intelligent node cooperation and distributed MIMO communication. The key ingredient is a hierarchical and digital architecture for nodal exchange of information for realizing the cooperation.},
keywords={ad hoc networks;MIMO communication;linear capacity scaling;ad hoc network;multihop architecture;mutual interference;distributed MIMO communication;Ad hoc networks;Throughput;MIMO;Receiving antennas;Interference;Peer to peer computing;Decoding;Aggregates;Degradation;Transmitting antennas},
doi={10.1109/INFCOM.2007.52},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215635,
author={X. Wang and Z. Yao and D. Loguinov},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Residual-Based Measurement of Peer and Link Lifetimes in Gnutella Networks},
year={2007},
volume={},
number={},
pages={391-399},
abstract={Existing methods of measuring lifetimes in P2P systems usually rely on the so-called create-based method (CBM), which divides a given observation window into two halves and samples users "created" in the first half every Delta time units until they die or the observation period ends. Despite its frequent use, this approach has no rigorous accuracy or overhead analysis in the literature. To shed more light on its performance, we flrst derive a model for CBM and show that small window size or large Delta may lead to highly inaccurate lifetime distributions. We then show that create-based sampling exhibits an inherent tradeoff between overhead and accuracy, which does not allow any fundamental improvement to the method. Instead, we propose a completely different approach for sampling user dynamics that keeps track of only residual lifetimes of peers and uses a simple renewal-process model to recover the actual lifetimes from the observed residuals. Our analysis indicates that for reasonably large systems, the proposed method can reduce bandwidth consumption by several orders of magnitude compared to prior approaches while simultaneously achieving higher accuracy. We finish the paper by implementing a two-tier Gnutella network crawler equipped with the proposed sampling method and obtain the distribution of ultrapeer lifetimes in a network of 6.4 million users and 60 million links. Our experimental results show that ultrapeer lifetimes are Pareto with shape a alpha ap 1.1; however, link lifetimes exhibit much lighter tails with alpha ap 1.9.},
keywords={computer network reliability;peer-to-peer computing;sampling methods;statistical distributions;residual-based measurement;peer lifetimes;link lifetimes;Gnutella networks;P2P systems;create-based method;lifetime distributions;sampling method;renewal-process model;Sampling methods;Time measurement;Bandwidth;Crawlers;Streaming media;Routing;Communications Society;Computer science;USA Councils;Shape},
doi={10.1109/INFCOM.2007.53},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215636,
author={R. Prasad and P. J. Winzer and S. C. Borst and M. K. Thottan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Queuing Delays in Randomized Load Balanced Networks},
year={2007},
volume={},
number={},
pages={400-408},
abstract={Valiant's concept of randomized load balancing (RLB), also promoted under the name 'two-phase routing', has previously been shown to provide a cost-effective way of implementing overlay networks that are robust to dynamically changing demand patterns. RLB is accomplished in two steps; in the first step, traffic is randomly distributed across the network, and in the second step traffic is routed to the final destination. One of the benefits of RLB is that packets experience only a single stage of routing, thus reducing queueing delays associated with multi-hop architectures. In this paper, we study the queuing performance of RLB, both through analytical methods and packet-level simulations using ns2 on three representative carrier networks. We show that purely random traffic splitting in the randomization step of RLB leads to higher queuing delays than pseudo-random splitting using, e.g., a round-robin schedule. Furthermore, we show that, for pseudo-random scheduling, queuing delays depend significantly on the degree of uniformity of the offered demand patterns, with uniform demand matrices representing a provably worst-case scenario. These results are independent of whether RLB employs priority mechanisms between traffic from step one over step two. A comparison with multi-hop shortest-path routing reveals that RLB eliminates the occurrence of demand-specific hot spots in the network.},
keywords={computer networks;matrix algebra;queueing theory;random processes;resource allocation;scheduling;telecommunication network routing;telecommunication traffic;queuing delay;randomized load balanced network;two-phase routing;overlay network;network traffic;multihop architecture;packet-level simulation;pseudorandom scheduling;uniform demand matrix;Telecommunication traffic;Traffic control;Routing;Delay;Load management;Robustness;Queueing analysis;Performance analysis;Analytical models;Spread spectrum communication},
doi={10.1109/INFCOM.2007.54},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215637,
author={J. Ni and S. Tatikonda},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Performance Evaluation of Loss Networks via Factor Graphs and the Sum-Product Algorithm},
year={2007},
volume={},
number={},
pages={409-417},
abstract={Loss networks provide a powerful tool for the analysis and design of many communication and networking systems. It is well known that a large number of loss networks have product-form steady-state probabilities. However, for most networks of practical interest, evaluating the system performance is a difficult task due to the presence of a normalization constant. In this paper, we present a new framework based on probabilistic graphical models to tackle this task. Specifically, we propose to use factor graphs to model the stationary distribution of a network. Based on the factor graph model, we can easily derive recursive formulas for symmetric networks. Most importantly, for networks with arbitrary topology, we can apply efficient message-passing algorithms like the sum-product algorithm to compute the exact or approximate marginal distributions of all state variables and the related performance measures such as call blocking probabilities. Through extensive numerical experiments, we show that the sum-product algorithm returns very accurate blocking probabilities and greatly outperforms the reduced load approximation for both single-service and multiservice loss networks with a variety of topologies.},
keywords={graph theory;message passing;probability;telecommunication network reliability;telecommunication network routing;telecommunication network topology;multiservice loss network performance evaluation;factor graph model;sum-product algorithm;steady-state call blocking probability;probabilistic graphical model;recursive formula;symmetric network topology;message-passing algorithm;network routing;Performance loss;Sum product algorithm;Computer networks;Bandwidth;Stochastic processes;Optical losses;Probability;Algorithm design and analysis;Steady-state;Network topology},
doi={10.1109/INFCOM.2007.55},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215638,
author={J. Pongsajapan and S. H. Low},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Reverse Engineering TCP/IP-Like Networks Using Delay-Sensitive Utility Functions},
year={2007},
volume={},
number={},
pages={418-426},
abstract={TCP/IP can be interpreted as a distributed primal-dual algorithm to maximize aggregate utility over source rates. It has recently been shown that an equilibrium of TCP/IP, if it exists, maximizes the same delay-insensitive utility over both source rates and routes, provided pure congestion prices are used as link costs in the shortest-path calculation of IP. In practice, however, pure dynamic routing is never used and link costs are weighted sums of both static as well as dynamic components. In this paper, we introduce delay-sensitive utility functions and identify a class of utility functions that such a TCP/IP equilibrium optimizes. We exhibit some counter-intuitive properties that any class of delay-sensitive utility functions optimized by TCP/IP necessarily possess. We prove a sufficient condition for global stability of routing updates for general networks. We construct example networks that defy conventional wisdom on the effect of link cost parameters on network stability and utility.},
keywords={distributed algorithms;IP networks;optimisation;reverse engineering;telecommunication network routing;transport protocols;utility theory;reverse engineering TCP/IP network;delay-sensitive utility function;distributed primal-dual algorithm;dynamic network routing;Reverse engineering;Routing;TCPIP;Stability;Aggregates;Costs;Propagation delay;IP networks;Multicast algorithms;Internet},
doi={10.1109/INFCOM.2007.56},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215639,
author={A. Legrand and C. Touati},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Non-Cooperative Scheduling of Multiple Bag-of-Task Applications},
year={2007},
volume={},
number={},
pages={427-435},
abstract={Multiple applications that execute concurrently on heterogeneous platforms compete for CPU and network resources. In this paper we analyze the behavior of K non-cooperative schedulers using the optimal strategy that maximize their efficiency while fairness is ensured at a system level ignoring applications characteristics. We limit our study to simple single-level master-worker platforms and to the case where each scheduler is in charge of a single application consisting of a large number of independent tasks. The tasks of a given application all have the same computation and communication requirements, but these requirements can vary from one application to another. In this context, we assume that each scheduler aims at maximizing its throughput. We give closed-form formula of the equilibrium reached by such a system and study its performance. We characterize the situations where this Nash equilibrium is optimal (in the Pareto sense) and show that even though no catastrophic situation (Braess-like paradox) can occur, such an equilibrium can be arbitrarily bad for any classical performance measure.},
keywords={computer networks;decision theory;game theory;processor scheduling;resource allocation;noncooperative scheduling;multiple bag-of-task applications;CPU resources;network resources;optimal strategy;single-level master-worker platforms;throughput maximization;Nash equilibrium;computer network technology;noncooperative game;Throughput;Degradation;Processor scheduling;Central Processing Unit;Context;Nash equilibrium;Resource management;Bandwidth;Communications Society;Computer networks},
doi={10.1109/INFCOM.2007.57},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215640,
author={M. E. Kounavis and A. Kumar and R. Yavatkar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Sorting Packets by Packet Schedulers Using a Connected Trie Data Structure},
year={2007},
volume={},
number={},
pages={436-444},
abstract={Packet scheduling is a critical component of router data paths because it allows routers to divide bandwidth intelligently between competing flows. A large number of scheduling algorithms annotate packets with time stamps and subsequently sort these packets according to their annotated time stamp values. For these algorithms the problems of efficiently tagging and sorting packets are still open to investigation. In this paper we propose a data structure and algorithm that reduces the latency of determining the packet with the smallest time stamp to a single memory access time and a small constant number of computation steps, independent of the number of flows serviced by the scheduler. The complexity of inserting a packet into our sorting data structure is logarithmic as a function of the ratio between the maximum packet size and minimum connection weight. The latency of inserting a packet can be hidden by performing insertions of several packets in parallel. This is the fastest sorting data structure known to us. One of the most efficient alternative implementation techniques proposed by Chao et. al. [20] is associated with logarithmic complexity of the scheduling decision time, as a function of the maximum value of packet time stamps. Our solution applies to many different packet fair queuing algorithms including Weighted Fair Queuing [28], Self-Clocked Fair Queuing (SCFQ) [28] and Start Time Fair Queuing [4].},
keywords={data structures;scheduling;telecommunication network routing;sorting packets;connected trie data structure;packet scheduling;router data paths;scheduling algorithms;minimum connection weight;packet time stamps;Sorting;Scheduling algorithm;Data structures;Delay;Processor scheduling;Bandwidth;Costs;Data flow computing;Communications Society;USA Councils},
doi={10.1109/INFCOM.2007.58},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215641,
author={M. Bayati and B. Prabhakar and D. Shah and M. Sharma},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Iterative Scheduling Algorithms},
year={2007},
volume={},
number={},
pages={445-453},
abstract={The input-queued switch architecture is widely used in Internet routers due to its ability to run at very high line speeds. A central problem in designing an input-queued switch is the scheduling algorithm that decides which packets to transfer from ingress ports to egress ports in a given timeslot. It is desirable that such algorithms be iterative (so as to be pipelineable), distributed (allowing flexibility in hardware implementation) and are able to deliver high performance (in terms of throughput and delay). In practice, implementable algorithms have so far had limited success in combining all of the above properties. For example, the popular iSLIP algorithm is known to perform suboptimally, but it is commercially deployed mainly because it is iterative and distributed. The main contribution of this paper is the design and systematic analysis of two algorithms which, to the best of our knowledge, are the first high-performance iterative and distributed scheduling algorithms with possibility of efficient implementation. We first present an iterative, distributed and low-delay maximal throughput algorithm based on the celebrated "auction algorithm". This algorithm can be seen as a natural extension of iSLIP when queue-size information is allowed to be exchanged. The standard auction algorithm can take an unbounded number of iterations to converge in the worst case. However we show that under admissible Bernoulli i.i.d. traffic, our algorithm takes O(n<sup>2</sup>) iterations, where n is the number of ingress/egress ports in the switch. Moreover for a switch with finite buffer-size, the algorithm allows for a graceful trade-off between running time and performance, which we verify by representative simulation results. Next, we propose and analyze a throughput-optimal, iterative and distributed scheduling algorithm influenced by Max-product belief propagation. Recently the problem of efficient transmission over multi-hop wireless networks has been formulated as that of finding an appropriate schedule over the grid-graph abstraction of the network. A key feature of the multi-hop wireless transmission problem is that while the communication subgraph is bipartite, the bi-partition is allowed to change in each scheduling epoch. We show that our algorithm can be used to efficiently schedule traffic in multi-hop wireless networks.},
keywords={distributed algorithms;Internet;iterative methods;packet switching;queueing theory;scheduling;telecommunication network management;telecommunication network routing;telecommunication traffic;iterative scheduling algorithms;input-queued switch architecture;Internet routers;packet transfer;distributed scheduling algorithms;standard auction algorithm;Bernoulli i.i.d. traffic;O(n2) iterations;ingress port;egress port;Max-product belief propagation;multihop wireless networks;bipartition;scheduling epoch;traffic scheduling;low-delay maximal throughput algorithm;auction algorithm;Scheduling algorithm;Iterative algorithms;Switches;Algorithm design and analysis;Spread spectrum communication;Throughput;Traffic control;Wireless networks;Internet;Packet switching},
doi={10.1109/INFCOM.2007.59},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215642,
author={X. Zhang and S. R. Mohanty and L. N. Bhuyan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Adaptive Max-Min Fair Scheduling in Buffered Crossbar Switches Without Speedup},
year={2007},
volume={},
number={},
pages={454-462},
abstract={A good crossbar switch scheduler should be able to sustain full bandwidth and maintain fairness among competing flows. A pure input-queued (IQ) non-buffered switch requires an impractically complex scheduler to achieve this goal. Common solutions are to use crossbar speedup and/or buffered crossbar. In this paper, we explore this issue in a buffered crossbar without speedup. We first discuss the conflict between fairness and throughput and the fairness criteria in crossbar switch scheduling, and justify that a desirable scheduler should sustain full bandwidth for admissible traffic and ensure max-min fairness for non-admissible traffic. Then we describe an <i>adaptive max-min fair scheduling </i>(AMFS) algorithm and show by analysis and simulation that it can provide both 100% throughput and max-min fairness. Finally we briefly discuss the hardware implementation of the AMFS algorithm.},
keywords={adaptive scheduling;minimax techniques;queueing theory;telecommunication switching;telecommunication traffic;adaptive max-min fair scheduling;buffered crossbar switches;input-queued non-buffered switch;fairness criteria;crossbar switch scheduling;admissible traffic;Adaptive scheduling;Switches;Throughput;Traffic control;Scheduling algorithm;Bandwidth;Quality of service;Processor scheduling;Very large scale integration;Integrated circuit technology},
doi={10.1109/INFCOM.2007.60},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215643,
author={S. Seetharaman and V. Hilt and M. Hofmann and M. Ammar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Preemptive Strategies to Improve Routing Performance of Native and Overlay Layers},
year={2007},
volume={},
number={},
pages={463-471},
abstract={Overlay routing is known to cause undesired instability in a network by operating in a selfish manner. The objectives of overlay routing, such as optimizing end-to-end latency, are often in conflict with the objectives of traffic engineering in the native layer, which is concerned about balancing load. In our work, we build on past research that has investigated the recurring non-cooperative interaction between overlay routing and traffic engineering, and develop strategies that improve the routing performance of a particular layer with incomplete information about the other layer. In our strategies, one layer acts as a leader that predicts the follower's reaction and undertakes countermeasures to prevent future deterioration in performance. Specifically, we propose two classes of strategies - friendly or hostile - for each layer. By simulating under different network characteristics, we show that these preemptive strategies achieve near-optimal performance for the leader and increase the overall stability of the network. Furthermore, we observe that the best performance for a particular layer is achieved only when the goals of the other layer are completely violated, thereby motivating a higher level of selfishness.},
keywords={stability;telecommunication network routing;telecommunication traffic;overlay routing;traffic engineering;network stability;overlay layers;native layers;end-to-end latency;load balancing;Routing;Telecommunication traffic;Delay;Costs;Communications Society;Educational institutions;Context-aware services;Stability;IP networks;Tellurium},
doi={10.1109/INFCOM.2007.61},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215644,
author={J. Liang and X. Gu and K. Nahrstedt},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Self-Configuring Information Management for Large-Scale Service Overlays},
year={2007},
volume={},
number={},
pages={472-480},
abstract={Service overlay networks (SON) provide important infrastructure support for many emerging distributed applications such as web service composition, distributed stream processing, and workflow management. Quality-sensitive distributed applications such as multimedia services and on-line data analysis often desire the SON to provide up-to-date dynamic information about different overlay nodes and overlay links. However, it is a challenging task to provide scalable and efficient information management for large-scale SONs, where both system conditions and application requirements can change over time. In this paper, we present InfoEye, a model-based self-configuring distributed information management system that consists of a set of monitoring sensors deployed on different overlay nodes. InfoEye can dynamically configure the operations of different sensors based on current statistical application query patterns and system attribute distributions. Thus, InfoEye can greatly improve the scalability of SON by answering information queries with minimum monitoring overhead. We have implemented a prototype of InfoEye and evaluated its performance using both extensive simulations and micro-benchmark experiments on PlanetLab. The experimental results show that InfoEye can significantly reduce the information management overhead compared with existing approaches. In addition, InfoEye can quickly reconfigure itself in response to application requirement and system information pattern changes.},
keywords={computer network management;quality of service;system monitoring;InfoEye model-based self-configuring distributed information management system;large-scale service overlay network;quality-sensitive distributed application;monitoring sensor;statistical application query pattern;system attribute distribution;PlanetLab;Information management;Large-scale systems;Streaming media;Sensor phenomena and characterization;Web services;Data analysis;Sensor systems;Sensor systems and applications;Scalability;Monitoring},
doi={10.1109/INFCOM.2007.62},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215645,
author={C. Wu and B. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Strategies of Conflict in Coexisting Streaming Overlays},
year={2007},
volume={},
number={},
pages={481-489},
abstract={In multimedia applications such as IPTV, it is natural to accommodate multiple coexisting peer-to-peer streaming overlays, corresponding to channels of programming. With coexisting streaming overlays, one wonders how these overlays may efficiently share the available upload bandwidth on peers. In order to satisfy the required streaming rate in each overlay, as well as to minimize streaming costs. In this paper, we seek to design simple, effective and decentralized strategies to resolve conflicts among coexisting streaming overlays. Since such strategies of conflict are game theoretic in nature, we characterize them as a decentralized collection of dynamic auction games, in which downstream peers submit bids for bandwidth at the upstream peers. With extensive theoretical analysis and performance evaluation, we show that the outcome of these local games is an optimal topology for each overlay that minimizes streaming costs. These overlay topologies evolve and adapt to peer dynamics, fairly share peer upload bandwidth, and can be prioritized.},
keywords={media streaming;peer-to-peer computing;coexisting streaming overlays;multimedia applications;peer-to-peer streaming overlays;upload bandwidth;decentralized strategies;dynamic auction games;Bandwidth;Game theory;Streaming media;Topology;Peer to peer computing;Performance analysis;Cost function;Network servers;Communications Society;Application software},
doi={10.1109/INFCOM.2007.63},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215646,
author={N. Laoutaris and G. Smaragdakis and A. Bestavros and J. W. Byers},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Implications of Selfish Neighbor Selection in Overlay Networks},
year={2007},
volume={},
number={},
pages={490-498},
abstract={In a typical overlay network for routing or content sharing, each node must select a fixed number of immediate overlay neighbors for routing traffic or content queries. A selfish node entering such a network would select neighbors so as to minimize the weighted sum of expected access costs to all its destinations. Previous work on selfish neighbor selection has built intuition with simple models where edges are undirected, access costs are modeled by hop-counts, and nodes have potentially unbounded degrees. However, in practice, important constraints not captured by these models lead to richer games with substantively and fundamentally different outcomes. Our work models neighbor selection as a game involving directed links, constraints on the number of allowed neighbors, and costs reflecting both network latency and node preference. We express a node's "best response" wiring strategy as a k-median problem on asymmetric distance, and use this formulation to obtain pure Nash equilibria. We experimentally examine the properties of such stable wirings on synthetic topologies, as well as on real topologies and maps constructed from PlanetLab and AS-level Internet measurements. Our results indicate that selfish nodes can reap substantial performance benefits when connecting to overlay networks constructed by naive nodes. On the other hand, in overlays that are dominated by selfish nodes, the resulting stable wirings are optimized to such great extent that even uninformed newcomers can extract near-optimal performance through naive wiring strategies.},
keywords={computer networks;game theory;telecommunication links;telecommunication network routing;telecommunication network topology;telecommunication traffic;selfish neighbor selection;overlay network latency;routing traffic;content queries;game theory;node best response wiring strategy;k-median problem;Nash equilibria;synthetic topologies;Wiring;Costs;Routing;Network topology;Telecommunication traffic;Traffic control;Delay;Internet;Extraterrestrial measurements;Joining processes},
doi={10.1109/INFCOM.2007.64},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215647,
author={A. Eryilmaz and A. Ozdaglar and E. Modiano},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Polynomial Complexity Algorithms for Full Utilization of Multi-Hop Wireless Networks},
year={2007},
volume={},
number={},
pages={499-507},
abstract={In this paper, we provide and study a general framework that allows the development of distributed mechanisms to achieve full utilization of multi-hop wireless networks. In particular, we describe a generic randomized routing, scheduling and flow control scheme that is applicable to a large class of interference models, and that allows for the development of distributed algorithms which maximize network throughput and utilization. In particular, we focus on a specific interference model, namely the secondary interference model, and develop distributed algorithms with polynomial communication and computation complexity in the network size. This is an important result given that earlier throughput-optimal algorithms developed for such a model relies on the solution to an NP-hard problem. This results in a polynomial complexity cross-layer algorithm that achieves throughput optimality and fair allocation of network resources amongst the users. We further show that our algorithmic approach enables us to efficiently approximate the capacity region of a multi-hop wireless network.},
keywords={computational complexity;distributed algorithms;radio networks;resource allocation;scheduling;telecommunication network routing;multihop wireless network;polynomial complexity algorithm;generic randomized routing;flow control scheme;distributed algorithm;interference model;throughput-optimal algorithm;NP-hard problem;resource allocation;Polynomials;Spread spectrum communication;Wireless networks;Interference;Distributed algorithms;Throughput;Routing;Communication system control;Computer networks;Distributed computing},
doi={10.1109/INFCOM.2007.65},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215648,
author={L. Lai and H. El Gamal},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Cooperation in Energy Limited Wireless Networks},
year={2007},
volume={},
number={},
pages={508-516},
abstract={This paper considers wireless networks with energy limited nodes. In this scenario, multi-hop forwarding is needed to minimize the network energy consumption. In many practical scenarios, however, nodes' selfishness raises doubts on whether each node will be willing to forward packets in order to minimize the overall energy expenditure. To analyze this problem, a non-cooperative game theoretic approach is adopted in our work. Using this framework, the critical role of altruistic nodes in encouraging cooperation is established. More specifically, we show that it is sufficient to have a vanishingly small fraction of the nodes to be altruistic, i.e., relay nodes, in order to ensure full cooperation from all the nodes in the network. This result hinges on using the appropriate forwarding policies by the altruistic nodes, as detailed in the sequel. An important aspect of our work is that only reward/punishment policies that can be realized on the physical layer are used, and hence, our results establish the achievability of full cooperation without requiring additional incentive mechanisms at the higher layer.},
keywords={game theory;radio networks;energy limited wireless network;multihop forwarding;energy consumption;noncooperative game theory;altruistic node;Wireless networks;Peer to peer computing;Protocols;Relays;Spread spectrum communication;Game theory;Physical layer;Energy efficiency;Energy consumption;Ad hoc networks},
doi={10.1109/INFCOM.2007.66},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215649,
author={N. Bisnik and A. A. Abouzeid},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Capacity Deficit in Mobile Wireless Ad Hoc Networks Due to Geographic Routing Overheads},
year={2007},
volume={},
number={},
pages={517-525},
abstract={Overheads incurred by routing protocols diminish the capacity available for relaying useful data over a mobile wireless ad hoc network. Discovering and understanding the lower bounds on the amount of protocol overhead incurred for routing data packets is important for development of efficient routing protocols, and for understanding the actual (effective) capacity available for network users. In this paper we use an information-theoretic approach for characterizing the minimum routing overheads of geographic routing in a mobile network. We formulate the minimum overhead problem as a rate-distortion problem. The formulation may be applied to networks with arbitrary traffic arrival and location service schemes. We evaluate lower bounds on the minimum overheads incurred for maintaining the location of destination nodes and consistent neighborhood information in terms of node mobility and packet arrival process. We also characterize the deficit caused by the routing overheads in the overall transport capacity of a mobile network.},
keywords={ad hoc networks;mobile radio;routing protocols;telecommunication traffic;wireless sensor networks;mobile wireless ad hoc network;geographic routing overhead;routing protocol;routing data packets;information-theoretic approach;rate-distortion problem;Mobile ad hoc networks;Routing protocols;Rate-distortion;Distortion measurement;Error correction;Mobile computing;Peer to peer computing;Network topology;Information theory;Communications Society},
doi={10.1109/INFCOM.2007.67},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215650,
author={Y. Li and M. Chiang and A. R. Calderbank and S. N. Diggavi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Rate-Reliability-Delay Tradeoff in Networks with Composite Links},
year={2007},
volume={},
number={},
pages={526-534},
abstract={Networks need to accommodate diverse applications with different quality-of-service (QoS) requirements. New ideas at the physical layer are being developed for this purpose, such as diversity embedded coding, which is a technique that combines high rates with high reliability. We address the problem of how to fully utilize different rate-reliability characteristics at the physical layer to support different types of traffic over a network and to jointly maximize their utilities. We set up a new framework based on utility maximization for networks with composite links, meaning that each link consists of sub-links that can attain different rate-reliability characteristics simultaneously. We incorporate delay, in addition to rate and reliability, into the utility functions. To accommodate different types of traffic, we propose distributed algorithms for the optimal rate-reliability-delay tradeoff based on capacity division and priority queueing. Numerical results show that compared with traditional codes, the new codes can provide higher network utilities for all traffic types simultaneously. The results also show that priority queueing achieves higher network utility than capacity division.},
keywords={codes;distributed algorithms;Internet telephony;quality of service;queueing theory;telecommunication links;telecommunication network planning;telecommunication network reliability;telecommunication traffic;composite link;quality of service;QoS;network traffic;network utility maximization;network reliability;distributed algorithm;network delay;capacity division;priority queueing;diversity embedded code;VoIP;Traffic control;Physical layer;Telecommunication traffic;Utility programs;Communication system traffic control;Diversity reception;Resource management;Channel coding;Delay effects;Technological innovation},
doi={10.1109/INFCOM.2007.68},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215651,
author={V. P. Mhatre and K. Papagiannaki and F. Baccelli},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Interference Mitigation Through Power Control in High Density 802.11 WLANs},
year={2007},
volume={},
number={},
pages={535-543},
abstract={The low cost and the ease of deployment of WiFi devices, as well as the need to support high bandwidth applications over 802.11 WLANs has led to the emergence of high density 802.11 networks in urban areas and enterprises. High density wireless networks, by design, face significant challenges due to increased interference resulting from the close proximity of co-channel cells. We demonstrate that power control can be used to mitigate interference in such an environment. It is well-known that variable transmit powers result in asymmetric links in the network, and can potentially lead to throughput starvation of some nodes. We first show that in order to perform starvation-free power control in 802.11 networks, a <i>cross-layer </i>approach is required, whereby the transmit powers and the carrier sensing parameter of the MAC layer of the nodes should be <i>jointly</i> tuned. We then propose a framework that determines optimum settings for these parameters with the objective of maximizing the network-wide throughput for elastic traffic. Within this framework, we devise a distributed power control algorithm that uses a Gibbs sampler. OPNET simulations and experiments over a proof of concept testbed demonstrate that in a dense network the proposed power control algorithm yields significant improvement in client throughput.},
keywords={interference suppression;sampling methods;telecommunication control;telecommunication traffic;wireless channels;wireless LAN;802.11 wireless LAN;interference mitigation;WiFi device;co-channel cell;cross-layer approach;MAC layer;medium access control;distributed power control algorithm;Gibbs sampler;OPNET simulation;elastic traffic;Interference;Power control;Throughput;Costs;Bandwidth;Urban areas;Wireless networks;Communication system traffic control;Traffic control;Testing},
doi={10.1109/INFCOM.2007.69},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215652,
author={B. Wang and Z. Han and K. J. R. Liu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Distributed Relay Selection and Power Control for Multiuser Cooperative Communication Networks Using Buyer/Seller Game},
year={2007},
volume={},
number={},
pages={544-552},
abstract={The performances in cooperative communications depend on careful resource allocation such as relay selection and power control, but traditional centralized resource allocation needs considerable overhead and signaling to exchange the information for channel estimations. In this paper, we propose a distributed buyer/seller game theoretic framework over multiuser cooperative communication networks to stimulate cooperation and improve the system performance. By employing a two-level game to jointly consider the benefits of source nodes as buyers and relay nodes as sellers, the proposed approach not only helps the source smartly find the relays at relatively better locations and buy optimal amount of power from them, but also helps the competing relays maximize their own utilities by asking the reasonable prices. The game is proved to converge to a unique optimal equilibrium. From the simulation results, the relays in good locations can play more important roles in increasing source node's utility, so the source would like to buy more power from these preferred relays. On the other hand, the relays have to set the proper prices to attract the source's buying because of competition from other relays and selections from the source. Moreover, the distributed game resource allocation can achieve comparable performance compared with the centralized one.},
keywords={channel estimation;game theory;radio networks;resource allocation;distributed relay selection;multiuser cooperative communication network;buyer-seller game;channel estimation;unique optimal equilibrium;distributed game resource allocation;Relays;Power control;Communication networks;Resource management;Power system relaying;Wireless networks;Game theory;Peer to peer computing;USA Councils;Channel estimation},
doi={10.1109/INFCOM.2007.70},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215653,
author={R. Bhatia and A. Kashyap and L. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={The Power Balancing Problem in Energy Constrained Multi-Hop Wireless Networks},
year={2007},
volume={},
number={},
pages={553-561},
abstract={Power efficient operation is very critical in energy constrained multi-hop wireless networks. One important technique is to intelligently assign transmission powers to nodes while maintaining network connectivity. Previous work has focused on assigning a single transmission power to each node. This often leads to "power imbalance", where some nodes use much more power than other nodes. This can reduce network lifetime. In this paper, we investigate the problem of two power assignments where nodes alternate the use of these assigned powers. We rigorously formulate the problem of two power assignment under the constraint that the network connectivity is maintained. The objective here is to minimize the maximum average power used by the nodes. We show that, in general, the problem is not just NP-hard but also hard to approximate. We then propose a distributed localized heuristic to compute the two power assignments. We perform extensive simulations to show that the algorithm can reduce the average power significantly when compared with algorithms that assign a single power. By assuming some properties on radio propagation, we also present a centralized algorithm with bounded worst case guarantees for the two power assignment problem.},
keywords={radio networks;radiowave propagation;telecommunication network management;power balancing problem;energy constrained multihop wireless network;network connectivity maintenance;NP-hard problem;distributed localized heuristic;radio propagation;two power assignment problem;Spread spectrum communication;Wireless networks;Peer to peer computing;Radio propagation;USA Councils;Approximation algorithms;Algorithm design and analysis;Communications Society;Laboratories;Educational institutions},
doi={10.1109/INFCOM.2007.71},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215654,
author={Z. Ji and M. Varshney and J. Zhou and R. Bagrodia},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Point-Casting Service in Wireless Networks},
year={2007},
volume={},
number={},
pages={562-570},
abstract={The broadcast nature of existing wireless LANs can produce excessive radio coverage which is often undesirable for applications like wireless IPTV or location-based service. To address this issue, we utilize the characteristics of signal attenuation common to all wireless communications and implement a <i>point-casting</i> <i>service</i> <sup>1</sup> (<i>PCast</i>) over existing wireless networks that can significantly restrict the coverage for transmissions. The principle of PCast is to split and encode the downlink traffic and deliver it to the client via a few surrounding access points (APs). Hence, an unintended client cannot decode a packet without all its fragments. Equivalently, the service area is bounded within the intersection of communication coverage of all APs. The result coverage area can be further reduced via rate and power control at the APs. In this paper, we present our design and implementation of the PCast service on top of an 802.11a wireless LAN. Experiments conducted in a lab environment show that PCast can bound the service region to be within 2 meters around a client, while incurring jitter of less than 1ms, and bandwidth capacity loss of less than 10%.},
keywords={broadcasting;encoding;telecommunication traffic;wireless LAN;point-casting service;wireless communication network;IEEE 802.11a wireless LAN broadcasting;radio coverage;signal attenuation;downlink traffic encoding;PCast service;Wireless networks;Wireless LAN;Radio broadcasting;IPTV;Attenuation;Wireless communication;Downlink;Telecommunication traffic;Decoding;Power control},
doi={10.1109/INFCOM.2007.72},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215655,
author={J. Huang and C. W. Tan and M. Chiang and R. Cendrillon},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Statistical Multiplexing Over DSL Networks},
year={2007},
volume={},
number={},
pages={571-579},
abstract={Most previous work in statistical multiplexing only considered the case where the link transmission rates are fixed. In this paper, we consider statistical multiplexing in networks with adaptive transmission rates, with focus on DSL broadband access networks. This requires a jointly optimized allocation of buffer space and transmission bandwidth to traffic flows, which takes the flow traffic characteristics, the user QoS requirements, and the user interactions at the physical layer into consideration. Using the effective bandwidth concept, we propose a class of alternate maximization (AM) algorithms (AM-D and AM-M), which solve the statistical multiplexing problem for both delay insensitive data traffic and delay sensitive multimedia traffic. With low complexity as a design goal, the AM algorithms incorporate our recently proposed autonomous spectrum balancing (ASB) algorithm, which was originally designed for DSL physical layer spectrum management. Our numerical results show that the AM algorithms combines the gain due to statistical multiplexing and that due to spectrum management.},
keywords={bandwidth allocation;broadband networks;buffer storage;digital subscriber lines;multimedia communication;optimisation;quality of service;statistical multiplexing;telecommunication traffic;digital subscriber line network;statistical multiplexing;DSL broadband access network;jointly optimized bandwidth allocation;quality of service;alternate maximization algorithm;delay insensitive data traffic;delay sensitive multimedia traffic;autonomous spectrum balancing algorithm;buffer resource;DSL;Bandwidth;Physical layer;Resource management;Quality of service;Radio spectrum management;Telecommunication traffic;Delay effects;Algorithm design and analysis;Performance gain},
doi={10.1109/INFCOM.2007.73},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215656,
author={G. Morabito},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Increasing Capacity Through the Use of the Timing Channel in Power-Constrained Satellite Networks},
year={2007},
volume={},
number={},
pages={580-588},
abstract={The timing channel is the logical communication link established between a sender and a receiver in which the information flowing is encoded in the timing between events. Accordingly, information can be transferred by means of the transmitted packets, the time interval between such transmissions, and the size of the packets. In wired networks approaches using the timing channel can lead to a small increase in the overall communication capacity. In wireless networks with strict power constraints, instead, these can lead to significant performance improvements. In this paper attention is focused on power-constrained satellite networks where there is a large amount of bandwidth which cannot be used because the power required for operations executed on-board the satellite is much higher than what is available. In such scenarios the use of the timing channel can significantly improve the overall capacity of the system. In this paper a methodology is introduced which allows exploitation of the timing channel in power-constrained satellite networks and an analytical framework is derived for its assessment. Numerical results show that the proposed approach can achieve much higher capacity than what can be theoretically achieved without using the timing channel.},
keywords={satellite communication;telecommunication links;wireless channels;timing channel;power-constrained satellite network;logical communication link;Timing;Pulse modulation;Queueing analysis;Wireless sensor networks;Solar power generation;Energy consumption;Satellite communication;Communications Society;Artificial satellites;Telecommunications},
doi={10.1109/INFCOM.2007.74},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215657,
author={Y. Choi and S. Choi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Service Charge and Energy-Aware Vertical Handoff in Integrated IEEE 802.16e/802.11 Networks},
year={2007},
volume={},
number={},
pages={589-597},
abstract={This paper considers two issues arising in an integrated IEEE 802.16e/802.11 network: (1) finding a possible network, which mobile station (MSTA) can switch to, and (2) making a decision whether to execute a vertical handoff (VHO). For this purpose, we propose that 802.16e Base Stations (BSs) periodically broadcast the information about the density of 802.11 access points (APs) within their cell coverage. Based on this information, we develop a novel model, which predicts the successful scan probability during a given scan time. Using this analytical model, we devise an energy-efficient scan policy (ESP) algorithm, which enables an MSTA to decide (1) whether to attempt to discover APs in the current 802.16e cell, and (2) if so, how to set the 802.11 active scan interval considering the energy consumption. For the VHO decision, we mainly consider the impact of the service charge. Especially, a practical service fee models, i.e., flat pricing for WLAN and partially-flat pricing for 802.16e network, are considered. Under this service charge plan, we need to control the usage of the 802.16e network to minimize the user's payment. To this end, we propose a scheme, which intelligently postpones the delivery of the delay-tolerant traffic within a certain time limit combined with ESP algorithm.},
keywords={broadband networks;cellular radio;decision making;probability;radio access networks;telecommunication traffic;wireless LAN;service charge;energy-aware vertical handoff;integrated IEEE 802.16e-802.11 networks;mobile station;VHO decision making;access points;cell coverage;scan probability;energy-efficient scan policy algorithm;ESP algorithm;WLAN;user payment minimization;delay-tolerant traffic;flat pricing;mobile broadband wireless access network;Switches;Electrostatic precipitators;Pricing;Femtocell networks;Broadcasting;Predictive models;Analytical models;Energy efficiency;Energy consumption;Wireless LAN},
doi={10.1109/INFCOM.2007.75},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215658,
author={P. Dutta and S. Jaiswal and R. Rastogi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Routing and Channel Allocation in Rural Wireless Mesh Networks},
year={2007},
volume={},
number={},
pages={598-606},
abstract={IEEE 802.11 Wi-Fi equipment based wireless mesh networks have recently been proposed as an inexpensive approach to connect far-flung rural areas. Such networks are built using high-gain directional antenna that can establish long-distance point-point links. In recent work, a new MAC protocol named 2P has been proposed that is suited for the interference pattern within such a network. However, the 2P protocol requires the underlying graph (for each 802.11 channel) to be bi-partite. Under the assumption that 2P is the MAC protocol used in the mesh network, we make the following contributions in this paper. Given <i>K</i> non-interfering 802.11 channels, we propose a simple cut-based algorithm to compute <i>K</i> bi-partite sub-graphs (on each of which the 2P protocol can be run separately). We establish the class of graphs that can thus be completely covered by <i>K</i> bipartite subgraphs. For the remaining set of graphs, we look into the "price" of routing all end-to-end demands over <i>only</i> the bipartite subgraphs. We analytically establish what fraction of the max flow of the original mesh-graph can be routed over the bipartite subgraphs. Finally we look into the problem of mismatch between the load on a link (as computed by max flow) and its effective capacity under a given channel allocation. We propose heuristics to cluster links with similar loads into the same bipartite graphs (channels) and through comprehensive numerical simulations show that our heuristics come very close to the best possible flow.},
keywords={access protocols;directive antennas;graph theory;network theory (graphs);resource allocation;telecommunication network routing;wireless LAN;channel allocation;rural wireless mesh network;network routing;IEEE 802.11 Wi-Fi equipment;high-gain directional antenna;long-distance point-point links;MAC protocol;2P protocol;simple cut-based algorithm;bipartite graphs;Routing;Channel allocation;Wireless mesh networks;Mesh networks;Interference;Costs;Media Access Protocol;Internet;Network topology;Directive antennas},
doi={10.1109/INFCOM.2007.76},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215659,
author={R. Torres and X. Sun and A. Walters and C. Nita-Rotaru and S. Rao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Enabling Confidentiality of Data Delivery in an Overlay Broadcasting System},
year={2007},
volume={},
number={},
pages={607-615},
abstract={Most prior work on the use of key management algorithms to enable confidentiality of video delivery has been conducted in the context of IP Multicast. In this paper, we consider the unique challenges and opportunities of integrating key management algorithms in an overlay multicast system. We conduct a systematic and extensive performance evaluation of strategies for key dissemination in the context of an operational overlay broadcasting system on the Planetlab testbed using real traces of join/leave dynamics. We show that leveraging TCP in each hop of the overlay dissemination structure can significantly simplify reliable key dissemination. The performance can be further enhanced if convergence properties of overlays are considered. We show that using two specialized dissemination structures, one for data and one for keys, potentially achieves low overhead for key dissemination without sacrificing application performance. To our knowledge, this is the first paper to study key management schemes in an overlay context using real implementation and Internet experiments and the first to consider issues in resilient key dissemination with overlays.},
keywords={broadcasting;computer network management;cryptography;Internet;IP networks;multicast communication;telecommunication security;transport protocols;overlay broadcasting system;key management;video delivery;data confidentiality;IP multicast;TCP;Internet;Broadcasting;Multicast algorithms;Internet;System testing;Convergence;Data security;Cryptography;Cryptographic protocols;Communications Society;Multimedia communication},
doi={10.1109/INFCOM.2007.77},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215660,
author={S. Jaggi and M. Langberg and S. Katti and T. Ho and D. Katabi and M. Medard},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Resilient network coding in the presence of Byzantine adversaries},
year={2007},
volume={},
number={},
pages={616-624},
abstract={Network coding substantially increases network throughput. But since it involves mixing of information inside the network, a single corrupted packet generated by a malicious node can end up contaminating all the information reaching a destination, preventing decoding. This paper introduces <i>the</i> <i>first</i> <i>distributed</i> <i>polynomial-time</i> <i>rate-optimal</i> network codes that work in the presence of Byzantine nodes. We present algorithms that target adversaries with different attacking capabilities. When the adversary can eavesdrop on all links and jam z<sub>O</sub> links , our first algorithm achieves a rate of <i>C</i> - 2z<sub>O</sub>, where C is the network capacity. In contrast, when the adversary has limited snooping capabilities, we provide algorithms that achieve the higher rate of <i>C</i> - z<sub>O</sub>. Our algorithms attain the optimal rate given the strength of the adversary. They are information-theoretically secure. They operate in a distributed manner, assume no knowledge of the topology, and can be designed and implemented in polynomial-time. Furthermore, only the source and destination need to be modified; non-malicious nodes inside the network are oblivious to the presence of adversaries and implement a classical distributed network code. Finally, our algorithms work over wired and wireless networks.},
keywords={communication complexity;encoding;telecommunication security;resilient network coding;distributed polynomial-time rate-optimal network codes;Byzantine nodes;nonmalicious nodes;distributed network code;Network coding;Peer to peer computing;Throughput;Decoding;Network topology;Polynomials;Wireless networks;Redundancy;Communications Society;Robustness},
doi={10.1109/INFCOM.2007.78},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215661,
author={T. Ahmed and M. Coates and A. Lakhina},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Multivariate Online Anomaly Detection Using Kernel Recursive Least Squares},
year={2007},
volume={},
number={},
pages={625-633},
abstract={High-speed backbones are regularly affected by various kinds of network anomalies, ranging from malicious attacks to harmless large data transfers. Different types of anomalies affect the network in different ways, and it is difficult to know a priori how a potential anomaly will exhibit itself in traffic statistics. In this paper we describe an online, sequential, anomaly detection algorithm, that is suitable for use with multivariate data. The proposed algorithm is based on the kernel version of the recursive least squares algorithm. It assumes no model for network traffic or anomalies, and constructs and adapts a dictionary of features that approximately spans the subspace of normal behaviour. The algorithm raises an alarm immediately upon encountering a deviation from the norm. Through comparison with existing block-based offline methods based upon Principal Component Analysis, we demonstrate that our online algorithm is equally effective but has much faster time-to-detection and lower computational complexity. We also explore minimum volume set approaches in identifying the region of normality.},
keywords={computer networks;data analysis;least squares approximations;principal component analysis;security of data;telecommunication security;telecommunication traffic;multivariate online anomaly detection;kernel recursive least square algorithm;data transfer;network traffic statistics;principal component analysis;computational complexity;Kernel;Least squares methods;Telecommunication traffic;Traffic control;Spine;Statistics;Detection algorithms;Dictionaries;Least squares approximation;Principal component analysis},
doi={10.1109/INFCOM.2007.79},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215662,
author={Y. J. Pyun and Y. H. Park and X. Wang and D. S. Reeves and P. Ning},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Tracing Traffic through Intermediate Hosts that Repacketize Flows},
year={2007},
volume={},
number={},
pages={634-642},
abstract={Tracing interactive traffic that traverses stepping stones (i.e., intermediate hosts) is challenging, as the packet headers, lengths, and contents can all be changed by the stepping stones. The traffic timing has therefore been studied as a means of tracing traffic. One such technique uses traffic timing as a side channel into which a watermark, or identifying tag, can be embedded to aid with tracing. The effectiveness of such techniques is greatly reduced when repacketization of the traffic occurs at the stepping stones. Repacketization is a natural effect of many applications, including SSH, and therefore poses a serious challenge for traffic tracing. This paper presents a new method of embedding a watermark in traffic timing, for purposes of tracing the traffic in the presence of repacketization. This method uses an invariant characteristic of two traffic flows which are part of the same stepping stone chain, namely, elapsed time of the flows. The duration of each flow is sliced into short fixed-length intervals. Packet timing is adjusted to manipulate the packet count in specific intervals, for purposes of embedding the watermark. A statistical analysis of the method, with no assumptions or limitations concerning the distribution of packet times, proves the effectiveness of the method given a sufficient number of packets, despite natural and/or deliberate repacketization and perturbation of the traffic timing by an adversary. The method has been implemented and tested on a large number of synthetically-generated SSH traffic flows. The results demonstrate that 100% detection rates and less than 1% false positive rates are achievable under conditions of 2 seconds of maximum timing perturbation and 12% repacketization rate, using fewer than 1000 packets.},
keywords={Internet;statistical analysis;telecommunication security;telecommunication traffic;watermarking;interactive traffic tracing;intermediate hosts;repacketization;watermark;stepping stone chain;statistical analysis;Internet;Timing;Watermarking;Traffic control;USA Councils;Delay;Communications Society;Computer science;Software engineering;TCPIP;Protocols},
doi={10.1109/INFCOM.2007.80},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215663,
author={P. Thulasiraman and S. Ramasubramanian and M. Krunz},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Disjoint Multipath Routing to Two Distinct Drains in a Multi-Drain Sensor Network},
year={2007},
volume={},
number={},
pages={643-651},
abstract={Wireless sensor networks (WSN) are typically employed for monitoring applications that require data collection at specific nodes, called drains. In order to improve the robustness of data collection, multiple drains may be employed. Data from every sensor is required to be logged into two distinct sensors for data collection to be resilient to any single drain failures. In this paper, we develop a routing mechanism based on colored trees. Every node forwards the packets based on the drain address and one additional bit. The number of routing table entries at each node is 2|D|, where |D| denotes the number of drains in the network. The construction of the colored trees guarantees that every node has two node-disjoint paths to two distinct drains. The running time complexity of the algorithm is O(|D||L|), where |L| denotes the number of links in the network. Through extensive simulations, we demonstrate that employing multiple drains and disjoint routing to two distinct drains reduces the average path length compared to disjoint routing to one of the multiple drains.},
keywords={telecommunication network routing;trees (mathematics);wireless sensor networks;disjoint multipath routing;multidrain sensor network;wireless sensor network;colored tree;time complexity;Routing;Wireless sensor networks;Peer to peer computing;Robustness;Wireless networks;Communications Society;Computerized monitoring;Condition monitoring;Application software;Sensor phenomena and characterization},
doi={10.1109/INFCOM.2007.81},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215664,
author={P. Mannersalo and A. Keshavarz-Haddad and R. Riedi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Broadcast Flooding Revisited: Survivability and Latency},
year={2007},
volume={},
number={},
pages={652-660},
abstract={This paper addresses the dynamics of broadcast flooding in random wireless ad hoc networks. In particular, we study the subset of nodes covered by a flood as well as timing issues related to the first (latency) and the last time (duration of back-chatter) at which a broadcast is received by a fixed node. Notably, this analysis takes into account the MAC-layer as well as background traffic which both are often neglected in related studies. Assuming a protocol model for the transmission channel which accounts for carrier sensing and interference, we find bounds for the probability of survival of the flood and for its coverage probabilities. Moreover, under certain conditions on the parameters, we establish asymptotical linear bounds on the latency as the distance from the origin of the flood increases and show that the duration of the back-chatter is stochastically bounded. The analytical results are compared to simulation.},
keywords={access protocols;ad hoc networks;mobile radio;probability;random processes;routing protocols;telecommunication traffic;broadcast flooding;random wireless ad hoc network;MAC layer;network traffic;probability;asymptotical linear bound;mobile radio;routing protocol;Floods;Delay;Radio broadcasting;Mobile ad hoc networks;Spine;Telecommunication traffic;Peer to peer computing;Traffic control;Interference;Routing protocols},
doi={10.1109/INFCOM.2007.82},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215665,
author={A. Nguyen and N. Milosavljevic and Q. Fang and J. Gao and L. J. Guibas},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Landmark Selection and Greedy Landmark-Descent Routing for Sensor Networks},
year={2007},
volume={},
number={},
pages={661-669},
abstract={We study the problem of landmark selection for landmark-based routing in a network of fixed wireless communication nodes. We present a distributed landmark selection algorithm that does not rely on global clock synchronization, and a companion local greedy landmark-based routing scheme. We assume no node location information, and that each node can communicate with some of its geographic neighbors. Each node is named by its hop count distances to a small number of nearby landmarks. Greedy routing at a node is performed to equalize its vector of landmark distances to that of the destination. This is done by following the shortest path to the landmark that maximizes the ratio of its distances to the source and the destination. In addition, we propose a method to alleviate the difficulty in routing to destinations near the boundaries by virtually expanding the network boundaries. The greedy routing, when combined with our landmark selection scheme, has a provable bounded path stretch relative to the best path possible, and guarantees packet delivery in the continuous domain. In the discrete domain, our simulations show that the landmark selection scheme is effective, and the companion routing scheme performs well under realistic settings. Both the landmark selection and greedy routing assumes no specific communication model and works with asymmetric links. Although some of the analysis are non-trivial, the algorithms are simple, flexible and cost-effective enough to warrant a real-world deployment.},
keywords={ad hoc networks;distributed algorithms;greedy algorithms;protocols;synchronisation;telecommunication network routing;wireless sensor networks;distributed landmark selection protocol;greedy landmark-descent routing;sensor networks;wireless ad hoc networks;clock synchronization;Routing;Tiles;Peer to peer computing;Computer science;Force sensors;Communications Society;Wireless sensor networks;Wireless communication;Clocks;Synchronization},
doi={10.1109/INFCOM.2007.83},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215666,
author={M. S. Nassr and J. Jun and S. J. Eidenbenz and A. A. Hansson and A. M. Mielke},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Scalable and Reliable Sensor Network Routing: Performance Study from Field Deployment},
year={2007},
volume={},
number={},
pages={670-678},
abstract={Scalable and reliable routing is a critical issue in sensor network deployment. A number of approaches have been proposed for sensor network routing, but sensor field implementation tends to be lacking in the literature. In our study, the problems of scalability and reliability in sensor network routing are addressed through a simple but powerful scheme implemented on Mica2 motes running TinyOS along with other, more widely-used routing protocols. Motes are tested in an outdoor sensor field, and detailed experiments are carried out for performance analysis. This paper presents the implementation details and the results obtained from head-to-head comparison of routing protocols. The proposed protocol delivers 93% of packets injected at a rate of one packet per second in networks with end to end hop distances of over 10 hops-a result which significantly improves upon results from the standard TinyOS routing implementation of MINTRoute. The promising results can be explained by the key protocol properties of reliability (via multi-path redundancy), scalability (with efficiently contained flooding), and flexibility (source-tunable per-packet priority) which are achieved without adding protocol complexity or resource consumption. These strengths enable the protocol to outperform even sophisticated link estimation based protocols especially in adverse outdoor sensor field environments.},
keywords={routing protocols;telecommunication network reliability;wireless sensor networks;sensor network routing scalability problem;sensor network routing reliability problem;sensor network deployment;Mica2 motes;TinyOS;routing protocols;multipath redundancy;source-tunable per-packet priority;protocol complexity;resource consumption;outdoor sensor field environments;Telecommunication network reliability;Scalability;Routing protocols;Wireless sensor networks;Ad hoc networks;Capacitive sensors;Sensor systems;Mobile ad hoc networks;Computer networks;Bandwidth},
doi={10.1109/INFCOM.2007.84},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215667,
author={Y. -. Chen and C. -. Chang and J. Cheng and D. -. Lee and C. -. Huang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Feedforward SDL Constructions of Output-Buffered Multiplexers and Switches with Variable Length Bursts},
year={2007},
volume={},
number={},
pages={679-687},
abstract={In this paper, we study the problem of exact emulation of two types of optical queues: (i) <i>N</i>-to-1 output-buffered multiplexers with variable length bursts, and (ii) N times N output-buffered switches with variable length bursts. For both queues, the delay of a packet (in a burst) is known upon its arrival. As such, one can emulate such queues by finding a delay path that yields the exact delay for each packet. For emulating the delay of a packet in such queues, in this paper we consider a multistage feedforward network with optical crossbar switches and fiber delay lines (SDL). For any fixed delay d, there exist multiple delay paths in such a network. A delay path is feasible if it satisfies the following three constraints: (i) conflict constraint: no more than one packet can be scheduled at the same input/output ports of each crossbar switch at the same time, (ii) causality constraint: no packet can be scheduled before its arrival, and (iii) strong contiguity constraint: packets in the same burst should be routed through any fiber delay lines contiguously. By the worst case analysis, we find sufficient conditions for the numbers of delay lines needed in each stage of such a feedforward network to achieve exact emulation of both queues. For N-to-1 output-buffered multiplexers, our sufficient conditions are also necessary when each burst contains exactly one packet. By computer simulation, we also show that the number of delay lines in each stage can be greatly reduced due to statistical multiplexing gain.},
keywords={multiplexing;optical burst switching;optical fibre networks;optical switches;packet switching;queueing theory;feedforward SDL construction;output-buffered multiplexer;variable length burst;optical queues;multistage feedforward network;optical crossbar switch;fiber delay line;Multiplexing;Delay lines;Optical switches;Emulation;Optical fiber networks;Sufficient conditions;Optical packet switching;Delay effects;Packet switching;Time factors},
doi={10.1109/INFCOM.2007.85},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215668,
author={C. -. Chang and T. -. Chao and J. Cheng and D. -. Lee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Constructions of Fault Tolerant Linear Compressors and Linear Decompressors},
year={2007},
volume={},
number={},
pages={688-696},
abstract={The constructions of optical buffers is one of the most critically sought after optical technologies in all-optical packet-switched networks, and constructing optical buffers directly via optical switches and fiber delay lines (SDL) has received a lot of attention recently in the literature. A practical and challenging issue of the constructions of optical buffers that has not been addressed before is on the fault tolerant capability of such constructions. In this paper, we focus on the constructions of fault tolerant linear compressors and linear decompressors. The basic network element for our constructions is scaled optical memory cell, which is constructed by a 2 x 2 optical crossbar switch and a fiber delay line. We give a multistage construction of a self-routing linear compressor by a concatenation of scaled optical memory cells. We also show that if the delays, say d<sub>1</sub>,d<sub>2</sub>,... ,d<sub>m</sub> , of the fibers in the scaled optical memory cells satisfy a certain condition (specifically, the condition in (A 2) given in Section I), then our multistage construction can be operated as a self-routing linear compressor with maximum delay Sigma <sup>M-F</sup> <sub>i=1</sub> d <sub>i</sub> even after up to F of the M scaled optical memory cells fail to function properly, where 0 les F les M - 1. Furthermore, we prove that our multistage construction with the fiber delays d1, d2, ... , d <sub>M</sub> given by the generalized Fibonacci sequence of order F is the best among all constructions of a linear compressor that can tolerate up to F faulty scaled optical memory cells by using M scaled optical memory cells. Similar results are also obtained for the constructions of fault tolerant linear decompressors.},
keywords={data compression;fault tolerance;optical delay lines;optical storage;optical switches;fault tolerant linear compressors;optical buffers;all-optical packet-switched networks;optical switches;fiber delay lines;fault tolerant capability;scaled optical memory cell;optical crossbar switch;self-routing linear compressor;multistage construction;fault tolerant linear decompressors;Fault tolerance;Compressors;Optical buffering;Optical packet switching;High speed optical techniques;Delay lines;Optical fiber networks;Optical switches;Electron optics;Optical design},
doi={10.1109/INFCOM.2007.86},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215669,
author={N. J. A. Harvey and M. Patrascu and Y. Wen and S. Yekhanin and V. W. S. Chan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Non-Adaptive Fault Diagnosis for All-Optical Networks via Combinatorial Group Testing on Graphs},
year={2007},
volume={},
number={},
pages={697-705},
abstract={We consider the problem of detecting failures for all-optical networks, with the objective of keeping the diagnosis cost low. Compared to the passive paradigm based on parity check in SONET, optical probing signals are sent proactively along lightpaths to probe their state of health and failure pattern is identified through the set of test results (i.e., probe syndromes). As an alternative to our previous adaptive approach where all the probes are sent sequentially, we consider in this work a non-adaptive approach where all the probes are sent in parallel. The design objective is to minimize the number of parallel probes, so as to keep network cost low. The non-adaptive fault diagnosis approach motivates a new technical framework that we introduce: combinatorial group testing with graph-based constraints. Using this framework, we develop several new probing schemes to detect network faults for all-optical networks with different topologies. The efficiency of our schemes often depends on the network topology; in many cases we can show that our schemes are optimal in minimizing the number of probes.},
keywords={fault diagnosis;graph theory;optical fibre networks;SONET;telecommunication network management;telecommunication network topology;nonadaptive fault diagnosis;all-optical network;combinatorial group testing;graph theory;failure detection;parity check;SONET;optical probing signal;network topology;network management;Fault diagnosis;All-optical networks;Testing;Probes;Costs;Network topology;Parity check codes;SONET;Signal processing;Fault detection},
doi={10.1109/INFCOM.2007.87},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215670,
author={H. Kogan and I. Keslassy},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal-Complexity Optical Router},
year={2007},
volume={},
number={},
pages={706-714},
abstract={In the past years, electronic routers have had trouble keeping up with the increase in optical fiber capacity. As their power consumption has grown exponentially and already exceeds standards, it seems that an alternative solution is mandatory. Many have suggested all-optical routers as an alternative. However, these are deemed too complex, especially given the need to implement both switching and buffering, even though their fundamental complexity has apparently never been analyzed. In this paper, we study the number of fundamental optical components (2 times 2 switches and fiber delay lines) needed to emulate ideal routers. We first demonstrate that an N times N router with a buffer size of B per port needs at least thetas(N log(N B)) components, and then build a construction that achieves this lower bound. On the way, we also present an optical buffer construction of size B that works with thetas(log(B)) components, which is also shown to be a lower bound. Finally, we generalize this result to different router architectures and scheduling disciplines.},
keywords={buffer storage;optical fibre networks;routing protocols;optimal-complexity optical router;optical buffer construction;routing protocol;Optical buffering;Delay lines;Optical switches;Energy consumption;Optical packet switching;Optical fibers;Optical fiber communication;Routing protocols;Communications Society;Optical devices},
doi={10.1109/INFCOM.2007.88},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215671,
author={V. Bhandari and N. H. Vaidya},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Reliable Broadcast in Wireless Networks with Probabilistic Failures},
year={2007},
volume={},
number={},
pages={715-723},
abstract={We consider the problem of reliable broadcast in a wireless network in which nodes are prone to failure. Each node can fail independently with probability p. Failures are permanent. The primary focus is on Byzantine failures, but we also handle crash-stop failures. We consider two network models: a regular grid, and a random network. Our necessary and sufficient conditions for the Byzantine failure model indicate that p should be less than frac12, and the critical node degree is Theta(d<sub>min</sub>+(ln<i>n</i>/ln(1/2p))+ln(1/2(1-p))) (where d<sub>min</sub> is the minimum node degree associated with a non-empty neighborhood, and is a small constant). For a random network we prove that, for failure probability less than frac12, the critical average degree for reliable broadcast is O(ln<i>n</i>/frac12-p+frac12ln(1/2(1-p))). We briefly discuss the issue of crash-stop failures for which we have results that improve upon previously existing results for this model, when p approaches 0. We also identify an interesting similarity in the structure of various known results in the literature pertaining to a set of related problems in the realm of connectivity and reliable broadcast.},
keywords={broadcasting;failure analysis;radio networks;telecommunication network reliability;reliable broadcast;wireless networks;probabilistic failures;Byzantine failures;crash-stop failures;critical node degree;random network;critical average degree;Broadcasting;Wireless networks;Computer crashes;Peer to peer computing;Computer network reliability;Wireless sensor networks;Communications Society;Telecommunication network reliability;Computer science;Computer networks},
doi={10.1109/INFCOM.2007.89},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215672,
author={J. Liu and D. Goeckel and D. Towsley},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Bounds on the Gain of Network Coding and Broadcasting in Wireless Networks},
year={2007},
volume={},
number={},
pages={724-732},
abstract={Gupta and Kumar established that the per node throughput of ad hoc networks with multi-pair unicast traffic scales (poorly) as lambda(n) = Theta (1 / radic(n log n)) with an increasing number of nodes n. However, Gupta and Kumar did not consider the possibility of network coding and broadcasting in their model, and recent work has suggested that such techniques have the potential to greatly improve network throughput. In [1], we have shown that for the protocol communication model of Gupta and Kumar [2], the multi-unicast throughput of schemes using arbitrary network coding and broadcasting in a two-dimensional random topology also scales as lambda(n) = Theta (1 / radic(n log n))<sup>1</sup>, thus showing that network coding provides no order difference improvement on throughput. Of course, in practice the constant factor of improvement is important; thus, here we derive bounds for the throughput benefit ratio -the ratio of the throughput of the optimal network coding scheme to the throughput of the optimal non-coding flow scheme. We show that the improvement factor is 1+ Delta / 1+Delta /2for 1D random networks, where Delta &gt; 0 is a parameter of the wireless medium that characterizes the intensity of the interference. We obtain this by giving tight bounds (both upper and lower) on the throughput of the coding and flow schemes. For 2D networks, we obtain an upper bound for the throughput benefit ratio as alpha (n) les 2c<sub>Delta</sub> radic(pi = 1+Delta/Delta) for large n, wnere c<sub>Delta</sub> = max {2, radic(Delta<sup>2</sup> + 2Delta)}. This is obtained by finding an upper bound for the coding throughput and a lower bound for the flow throughput. We then consider the more general physical communication model as in Gupta and Kumar. We show that the coding scheme throughput in this case is upper bounded by Theta (1/n) for the 1D random network and by Theta(1/radic(n)) for the 2D case. We also show the flow scheme throughput for the ID case can achieve the same order throughput as the coding scheme. Combined with previous work on a 2D lower bound [3], we conclude that the throughput benefit ratio under the physical model is also bounded by a constant; thus, we have shown for both the protocol and physical model that the coding benefit in terms of throughput is a constant factor. Finally, we evaluate the potential coding gain from another important perspective - total energy efficiency - and show that the factor by which the total energy is decreased is upper bounded by 3.},
keywords={ad hoc networks;broadcasting;encoding;protocols;telecommunication network topology;telecommunication traffic;network coding;broadcasting;wireless network;multipair unicast traffic scale;protocol communication model;two-dimensional random topology;1D random network;Network coding;Broadcasting;Wireless networks;Throughput;Protocols;Upper bound;Ad hoc networks;Unicast;Telecommunication traffic;Traffic control},
doi={10.1109/INFCOM.2007.90},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215673,
author={S. C. -. Huang and P. -. Wan and X. Jia and H. Du and W. Shang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Minimum-Latency Broadcast Scheduling in Wireless Ad Hoc Networks},
year={2007},
volume={},
number={},
pages={733-739},
abstract={A wide range of applications for wireless ad hoc networks are time-critical and impose stringent requirement on the communication latency. This paper studies the problem Minimum-Latency Broadcast Scheduling (MLBS) in wireless ad hoc networks represented by unit-disk graphs. This problem is NP-hard. A trivial lower bound on the minimum broadcast latency is the radius R of the network with respect to the source of the broadcast, which is the maximum distance of all the nodes from the source of the broadcast. The previously best-known approximation algorithm for MLBS produces a broadcast schedule with latency at most 648 R. In this paper, we present three progressively improved approximation algorithms for MLBS. They produce broadcast schedules with latency at most 24 R -23, 16 R -15, and R + O (log R) respectively.},
keywords={ad hoc networks;approximation theory;broadcasting;computational complexity;graph theory;minimisation;multicast communication;scheduling;minimum-latency broadcast scheduling;wireless ad hoc networks;unit-disk graphs;approximation algorithm;minimum-latency multisource multicast scheduling;Mobile ad hoc networks;Delay;Approximation algorithms;Processor scheduling;Computer science;Peer to peer computing;Scheduling algorithm;Time factors;Radio broadcasting;Communications Society},
doi={10.1109/INFCOM.2007.91},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215674,
author={Z. Chen and C. Qiao and J. Xu and T. Lee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Constant Approximation Algorithm for Interference Aware Broadcast in Wireless Networks},
year={2007},
volume={},
number={},
pages={740-748},
abstract={Broadcast protocols play a vital role in multihop wireless networks. Due to the broadcast nature of radio signals, a node's interference range can be larger than its transmission range, i.e., it can interfere with other node's reception even if the latter is not within its transmission range. To design an efficient broadcast protocol, both the collision and the interference among multiple transmissions must be addressed. However, most of the previous works on wireless broadcast protocols either treated interference in the same way as collision or did not consider interference at all. In this paper, we study a more general model in which interference is distinguished from collision, and propose a simple and yet efficient interference and collision free broadcast protocol. Our objective is to minimize the makespan, i.e., the earliest time such that every node receives the message. By exploiting the geometry property of the nodes that interfere with each other, we show that our algorithm is a constant approximation algorithm, it guarantees to deliver the message to all nodes within a small constant factor of the optimal makespan. We apply our algorithm under both the unit disk graph model and the more realistic radio irregularity model. The experimental results show that our algorithm consistently outperforms the previous algorithms.},
keywords={graph theory;interference;protocols;radio broadcasting;radio networks;approximation algorithm;interference aware wireless broadcast protocol;multihop wireless network;collision free broadcast protocol;unit disk graph model;realistic radio irregularity model;Approximation algorithms;Interference;Wireless networks;Radio broadcasting;Peer to peer computing;Spread spectrum communication;Wireless application protocol;Geometry;Communications Society;Computer science},
doi={10.1109/INFCOM.2007.92},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215675,
author={H. Wu and K. Tan and Y. Zhang and Q. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Proactive Scan: Fast Handoff with Smart Triggers for 802.11 Wireless LAN},
year={2007},
volume={},
number={},
pages={749-757},
abstract={It has been a challenging problem to support VoIP-type delay sensitive applications in an 802.11 wireless LAN, because the standard handoff procedure implemented in many current 802.11 products occurs a delay deem unacceptable to VoIP users. To reduce this delay, we have developed a fast handoff scheme called Proactive Scan. It employs two new techniques. The first is to decouple the time-consuming channel scan from the actual handoff, and to eliminate channel scan delay by doing scan early and interleaving it with ongoing traffic in a non-intrusive way. The second technique is a smart trigger that takes into account both uplink and downlink quality and explicitly addresses the link asymmetry which has yet not been touched in previous work. Through implementation and experimentation study, we have shown that Proactive Scan does provide fast handoff and satisfactory performance to VoIP applications. Further, it is a software-only client-only solution that any mobile device can use in any existing 802.11 networks.},
keywords={Internet telephony;mobile radio;wireless LAN;802.11 wireless LAN trigger;VoIP-type delay sensitive application;proactive scan handoff procedure;mobile device;Wireless LAN;Delay;Roaming;Downlink;Application software;Hardware;Communications Society;Wireless sensor networks;Asia;Interleaved codes},
doi={10.1109/INFCOM.2007.93},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215676,
author={W. -. Hsu and T. Spyropoulos and K. Psounis and A. Helmy},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Modeling Time-Variant User Mobility in Wireless Mobile Networks},
year={2007},
volume={},
number={},
pages={758-766},
abstract={Realistic mobility models are important to understand the performance of routing protocols in wireless ad hoc networks, especially when mobility-assisted routing schemes are employed, which is the case, for example, in delay-tolerant networks (DTNs). In mobility-assisted routing, messages are stored in mobile nodes and carried across the network with nodal mobility. Hence, the delay involved in message delivery is tightly coupled with the properties of nodal mobility. Currently, commonly used mobility models are simplistic random i.i.d. model that do not reflect realistic mobility characteristics. In this paper we propose a novel time-variant community mobility model. In this model, we define communities that are visited often by the nodes to capture skewed location visiting preferences, and use time periods with different mobility parameters to create periodical re-appearance of nodes at the same location. We have clearly observed these two properties based on analysis of empirical WLAN traces. In addition to the proposal of a realistic mobility model, we derive analytical expressions to highlight the impact on the hitting time and meeting times if these mobility characteristics are incorporated. These quantities in turn determine the packet delivery delay in mobility-assisted routing settings. Simulation studies show our expressions have error always under 20%, and in 80% of studied cases under 10%.},
keywords={ad hoc networks;mobile radio;routing protocols;wireless LAN;wireless mobile ad hoc network;time-variant user mobility modeling;routing protocol;delay-tolerant network;wireless LAN;message delivery;Wireless LAN;Peer to peer computing;Routing protocols;Delay;Proposals;Wireless communication;Ad hoc networks;Wireless networks;Mathematical model;Communications Society},
doi={10.1109/INFCOM.2007.94},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215677,
author={M. Varshney and R. Bagrodia},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Performance Implication of Environmental Mobility in Wireless Networks},
year={2007},
volume={},
number={},
pages={767-775},
abstract={Environmental mobility refers to the ambient motion of people, vehicles and other objects in the vicinity of wireless communication. Whereas the effect of mobility of transmitting and receiving radios has been widely researched, the impact of environmental mobility has been relatively unexplored in wireless networks. In this paper, we present a systematic study to analyze the effect of environmental mobility on wireless link behavior and protocol performance using measurement, analysis, and simulations. Measurement data from channel traces was collected to isolate and quantify the effects of environmental mobility on the channel performance. Efficient models were developed to explain the observed behavior and integrated with network simulation to enable protocol level analysis under such dynamics. We found that the class of protocols that maintain state or have memory but are otherwise agnostic of the channel operations fare poorly by acquiring incorrect information about the channel and are not able to adequately exploit durations where channel conditions are good. Two case studies at different layers of protocol stack are used to quantify such behavior to show that protocol perform maybe as much as 20-50% below their expected performance. To remedy this situation we present a cross layer optimization scheme, called Recovery from Earlier Good State (REGS), that allows protocols to become aware of the underlying channel operations. We show that use of REGS together with existing optimizations can improve throughputs in the presence of EM by more than 100%.},
keywords={mobile radio;protocols;wireless channels;environmental mobility;wireless network;protocol performance;channel operation;Wireless networks;Performance analysis;Fading;Analytical models;Vehicle dynamics;Mobile computing;Computer science;Wireless communication;Wireless application protocol;Scattering},
doi={10.1109/INFCOM.2007.95},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215678,
author={N. Banerjee and M. D. Corner and B. N. Levine},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Energy-Efficient Architecture for DTN Throwboxes},
year={2007},
volume={},
number={},
pages={776-784},
abstract={Disruption Tolerant Networks rely on intermittent contacts between mobile nodes to deliver packets using store-carry-and-forward paradigm. The key to improving performance in DTNs is to engineer a greater number of transfer opportunities. We earlier proposed the use of throwbox nodes, which are stationary, battery powered nodes with storage and processing, to enhance the capacity of DTNs. However, the use of throwboxes without efficient power management is minimally effective. If the nodes are too liberal with their energy consumption, they will fail prematurely. However if they are too conservative, they may miss important transfer opportunities, hence increasing lifetime without improving performance. In this paper, we present a hardware and software architecture for energy efficient throwboxes in DTNs. We propose a hardware platform that uses a multi-tiered, multi-radio, scalable, solar powered platform. The throwbox employs an approximate heuristic for solving the NP-Hard problem of meeting an average power constraint while maximizing the number of bytes forwarded by it. We built and deployed prototype throwboxes in UMassDieselNet -a bus DTN testbed. Through extensive trace-driven simulations and prototype deployment we show that a single throwbox with a 270 cm<sup>2</sup> solar panel can run perpetually while improving packet delivery by 37% and reducing message delivery latency by at least 10% in the network.},
keywords={computational complexity;mobile communication;optimisation;power consumption;energy-efficient architecture;disruption tolerant networks;mobile nodes;packet delivery;store-carry-and-forward paradigm;throwbox nodes;battery powered nodes;power management;energy consumption;hardware-software architecture;energy efficient throwboxes;NP-hard problem;UMassDieselNet;trace-driven simulations;message delivery latency;Energy efficiency;Disruption tolerant networking;Hardware;Power engineering and energy;Batteries;Energy management;Energy consumption;Software architecture;NP-hard problem;Prototypes},
doi={10.1109/INFCOM.2007.96},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215679,
author={V. Bhandari and N. H. Vaidya},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Connectivity and Capacity of Multi-Channel Wireless Networks with Channel Switching Constraints},
year={2007},
volume={},
number={},
pages={785-793},
abstract={This paper argues for the need to address the issue of multi-channel network performance under constraints on channel switching. We present examples from emergent directions in wireless networking to motivate the need for such a study, and introduce some models to capture channel switching constraints. For some of these models, we study connectivity and capacity of a wireless network comprising n randomly deployed nodes, equipped with a single interface each, when there are c=O(logn) channels of equal bandwidth W/c available. We consider an adjacent (c,f) channel assignment where a node may switch between f adjacent channels, but the adjacent channel block is randomly assigned. We show that the per-flow capacity for this channel assignment model is Theta(Wradic(f/cnlogn)). We then show the adjacent (c,2) assignment maps to the case of untuned radios. We also consider a random (c,f) assignment where each node may switch between a pre-assigned random subset of f channels. For this model, we prove that per-flow capacity is O(Wradic(p<sub>rnd</sub>/nlogn)) (where p<sub>rnd</sub>=1-(1-f/c)(1-f/(c-1))...(1-f/(c-f+1)) and Omega(Wradic(f/cnlogn))).},
keywords={channel allocation;channel capacity;radio networks;telecommunication switching;wireless channels;multichannel wireless network performance;channel switching constraint;adjacent channel block;channel assignment model;channel capacity;Wireless networks;Switches;Peer to peer computing;Cognitive radio;Wireless sensor networks;Transceivers;Manufacturing;Frequency;Spread spectrum communication;Constraint theory},
doi={10.1109/INFCOM.2007.97},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215680,
author={T. C. Clancy},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Achievable Capacity Under the Interference Temperature Model},
year={2007},
volume={},
number={},
pages={794-802},
abstract={The interference temperature model was proposed by the FCC in 2003 as a way to dynamically manage and allocate spectrum resources. It would allow unlicensed radios to sense their current RF environment and transmit in licensed bands, provided their transmission does not raise the interference temperature for that frequency band over the interference temperature limit. It never received much interest because nobody was sure exactly how to use it or how if it would work. This research focuses on a mathematical analysis of the interference temperature model in an effort to examine the relationships between the capacity achieved by the unlicensed network and the interference caused to the licensed network. We develop a model for the RF environment and determine probability distributions governing interference temperature as a function of various elements in the model. We then determine bounds on the amount of interference caused by implementing such a system. We examine model environments for a wireless WAN and a wireless LAN, each coexisting with a licensed carrier. For each, we quantify both the impact on the licensed signal and also the capacity achieved by our underlay network. By substituting numeric values for RF environments in which the interference temperature model might be applied, we show that achievable capacity is very small, while the impact the licensee can be very large. Based on this, we propose alternate usages for interference temperature and ways to boost capacity.},
keywords={channel capacity;interference (signal);statistical distributions;wide area networks;wireless LAN;interference temperature model;achievable capacity;unlicensed network;probability distributions;wireless WAN;wireless LAN;Temperature sensors;Radiofrequency interference;Radio frequency;Resource management;Wireless LAN;FCC;Mathematical analysis;Mathematical model;Probability distribution;Temperature distribution},
doi={10.1109/INFCOM.2007.98},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215681,
author={T. -. Lin and J. C. Hou},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Interplay of Spatial Reuse and SINR-Determined Data Rates in CSMA/CA-Based, Multi-Hop, Multi-Rate Wireless Networks},
year={2007},
volume={},
number={},
pages={803-811},
abstract={In CSMA/CA-based, multi-hop, multi-rate wireless networks, spatial reuse can be increased by tuning the carrier-sensing threshold (T<sub>cs</sub>) to reduce the carrier sense range (d<sub>cs</sub>). While reducing d<sub>cs</sub> enables more concurrent transmissions, the transmission quality suffers from the increased accumulative interference contributed by concurrent transmissions outside d<sub>cs</sub>. As a result, the data rate at which the transmission can sustain may decrease. How to balance the interplay of spatial reuse and transmission quality (and hence the sustainable data rate) so as to achieve high network capacity is thus an important issue. In this paper, we investigate this issue by extending Cali's model and devising an analytical model that characterizes the transmission activities as governed by IEEE 802.11 DCF in a single-channel, multi-rate, multi-hop wireless network. The systems throughput is derived as a function of T<sub>cs</sub>, SINR, beta, and other PHY/MAC systems parameters. We incorporate the effect of varying the degree of spatial reuse by tuning the T<sub>cs</sub>. Based on the physical radio propagation model, we theoretically estimate the potential accumulated interference contributed by concurrent transmissions and the corresponding SINR. For a given SINR value, we then determine an appropriate data rate at which a transmission can sustain. To the best of our knowledge, this is perhaps the first effort that considers tuning of PHY characteristics (transmit power and data rates) and MAC parameters (contention backoff timer) jointly in an unified framework in order to optimize the overall network throughput. Analytical results indicate that the systems throughput is not a monotonically increasing/decreasing function of T<sub>cs</sub>, but instead exhibits transitional points where several possible choices of T<sub>cs</sub> can be made. In addition, the network capacity can be further improved by choosing the backoff timer values appropriately.},
keywords={carrier sense multiple access;IEEE standards;wireless LAN;interplay;spatial reuse;SINR-determined data rates;multihop networks;multirate wireless networks;CSMA/CA-based networks;the carrier-sensing threshold;carrier sense range;concurrent transmissions;Cali model;IEEE 802.11 DCF;single-channel;PHY/MAC systems parameters;physical radio propagation model;MAC parameters;Multiaccess communication;Spread spectrum communication;Wireless networks;Throughput;Signal to noise ratio;Interference;Physical layer;Analytical models;Radio propagation;Estimation theory},
doi={10.1109/INFCOM.2007.99},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215682,
author={M. Felegyhazi and M. Cagalj and D. Dufour and J. -. Hubaux},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Border Games in Cellular Networks},
year={2007},
volume={},
number={},
pages={812-820},
abstract={In each country today, cellular networks operate on carefully separated frequency bands. This separation is imposed by the regulators of the given country to avoid interference between these networks. But, the separation is only valid within the borders of a country, hence the operators are left on their own to resolve cross-border interference of their cellular networks. In this paper, we focus on the scenario of two operators, each located on one side of the border. We assume that they want to fine-tune the emitting power of the pilot signals (i.e., beacon signals) of their base stations. This operation is crucial, because the pilot signal power determines the number of users they can attract and hence the revenue they can obtain. In the case of no power costs, we show that there exists a motivation for the operators to be strategic, meaning to fine-tune the pilot signal powers of their base stations. In addition, we study Nash equilibrium conditions in an empirical model and investigate the efficiency of the Nash equilibria for different user densities. Finally, we modify our game model to take power costs into account. The game with power costs corresponds to the well-known prisoner's dilemma: The players are still motivated to adjust their pilot powers, but their strategic behavior leads to a sub-optimal Nash equilibrium.},
keywords={cellular radio;code division multiple access;game theory;interference suppression;cellular networks;border games;cross-border interference avoidance;Nash equilibria;pilot power control;CDMA networks;Land mobile radio cellular systems;Base stations;Costs;Multiaccess communication;Frequency;Interference;Nash equilibrium;Power control;Electronic mail;3G mobile communication},
doi={10.1109/INFCOM.2007.100},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215683,
author={D. Guo and J. Wu and H. Chen and X. Luo},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Moore: An Extendable Peer-to-Peer Network Based on Incomplete Kautz Digraph with Constant Degree},
year={2007},
volume={},
number={},
pages={821-829},
abstract={The topological properties of peer-to-peer overlay networks are critical factors that dominate the performance of these systems. Several non-constant and constant degree interconnection networks have been used as topologies of many peer-to-peer networks. One of these has many desirable properties: the Kautz digraph. Unlike interconnection networks, peer-to-peer networks need a topology with an arbitrary size and degree, but the complete Kautz digraph does not possess these properties. In this paper, we propose Moore: the first effective and practical peer-to-peer network based on the incomplete Kautz digraph with <i>O</i>(log<i> <sub>d</sub> </i> <i>N</i>) diameter and constant degree under a dynamic environment. The diameter and average routing path length are [log<i> <sub>d</sub> </i>(<i>N</i>) - log<i> <sub>d</sub> </i>(1 + 1/<i>d</i>)] and log<i> <sub>d</sub> </i> <i>N</i>, respectively, and are shorter than that of CAN, butterfly, and cube-connected-cycle. They are close to that of complete de Bruijn and Kautz digraphs. The message cost of node joining and departing operations are at most 2.5 <i>d</i> log<i> <sub>d</sub> </i> <i>N</i> and (2.5 <i>d</i> + 1) log<i> <sub>d</sub> </i> <i>N</i>, and only <i>d</i> and 2<i>d</i> nodes need to update their routing tables. Moore can achieve optimal diameter, high performance, good connectivity and low congestion evaluated by formal proofs and simulations.},
keywords={directed graphs;peer-to-peer computing;telecommunication network routing;telecommunication network topology;peer-to-peer overlay network;Kautz digraph;interconnection network;network topology;routing table;Moore network;Peer to peer computing;Network topology;Routing;Multiprocessor interconnection networks;Costs;Hypercubes;Communications Society;Laboratories;Educational institutions;Management information systems},
doi={10.1109/INFCOM.2007.101},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215684,
author={Y. Li and Y. Zhang and L. Qiu and S. Lam},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={SmartTunnel: Achieving Reliability in the Internet},
year={2007},
volume={},
number={},
pages={830-838},
abstract={Reliability is critical to a variety of network applications. Unfortunately, due to lack of QoS support across ISP boundaries, it is difficult to achieve even two 9s (99%) reliability in toadyism Internet. In this paper, we propose SmartTunnel, an end-to-end approach to achieving reliability. A SmartTunnel is a logical point-to-point tunnel between two end points that spans multiple physical network paths. It achieves reliability by strategically allocating traffic onto multiple paths and performing FEC coding. Such an end-to-end approach requires no explicit QoS support from intermediate ISPs, and is therefore easy to deploy in today's Internet. To fully realize the potential of SmartTunnel, we analytically derive near-optimal traffic allocation schemes that minimize loss rates. We extensively evaluate our approach using trace-driven simulations, ns-2 simulations, and experiments on PlanetLab. Our results clearly demonstrate that SmartTunnel is effective in achieving high reliability.},
keywords={computer network reliability;Internet;quality of service;telecommunication traffic;Internet service provider;QoS;logical point-to-point tunnel;multiple physical network path reliability;near-optimal traffic allocation;quality of service;Forward error correction;Extraterrestrial measurements;Telecommunication traffic;Routing;Computer network reliability;Protection;Telecommunication network reliability;Traffic control;Internet telephony;Loss measurement},
doi={10.1109/INFCOM.2007.102},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215685,
author={Y. Zhu and C. Dovrolis and M. Ammar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Combining Multihoming with Overlay Routing (or, How to Be a Better ISP without Owning a Network)},
year={2007},
volume={},
number={},
pages={839-847},
abstract={Multihoming and overlay routing are used, mostly separately, to bypass Internet outages, congested links and long routes. In this paper, we examine a scenario in which multihoming and overlay routing are jointly used. Specifically, we assume that an overlay service provider (OSP) aims to offer its customers the combined benefits of multihoming and overlay routing, in terms of improved performance, availability and reduced cost, through a network of multihomed overlay routers. We focus on the corresponding design problem, i.e., where to place the overlay routers and how to select the upstream ISPs for each router, with the objective to maximize the profit of the OSP. We examine, with realistic network performance and pricing data, whether the OSP can provide a network service that is profitable, better (in terms of round-trip time), and less expensive than the competing native ISPs. Perhaps surprisingly, we find out that the OSP can meet all three objectives at the same time. We also show that the MON design process is crucial. For example, operating more than 10 overlay nodes or routing traffic through the minimum-delay overlay path, rarely leads to profitability in our simulations.},
keywords={Internet;telecommunication network routing;telecommunication traffic;ISP;Internet service provider;multihomed overlay router;network traffic;minimum-delay overlay path;Routing;Availability;Costs;Traffic control;IP networks;Internet;Communication system traffic control;Communications Society;Pricing;Process design},
doi={10.1109/INFCOM.2007.103},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215686,
author={N. Laoutaris and G. Zervas and A. Bestavros and G. Kollios},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={The Cache Inference Problem and its Application to Content and Request Routing},
year={2007},
volume={},
number={},
pages={848-856},
abstract={In many networked applications, independent caching agents cooperate by servicing each other's miss streams, without revealing the operational details of the caching mechanisms they employ. Inference of such details could be instrumental for many other processes. For example, it could be used for optimized forwarding (or routing) of one's own miss stream (or content) to available proxy caches, or for making cache-aware resource management decisions. In this paper, we introduce the cache inference problem (CIP) as that of inferring the characteristics of a caching agent, given the miss stream of that agent. While CIP is insolvable in its most general form, there are special cases of practical importance in which it is, including when the request stream follows an independent reference model (IRM) with generalized power-law (GPL) demand distribution. To that end, we design two basic "litmus" tests that are able to detect the LFU and LRU replacement policies, the effective size of the cache and of the object universe, and the skewness of the GPL demand for objects. Using extensive experiments under synthetic as well as real traces, we show that our methods infer such characteristics accurately and quite efficiently, and that they remain robust even when the IRM/GPL assumptions do not hold, and even when the underlying replacement policies are not "pure" LFU or LRU. We demonstrate the value of our inference framework by considering example applications.},
keywords={cache storage;computer networks;resource allocation;telecommunication network routing;cache inference problem;request routing stream;independent reference model;generalized power-law demand distribution;Routing;Web server;Communications Society;Helium;Instruments;Resource management;Testing;Object detection;Robustness;Concrete},
doi={10.1109/INFCOM.2007.104},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215687,
author={M. Guirguis and A. Bestavros and I. Matta and Y. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Reduction of Quality (RoQ) Attacks on Dynamic Load Balancers: Vulnerability Assessment and Design Tradeoffs},
year={2007},
volume={},
number={},
pages={857-865},
abstract={One key adaptation mechanism often deployed in networking and computing systems is dynamic load balancing. The goal from employing dynamic load balancers is to ensure that the offered load would be judiciously distributed across resources to optimize the overall performance. To that end, this paper discovers and studies new instances of Reduction of Quality (RoQ) attacks that target the dynamic operation of load balancers. Our exposition is focused on a number of load balancing policies that are either employed in current commercial products or have been proposed in literature for future deployment. Through queuing theory analysis, numerical solutions, simulations and Internet experiments, we are able to assess the impact of RoQ attacks through the potency metric. We identify the key factors, such as feedback delay and averaging parameters, that expose the trade-offs between resilience and susceptibility to RoQ attacks. These factors could be used to harden load balancers against RoQ attacks. To the best of our knowledge, this work is the first to study adversarial exploits on the dynamic operation of load balancers.},
keywords={Internet;performance evaluation;quality of service;queueing theory;resource allocation;telecommunication security;reduction of quality attack;dynamic load balancing;vulnerability assessment;key adaptation mechanism;queuing theory analysis;numerical solution;Internet experiment;denial of service attack;performance evaluation;Load management;Delay;Computer science;USA Councils;Resource management;Feedback;Communications Society;Educational institutions;Computer networks;Queueing analysis},
doi={10.1109/INFCOM.2007.105},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215688,
author={A. El-Atawy and T. Samak and E. Al-Shaer and H. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Using Online Traffic Statistical Matching for Optimizing Packet Filtering Performance},
year={2007},
volume={},
number={},
pages={866-874},
abstract={Packet classification plays a critical role in many of the current networking technologies, and efficient yet lightweight packet classification techniques are highly crucial for their successful deployment. Most of the current packet classification techniques exploit the characteristics of classification policies, without considering the traffic behavior in optimizing their search data structures. In this paper, we present novel techniques that utilize traffic characteristics coupled with careful analysis of the policy to obtain adaptive methods that can accommodate varying traffic statistics while maintaining a high throughput. The first technique uses segmentation of the traffic space to achieve disjoint subsets of traffic properties and build bounded depth Huffman trees using the statistics collected for these segments. The second technique simplifies the structure maintenance by keeping the segments ordered in a most-recently-used (MRU) list instead of a tree. The techniques are evaluated and their performance are compared. Moreover, attacks targeting the firewall performance are discussed and corresponding protection schemes are presented.},
keywords={authorisation;computer networks;filtering theory;optimisation;statistical analysis;telecommunication traffic;tree data structures;online traffic statistical matching;packet filtering performance optimization;packet classification;traffic behavior;data structure;traffic statistics;bounded depth Huffman trees;most recently used list;firewall performance;Matched filters;Telecommunication traffic;Information filtering;Information filters;Intrusion detection;Internet;Communications Society;Computer science;USA Councils;Data structures},
doi={10.1109/INFCOM.2007.106},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215689,
author={Y. Duan and J. Canny},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Scalable Secure Bidirectional Group Communication},
year={2007},
volume={},
number={},
pages={875-883},
abstract={Many network applications are based on a group communications model where one party sends messages to a large number of authorized recipients and/or receives messages from multiple senders. In this paper we present a secure group communication scheme based on a new cryptosystem that admits a rigorous proof of security against adaptive chosen ciphertext attack (IND-CCA2). Our scheme is bi-directional, supporting both one-to-many and many-to-one communications. Compared with existing solutions, our scheme achieves the following improvements: (1) It guarantees data confidentiality and authenticity in both directions; (2) It is the most scalable solution so far among all existing schemes achieving (1). The group member storage overhead is constant while both the center storage and rekeying communication complexity are independent of group size. (3) It can be made to achieve higher level of security and hide even the information about the group dynamics. We show that this protection is more effective and more efficient than existing solutions.},
keywords={communication complexity;cryptography;data privacy;message authentication;telecommunication security;scalable secure bidirectional group communication;cryptosystem;ciphertext attack;one-to-many communications;many-to-one communications;data confidentiality;authenticity;group member storage overhead;communication complexity;Intrusion detection;Cryptography;Data security;Multicast protocols;Secure storage;Protection;Internet;Context;Public key;Communications Society},
doi={10.1109/INFCOM.2007.107},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215690,
author={G. Theodorakopoulos and J. S. Baras},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Malicious Users in Unstructured Networks},
year={2007},
volume={},
number={},
pages={884-891},
abstract={Unstructured networks (like ad-hoc or peer-to-peer networks) are networks without centralized control of their operation. Users make local decisions regarding whether to follow the network protocol or not. While providing scalability benefits, this degrades the performance, which is compounded by the potential presence of Malicious Users. In general, these users are trying to disrupt the operation of the network, and prevent the legitimate users from achieving their objectives. More specifically, they could try to break the connectivity of the network, or waste the resources of the legitimate users. In this work we use game theory to examine the effect of malicious users. All users are modeled as payoff-maximizing strategic agents. A simple model, fictitious play, is used for the legitimate user behavior, but no limits are imposed on the Malicious Users strategies. We look for the worst case equilibrium: the one that gives Malicious Users the highest payoff. We identify the importance of the network topology.},
keywords={ad hoc networks;game theory;protocols;telecommunication network topology;unstructured network;network protocol;malicious user;legitimate user;game theory;network topology;Protocols;Costs;Peer to peer computing;Game theory;Network topology;Bandwidth;Communications Society;Educational institutions;Centralized control;Scalability},
doi={10.1109/INFCOM.2007.108},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215691,
author={P. R. Jelenkovic and J. Tan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Can Retransmissions of Superexponential Documents Cause Subexponential Delays?},
year={2007},
volume={},
number={},
pages={892-900},
abstract={Consider a generic data unit of random size L that needs to be transmitted over a channel of unit capacity. The channel dynamics is modeled as an on-off process {(Ai, E/j)}iles1 with alternating independent periods when channel is available A<sub>i</sub> and unavailable U<sub>i</sub>, respectively. During each period of time that the channel becomes available, say A<sub>i</sub>, we attempt to transmit the data unit. If L les A<sub>i</sub>, the transmission was considered successful; otherwise, we wait for the next period A<sub>i+i</sub> when the channel is available and attempt to retransmit the data from the beginning. We study the asymptotic properties of the total transmission time T and number of retransmissions N until the data is successfully transmitted. In recent studies it was proved that the waiting time T follows a power law when the distributions of L and A<sub>1</sub> are of an exponential type, e.g., Gamma distribution. In this paper, we show that the distributions of N and T follow power laws with exponent alpha as long as logP[L &gt; x] apalphalogP[A<sub>1</sub> &gt; x] for large x. Hence, it may appear surprising that we obtain power law distributions irrespective of how heavy or light the distributions of L and A<sub>1</sub> may be. In particular, both L and A<sub>1</sub> can decay faster than any exponential, which we term superexponential. For example, if L and A<sub>1</sub> are Gaussian with variances sigma<sup>2</sup> <sub>L</sub> and sigma<sup>2</sup> <sub>A</sub>, respectively, then N and T have power law distributions with exponent alpha = sigma<sup>2</sup> <sub>A</sub>/sigma<sup>2</sup> <sub>L</sub>; note that, if sigma<sup>2</sup> <sub>A</sub>&lt;sigma<sup>2</sup> <sub>L</sub>, the transmission time has an infinite mean and, thus, the system is unstable. The preceding model, as recognized in (Fiorini et al., 2005), describes a variety of situations where failures require jobs to restart from the beginning. Here, we identify that this model also provides a new mechanism for explaining the frequently observed power law phenomenon in data networks. Specifically, we argue that it may imply the power laws on both the application as well as the data link layer, where variable-sized documents and (IP) packets are transmitted, respectively. We discuss the engineering ramifications of our observations, especially in the context of wireless ad hoc and sensor networks where channel failures are frequent. Furthermore, our results provide an easily computable benchmark for measuring the matching between the data and channel characteristics that permits/prevents satisfactory transmission.},
keywords={ad hoc networks;data communication;delays;document handling;gamma distribution;wireless sensor networks;superexponential documents retransmissions;subexponential delays;unit capacity channel;channel dynamics;Gamma distribution;power law phenomenon;data networks;wireless ad hoc networks;wireless sensor networks;Delay;Wireless sensor networks;Power system modeling;Automatic repeat request;Communications Society;Channel capacity;Power engineering and energy;Sensor phenomena and characterization;Web pages;Internet},
doi={10.1109/INFCOM.2007.109},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215692,
author={P. Brown},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Stability of Networks with Age-Based Scheduling},
year={2007},
volume={},
number={},
pages={901-909},
abstract={Aged based scheduling policies, as proposed for network routers or links, give priority to packets belonging to connections having sent a smaller volume of data. Examples of such policies are least attained service (LAS) and multi-level processor sharing (MLPS). These policies have been shown to be efficient in the context of an isolated queue when the distribution of connection sizes has a large variance or a decreasing failure rate. This is the case of Internet connections. The motivation to use such policies is to reduce the mean transfer times for connections, to reduce the number of ongoing connections, and to give precedence to interactive transactions for which users have higher expectation. However it has been argued recently that these policies may lead to network instabilities: the network may become unstable although the average load offered to each resource is smaller than one. In this paper we introduce a packet level model in contrast to flow level models used recently to model resource sharing policies in networks. We extend and generalize former stability properties in queueing networks where priority decreases. These results are used to obtain stability conditions for aged-based policies in data networks. We compare our conclusions with those obtained with flow level models and explain the differences obtained.},
keywords={Internet;queueing theory;resource allocation;scheduling;telecommunication links;telecommunication network reliability;telecommunication network routing;age-based scheduling;network router;network link;network stability;Internet;packet level model;resource sharing;queueing network;data network;Stability;Processor scheduling;Delay;Communications Society;Telecommunications;Research and development;Internet;Resource management;Distribution functions;Resumes},
doi={10.1109/INFCOM.2007.110},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215693,
author={H. Cai and D. Y. Eun and S. Ha and I. Rhee and L. Xu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Stochastic Ordering for Internet Congestion Control and its Applications},
year={2007},
volume={},
number={},
pages={910-918},
abstract={Window growth function for congestion control is a strong determinant of protocol behaviors, especially its second and higher-order behaviors associated with the distribution of transmission rates, its variances, and protocol stability. This paper presents a new stochastic tool, called convex ordering, that provides an ordering of any convex function of transmission rates of two protocols and valuable insights into high order behaviors of protocols. As the ordering determined by this tool is consistent with any convex function of rates, it can be applied to any unknown metric for protocol performance that consists of some high-order moments of transmission rates, as well as those already known such as rate variance. Using the tool, it is analyzed that a protocol with a growth function that starts off with a concave function and then switches to a convex function (e.g., an odd order function such as x<sup>3</sup> and x<sup>5</sup>) around the maximum window size in the previous loss epoch, gives the smallest rate variation under a variety of network conditions. Among existing protocols, BIC and CUBIC have this window growth function. Experimental and simulation results confirm the analytical findings.},
keywords={convex programming;Internet;protocols;stochastic programming;telecommunication congestion control;Internet congestion control;stochastic convex function ordering;window growth function;protocol transmission rate;Stochastic processes;Internet;Stability;Transport protocols;Access protocols;IP networks;Polynomials;Remote monitoring;Fluctuations;Communications Society},
doi={10.1109/INFCOM.2007.111},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215694,
author={R. Kumar and Y. Liu and K. Ross},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Stochastic Fluid Theory for P2P Streaming Systems},
year={2007},
volume={},
number={},
pages={919-927},
abstract={We develop a simple stochastic fluid model that seeks to expose the fundamental characteristics and limitations of P2P streaming systems. This model accounts for many of the essential features of a P2P streaming system, including the peers' realtime demand for content, peer churn (peers joining and leaving), peers with heterogeneous upload capacity, limited infrastructure capacity, and peer buffering and playback delay. The model is tractable, providing closed-form expressions which can be used to shed insight on the fundamental behavior of P2P streaming systems. The model shows that performance is largely determined by a critical value. When the system is of moderate-to-large size, if a certain ratio of traffic loads exceeds the critical value, the system performs well; otherwise, the system performs poorly. Furthermore, large systems have better performance than small systems since they are more resilient to bandwidth fluctuations caused by peer churn. Finally, buffering can dramatically improve performance in the critical region, for both small and large systems. In particular, buffering can bring more improvement than can additional infrastructure bandwidth.},
keywords={peer-to-peer computing;stochastic processes;video streaming;stochastic fluid theory;P2P streaming system;closed-form expressions;bandwidth fluctuation;peer churn;buffering;video streaming;Stochastic systems;Streaming media;Peer to peer computing;USA Councils;Bandwidth;Bit rate;Internet;Communications Society;Information science;Delay},
doi={10.1109/INFCOM.2007.112},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215695,
author={R. K. Panta and I. Khalil and S. Bagchi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Stream: Low Overhead Wireless Reprogramming for Sensor Networks},
year={2007},
volume={},
number={},
pages={928-936},
abstract={Wireless reprogramming of a sensor network is useful for uploading new code or for changing the functionality of existing code. Through the process, a node should remain receptive to future code updates because reprogramming may be done multiple times during the node's lifetime. Existing reprogramming protocols, such as Deluge, achieve this by bundling the reprogramming protocol and the application as one program image, thereby increasing the overall size of the image which is transferred through the network. This increases both time and energy required for network reprogramming. We present a protocol called Stream that mitigates the problem by significantly reducing the size of the program image. Using the facility of having multiple code images on a node and switching between them, Stream pre-installs the reprogramming protocol as one image and the application program equipped with the ability to listen to new code updates as the second image. For a sample application, Stream reduces the size of the program image by 10 pages (48 packets/page) compared to Deluge. Stream is implemented on the Mica2 nodes and we conduct testbed and simulation experiments to show the reduction in energy and reprogramming time of Stream compared to Deluge.},
keywords={protocols;wireless sensor networks;wireless sensor network reprogramming protocol;Deluge protocol;Stream protocol;Mica2 sensor node;Wireless sensor networks;Streaming media;Peer to peer computing;Costs;Sensor systems;Computer networks;Wireless application protocol;Communications Society;Testing;Degradation},
doi={10.1109/INFCOM.2007.113},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215696,
author={S. Yoon and C. Qiao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A New Search Algorithm using Autonomous and Cooperative Multiple Sensor Nodes},
year={2007},
volume={},
number={},
pages={937-945},
abstract={In this paper, we study search algorithms for using a set of autonomous and cooperative mobile sensor nodes (MSN) with limited sensing and communication ranges to search a large area. Our objectives include minimizing the total search time and the travel distance of MSNs while enabling fault tolerance to possible MSN failures. We propose a new rendezvous scheme, namely X synchronization (XS) to facilitate the exchange of both data and control signals among the MSNs during search. We also devise a way to calculate appropriate timeout periods used to detect an MSN failure at rendezvous points and describe how surviving MSNs subsequently carry out the search mission. Numerical analysis and simulations have been performed to evaluate the performance of XS. The results show that XS can outperform other rendezvous schemes in terms of the total search time and the average travel distance of MSNs.},
keywords={fault tolerance;mobile radio;wireless sensor networks;search algorithm;autonomous multiple sensor nodes;cooperative multiple sensor nodes;mobile sensor nodes;fault tolerance;X synchronization;travel distance;Peer to peer computing;Underwater communication;Communication system control;Mobile communication;Communications Society;Acoustic sensors;Bit rate;Bandwidth;Underwater acoustics;Optical fiber communication},
doi={10.1109/INFCOM.2007.114},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215697,
author={R. Flury and R. Wattenhofer},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Routing, Anycast, and Multicast for Mesh and Sensor Networks},
year={2007},
volume={},
number={},
pages={946-954},
abstract={This paper studies routing schemes and their distributed construction in limited wireless networks, such as sensor or mesh networks. We argue that the connectivity of such networks is well captured by a constant doubling metric and present a constant stretch multicast algorithm through which any network node <i>u</i> can send messages to an arbitrary receiver set <i>U</i>. In other words, we describe a distributed approximation algorithm which is only a constant factor off the NP-hard minimum Steiner tree on <i>u</i> cup<i>U</i>. As a building block for the multicasting, we construct a 1 + epsiv stretch labeled routing scheme with label size O(log ominus) and storage overhead O(1/epsiv)<sup>alpha</sup>(log ominus)(O(<i>alpha</i>) + log Delta), where ominus is the diameter of the network, Delta the maximum degree of any network node, and <i>alpha</i> a constant representing the doubling dimension of the network. In addition to unicast and multicast, we present a constant approximation for anycasting on the basis of radic(6)-approximate distance queries. We provide a distributed algorithm to construct the required labeling and routing tables.},
keywords={approximation theory;communication complexity;distributed algorithms;multicast communication;radio receivers;telecommunication network routing;trees (mathematics);wireless sensor networks;network routing;wireless network;mesh network;stretch multicast algorithm;receiver;distributed approximation algorithm;NP-hard minimum Steiner tree;anycasting;approximate distance query;routing table;sensor network;Routing;Multicast algorithms;Wireless sensor networks;Fires;Wireless networks;Computer networks;Distributed computing;Laboratories;Wireless mesh networks;Peer to peer computing},
doi={10.1109/INFCOM.2007.115},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215698,
author={D. Starobinski and W. Xiao and X. Qin and A. Trachtenberg},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Near-Optimal Data Dissemination Policies for Multi-Channel, Single Radio Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={955-963},
abstract={We analyze the performance limits of data dissemination with multi-channel, single radio sensors. We formulate the problem of minimizing the average delay of data dissemination as a stochastic shortest path problem and show that, for an arbitrary topology network, an optimal control policy can be found in a finite number of steps, using value iteration or Dijsktra's algorithm. However, the computational complexity of this solution is generally prohibitive. We thus focus on two special classes of network topologies of practical interest, namely single-hop clusters and multi-hop cluster trees. For these topologies, we derive the structure of policies that achieve an average delay within a factor 1 + e of the optimal average delay, in networks with large number of nodes. Through simulation, we show that these policies perform close to optimal even for networks with small and moderate numbers of nodes. Our analysis and simulations reveal that multichannel data dissemination policies lead to a drastic reduction in the average delay, up to a factor as large as the total number of channels available, even though each node can communicate over only one channel at any point of time. Finally, we present the foundations of a methodology, based on extreme value theory, allowing the implementation of our near-optimal dissemination policies with minimal overhead.},
keywords={minimisation;stochastic processes;telecommunication network topology;trees (mathematics);wireless channels;wireless sensor networks;near optimal data dissemination policy;single radio wireless sensor network;stochastic shortest path problem;arbitrary topology network;Dijsktra algorithm;computational complexity;multihop cluster tree;optimal average delay;wireless channel;Wireless sensor networks;Network topology;Performance analysis;Stochastic processes;Shortest path problem;Optimal control;Clustering algorithms;Computational complexity;Spread spectrum communication;Analytical models},
doi={10.1109/INFCOM.2007.116},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215699,
author={C. W. Tan and D. P. Palomar and M. Chiang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Exploiting Hidden Convexity For Flexible And Robust Resource Allocation In Cellular Networks},
year={2007},
volume={},
number={},
pages={964-972},
abstract={A systematic approach to solve seemingly nonconvex resource allocation problems in wireless cellular networks is studied in this paper. By revealing and exploiting the hidden convexity in the problem formulations, we obtain solutions that can tackle a variety of objective functions, provide robustness to resource allocations such as power, and be obtained often through distributed algorithms. The advantages of such flexibility and robustness are demonstrated through comparisons with the state-of-the-art in recent research literature. First we show how to distributively solve a variety of resource allocation problems in CDMA and interference limited CDMA channels with quality of service constraints, such as meeting minimum queueing delay or energy per bit requirement. Then, for uplink transmission in a CDMA cellular network, we propose an optimal power control scheme with congestion-aware active link protection. In particular, the tradeoff between power expenditure and the protection margin of the SIR-balancing power algorithm is optimized.},
keywords={cellular radio;code division multiple access;concave programming;distributed algorithms;optimal control;power control;quality of service;queueing theory;resource allocation;telecommunication congestion control;wireless channels;hidden convexity;nonconvex resource allocation problems;wireless cellular networks;distributed algorithms;interference limited CDMA channels;quality of service;QoS constraints;minimum queueing delay;energy per bit requirement;uplink transmission;optimal power control scheme;congestion-aware active link protection;flexible resource control;SIR-balancing power algorithm;Robustness;Resource management;Land mobile radio cellular systems;Multiaccess communication;Protection;Distributed algorithms;Quality of service;Interference constraints;Delay;Power control},
doi={10.1109/INFCOM.2007.117},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215700,
author={Y. Yu and G. B. Giannakis},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Joint Congestion Control and OFDMA Scheduling for Hybrid Wireline-Wireless Networks},
year={2007},
volume={},
number={},
pages={973-981},
abstract={We consider joint congestion control and multiuser scheduling in a hybrid wireline and wireless network, where the air interface of wireless links is based on orthogonal frequency division multiplexing (OFDM). For static channels, we formulate this cross-layer design as a network utility maximization (NUM) problem with both wireline and wireless link constraints. The convexity of the problem enables a well-established dual-based approach to decompose it into two subproblems, the transport layer source rate adaptation and the medium access control (MAC) layer multiuser OFDM scheduling, which are connected and coordinated by link prices. While the rate and link price adjustments follow the same fashion as the conventional utility-based congestion control for wireline networks, the key difference is the multiuser OFDM scheduling performed at the wireless access point (AP). Independent from specific utilities used by each source, this scheduling problem always maximizes a wireless link-price-weighted sum throughput (LPWST), which can be solved efficiently by a block-coordinate descent method, resulting in optimal subcarrier assignment and power allocation at the AP. Convergence of the dual-based algorithm is established using the convex optimization theory. To extend our results to dynamic wireless channels, we provide a NUM formulation with long-term average feasible rate region and develop a gradient scheduling algorithm to handle channel variations. Our work represents a systematic cross-design framework for distributed fair resource allocation in a hybrid network with both static and dynamic wireless channels.},
keywords={access protocols;convex programming;frequency division multiple access;multiuser channels;OFDM modulation;radio links;resource allocation;scheduling;telecommunication congestion control;wireless channels;joint congestion control;multiuser OFDMA scheduling;hybrid wireline-wireless networks;wireless links;orthogonal frequency division multiplexing;network utility maximization problem;transport layer source rate adaptation;medium access control layer;wireless access point;convex optimization theory;dynamic wireless channels;distributed fair resource allocation;OFDM;Scheduling algorithm;Wireless networks;Cross layer design;Utility programs;Media Access Protocol;Throughput;Convergence;Optimization methods;Resource management},
doi={10.1109/INFCOM.2007.118},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215701,
author={H. Kim and G. de Veciana},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Losing Opportunism: Evaluating Service Integration in an Opportunistic Wireless System},
year={2007},
volume={},
number={},
pages={982-990},
abstract={In this paper we evaluate interactions among flow-level performance metrics when integrating QoS and best effort flows in a wireless system using opportunistic scheduling. We introduce a simple flow-level model capturing the salient features of bandwidth sharing for an opportunistic scheduler which ensures a mean throughput to each QoS stream for every time slot. We then explore the flow-level performance showing that integration of QoS and best effort flows results in loss in opportunism, which in turn results in a reduction of the stability region, degradation in system throughput, and increased file transfer delay. These losses are shown to be proportional to opportunistic gains, the guaranteed bandwidth and number of QoS flows, but inversely proportional to SNR under a Rayleigh fading channel model. In an integrated system exploiting opportunism, local instability appears to be more severe than in wired networks and average delays experienced by best effort flows are prolonged. We suggest that a form of admission control for best effort flows is necessary to avoid local instability, and ensure adequate performance.},
keywords={bandwidth allocation;quality of service;Rayleigh channels;telecommunication congestion control;opportunistic wireless system;opportunistic scheduling;bandwidth sharing;QoS stream;file transfer delay;Rayleigh fading channel model;admission control;Traffic control;Telecommunication traffic;Throughput;Bandwidth;Wireless networks;Delay;Admission control;Communication system traffic control;Communications Society;Wireless communication},
doi={10.1109/INFCOM.2007.119},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215702,
author={D. Amzallag and J. Naor and D. Raz},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Algorithmic Aspects of Access Networks Design in B3G/4G Cellular Networks},
year={2007},
volume={},
number={},
pages={991-999},
abstract={The forthcoming 4G cellular systems will provide broadband wireless access to a variety of advanced data and voice services. In order to do that, these networks will have a significantly larger number of base stations and a much higher bandwidth demand from their radio access networks. This will motivate operators to replace the commonly used star based architecture, in which an RNC is connected to a set of base stations via direct links, with a more complex tree structure, in which a base station can be connected to an RNC via other base stations. In this paper we address algorithmic aspects of this challenging design problem, in which tree-topology is used to connect base stations and RNCs. We formulate the problem as an optimization problem and prove that it is NP-hard to approximate it in the general case. For the metric case, however, we develop an O(log n)-approximation algorithm. We then study the performance of this algorithm and several other heuristics in practical scenarios. Our results indicate that a combination of a certain greedy heuristic and the proven approximation algorithm, generates a solution that produces close to optimal results in practical scenarios and can be efficiently computed for sufficiently large network sizes.},
keywords={3G mobile communication;4G mobile communication;approximation theory;broadband networks;cellular radio;optimisation;radio access networks;telecommunication network topology;access network design;B3G/4G cellular network;broadband wireless access;base station;tree-topology;algorithmic aspect;optimization problem;approximation algorithm;Algorithm design and analysis;Land mobile radio cellular systems;Base stations;Radio access networks;Computer networks;Bandwidth;Frequency;Degradation;Radio network;Radio control},
doi={10.1109/INFCOM.2007.120},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215703,
author={S. Kwon and N. B. Shroff},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Paradox of Shortest Path Routing for Large Multi-Hop Wireless Networks},
year={2007},
volume={},
number={},
pages={1001-1009},
abstract={In this paper, we analyze the impact of straight line routing in large homogeneous multi-hop wireless networks. We estimate the nodal load, which is defined as the number of packets served at a node, induced by straight line routing. For a given total offered load on the network, our analysis shows that the nodal load at each node is a function of the node's Voronoi cell, the node's location in the network, and the traffic pattern specified by the source and destination randomness and straight line routing. The traffic pattern determines where the hot spot is created in the network, and straight line routing itself can balance the relay load in certain cases. In the asymptotic regime, each node's probability that the node serves a packet arriving to the network can be approximated as the multiplication of a half length of its Voronoi cell perimeter and the probability density function that a packet goes through the node's location. Both simulations and analysis confirm that this approximation converges to the exact value. The scaling order of network performance in our analysis is independent of traffic patterns generated by source-destination pair randomness, but for a given node the performance of each node is strongly related to the source-destination pair randomness.},
keywords={graph theory;probability;radio networks;telecommunication network routing;telecommunication traffic;shortest path routing;large multihop wireless network;Voronoi cell;network traffic;probability density function;network performance;source-destination pair randomness;Routing;Spread spectrum communication;Wireless networks;Telecommunication traffic;Pattern analysis;Relays;Probability density function;Analytical models;Performance analysis;Traffic control},
doi={10.1109/INFCOM.2007.121},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215704,
author={R. Catanuto and S. Toumpis and G. Morabito},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Opti{c,m}al: Optical/Optimal Routing in Massively Dense Wireless Networks},
year={2007},
volume={},
number={},
pages={1010-1018},
abstract={We study routing for massively dense wireless networks, i.e., wireless networks that contain so many nodes that, in addition to their usual microscopic description, a novel macroscopic description becomes possible. The macroscopic description is not detailed, but nevertheless contains enough information to permit a meaningful study and performance optimization of the network. Within this context, we continue and significantly expand previous work on the analogy between optimal routing and the propagation of light according to the laws of Geometrical Optics. Firstly, we pose the analogy in a more general framework than previously, notably showing how the eikonal equation, which is the central equation of Geometrical Optics, also appears in the networking context. Secondly, we develop a methodology for calculating the cost function, which is the function describing the network at the macroscopic level. We apply this methodology for two important types of networks: bandwidth limited and energy limited.},
keywords={geometrical optics;radio networks;telecommunication network routing;optical routing;optimal routing;dense wireless network;microscopic description;geometrical optics;eikonal equation;Optical fiber networks;Routing;Wireless networks;Geometrical optics;Equations;Microscopy;Optimization;Optical propagation;Cost function;Bandwidth},
doi={10.1109/INFCOM.2007.122},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215705,
author={S. Subramanian and S. Shakkottai and P. Gupta},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Optimal Geographic Routing in Wireless Networks with Holes and Non-Uniform Traffic},
year={2007},
volume={},
number={},
pages={1019-1027},
abstract={Geographic forwarding has been widely studied as a routing strategy for large wireless networks, mainly due to the low complexity of the routing algorithm, scalability of the routing information with network size and fast convergence times of routes. On a planar network with no holes, Gupta and Kumar (2000) have shown that a uniform traffic demand of ominus(1/radicn log n) is achievable. However, in a network with routing holes (regions on the plane which do not have active nodes), geographic routing schemes such as GPSR or GOAFR could cause the throughput capacity to significantly drop due to concentration of traffic on the face of the holes. Similarly, geographic schemes could fail to support non-uniform traffic patterns due to spatial congestion (traffic concentration) caused by greedy "straight-line" routing. In this paper, we first propose a randomized geographic routing scheme that can achieve a throughput capacity of ominus(1/radicn) (within a poly-logarithmic factor) even in networks with routing holes. Thus, we show that our scheme is throughput optimal (up to a poly-logarithmic factor) while preserving the inherent advantages of geographic routing. We also show that the routing delay incurred by our scheme is within a poly-logarithmic factor of the optimal throughput-delay trade-off curve. Next, we construct a geographic forwarding based routing scheme that can support wide variations in the traffic requirements (as much as ominus(1) rates for some nodes, while supporting ominus(1/radicn) for others). We finally show that the above two schemes can be combined to support non-uniform traffic demands in networks with holes.},
keywords={radio networks;telecommunication network routing;telecommunication traffic;optimal geographic routing;wireless networks;nonuniform traffic;geographic forwarding;routing strategy;routing algorithm;routing information scalability;uniform traffic demand;routing holes;greedy straight-line routing;Routing;Wireless networks;Telecommunication traffic;Throughput;Delay;Wireless sensor networks;Feedback;Communications Society;Scalability;Convergence},
doi={10.1109/INFCOM.2007.123},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215706,
author={S. Sengupta and S. Rayanchu and S. Banerjee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Analysis of Wireless Network Coding for Unicast Sessions: The Case for Coding-Aware Routing},
year={2007},
volume={},
number={},
pages={1028-1036},
abstract={A recent approach, COPE, for improving the throughput of unicast traffic in wireless multi-hop networks exploits the broadcast nature of the wireless medium through opportunistic network coding. In this paper, we analyze throughput improvements obtained by COPE-type network coding in wireless networks from a theoretical perspective. We make two key contributions. First, we obtain a theoretical formulation for computing the throughput of network coding on any wireless network topology and any pattern of concurrent unicast traffic sessions. Second, we advocate that routing be made aware of network coding opportunities rather than, as in COPE, being oblivious to it. More importantly, our work studies the tradeoff between routing flows "close to each other" for utilizing coding opportunities and "away from each other" for avoiding wireless interference. Our theoretical formulation provides a method for computing source-destination routes and utilizing the best coding opportunities from available ones so as to maximize the throughput. We handle scheduling of broadcast transmissions subject to wireless transmit/receive diversity and link interference in our optimization framework. Using our formulations, we compare the performance of traditional unicast routing and network coding with coding-oblivious and coding-aware routing on a variety of mesh network topologies, including some derived from contemporary mesh network testbeds. Our evaluations show that a route selection strategy that is aware of network coding opportunities leads to higher end-to-end throughput when compared to coding-oblivious routing strategies.},
keywords={codes;telecommunication network routing;telecommunication network topology;telecommunication traffic;wireless network coding;unicast sessions;coding-aware routing;unicast traffic;COPE-type network coding;wireless multihop networks;wireless network topology;source-destination routes;broadcast transmission scheduling;wireless transmit-receive diversity;link interference;unicast routing;coding-oblivious routing;mesh network topologies;Wireless networks;Unicast;Routing;Network coding;Throughput;Telecommunication traffic;Broadcasting;Network topology;Interference;Mesh networks},
doi={10.1109/INFCOM.2007.124},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215707,
author={Y. Gu and D. Towsley and C. V. Hollot and H. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Congestion Control for Small Buffer High Speed Networks},
year={2007},
volume={},
number={},
pages={1037-1045},
abstract={There is growing interest in designing high speed routers with small buffers that store only tens of packets. Recent studies suggest that TCP NewReno, with the addition of a pacing mechanism, can interact with such routers without sacrificing link utilization. Unfortunately, as we show in this paper, as workload requirements grow and connection bandwidths increase, the interaction between the congestion control protocol and small buffer routers produce link utilizations that tend to zero. This is a simple consequence of the inverse square root dependence of TCP throughput on loss probability. In this paper we present a new congestion controller that avoids this problem by allowing a TCP connection to achieve arbitrarily large bandwidths without demanding the loss probability go to zero. We show that this controller produces stable behavior and, through simulation, we show its performance to be superior to TCP NewReno in a variety of environments. Lastly, because of its advantages in high bandwidth environments, we compare our controller's performance to some of the recently proposed high performance versions of TCP including HSTCP, STCP, and FAST. Simulations illustrate the superior performance of the proposed controller in a small buffer environment.},
keywords={telecommunication congestion control;telecommunication network management;telecommunication network routing;congestion control;high speed routers;loss probability;small buffer high speed networks;High-speed networks;Optical buffering;Buffer storage;Bandwidth;Throughput;Computer science;Communications Society;Communication system control;Protocols;Costs},
doi={10.1109/INFCOM.2007.125},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215708,
author={A. Baiocchi and F. Vacirca},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={TCP Fluid Modeling with a Variable Capacity Bottleneck Link},
year={2007},
volume={},
number={},
pages={1046-1054},
abstract={A single TCP connection with a time varying capacity bottleneck link is considered. The bottleneck capacity varies arbitrarily and independently of the TCP connection traffic; it aims at reproducing typical situations where capacity is modulated by exogenous process, such as wireless channel with link adaptation or bursty channels. The key point is to understand the interplay of the TCP congestion control evolution and the time constants of the bottleneck link capacity time variation. Fluid modeling is used to describe the time evolution of the congestion window size and of the bottleneck buffer content with a completely general capacity time function, ns-2 based simulations are used as mean to assess the fluid model accuracy. Numerical results show the existence of a "resonance" phenomena, that can significantly degrade the TCP long term performance (even more than halved). The degradation depends on the ratio between the fundamental time constant of the link capacity variation and the TCP average round trip time.},
keywords={channel capacity;radio links;telecommunication congestion control;telecommunication traffic;transport protocols;wireless channels;TCP fluid modeling;variable capacity bottleneck link;TCP connection traffic;wireless channel;link adaptation;bursty channels;congestion window size;bottleneck buffer content;TCP congestion control;Traffic control;Analytical models;Communication system traffic control;Degradation;Communications Society;Resonance;Jacobian matrices;Delay;Steady-state;Throughput},
doi={10.1109/INFCOM.2007.126},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215709,
author={J. Choi and K. Park and C. -. Kim},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Cross-Layer Analysis of Rate Adaptation, DCF and TCP in Multi-Rate WLANs},
year={2007},
volume={},
number={},
pages={1055-1063},
abstract={Wireless Internet access is facilitated by IEEE 802.11 WLANs that, in addition to realizing a specific form of CSMA/CA-distributed coordination function (DCF)- implement a range of performance enhancement features such as multi-rate adaptation that induce cross-layer protocol coupling. Recent works in empirical WLAN performance evaluation have shown that cross-layer interactions can be subtle, sometimes leading to unexpected outcomes. Two such instances are: significant throughput degradation (a bell-shaped throughput curve) resulting from automatic rate fallback (ARF) having difficulty distinguishing collision from channel noise, and scalable TCP performance over DCF that is able to curtail effective multiple access contention in the presence of many contending stations. The latter also mitigates the negative performance effect of ARF. In this paper, we present station-centric Markov chain models of WLAN cross-layer performance aimed at capturing complex interactions between ARF, DCF, and TCP. Our performance analyses may be viewed as multi-protocol extensions of Bianchi's IEEE 802.11 model that, despite significantly increased complexity, lead to tractable and accurate performance predictions due to modular coupling. Our results complement empirical and simulation-based findings, demonstrating the versatility and efficacy of station-centric Markov chain analysis for capturing cross-layer WLAN dynamics.},
keywords={carrier sense multiple access;Internet;Markov processes;transport protocols;wireless channels;wireless LAN;multirate wireless IEEE 802.11 LAN;wireless Internet access;distributed coordination function;cross-layer protocol coupling;automatic rate fallback;channel noise;scalable TCP performance;multiple access contention;station-centric Markov chain model;carrier sense multiple access;Wireless LAN;Throughput;Internet;Multiaccess communication;Wireless application protocol;Access protocols;Degradation;Collision mitigation;Performance analysis;Predictive models},
doi={10.1109/INFCOM.2007.127},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215710,
author={M. Becchi and S. Cadambi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Memory-Efficient Regular Expression Search Using State Merging},
year={2007},
volume={},
number={},
pages={1064-1072},
abstract={Pattern matching is a crucial task in several critical network services such as intrusion detection and policy management. As the complexity of rule-sets increases, traditional string matching engines are being replaced by more sophisticated regular expression engines. To keep up with line rates, deal with denial of service attacks and provide predictable resource provisioning, the design of such engines must allow examining payload traffic at several gigabits per second and provide worst case speed guarantees. While regular expression matching using deterministic finite automata (DFA) is a well studied problem in theory, its implementation either in software or specialized hardware is complicated by prohibitive memory requirements. This is especially true for DFAs representing complex regular expressions present in practical rule-sets. In this paper, we introduce a novel method to drastically reduce the DFA memory requirement and still provide worst-case speed guarantees. Specifically, we merge several "non-equivalent" states in a DFA by introducing labels on their input and output transitions. We then propose a data structure to represent the merged states and the transition labels. We show that, with very few assumptions about the original DFA, such a transformation results in significant compression in the DFA representation. We have implemented a state merging and transition labeling algorithm for DFAs, and show that for Snort and Bro security rule-sets, state merging results in memory reductions of an order of magnitude.},
keywords={finite automata;search problems;security of data;telecommunication security;memory-efficient regular expression search;state merging;pattern matching;critical network services;intrusion detection;policy management;rule-sets;string matching engines;regular expression engines;line rates;denial of service attacks;resource provisioning;payload traffic;regular expression matching;deterministic finite automata;DFA memory requirement;non-equivalent states;data structure;merged states;transition labels;transition labeling algorithm;Merging;Doped fiber amplifiers;Engines;Pattern matching;Intrusion detection;Computer crime;Payloads;Automata;Hardware;Data structures},
doi={10.1109/INFCOM.2007.128},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215711,
author={L. Massoulie and A. Twigg and C. Gkantsidis and P. Rodriguez},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Randomized Decentralized Broadcasting Algorithms},
year={2007},
volume={},
number={},
pages={1073-1081},
abstract={We consider the problem of broadcasting a live stream of data in an unstructured network. The broadcasting problem has been studied extensively for edge-capacitated networks. We give the first proof that whenever demand lambda + epsiv is feasible for epsiv &gt; 0, a simple local-control algorithm is stable under demand lambda, and as a corollary a famous theorem of Edmonds. We then study the node-capacitated case and show a similar optimality result for the complete graph. We study through simulation the delay that users must wait in order to playback a video stream with a small number of skipped packets, and discuss the suitability of our algorithms for live video streaming.},
keywords={digital video broadcasting;directed graphs;randomised algorithms;video streaming;randomized decentralized broadcasting algorithm;edge-capacitated network;local-control algorithm;Edmonds theorem;directed graph;live video streaming;Broadcasting;Peer to peer computing;Delay;Streaming media;Scheduling algorithm;Communications Society;Multimedia communication;Motion pictures;Network topology;Heuristic algorithms},
doi={10.1109/INFCOM.2007.129},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215712,
author={M. Wang and B. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Lava: A Reality Check of Network Coding in Peer-to-Peer Live Streaming},
year={2007},
volume={},
number={},
pages={1082-1090},
abstract={In recent literature, network coding has emerged as a promising information theoretic approach to improve the performance of both peer-to-peer and wireless networks. It has been widely accepted and acknowledged that network coding can theoretically improve network throughput of multicast sessions in directed acyclic graphs, achieving their cut-set capacity bounds. Recent studies have also supported the claim that network coding is beneficial for large-scale peer-to-peer content distribution, as it solves the problem of locating the last missing blocks to complete the download. We seek to perform a reality check of using network coding for peer-to-peer live multimedia streaming. We start with the following critical question: How helpful is network coding in peer-to-peer streaming? To address this question, we first implement the decoding process using Gauss-Jordan elimination, such that it can be performed while coded blocks are progressively received. We then implement a realistic testbed, called Lava, with actual network traffic to meticulously evaluate the benefits and tradeoffs involved in using network coding in peer-to-peer streaming. We present the architectural design challenges in implementing network coding for the purpose of streaming, along with a pull-based peer-to-peer live streaming protocol in our comparison studies. Our experimental results show that network coding makes it possible to perform streaming with a finer granularity, which reduces the redundancy of bandwidth usage, improves resilience to network dynamics, and is most instrumental when the bandwidth supply barely meets the streaming demand.},
keywords={directed graphs;multimedia systems;peer-to-peer computing;radio access networks;telecommunication traffic;Lava;network coding;peer-to-peer live streaming;wireless networks;directed acyclic graphs;multimedia streaming;Gauss-Jordan elimination;network traffic;Network coding;Peer to peer computing;Streaming media;Bandwidth;Wireless networks;Throughput;Large-scale systems;Decoding;Gaussian processes;Testing},
doi={10.1109/INFCOM.2007.130},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215713,
author={Z. Zhang and S. Chen and M. Yoon},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={MARCH: A Distributed Incentive Scheme for Peer-to-Peer Networks},
year={2007},
volume={},
number={},
pages={1091-1099},
abstract={As peer-to-peer networks grow larger and include more diverse users, the lack of incentive to encourage cooperative behavior becomes one of the key problems. This challenge cannot be fully met by traditional incentive schemes, which suffer from various attacks based on false reports. Especially, due to the lack of central authorities in typical P2P systems, it is difficult to detect colluding groups. Members in the same colluding group can cooperate to manipulate their history information, and the damaging power increases dramatically with the group size. In this paper, we propose a new distributed incentive scheme, in which the benefit that a node can obtain from the system is proportional to its contribution to the system, and a colluding group cannot gain advantage by cooperation regardless of its size. Consequently, the damaging power of colluding groups is strictly limited. The proposed scheme includes three major components: a distributed authority infrastructure, a key sharing protocol, and a contract verification protocol.},
keywords={peer-to-peer computing;protocols;peer-to-peer networks;MARCH distributed incentive scheme;distributed authority infrastructure;key sharing protocol;contract verification protocol;Incentive schemes;Peer to peer computing;History;Contracts;Feedback;Cryptographic protocols;Communications Society;Computer networks;Distributed computing;Information science},
doi={10.1109/INFCOM.2007.131},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215714,
author={Y. Yan and A. El-Atawy and E. Al-Shaer},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Ranking-Based Optimal Resource Allocation in Peer-to-Peer Networks},
year={2007},
volume={},
number={},
pages={1100-1108},
abstract={This paper presents a theoretic framework of optimal resource allocation and admission control for peer-to-peer networks. Peer's behavioral rankings are incorporated into the resource allocation and admission control to provide differentiated services and even to block peers with bad rankings. These peers may be free-riders or suspicious attackers. A peer improves her ranking by contributing resources to the P2P system or deteriorates her ranking by consuming services. Therefore, the ranking-based resource allocation provides necessary incentives for peers to contribute their resources to the P2P systems. We define a utility function which captures the best wish for the source peer to serve competing peers, who request services from the source peer. Although the utility function is convex, Harsanyi-type social welfare functions are devised to obtain a unique optimal resource allocation that achieves max-min fairness. The parameters used in our model can be derived from the nature of the services or chosen by the source peer. No private information is required to reveal from individual peers. This prevents selfish peers to play the system strategically and cheat the resource allocation mechanism for their own benefits. The resource allocation and admission control are fully distributed and linearly scalable.},
keywords={peer-to-peer computing;resource allocation;ranking-based optimal resource allocation;peer-to-peer networks;admission control;free-riders;suspicious attackers;Harsanyi-type social welfare functions;Resource management;Peer to peer computing;History;Admission control;Communications Society;Computer science;Information systems;USA Councils;IP networks;Protocols},
doi={10.1109/INFCOM.2007.132},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215715,
author={C. Guo},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={G-3: An O(1) Time Complexity Packet Scheduler That Provides Bounded End-to-End Delay},
year={2007},
volume={},
number={},
pages={1109-1117},
abstract={In this paper, we present an <i>O</i>(1) time-complexity packet scheduling algorithm which we call G-3 that provides bounded end-to-end delay for fixed size packet networks. G-3 is built over two round-robin schedulers SRR (Chuanxiong Guo, 2004) and RRR (Garg and Xiaoqiang Chen, 1999) and several novel data structures. In G-3, bounded delay is provided by evenly distributing the binary coded weight of a flow into a square weight matrix (SWM) and several perfect weighted binary trees (PWBTs). In order to achieve <i>O</i>(1) time complexity, the SWM matrix is further spread by a weight spread sequence (WSS) and each PWBT tree is spread by a corresponding time-slot sequence (TSS), respectively. G-3 then performs packet scheduling by sequential scanning the WSS and TSS sequences. G-3 can be implemented in high-speed packet networks to provide bandwidth guarantee, fairness, and bounded delay due to its <i>O</i>(1) time complexity.},
keywords={communication complexity;delays;matrix algebra;packet radio networks;scheduling;spread spectrum communication;trees (mathematics);time complexity;G-3 packet scheduling;bounded end-to-end delay;fixed size packet network;round-robin scheduling;square weight matrix;perfect weighted binary trees;weight spread sequence;time-slot sequence;Scheduling algorithm;Delay effects;Round robin;Processor scheduling;Bandwidth;Data structures;Binary trees;Communications Society;Internet telephony;Video sharing},
doi={10.1109/INFCOM.2007.133},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215716,
author={X. Lin and S. Rasool},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Distributed Joint Channel-Assignment, Scheduling and Routing Algorithm for Multi-Channel Ad-hoc Wireless Networks},
year={2007},
volume={},
number={},
pages={1118-1126},
abstract={The capacity of ad hoc wireless networks can be substantially increased by equipping each network node with multiple radio interfaces that can operate on multiple non-overlapping channels. However, new scheduling, channel-assignment, and routing algorithms are required to fully utilize the increased bandwidth in multi-channel multi-radio ad hoc networks. In this paper, we develop a fully distributed algorithm that jointly solves the channel-assignment, scheduling and routing problem. Our algorithm is an online algorithm, i.e., it does not require prior information on the offered load to the network, and can adapt automatically to the changes in the network topology and offered load. We show that our algorithm is provably efficient. That is, even compared with the optimal centralized and offline algorithm, our proposed distributed algorithm can achieve a provable fraction of the maximum system capacity. Further, the achievable fraction that we can guarantee is larger than that of some other comparable algorithms in the literature.},
keywords={ad hoc networks;scheduling;telecommunication network routing;wireless channels;distributed joint channel-assignment;routing algorithm;multichannel ad hoc wireless network;multiple radio interface;scheduling;Routing;Scheduling algorithm;Wireless networks;Processor scheduling;Ad hoc networks;Wireless mesh networks;Control systems;Centralized control;Bandwidth;Distributed algorithms},
doi={10.1109/INFCOM.2007.134},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215717,
author={J. Liebeherr and M. Fidler and S. Valaee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Min-Plus System Interpretation of Bandwidth Estimation},
year={2007},
volume={},
number={},
pages={1127-1135},
abstract={Significant research has been dedicated to methods that estimate the available bandwidth in a network from traffic measurements. While estimation methods abound, less progress has been made on achieving a foundational understanding of the bandwidth estimation problem. In this paper, we develop a min-plus system theoretic formulation of bandwidth estimation. We show that the problem as well as previously proposed solutions can be concisely described and derived using min-plus system theory, thus establishing the existence of a strong link between network calculus and network probing methods. We relate difficulties in network probing to potential non-linearities of the underlying systems, and provide a justification for the distinctive treatment of FIFO scheduling in network probing.},
keywords={computer networks;minimax techniques;scheduling;telecommunication traffic;min-plus system interpretation;bandwidth estimation problem;traffic measurement;network calculus;network probing method;FIFO scheduling;Bandwidth;Calculus;Linear systems;Telecommunication traffic;Data mining;Algebra;Probes;Switches;Monitoring;Communications Society},
doi={10.1109/INFCOM.2007.135},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215718,
author={W. Chen and M. J. Neely and U. Mitra},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Energy Efficient Scheduling with Individual Packet Delay Constraints: Offline and Online Results},
year={2007},
volume={},
number={},
pages={1136-1144},
abstract={This paper focuses on energy-efficient packet transmission with individual packet delay constraints. The optimal offline scheduler (vis-a-vis total transmission energy), assuming information of all packet arrivals before scheduling, was developed by Zafer, et al. (2005) and Chen et al. (2006). This paper shows that when packet inter-arrival times are identically and independently distributed (Ltd.), the resulting optimal transmission durations of packets m and M - m +1, m epsiv [1, .. ., M], M ges 1, are identically distributed. This symmetry property leads to a simple and exact solution of the average packet delay under the optimal offline schedule. Two heuristic online scheduling algorithms, which assume no future arrival information, are then studied. These online schedulers are compared with the optimal offline scheduler in terms of delay and energy performance via analysis and simulations. While both online schedulers are inherently inferior, one online scheduler is shown to achieve a comparable energy performance to the optimal offline scheduler in a wide range of scenarios.},
keywords={queueing theory;radio networks;scheduling;energy efficient scheduling;energy-efficient packet transmission;individual packet delay constraints;optimal offline scheduler;packet inter-arrival times;heuristic online scheduling algorithms;wireless applications;queueing delays;Energy efficiency;Optimal scheduling;Scheduling algorithm;Dynamic scheduling;Delay effects;Dynamic programming;Communications Society;USA Councils;Low pass filters;Nonlinear filters},
doi={10.1109/INFCOM.2007.136},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215719,
author={J. K. Sundararajan and M. Medard and M. Kim and A. Eryilmaz and D. Shah and R. Koetter},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Network Coding in a Multicast Switch},
year={2007},
volume={},
number={},
pages={1145-1153},
abstract={We consider the problem of serving multicast flows in a crossbar switch. We show that linear network coding across packets of a flow can sustain traffic patterns that cannot be served if network coding were not allowed. Thus, network coding leads to a larger rate region in a multicast crossbar switch. We demonstrate a traffic pattern which requires a switch speedup if coding is not allowed, whereas, with coding the speedup requirement is eliminated completely. In addition to throughput benefits, coding simplifies the characterization of the rate region. We give a graph-theoretic characterization of the rate region with fanout splitting and intra-flow coding, in terms of the stable set polytope of the "enhanced conflict graph" of the traffic pattern. Such a formulation is not known in the case of fanout splitting without coding. We show that computing the offline schedule (i.e. using prior knowledge of the flow arrival rates) can be reduced to certain graph coloring problems. Finally, we propose online algorithms (i.e. using only the current queue occupancy information) for multicast scheduling based on our graph-theoretic formulation. In particular, we show that a maximum weighted stable set algorithm stabilizes the queues for all rates within the rate region.},
keywords={encoding;graph colouring;multicast communication;packet switching;telecommunication traffic;linear network coding;traffic patterns;multicast crossbar switch scheduling;stable set polytope;enhanced conflict graph coloring problem;maximum weighted stable set algorithm;Network coding;Switches;Traffic control;Unicast;Throughput;Multicast algorithms;Telecommunication traffic;Processor scheduling;Optimal scheduling;Fabrics},
doi={10.1109/INFCOM.2007.137},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215720,
author={D. Li and J. Wu and Y. Cui and J. Liu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={QoS-Aware Streaming in Overlay Multicast Considering the Selfishness in Construction Action},
year={2007},
volume={},
number={},
pages={1154-1162},
abstract={Most existing overlay multicast proposals have assumed that the nodes are cooperative and thus focus on the global topology optimization. However, a unique and important characteristic of overlay nodes is that, as application-layer agents, they can be selfish with their own interests. To achieve better quality-of-service (QoS) or to minimize forwarding overhead, an overlay node can behave selfishly in the information collection or in the overlay construction. While the former has recently been investigated, the impact of selfishness in the construction action remains unclear. In this paper, we present the first systematic study on the impact of selfishness in both tree and mesh overlay construction. Our investigation considers multiple QoS measures for streaming applications, including stream latency, resolution, and continuity. Our contribution is twofold: first, we analyze how for selfish overlay nodes to choose a construction-action policy to optimize their individual multi-metric QoS. Second, we demonstrate that the selfishness-aware policy for the construction action is consistent with the QoS optimization for the global multicast session, but not vice versa. The implication is significant: A globally optimal overlay construction itself can be vulnerable to individual selfishness; but, following our directions, we can design an overlay that is both globally optimal and selfish-resistant.},
keywords={multicast communication;quality of service;telecommunication network topology;QoS;streaming;overlay multicast;global topology optimization;quality-of-service;selfishness-aware policy;Peer to peer computing;Proposals;Delay;Topology;Quality of service;Routing;Communications Society;Computer science;Streaming media;Vehicles},
doi={10.1109/INFCOM.2007.138},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215721,
author={L. Chen and T. Ho and S. H. Low and M. Chiang and J. C. Doyle},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimization Based Rate Control for Multicast with Network Coding},
year={2007},
volume={},
number={},
pages={1163-1171},
abstract={Recent advances in network coding have shown great potential for efficient information multicasting in communication networks, in terms of both network throughput and network management. In this paper, we address the problem of rate control at end-systems for network coding based multicast flows. We develop two adaptive rate control algorithms for the networks with given coding subgraphs and without given coding subgraphs, respectively. With random network coding, both algorithms can be implemented in a distributed manner, and work at transport layer to adjust source rates and at network layer to carry out network coding. We prove that the proposed algorithms converge to the globally optimal solutions for intra-session network coding. Some related issues are discussed, and numerical examples are provided to complement our theoretical analysis.},
keywords={encoding;graph theory;multicast communication;optimisation;telecommunication network management;dual-based adaptive rate control algorithm;multicast communication network coding;network management;coding subgraphs;intra-session network coding;random network coding;Network coding;Multicast algorithms;Communication system control;Programmable control;Adaptive control;Routing;USA Councils;Cost function;Communication system traffic control;Distributed algorithms},
doi={10.1109/INFCOM.2007.139},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215722,
author={H. Won and H. Cai and D. Y. Eun and K. Guo and A. Netravali and I. Rhee and K. Sabnani},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Multicast Scheduling in Cellular Data Networks},
year={2007},
volume={},
number={},
pages={1172-1180},
abstract={Multicast is an efficient means of transmitting the same content to multiple receivers while minimizing network resource usage. Applications that can benefit from multicast such as multimedia streaming and download, are now being deployed over 3G wireless data networks. Existing multicast schemes transmit data at a fixed rate that can accommodate the farthest located users in a cell. However, users belonging to the same multicast group can have widely different channel conditions. Thus existing schemes are too conservative by limiting the throughput of users close to the base station. We propose two proportional fair multicast scheduling algorithms that can adapt to dynamic channel states in cellular data networks that use time division multiplexing: Inter-group Proportional Fairness (IPF) and multicast proportional fairness (MPF). These scheduling algorithms take into account (1) reported data rate requests from users which dynamically change to match their link states to the base station, and (2) the average received throughput of each user inside its cell. This information is used by the base station to select an appropriate data rate for each group. We prove that IPF and MPF achieve proportional fairness among groups and among all users in a group inside a cell respectively. Through extensive packet-level simulations, we demonstrate that these algorithms achieve good balance between throughput and fairness among users and groups.},
keywords={cellular radio;multicast protocols;scheduling;multicast scheduling;cellular data networks;multiple receivers;network resource usage;multimedia streaming;intergroup proportional fairness;multicast proportional fairness;Cellular networks;Base stations;Unicast;Throughput;Time division multiplexing;Streaming media;Downlink;Scheduling algorithm;Communications Society;Processor scheduling},
doi={10.1109/INFCOM.2007.140},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215723,
author={G. Bianchi and A. Di Stefano and C. Giaconia and L. Scalia and G. Terrazzino and I. Tinnirello},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Experimental Assessment of the Backoff Behavior of Commercial IEEE 802.11b Network Cards},
year={2007},
volume={},
number={},
pages={1181-1189},
abstract={It has been observed that different IEEE 802.11 commercial cards produced by different vendors experience different performance, either when accessing alone the channel, as well as when competing against each other. These differences persist also when thorough measurement methodologies (such as RF shielding, laptop rotation, etc) are applied, and alignment of the environmental factors (same laptop models, traffic generators, etc) is carried out. This paper provides an extensive experimental characterization of the backoff operation of six commercial NIC cards. It suggests a relevant methodological approach, namely a repeatable, well defined, set of experiments, for such a characterization. Low level backoff distribution measurements are taken through a custom equipment developed in our laboratory. Our work allows to detect both a non-standard backoff behavior of some commercial cards (in terms of minimum contention window size and neglection of EIFS times), as well as potential implementation limits (in either the card hardware/firmware and/or the software driver) which appear to severely alter the card performance in challenging conditions.},
keywords={peripheral interfaces;wireless LAN;commercial IEEE 802.11b network cards;environmental factors;backoff distribution measurements;Portable computers;Rotation measurement;Radio frequency;Environmental factors;Traffic control;Laboratories;Potential well;Hardware;Microprogramming;Software performance},
doi={10.1109/INFCOM.2007.141},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215724,
author={C. Hu and J. C. Hou},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Novel Approach to Contention Control in IEEE 802.11e-Operated WLANs},
year={2007},
volume={},
number={},
pages={1190-1198},
abstract={In this paper, we devise, in compliance with the IEEE 802.11e protocol, a novel MAC-centric approach, called MAC <i>contention</i> <i>control</i> (MCC), to maximizing the bandwidth utilization and achieving proportional bandwidth allocation. We first show that approaches based on estimating the number of competing nodes and then setting the contention window size may not converge (and in some cases diverge) because of network dynamics. Then, by studying the optimality condition derived in our prior work, we identify two parameters (referred to as <i>control</i> <i>references</i>) that remain approximately constant when the network operates at the optimal operational point, <i>regardless</i> <i>of</i> <i>the</i> <i>number</i> <i>of</i> <i>competing</i> <i>nodes</i> <i>in</i> <i>each</i> AC. We instrument MCC to measure these control references, compare measurement results to their optimal control reference levels, and adjust the packet dequeuing rate from the interface queues in an additive-increase-multiplicative-decrease (AIMD) fashion and with respect to prespecified bandwidth allocation ratio associated with its AC. In some sense, MCC controls the rate of passing packets from the interface queues to to the MAC access function, and thus practically controls the effective number of competing nodes. We have conducted an extensive simulation study, and demonstrated the superiority of MCC to 802.11e in terms of both the achievable network throughput and the capability of achieving proportional bandwidth allocation. This, coupled with the fact that MCC does not require change in firmware and can be practically deployed, makes MCC a viable approach to contention control in IEEE 802.11e-operated WLANs.},
keywords={access protocols;bandwidth allocation;IEEE standards;optimal control;queueing theory;telecommunication congestion control;wireless LAN;MAC contention control;IEEE 802.11e- protocol;wireless LAN;bandwidth utilization;proportional bandwidth allocation;optimal control reference level;packet dequeuing rate;optimal operational point;Bandwidth;Channel allocation;Optimal control;Throughput;Quality of service;Peer to peer computing;Access protocols;Proportional control;Media Access Protocol;Communications Society},
doi={10.1109/INFCOM.2007.142},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215725,
author={H. Q. Nguyen and F. Baccelli and D. Kofman},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Stochastic Geometry Analysis of Dense IEEE 802.11 Networks},
year={2007},
volume={},
number={},
pages={1199-1207},
abstract={This paper presents a stochastic geometry model for the performance analysis and the planning of dense IEEE 802.11 networks. This model allows one to propose heuristic formulas for various properties of such networks like the probability for users to be covered, the probability for access points to be granted access to the channel or the average long term throughput provided to end-users. The main merit of this model is to take the effect of interferences and that of CSMA into account within this dense network context. This analytic model, which is based on Matern point processes, is partly validated against simulation. It is then used to assess various properties of such networks. We show for instance how the long term throughput obtained by end-users behaves when the access point density increases. We also briefly show how to use this model for the planning of managed networks and for the economic modeling of unplanned networks.},
keywords={stochastic processes;wireless LAN;stochastic geometry analysis;dense IEEE 802.11 network;performance analysis;Matern point process;long term throughput;access point density;Stochastic processes;Geometry;Throughput;Interference;Multiaccess communication;Wireless LAN;Performance analysis;Wireless networks;Costs;Quality of service},
doi={10.1109/INFCOM.2007.143},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215726,
author={S. B. Eisenman and A. T. Campbell},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={E-CSMA: Supporting Enhanced CSMA Performance in Experimental Sensor Networks Using Per-Neighbor Transmission Probability Thresholds},
year={2007},
volume={},
number={},
pages={1208-1216},
abstract={A transmitter in a wireless network that uses CSMA, a simple carrier sensing-based MAC protocol, to determine the likelihood of successful packet reception at the intended receiver can easily be misled. At the same time, CSMA variants and hybrid MAC protocols based at least in part on carrier sensing have become the de facto standard in wireless sensor networks, underscoring a need to improve its performance. We propose to enhance the de facto state of carrier sensing-based MACs in wireless sensor networks by using low cost channel feedback combined with a learning approach to try to better predict the probability of a successful reception, on a per-receiver basis. We show results from an experimental wireless sensor network testbed, where our proposal E-CSMA (Enhanced CSMA) provides up to a 55% improvement in network performance.},
keywords={access protocols;carrier sense multiple access;packet radio networks;probability;wireless channels;wireless sensor networks;E-CSMA;carrier sense multiple access;per-neighbor transmission probability threshold;MAC protocol;media access control;packet reception;de facto standard;wireless sensor network;channel feedback;Multiaccess communication;Wireless sensor networks;Radio transmitters;Receivers;Media Access Protocol;Wireless application protocol;USA Councils;Wireless networks;Probability distribution;Communications Society},
doi={10.1109/INFCOM.2007.144},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215727,
author={M. Kodialam and T. Nandagopal and W. C. Lau},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Anonymous Tracking Using RFID Tags},
year={2007},
volume={},
number={},
pages={1217-1225},
abstract={The increasing use of RFID tags in many applications have brought forth valid concerns of privacy and anonymity among users. One of the primary concerns with RFID tags is their ability to track an individually tagged entity. While this capability is currently thought to be necessary for supporting some features of RFID systems, such practice can lead to potential privacy violations. In this paper, we propose a privacy-preserving scheme that enables anonymous estimation of the cardinality of a dynamic set of RFID tags, while allowing the set membership to vary in both the spatial and temporal domains. In addition, the proposed scheme can identify the dynamics of the changes in the tag set population. The main idea of the scheme is to avoid explicit identification of tags. We demonstrate that the proposed scheme is highly adaptive and can accurately estimate tag populations across many orders of magnitude, ranging from a few tens to millions of tags. The associated probing latency is also substantially lower (les 10%) than that of the schemes which require explicit tag identification. We also show that our proposed scheme performs well even in highly dynamic environments, where the tag set keeps changing rapidly.},
keywords={data privacy;radio tracking;radiofrequency identification;telecommunication security;RFID tag anonymous tracking;privacy-preserving scheme;RFID tag identification;RFID tags;Radiofrequency identification;Probes;Privacy;Aggregates;USA Councils;Statistics;Communications Society;Delay;Government},
doi={10.1109/INFCOM.2007.145},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215728,
author={E. Ayday and F. Delgosha and F. Fekri},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Location-Aware Security Services for Wireless Sensor Networks Using Network Coding},
year={2007},
volume={},
number={},
pages={1226-1234},
abstract={Security services such as data confidentiality, authenticity, and availability are critical in wireless sensor networks deployed in adversarial environments. Due to the resource constrains of sensor nodes, the existing protocols currently in use in ad-hoc networks cannot be employed in wireless sensor networks. In this paper, we propose a protocol called location-aware network coding security (LNCS) that provides all the aforementioned security services. By dividing the terrain into non-overlapping cells, the nodes take advantage of the location information to derive different location binding keys. An event in the field is sensed by several nodes and aggregated by all of them. Using a secret sharing algorithm, the aggregated information is divided into several shares that are forwarded toward the sink in a cell-by-cell fashion. The key idea in LNCS is that all the nodes involved in the protocol collaborate in every phase. We employ random network coding in our scheme to provide data availability significantly higher than that in other schemes. To generate authentication information, a hash tree is constructed on the generated packets. The packets that fail the authenticity test are considered as bogus and filtered enroute. Every node transmits only a small fraction of the generated packets along the corresponding authentication information to the next cell. The sink is the final entity being able to reconstruct the original message using a few shares of the message. We have provided a comparison between our scheme and previously proposed schemes. The results reveal significant improvement in data availability while maintaining the same level of data confidentiality and authenticity.},
keywords={cryptography;message authentication;mobility management (mobile radio);protocols;random codes;telecommunication security;wireless sensor networks;wireless sensor network;data confidentiality;authentication;location-aware network coding security protocol;secret sharing algorithm;random coding;location binding key;Wireless sensor networks;Network coding;Data security;Information security;Authentication;Availability;Wireless application protocol;Ad hoc networks;Cryptography;Collaboration},
doi={10.1109/INFCOM.2007.146},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215729,
author={C. Wang and H. Wu and N. -. Tzeng},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={RFID-Based 3-D Positioning Schemes},
year={2007},
volume={},
number={},
pages={1235-1243},
abstract={This research focuses on RFID-based 3-D positioning schemes, aiming to locate an object in a 3-dimensional space, with reference to a predetermined arbitrary coordinates system, by using RFID tags and readers. More specifically, we consider a hexahedron which may be a shipping container, a storage room, or other hexahedral shape spaces. A number of RFID tags and/or readers with known locations are deployed as reference nodes. We propose two positioning schemes, namely, the active scheme and the passive scheme. The former scheme locates an RFID reader. For example, it may be employed to locate a mobile person who is equipped with an RFID reader or an object that is approached by an RFID reader. The passive scheme locates an RFID tag, which is attached to the target object. Both approaches are based on a Nelder-Mead nonlinear optimization method that minimizes the error objective functions. We have carried out analyses and extensive simulations to evaluate the proposed schemes. Our results show that both schemes can locate the targets with acceptable accuracy. The active scheme usually results in smaller errors and has a lower hardware cost compared to its passive counterpart. On the other hand, the passive scheme is more efficient when locating multiple targets simultaneously. The effectiveness of our proposed approaches is verified experimentally using the IDENTEC RFID kits.},
keywords={optimisation;radiofrequency identification;RFID-based 3-D positioning scheme;predetermined arbitrary coordinate system;active scheme;passive scheme;Nelder-Mead nonlinear optimization method;IDENTEC RFID kits;error objective function;Radiofrequency identification;RFID tags;Containers;Robot kinematics;Target tracking;Optimization methods;Analytical models;Hardware;Costs;Communications Society},
doi={10.1109/INFCOM.2007.147},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215730,
author={S. Funke and N. Milosavljevic},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Guaranteed-Delivery Geographic Routing Under Uncertain Node Locations},
year={2007},
volume={},
number={},
pages={1244-1252},
abstract={Geographic routing protocols like GOAFR or GPSR rely on exact location information at the nodes, as when the greedy routing phase gets stuck at a local minimum, they require, as a fallback, a planar subgraph whose identification, in all existing methods, depends on exact node positions. In practice, however, location information at the network nodes is hardly precise; be it because the employed location hardware, such as GPS, exhibits an inherent measurement imprecision, or because the localization protocols which estimate positions of the network nodes cannot do so without errors. In this paper we propose a novel naming and routing scheme that can handle the uncertainty in location information. It is based on a macroscopic variant of geographic greedy routing, as well as a macroscopic planarization of the communication graph. If an upper bound on the deviation from true node locations is available, our routing protocol guarantees delivery of messages. Due to its macroscopic view, our routing scheme also produces shorter and more load-balanced paths than common geographic routing schemes, in particular in sparsely connected networks or in the presence of obstacles.},
keywords={Global Positioning System;routing protocols;guaranteed-delivery routing;geographic routing;uncertain node locations;routing protocols;GOAFR;GPSR;greedy routing;location information;network nodes;naming scheme;macroscopic planarization;communication graph;load-balanced paths;sparsely connected networks;Peer to peer computing;Wireless sensor networks;Routing protocols;Global Positioning System;Planarization;Communications Society;Computer science;Hardware;Position measurement;Upper bound},
doi={10.1109/INFCOM.2007.148},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215731,
author={H. Zlatokrilov and H. Levy},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Navigation in Distance Vector Spaces and Its Use for Node Avoidance Routing},
year={2007},
volume={},
number={},
pages={1253-1261},
abstract={Traditional network routing uses the single (shortest) path paradigm. This paradigm exposes sessions to various attacks along this path, such as eavesdropping, DoS attacks etc. As a result, certain nodes or network regions may pose security threats and it is desired to consider node routing schemes which avoid them. The task of node avoidance routing is particularly challenging in distance-vector networks, where only shortest-distance information is available to the nodes. We address this problem by proposing a new routing paradigm in which the forwarding mechanism exploits the distance-vector information towards several nodes and utilizes it to forward network traffic on non-shortest paths routes; in particular on node-avoiding routes aiming at bypassing security-suspected nodes. We study this paradigm, propose a routing algorithm based on it and establish their properties. Extensive evaluation of the algorithm in general situations is conducted via simulation.},
keywords={telecommunication network routing;node avoidance routing;network routing;distance-vector networks;Navigation;Peer to peer computing;Routing protocols;Information security;Intelligent networks;Communications Society;Computer crime;Telecommunication traffic;Traffic control;Machinery},
doi={10.1109/INFCOM.2007.149},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215732,
author={P. Momcilovic},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Scalability of Routing Tables in Wireless Networks},
year={2007},
volume={},
number={},
pages={1262-1270},
abstract={Consider a large wireless ad hoc network that facilitates communication between random pairs of network nodes. The paper investigates the size of routing tables as the number of nodes in the network increases. A routing protocol is information-efficient if the amount of information at individual nodes required to route packets does not increases with the network size. It is shown that the shortest-path and straight-line routing algorithms are not information-efficient, i.e., these protocols can be implemented only when nodes' memory increases with the network size. On the other hand, it is established that there exists an information-efficient routing algorithm -routing is feasible even if each node in the network is capable of storing information on a fixed number of destinations.},
keywords={radio networks;routing protocols;routing tables scalability;wireless networks;routing protocol;shortest-path routing algorithms;straight-line routing algorithms;information-efficient routing algorithm;Scalability;Wireless networks;Peer to peer computing;Throughput;Large-scale systems;Routing protocols;Mobile ad hoc networks;Lattices;Communications Society;Wireless application protocol},
doi={10.1109/INFCOM.2007.150},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215733,
author={G. Siganos and M. Faloutsos},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Neighborhood Watch for Internet Routing: Can We Improve the Robustness of Internet Routing Today?},
year={2007},
volume={},
number={},
pages={1271-1279},
abstract={Protecting BGP routing from errors and malice is one of the next big challenges for Internet routing. Several approaches have been proposed that attempt to capture and block routing anomalies in a proactive way. In practice, the difficulty of deploying such approaches limits their usefulness. We take a different approach: we start by requiring a solution that can be easily implemented now. With this goal in mind, we consider ourselves situated at an AS, and ask the question: how can I detect erroneous or even suspicious routing behavior? We respond by developing a systematic methodology and a tool to identify such updates by utilizing existing public and local information. Specifically, we process and use the allocation records from the Regional Internet Registries (RIR), the local policy of the AS, and records used to generate filters from Internet Routing Registries (IRR). Using our approach, we can automatically detect routing leaks. Additionally, we identify some simple organizational and procedural issues that would significantly improve the usefulness of the information of the registries. Finally, we propose an initial set of rules with which an ISP can react to routing problems in a way that is systematic, and thus, could be automated.},
keywords={Internet;telecommunication network routing;Internet routing;systematic methodology;Regional Internet Registries;local policy;Internet;Watches;Robustness;Information filtering;Information filters;Communications Society;Routing protocols;Certification;Profitability;Proposals},
doi={10.1109/INFCOM.2007.151},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215734,
author={M. Andrews},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Load Balancing in the Internet with Strict Delay Constraints},
year={2007},
volume={},
number={},
pages={1280-1288},
abstract={We study the problem of routing traffic in the Internet with strict delay constraints. This problem arises in the context of routing delay-sensitive traffic such as Voice-over-IP. We consider a set of demands that can be routed along a candidate set of paths. Each demand must be split among its paths in such a way that the total delay experienced by any of the traffic is less than a fixed threshold. In this paper we analyze the complexity of the problem and also present experimental results for heuristics that can be implemented in practice. In contrast to some other recent work on network optimization, our problem has a combinatorial aspect since we only enforce the delay bound on paths that have non-zero traffic. Our main theoretical result is that this causes the problem to be computationally hard, even if we only wish to approximately meet the delay bounds. We also discuss the limitations of online algorithms.},
keywords={Internet;optimisation;resource allocation;telecommunication network routing;telecommunication traffic;load balancing;Internet;strict delay constraint;Voice-over-IP;network optimization;online algorithm;Load management;Internet;Delay;Traffic control;Telecommunication traffic;Routing;Utility programs;Protocols;Aggregates;Communications Society},
doi={10.1109/INFCOM.2007.152},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215735,
author={P. P. C. Lee and T. Bu and T. Woo},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Detection of Signaling DoS Attacks on 3G Wireless Networks},
year={2007},
volume={},
number={},
pages={1289-1297},
abstract={Third generation (3G) wireless networks based on the CDMA2000 and UMTS standards are now increasingly being deployed throughout the world. Because of their complex signaling and relatively limited bandwidth, these 3G networks are generally more vulnerable than their wireline counterparts, thus making them fertile ground for new attacks. In this paper, we identify and study a novel denial of service (DoS) attack, called signaling attack, that exploits the unique vulnerabilities of the signaling/control plane in 3G wireless networks. Using simulations driven by real traces, we are able to demonstrate the impact of a signaling attack. Specifically, we show how a well-timed low-volume signaling attack can potentially overload the control plane and detrimentally affect the key elements in a 3G wireless infrastructure. The low-volume nature of the signaling attack allows it to avoid detection by existing intrusion detection algorithms, which are often signature or volume-based. As a counter-measure, we present and evaluate an online early detection algorithm based on the statistical CUSUM method. Through the use of extensive trace-driven simulations, we demonstrate that the algorithm is robust and can identify an attack in its inception, before significant damage is done.},
keywords={3G mobile communication;radio networks;statistical analysis;telecommunication security;3G wireless network;signaling DoS attack detection;CDMA2000 standard;UMTS standard;denial of service;intrusion detection algorithm;statistical CUSUM method;trace-driven simulation;Signal detection;Computer crime;Wireless networks;3G mobile communication;Signal processing;Signal generators;Bandwidth;Resource management;Channel allocation;Communication system traffic control},
doi={10.1109/INFCOM.2007.153},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215736,
author={M. Shao and S. Zhu and W. Zhang and G. Cao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={pDCS: Security and Privacy Support for Data-Centric Sensor Networks},
year={2007},
volume={},
number={},
pages={1298-1306},
abstract={The demand for efficient data dissemination/access techniques to find the relevant data from within a sensor network has led to the development of data-centric sensor networks (DCS), where the sensor data as contrast to sensor nodes are named based on attributes such as event type or geographic location. However, saving data inside a network also creates security problems due to the lack of tamper-resistance of the sensor nodes and the unattended nature of the sensor network. For example, an attacker may simply locate and compromise the node storing the event of his interest. To address these security problems, we present pDCS, a privacy-enhanced DCS network which offers different levels of data privacy based on different cryptographic keys. In addition, we propose several query optimization techniques based on Euclidean Steiner Tree and Keyed Bloom Filter to minimize the query overhead while providing certain query privacy. Finally, detailed analysis and simulations show that the Keyed Bloom Filter scheme can significantly reduce the message overhead with the same level of query delay and maintain a very high level of query privacy.},
keywords={cryptography;data privacy;information filters;query processing;telecommunication computing;telecommunication security;trees (mathematics);wireless sensor networks;data-centric sensor networks;data dissemination-access techniques;event type attribute;geographic location attribute;pDCS network;privacy-enhanced DCS network;security problems;cryptographic keys;query optimization techniques;Euclidean Steiner tree;keyed bloom filter scheme;wireless sensor netwoks;Data security;Data privacy;Animals;Sensor phenomena and characterization;Distributed control;Peer to peer computing;Filters;Wireless sensor networks;Computer science;Monitoring},
doi={10.1109/INFCOM.2007.154},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215737,
author={M. Li and I. Koutsopoulos and R. Poovendran},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Jamming Attacks and Network Defense Policies in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1307-1315},
abstract={We consider a scenario where a sophisticated jammer jams an area in a single-channel wireless sensor network. The jammer controls the probability of jamming and transmission range to cause maximal damage to the network in terms of corrupted communication links. The jammer action ceases when it is detected by a monitoring node in the network, and a notification message is transferred out of the jamming region. The jammer is detected at a monitor node by employing an optimal detection test based on the percentage of incurred collisions. On the other hand, the network computes channel access probability in an effort to minimize the jamming detection plus notification time. In order for the jammer to optimize its benefit, it needs to know the network channel access probability and number of neighbors of the monitor node. Accordingly, the network needs to know the jamming probability of the jammer. We study the idealized case of perfect knowledge by both the jammer and the network about the strategy of one another, and the case where the jammer or the network lack this knowledge. The latter is captured by formulating and solving optimization problems, the solutions of which constitute best responses of the attacker or the network to the worst-case strategy of each other. We also take into account potential energy constraints of the jammer and the network. We extend the problem to the case of multiple observers and adaptable jamming transmission range and propose a intuitive heuristic jamming strategy for that case.},
keywords={jamming;monitoring;optimisation;probability;telecommunication security;wireless channels;wireless sensor networks;wireless sensor network;optimal jamming attack;probability;node monitoring;wireless channel access probability;optimization problem;Jamming;Wireless sensor networks;Monitoring;Peer to peer computing;Protocols;Computer security;Laboratories;Computer networks;Communication system control;Broadcasting},
doi={10.1109/INFCOM.2007.155},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215738,
author={D. Chakrabarti and J. Leskovec and C. Faloutsos and S. Madden and C. Guestrin and M. Faloutsos},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Information Survival Threshold in Sensor and P2P Networks},
year={2007},
volume={},
number={},
pages={1316-1324},
abstract={Consider a network of, say, sensors, or P2P nodes, or Bluetooth-enabled cell-phones, where nodes transmit information to each other and where links and nodes can go up or down. Consider also a 'datum', that is, a piece of information, like a report of an emergency condition in a sensor network, a national traditional song, or a mobile phone virus. How often should nodes transmit the datum to each other, so that the datum can survive (or, in the virus case, under what conditions will the virus die out)? Clearly, the link and node fault probabilities are important - what else is needed to ascertain the survivability of the datum? We propose and solve the problem using non-linear dynamical systems and fixed point stability theorems. We provide a closed-form formula that, surprisingly, depends on only one additional parameter, the largest eigenvalue of the connectivity matrix. We illustrate the accuracy of our analysis on realistic and real settings, like mote sensor networks from Intel and MIT, as well as Gnutella and P2P networks.},
keywords={Bluetooth;cellular radio;matrix algebra;nonlinear dynamical systems;peer-to-peer computing;wireless sensor networks;information survival threshold;P2P network;Bluetooth-enabled cell-phone;datum survivability;nonlinear dynamical system;fixed point stability theorem;closed-form formula;connectivity matrix;peer-to-peer network;Peer to peer computing;Batteries;Cellular phones;Mobile handsets;Communications Society;Sensor systems;Fires;Event detection;Polynomials;Stability},
doi={10.1109/INFCOM.2007.156},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215739,
author={C. -. Chen and H. Luo and E. Seo and N. H. Vaidya and X. Wang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Rate-Adaptive Framing for Interfered Wireless Networks},
year={2007},
volume={},
number={},
pages={1325-1333},
abstract={The majority of existing wireless rate controls are based on the implicit assumption that frames are corrupted due to the random, arbitrary environmental and thermal noises. They generally reduce the channel rate on frame losses, trading lower efficiency in frequency band utilization for more robust modulation so that the current noise level may be tolerable. In highly interfered wireless networks where frames are lost mainly due to interference from other wireless transceivers, simply reducing the channel rate prolongs the frame transmission time and therefore aggravates frame loss ratio. This positive feedback in the rate control loop quickly diverges the interfered transceivers into a suboptimal channel rate and drives the network into a state with high interference. In the worst case, interfered transceivers can be starved. In this paper we present RAF, the rate-adaptive framing that jointly controls the channel rate and frame size according to the observed interference patterns and noise level at the receiver. Based on the inputs from physical layer carrier sense, the receiver derives the optimal channel rate and frame size that maximize throughput, and informs the transmitter of such optimal configuration in a few bits in the per-frame acknowledgement. Through intensive simulations we show that RAF consistently outperforms ARF, RBAR, and OAR in all simulated scenarios.},
keywords={interference;modulation;radio networks;random noise;thermal noise;wireless channels;rate-adaptive framing;interfered wireless network;random noise;arbitrary environmental noise;thermal noise;frequency band utilization;modulation;channel rate control;Wireless networks;Interference;Transceivers;Noise level;Working environment noise;Frequency;Noise robustness;Propagation losses;Feedback loop;State feedback},
doi={10.1109/INFCOM.2007.157},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215740,
author={R. Cohen and D. Raz},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Acyclic Type of Relationships Between Autonomous Systems},
year={2007},
volume={},
number={},
pages={1334-1342},
abstract={The Internet connectivity in the autonomous system (AS) level reflects the commercial relationship between ASes. A connection between two ASes could be of type <i>customer-provider</i> when one AS is a provider of the other AS, or of type <i>peer-peer</i>, if they are peering ASes. This commercial relationship induces a global hierarchical structure which is a key ingredient in the ability to understand the topological structure of the AS connectivity graph. Unfortunately, it is very difficult to collect data regarding the actual type of the relationships between ASes, and in general this information is not part of the collected AS connectivity data. The Type of Relationship (<i>ToR</i>) problem attempts to address this shortcoming, by inferring the type of relationship between connected ASes based on their routing policies. However, the approaches presented so far are local in nature and do not capture the global hierarchical structure. In this work we define a novel way to infer this type of relationship from the collected data, taking into consideration both local policies and global hierarchy constrains. We define the Acyclic Type of Relationship <i>AToR</i> problem that captures this global hierarchy and present an efficient algorithm that allows determining if there is a hierarchical assignment without invalid paths. We then show that the related general optimization problem is NP-complete and present a 2/3 approximation algorithm where the objective function is to minimize the total number of local policy mismatches. We support our approach by extensive experiments and simulation results showing that our algorithms classify the type of relationship between ASes much better than all previous algorithms.},
keywords={computational complexity;graph theory;Internet;optimisation;peer-to-peer computing;telecommunication network topology;Internet connectivity;autonomous system level;customer-provider;peer-peer computing;global hierarchical structure;acyclic type;optimization problem;NP-complete problem;Databases;Internet;Computer science;Guidelines;Communications Society;Approximation algorithms;Routing protocols;Specification languages;Europe;Topology},
doi={10.1109/INFCOM.2007.158},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215741,
author={P. P. C. Lee and V. Misra and D. Rubenstein},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Toward Optimal Network Fault Correction via End-to-End Inference},
year={2007},
volume={},
number={},
pages={1343-1351},
abstract={We consider an end-to-end approach of inferring network faults that manifest in multiple protocol layers, with an optimization goal of minimizing the expected cost of correcting all faulty nodes. Instead of first checking the most likely faulty nodes as in conventional fault localization problems, we prove that an optimal strategy should start with checking one of the candidate nodes, which are identified based on a potential function that we develop. We propose several efficient heuristics for inferring the best node to be checked in large-scale networks. By extensive simulation, we show that we can infer the best node in at least 95%, and that checking first the candidate nodes rather than the most likely faulty nodes can decrease the checking cost of correcting all faulty nodes by up to 25%.},
keywords={fault diagnosis;reliability;telecommunication network management;optimal network fault correction;end-to-end inference;multiple protocol layers;network diagnosis;fault localization;reliability engineering;Peer to peer computing;Protocols;Routing;Fault diagnosis;Network topology;Large-scale systems;Spine;Monitoring;Communications Society;Cost function},
doi={10.1109/INFCOM.2007.159},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215742,
author={R. Kokku and A. Bohra and S. Ganguly and A. Venkataramani},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Multipath Background Network Architecture},
year={2007},
volume={},
number={},
pages={1352-1360},
abstract={Background transfers, or transfers that humans do not actively wait on, dominate the Internet today. In today's best-effort Internet, background transfers can interfere with foreground transfers causing long wait times, thereby hurting human productivity. In this paper, we present the design and implementation of a background network, Harp, that addresses this problem. Harp has three significant advantages over recent end-host based background transport protocols; Harp (i) uses multiple paths to exploit path diversity and load imbalance in the Internet to tailor network resource allocation to human needs, (ii) provides better fairness and utilization compared to unipath end-host protocols, and (ill) can be deployed at either end-hosts or enterprise gateways, thereby aligning the incentive for deployment with the goals of network customers. Our evaluation using simulations and a prototype on Planetlab suggests that Harp improves foreground TCP transfer time by a factor of five and background transfer time by a factor of two using just two extra paths per connection.},
keywords={Internet;resource allocation;transport protocols;multipath background network architecture;Internet;human productivity;transport protocol;resource allocation;enterprise gateway;TCP protocol;multiple path;Harp;Internet;Relays;Humans;IP networks;Transport protocols;Traffic control;Delay;Routing;Computer architecture;Telecommunication traffic},
doi={10.1109/INFCOM.2007.160},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215743,
author={C. -. Yu and C. -. Chang and D. -. Lee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={CR Switch: A Load-Balanced Switch with Contention and Reservation},
year={2007},
volume={},
number={},
pages={1361-1369},
abstract={Load-balanced switches have received a great deal of attention recently as they are much more scalable than other existing switch architectures in the literature. However, as there exist multiple paths for flows of packets to traverse through load-balanced switches, packets in such switches may be delivered out of order. In this paper, we propose a new switch architecture, called the CR switch, that not only delivers packets in order but also guarantees 100% throughput. The key idea, as in a multiple access channel, is to operate the CR switch in two modes: (i) the contention mode in light traffic and (ii) the reservation mode in heavy traffic. To do this, we invent a new buffer management scheme, called I-VOQ (virtual output queue with insertion). With the I-VOQ scheme, we give rigorous mathematical proofs for 100% throughput and in order packet delivery of the CR switch. By computer simulations, we also demonstrate that the average packet delay of the CR switch is considerably lower than other schemes in the literature, including the uniform frame spreading scheme (Keslassy et al., 2003), the padded frame scheme (Jaramillo et al., 2006) and the mailbox switch (Chang et al., 2004).},
keywords={buffer storage;packet switching;storage management;CR switch;load-balanced switch;packet switching;multiple access channel;contention mode switch;reservation mode switch;buffer management scheme;virtual output queue with insertion;packet delivery;Switches;Chromium;Packet switching;Throughput;Traffic control;Delay;Communication switching;Time division multiplexing;Communications Society;Chaotic communication},
doi={10.1109/INFCOM.2007.161},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215744,
author={I. Papaefstathiou and V. Papaefstathiou},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Memory-Efficient 5D Packet Classification At 40 Gbps},
year={2007},
volume={},
number={},
pages={1370-1378},
abstract={Packet classification is one of the most important enabling technologies for next generation network services. Even though many multi-dimensional classification algorithms have been proposed, most of them are precluded from commercial equipments due to their high memory requirements. In this paper, we present an efficient packet classification scheme, called Bloom Based Packet Classification (B2PC). B2PC comprises of an innovative 5-field search algorithm that decomposes multifield classification rules into internal single field rules which are combined using multi-level Bloom filters. The design of B2PC is optimized for the common case based on analysis of real world classification databases. The hardware implementation of this scheme handles 4K rules by involving only 530KB of memory for its data structures, while it supports network streams at a rate of 15Gbps even in the worst case, and more than 40Gbps in the average case. This system covers 1.3 mm in a 0.18mum CMOS technology. We show that given a certain memory budget and silicon cost, the B2PC is the most efficient hardware-based approach to the classification problem.},
keywords={CMOS integrated circuits;computer networks;pattern classification;search problems;telecommunication services;5D packet classification;next generation network services;multidimensional classification algorithms;Bloom based packet classification;5-field search algorithm;multilevel Bloom filters;classification databases;CMOS technology;CMOS technology;Next generation networking;Classification algorithms;Filters;Design optimization;Databases;Hardware;Data structures;Silicon;Costs},
doi={10.1109/INFCOM.2007.162},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215745,
author={L. Shi and Y. Zhang and J. Yu and B. Xu and B. Liu and J. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Extreme Parallelism Inside Next-Generation Network Processors},
year={2007},
volume={},
number={},
pages={1379-1387},
abstract={Next-generation high-end network processors (NP) must address demands from both diversified applications and ever-increasing traffic pressure. One major challenge is to design an extraordinary scalable architecture. In this paper, it is argued that such an objective can only be sufficed by introducing highly paralleled structure, namely the paralleled processing-engine cluster (PPC). We demonstrate this point from the trade-off among aspects such as performance, programmability and flexibility. However, PPC natively suffers from several critical issues on load-balancing, intra-flow packet ordering and memory contention. After investigating several existing approaches, we present novel solutions for each issue according to the balance between performance and coast. Through intensive analysis and comprehensive simulations, it is shown that the shortest queue first scheduling with class-based prediction (SQF-C) performs nearly optimally, while the hardware based per-flow ordering mechanism resolves packet out-of-order independently with the load-balancing issue, inducting little throughput degradation. Implementing the unified solution, it is capable to design a PPC supporting up to OC-768c line rate. Real implementation is also carried out in our THNPU-1 prototype to verify the conclusions.},
keywords={microprocessor chips;parallel processing;queueing theory;resource allocation;scheduling;parallelism;network processor;highly paralleled structure;paralleled processing-engine cluster;shortest queue first scheduling;class-based prediction;load balancing;Next generation networking;Telecommunication traffic;Traffic control;Performance analysis;Analytical models;Predictive models;Queueing analysis;Hardware;Out of order;Throughput},
doi={10.1109/INFCOM.2007.163},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215746,
author={A. Bremler-Barr and D. Hendler},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Space-Efficient TCAM-Based Classification Using Gray Coding},
year={2007},
volume={},
number={},
pages={1388-1396},
abstract={Ternary content-addressable memories (TCAMs) are increasingly used for high-speed packet classification. TCAMs compare packet headers against all rules in a classification database in parallel and thus provide high throughput unparalleled by software-based solutions. TCAMs are not well-suited, however, for representing rules that contain range fields. Such rules have to be represented by multiple TCAM entries. The resulting range expansion can dramatically reduce TCAM utilization. The majority of real-life database ranges are short. We present a novel algorithm called short range gray encoding (SRGE) for the efficient representation of short range rules. SRGE encodes range borders as binary reflected gray codes and then represents the resulting range by a minimal set of ternary strings. SRGE is database independent and does not use TCAM extra bits. For the small number of ranges whose expansion is not significantly reduced by SRGE, we use dependent encoding that exploits the extra bits available on today's TCAMs. Our comparative analysis establishes that this hybrid scheme utilizes TCAM more efficiently than previously published solutions. The SRGE algorithm has worst-case expansion ratio of 2W-4, where W is the range-field length . We prove that any TCAM encoding scheme has worst-case expansion ratio W or more.},
keywords={content-addressable storage;Gray codes;Internet;telecommunication network routing;space-efficient TCAM-based packet classification;Gray coding;ternary content-addressable memory;classification database;software-based solution;short range gray encoding;worst-case expansion ratio;network routing;Internet;Databases;Encoding;Computer science;Throughput;Streaming media;Pattern matching;Communications Society;Reflective binary codes;Internet;Routing},
doi={10.1109/INFCOM.2007.164},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215747,
author={L. Ma and W. T. Ooi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Congestion Control in Distributed Media Streaming},
year={2007},
volume={},
number={},
pages={1397-1405},
abstract={Distributed media streaming, which uses multiple senders to collaboratively and simultaneously stream media content to a receiver, poses new challenges in congestion control. Such approach establishes multiple flows within a session. Since conventional congestion control only aims to make each of these flows TCP-friendly, selfish users can increase the number of flows to grab a larger share of the bandwidth, introducing more congestion and degrading the overall network performance. To address this issue, we propose the idea of task-level TCP-friendliness, which enforces TCP-friendliness upon a set of flows belonging to a task instead of upon individual flow. We design DMSCC, a congestion control scheme, to achieve task-level TCP-friendliness in distributed media streaming. By observing shared congestion, DMSCC identifies the set of flows experiencing congestion and dynamically adjusts those flows such that their combined throughput is TCP-friendly. To achieve this goal, DMSCC addresses two issues: (i) given a <i>beta</i> (<i>beta</i> &lt; 1), how to control a flow using AIMD such that it consumes <i>beta</i>-times the throughput of a TCP flow, and (ii) how to identify the set of flows that share a bottleneck. In our simulations, DMSCC can effectively regulate the throughput of flows on every bottleneck, resulting in a TCP-friendly combined throughput.},
keywords={media streaming;telecommunication congestion control;transport protocols;distributed media streaming;congestion control;transmission control protocol;network performance;TCP friendliness;Streaming media;Distributed control;Throughput;Bandwidth;Aggregates;Peer to peer computing;Distributed computing;Communications Society;Communication system control;Collaboration},
doi={10.1109/INFCOM.2007.165},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215748,
author={G. Liang and B. Liang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Balancing Interruption Frequency and Buffering Penalties in VBR Video Streaming},
year={2007},
volume={},
number={},
pages={1406-1414},
abstract={The main goal of a streaming application is to enable the successful decoding of each video object before its displaying deadline is violated, and to recover from a deadline violation properly. Hence, we define the main performance metric of a streaming system as the number of interruptions during a video presentation, or the number of jitters. Previous literature has described solutions to estimate the jitter-free probability for an entire video segment. In this work, we present a novel analytical framework, which requires only a Markov Variable Bit Rate (VBR) channel model, to study the frequency of jitters under the constraint of initial playback delay, receiver buffer size, and different jitter recovering schemes. Both the infinite and finite buffer cases are considered. This technique is then applied to investigate streaming over a wireless system modeled by an extended Gilbert channel with ARQ transmission control. Experimental results with MPEG-4 VBR encoded video validate our analysis. Finally, we show that the proposed analysis provides a theoretical foundation to quantify the tradeoffs between the jitter frequency, jitter recovering delay, initial delay, and the receiver buffer size for a general class of VBR streaming over random VBR channels with different jitter recovering schemes.},
keywords={automatic repeat request;decoding;jitter;Markov processes;media streaming;mobile radio;variable rate codes;video coding;wireless channels;video object decoding;deadline violation;interruption frequency;buffering penalty;jitter;Markov variable bit rate channel;extended Gilbert channel;ARQ transmission control;wireless system;media streaming;Frequency;Streaming media;Jitter;Delay;MPEG 4 Standard;Network servers;Automatic repeat request;Spine;Wireless networks;Communications Society},
doi={10.1109/INFCOM.2007.166},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215749,
author={T. Moscibroda and R. Rejaie},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={PRIME: Peer-to-Peer Receiver-drIven MEsh-Based Streaming},
year={2007},
volume={},
number={},
pages={1415-1423},
abstract={The success of swarming content delivery has motivated a new approach to live peer-to-peer (P2P) streaming that we call mesh-based streaming. In this approach, participating peers form a random mesh and incorporate swarming content delivery to stream live content. Despite the growing popularity of this approach, neither the design tradeoffs nor the basic performance bottlenecks in mesh-based P2P streaming are well understood. This paper presents PRIME, the first mesh-based P2P streaming for live content that effectively incorporates swarming content delivery. We identify two performance bottlenecks in a mesh-based P2P streaming, namely bandwidth bottleneck and content bottleneck. We derive proper peer connectivity to minimize bandwidth bottleneck as well as an efficient pattern of delivery for live content over a random mesh to minimize content bottleneck. We show that the pattern of delivery can be divided into diffusion and swarming phases and then identify proper packet scheduling algorithm at individual peers. Using ns simulations, we examine key characteristics, design tradeoffs and the relationship between main system parameters.},
keywords={Internet;peer-to-peer computing;video streaming;PRIME;peer-to-peer receiver;mesh-based streaming;swarming content delivery;peer-to-peer streaming;random mesh;bandwidth bottleneck;content bottleneck;peer connectivity;diffusion;packet scheduling;nanosecond simulation;Internet;Peer to peer computing;Bandwidth;Streaming media;Scheduling algorithm;Communications Society;IP networks;Throughput;Scalability;Engineering profession;Degradation},
doi={10.1109/INFCOM.2007.167},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215750,
author={N. Magharei and R. Rejaie and Y. Guo},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Mesh or Multiple-Tree: A Comparative Study of Live P2P Streaming Approaches},
year={2007},
volume={},
number={},
pages={1424-1432},
abstract={Existing approaches to P2P streaming can be divided into two general classes: (<i>i</i>) <i>tree-based approaches </i>use push-based content delivery over multiple tree-shaped overlays, and (<i>ii</i>) <i>mesh-based approaches </i>use swarming content delivery over a randomly connected mesh. Previous studies have often focused on a particular P2P streaming mechanism and no comparison between these two classes has been conducted. In this paper, we compare and contrast the performance of representative protocols from each class using simulations. We identify the similarities and differences between these two approaches. Furthermore, we separately examine the behavior of content delivery and overlay construction mechanisms for both approaches in static and dynamic scenarios. Our results indicate that the mesh-based approach consistently exhibits a superior performance over the tree-based approach. We also show that the main factors attributing in the inferior performance of the tree-based approach are (<i>i</i>) the static mapping of content to a particular tree, and (<i>ii</i>) the placement of each peer as an internal node in one tree and as a leaf in all other trees.},
keywords={Internet;media streaming;peer-to-peer computing;telecommunication network topology;trees (mathematics);live P2P streaming approaches;tree-based approaches;push-based content delivery;multiple tree-shaped overlays;mesh-based approaches;swarming content delivery;randomly connected mesh;protocols;Internet;Bandwidth;Protocols;Peer to peer computing;Streaming media;Stability;Communications Society;Vegetation mapping;Internet;Scalability;Aggregates},
doi={10.1109/INFCOM.2007.168},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215751,
author={T. Moscibroda and R. Rejaie and R. Wattenhofer},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={How Optimal are Wireless Scheduling Protocols?},
year={2007},
volume={},
number={},
pages={1433-1441},
abstract={In wireless networks mutual interference impairs the quality of received signals and might even prevent the correct reception of messages. It is therefore of paramount importance to dispose of power control and scheduling algorithms, coordinating the transmission of communication requests. We propose a new measure disturbance in order to comprise the intrinsic difficulty of finding a short schedule for a problem instance. Previously known approaches suffer from extremely bad performance in certain network scenarios even if disturbance is low. To overcome this problem, we present a novel scheduling algorithm for which we give analytical worst-case guarantees on its performance. Compared to previously known solutions, the algorithm achieves a speed up, which can be exponential in the size of the network.},
keywords={protocols;radio networks;radiofrequency interference;scheduling;wireless scheduling protocols;wireless networks mutual interference;received signals quality;communication requests;Wireless application protocol;Interference;Wireless networks;Scheduling algorithm;Power control;Performance analysis;Computer networks;Power engineering computing;Power engineering and energy;Laboratories},
doi={10.1109/INFCOM.2007.169},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215752,
author={M. Felegyhazi and M. Cagalj and S. S. Bidokhti and J. -. Hubaux},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Non-Cooperative Multi-Radio Channel Allocation in Wireless Networks},
year={2007},
volume={},
number={},
pages={1442-1450},
abstract={Channel allocation was extensively studied in the framework of cellular networks. But the emergence of new system concepts, such as cognitive radio systems, has brought this topic into the focus of research again. In this paper, we study in detail the problem of competitive multi-radio multi-channel allocation in wireless networks. We study the existence of Nash equilibria in a static game and we conclude that, in spite of the non-cooperative behavior of such devices, their channel allocation results in a load-balancing solution. In addition, we consider the fairness properties of the resulting channel allocations and their resistance to the possible coalitions of a subset of players. Finally, we present three algorithms that achieve a load-balancing Nash equilibrium channel allocation; each of them using a different set of available information.},
keywords={channel allocation;wireless channels;non-cooperative multi-radio channel allocation;wireless networks;Nash equilibria;Channel allocation;Wireless networks;Land mobile radio cellular systems;Electronic mail;Distributed algorithms;Convergence;Cognitive radio;Frequency division multiaccess;Telecommunication traffic;Nash equilibrium},
doi={10.1109/INFCOM.2007.170},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215753,
author={B. Kauffmann and F. Baccelli and A. Chaintreau and V. Mhatre and K. Papagiannaki and C. Diot},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Measurement-Based Self Organization of Interfering 802.11 Wireless Access Networks},
year={2007},
volume={},
number={},
pages={1451-1459},
abstract={The popularity of IEEE 802.11 WLANs has led to dense deployments in urban areas. High density leads to sub-optimal performance unless the interfering networks learn how to optimally use and share the spectrum. This paper proposes two fully distributed algorithms that allow (i) multiple interfering 802.11 access points to select their operating frequency in order to minimize interference, and (ii) users to choose the access point they attach to, in order to get their fair share of the whole network bandwidth. The proposed algorithms rely on Gibbs sampler, and do not require explicit coordination among the wireless devices. They only require the participating wireless nodes to measure local quantities such as interference and transmission delay. The algorithms are shown to lead to optimal bandwidth sharing, where optimality is defined according to the minimal potential delay. We analytically prove the convergence of the proposed algorithms, and study their performance by simulation.},
keywords={radio access networks;radiofrequency interference;wireless LAN;measurement-based self organization;interfering 802.11 wireless access networks;IEEE 802.11 WLAN;urban areas;distributed algorithms;multiple interfering 802.11 access points;wireless nodes;transmission delay;optimal bandwidth sharing;Wireless networks;Interference;Bandwidth;Delay;Urban areas;Distributed algorithms;Frequency;Particle measurements;Performance analysis;Algorithm design and analysis},
doi={10.1109/INFCOM.2007.171},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215754,
author={C. Peng and Q. Zhang and M. Zhao and Y. Yao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Performance Analysis of Network-Coded Cooperation in Wireless Networks},
year={2007},
volume={},
number={},
pages={1460-1468},
abstract={Cooperative communication is a powerful technology combating fading in wireless medium. In contrast to conventional cooperation (CC) which allows the relay to simply process and forward what it has heard, network-coded cooperation (NCC) endows network coding capability with the relay, i.e., allows the relay to first encode the data it has received from different sources and then forward the network-coded data to corresponding destinations. In this paper we systematically investigate the performance of NCC in terms of diversity-multiplexing tradeoff as well as exact system outage behavior. Under the assumption (denoted as A) that each destination can reliably overhear the data from other sources, we prove the diversity-multiplexing tradeoff of NCC outperforms that of CC. Moreover, we derive the close form of the system outage probability of NCC as a function of signal-to-noise ratio (SNR). The analytical and numerical results show that by requiring less bandwidth cost, NCC offers a similar or even reduced system outage probability compared with CC, and achieves the same full diversity order as CC at high SNR. Finally we discuss the performance of NCC in case the assumption A is removed. For a wireless network composed of N s-d pairs and a single relay, although there is a certain system outage probability increase for NCC, it still provides the same full diversity order of 2 as CC at high SNR, and has a diversity-multiplexing tradeoff superior to CC.},
keywords={encoding;multiplexing;radio networks;telecommunication network reliability;wireless network-coded cooperative communication;wireless telecommunication network performance analysis;diversity multiplexing;signal-to-noise ratio;Performance analysis;Wireless networks;Network coding;Relays;Power system relaying;Fading;Bandwidth;Protocols;Communications Society;Signal to noise ratio},
doi={10.1109/INFCOM.2007.172},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215755,
author={A. H. M. Rad and V. W. S. Wong},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Joint Channel Allocation, Interface Assignment and MAC Design for Multi-Channel Wireless Mesh Networks},
year={2007},
volume={},
number={},
pages={1469-1477},
abstract={In a wireless mesh network (WMN) with a number of stationary wireless routers, the aggregate capacity can be increased when each router is equipped with multiple network interface cards (NICs) and each NIC within a router is assigned to a distinct orthogonal frequency channel. In this paper, given the logical topology of the network, we formulate the joint channel allocation, interface assignment, and media access control (MAC) problem as a cross-layer non-linear mixed-integer network utility maximization problem. An optimal joint design, based on exact binary linearization techniques, is proposed which leads to a global maximum. A near-optimal joint design, based on approximate dual decomposition techniques, is also proposed which is of more interest in terms of practical deployment. Performance evaluation is given through a number of numerical examples in terms of network utility maximization and aggregate network throughput.},
keywords={access protocols;channel allocation;network interfaces;radio networks;telecommunication network routing;telecommunication network topology;joint channel allocation;interface assignment;MAC design;multichannel wireless mesh network;stationary wireless router;multiple network interface card;orthogonal frequency channel;logical topology;media access control;cross-layer nonlinear mixed-integer network utility maximization problem;approximate dual decomposition technique;Channel allocation;Wireless mesh networks;Aggregates;Utility programs;Network interfaces;Frequency;Network topology;Media Access Protocol;Linearization techniques;Throughput},
doi={10.1109/INFCOM.2007.173},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215756,
author={S. Du and A. K. Saha and D. B. Johnson},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={RMAC: A Routing-Enhanced Duty-Cycle MAC Protocol for Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1478-1486},
abstract={Duty-cycle MAC protocols have been proposed to meet the demanding energy requirements of wireless sensor networks. Although existing duty-cycle MAC protocols such as S-MAC are power efficient, they introduce significant end-to-end delivery latency and provide poor traffic contention handling. In this paper, we present a new duty-cycle MAC protocol, called RMAC (the routing enhanced MAC protocol), that exploits cross-layer routing information in order to avoid these problems without sacrificing energy efficiency. In RMAC, a setup control frame can travel across multiple hops and schedule the upcoming data packet delivery along that route. Each intermediate relaying node for the data packet along these hops sleeps and intelligently wakes up at a scheduled time, so that its upstream node can send the data packet to it and it can immediately forward the data packet to its downstream node. When wireless medium contention occurs, RMAC moves contention traffic away from the busy area by delivering data packets over multiple hops in a single cycle, helping to reduce the contention in the area quickly. Our simulation results in ns-2 show that RMAC achieves significant improvement in end-to-end delivery latency over S-MAC and can handle traffic contention much more efficiently than S-MAC, without sacrificing energy efficiency or network throughput.},
keywords={access protocols;telecommunication network routing;wireless sensor networks;routing-enhanced duty-cycle MAC protocol;wireless sensor networks;end-to-end delivery latency;cross-layer routing information;data packet delivery;wireless medium contention;Media Access Protocol;Wireless application protocol;Wireless sensor networks;Delay;Routing protocols;Energy efficiency;Traffic control;Communication system traffic control;Relays;Sleep},
doi={10.1109/INFCOM.2007.174},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215757,
author={H. Su and X. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Efficient Single-Transceiver CDMA-Based MAC Protocol for Wireless Networks},
year={2007},
volume={},
number={},
pages={1487-1495},
abstract={Applying the code division multiple access (CDMA) techniques, we propose an efficient medium access control (MAC) protocol with single-transceiver for wireless ad hoc networks. Our protocol adopts the time-division method to solve the near-far power control problem inherently associated with the CDMA-based networks. In particular, employing the variable ad-hoc traffic indication messages (ATIM) window to properly determine the required transmission power for data packets, our scheme enables the interference-limited simultaneous transmissions to achieve the high utilization of the limited/precious bandwidth in wireless networks. In addition, our scheme requires only one transceiver per node, which reduces the hardware costs for large scale wireless networks. Using the Markov-chain techniques, we develop an analytical model to evaluate the aggregate throughput under our protocol. Both the analytical and simulation results show that our protocol can improve the network throughput significantly as compared with other existing schemes.},
keywords={ad hoc networks;code division multiple access;Markov processes;telecommunication traffic;transceivers;single-transceiver CDMA-based MAC protocol;code division multiple access;medium access control protocol;wireless ad hoc networks;time-division method;near-far power control problem;variable ad-hoc traffic indication message window;bandwidth utilization;Markov-chain technique;Media Access Protocol;Wireless application protocol;Wireless networks;Access protocols;Multiaccess communication;Analytical models;Throughput;Mobile ad hoc networks;Power control;Communication system traffic control},
doi={10.1109/INFCOM.2007.175},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215758,
author={A. A. Cardenas and S. Radosavac and J. S. Baras},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Performance Comparison of Detection Schemes for MAC Layer Misbehavior},
year={2007},
volume={},
number={},
pages={1496-1504},
abstract={This paper revisits the problem of detecting greedy behavior in the IEEE 802.11 MAC protocol by evaluating the performance of two previously proposed schemes: DOMINO and the sequential probability ratio test (SPRT). The evaluation is carried out in four steps. We first derive a new analytical formulation of the SPRT that takes into account the discrete nature of the problem. Then we develop a new tractable analytical model for DOMINO. As a third step, we evaluate the theoretical performance of SPRT and DOMINO with newly introduced metrics that take into account the repeated nature of the tests. This theoretical comparison provides two major insights into the problem: it confirms the optimality of SPRT and motivates us to define yet another test, a nonparametric CUSUM statistic that shares the same intuition as DOMINO but gives better performance. We finalize the paper with experimental results, confirming our theoretical analysis and validating the introduction of the new nonparametric CUSUM statistic.},
keywords={access protocols;probability;wireless LAN;detection schemes;MAC layer misbehavior;IEEE 802.11 MAC protocol;DOMINO;sequential probability ratio test;tractable analytical model;Media Access Protocol;Access protocols;System performance;Statistical analysis;Collaboration;Communications Society;Educational institutions;System testing;Sequential analysis;Analytical models},
doi={10.1109/INFCOM.2007.176},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215759,
author={D. Xu and Y. Li and M. Chiang and A. R. Calderbank},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Provisioning of Elastic Service Availability},
year={2007},
volume={},
number={},
pages={1505-1513},
abstract={Service availability is one of the most closely scrutinized metrics in offering network services. The network vendor can earn more revenue from the customers by guaranteeing higher service availability at the cost of higher operational expense. It is important to cost-effectively provision a managed and differentiated network with various service availability guarantees under a unified platform. In this paper, we establish the framework of provisioning elastic service availability through network utility maximization, and propose an optimal and distributed solution using differentiated failure recovery schemes. First, we develop a utility function with configurable parameters to represent the satisfaction perceived by a user upon service availability as well as its allowed source rate. Second, adopting quality of protection [1] and shared path protection, we transform optimal provisioning of elastic service availability into a convex optimization problem. The desirable service availability and source rate for each user can be achieved using a price-based distributed algorithm. Finally, we numerically show the tradeoff between the throughput and the service availability obtained by users in various network topologies. Several quantitative observations are made from this investigation. For example, indiscriminately provisioning service availabilities for different kinds of users within one network leads to noteworthy sub-optimality in total network utility. The profile of bandwidth usage also illustrates that provisioning high service availability exclusively for critical applications leads to significant waste in bandwidth resource.},
keywords={bandwidth allocation;computer network management;convex programming;DiffServ networks;distributed algorithms;quality of service;system recovery;telecommunication network topology;telecommunication security;optimal elastic service availability provisioning;network vendor;differentiated services network management;network utility maximization;differentiated failure recovery scheme;utility function;quality of protection;shared path protection;convex optimization problem;price-based distributed algorithm;network topology;bandwidth usage profile;Availability;Utility programs;Protection;Distributed algorithms;Resource management;Quality of service;Costs;Bandwidth;Communications Society;USA Councils},
doi={10.1109/INFCOM.2007.177},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215760,
author={W. L. Tan and F. Lam and W. C. Lau},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Empirical Study on 3G Network Capacity and Performance},
year={2007},
volume={},
number={},
pages={1514-1522},
abstract={This paper presents the findings of an extensive measurement study on multiple commercial 3G UMTS networks. We have investigated the performances of those 3G networks in terms of their data throughput, latency, video and voice calls handling capacities, and their ability to provide service guarantees to different traffic classes under various loading conditions. Our findings indicate the diverse nature of network resources allocation and call admission control policies employed by different operators. It is also found that the 3G network operators seem to have extensively customized their network configurations in a cell-by-cell manner according to the individual site's local demographics, projected traffic demand and the target coverage area of the cell. As such, the cell capacity varies widely not only across different operators but also across different measurement sites of the same operator. Even for the same site, the capacity can easily change by more than 10% across multiple measurements taken at different time of the day. The results also show that it is practically impossible to predict the actual capacity of a cell based on known theoretical models and standard parameters, even when supplemented by key field measurements such as the received signal-to-noise ratio (E<sub>c</sub>/N<sub>0</sub>).},
keywords={3G mobile communication;bandwidth allocation;cellular radio;performance evaluation;queueing theory;radio links;resource allocation;scheduling;telecommunication congestion control;telecommunication traffic;transport protocols;3G cellular network capacity;commercial 3G UMTS network performance;data throughput;voice call handling capacities;service guarantees;traffic classes;bandwidth resource allocation;call admission control policies;cell capacity;TCP throughput;radio link scheduler;queueing latency;Communication system traffic control;3G mobile communication;Throughput;Delay;Resource management;Call admission control;Demography;Time measurement;Predictive models;Measurement standards},
doi={10.1109/INFCOM.2007.178},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215761,
author={R. Doverspike and G. Li and K. Oikonomou and K. K. Ramakrishnan and D. Wang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={IP Backbone Design for Multimedia Distribution: Architecture and Performance},
year={2007},
volume={},
number={},
pages={1523-1531},
abstract={Multimedia distribution, especially broadcast TV distribution over an IP network requires high bandwidth combined with tight latency and loss constraints, even under failure conditions. Due to the high bandwidth requirements of broadcast TV distribution, use of IP-based multicast to distribute TV content is needed for efficient use of capacity. The protection and restoration mechanisms currently adopted in IP backbones use either IGP re-convergence or some form of fast reroute. The IGP re-convergence mechanism is too slow for real-time multimedia distribution while a drawback of fast reroute is that traffic is re-routed on a link-basis (instead of end-to-end) so there can be traffic overlap during failures. By this we mean traffic passing through the same link along the same direction more than once; this requires more link capacity or it will result in congestion. We propose a routing method that interacts with Fast Reroute and multicast to minimize traffic overlap during failures. We also present an algorithm for link weight setting that avoids traffic overlap due to any single link failure. Performance analysis shows that our methods improve network service availability and significantly reduce the impact of failures.},
keywords={IP networks;multimedia communication;real-time systems;telecommunication network routing;telecommunication traffic;television broadcasting;IP backbone design;multimedia distribution;broadcast TV distribution;IP network;restoration mechanism;IGP re-convergence mechanism;real-time multimedia distribution;traffic overlap;routing method;Spine;Multimedia communication;TV broadcasting;Bandwidth;Telecommunication traffic;Digital multimedia broadcasting;IP networks;Delay;Protection;Routing},
doi={10.1109/INFCOM.2007.179},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215762,
author={S. Q. Zheng and B. Yang and M. Yang and J. Wang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Finding Minimum-Cost Paths with Minimum Sharability},
year={2007},
volume={},
number={},
pages={1532-1540},
abstract={In communication networks, multiple communication paths sharing minimum number of links or/and nodes may be desirable for improved performance, resource utilization and reliability. We introduce the notion of link sharability and node sharability, and consider the problems of finding minimum-cost k paths subject to minimum link/node sharability constraints. We identify 65 different link/node sharability constraints, and consider the fundamental problem of finding minimum-cost k paths between a pair of nodes under these constraints. We present a unified polynomial-time algorithm scheme for solving this problem subject to 25 of these different sharability constraints.},
keywords={computational complexity;computer network reliability;resource allocation;multiple communication path;resource utilization;node sharability;link sharability;polynomial-time algorithm;minimum-cost network flow;Peer to peer computing;Costs;USA Councils;Computer science;Communication networks;Telecommunication network reliability;Polynomials;Routing protocols;Protection;Communications Society},
doi={10.1109/INFCOM.2007.180},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215763,
author={D. Shah and S. Shakkottai},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Oblivious Routing with Mobile Fusion Centers over a Sensor Network},
year={2007},
volume={},
number={},
pages={1541-1549},
abstract={We consider the problem of aggregating data at a mobile fusion center (fusor) (eg. a PDA or a cellular phone) moving within a spatial region over which a wireless sensor network (eg., fixed motes) has been deployed. Each sensor node generates packets destined to the fusor, and our objective is to develop strategies that can route the packets to the mobile fusor. For an arbitrary (possibly random) fusor mobility pattern over any connected subset of the sensor deployment area, we first derive upper bounds on the aggregation data rate (i.e., the uniform rate region from each sensor node to the mobile fusor), where we allow all sensor nodes to have complete knowledge of the mobility pattern of the fusor. We then consider aggregation data rates that can be achieved when the mobility pattern of the fusor is unknown to the sensor nodes. Surprisingly, we show that for a class of mobility patterns (random mobility over connected-compositions of convex sets of the deployment region, e.g. random walks over piece-wise linear sets), we can construct "universal" mobility-oblivious routing strategies that achieve aggregation data rates that are of the same order as the (mobility-aware) upper bound.},
keywords={mobile radio;sensor fusion;telecommunication network routing;wireless sensor networks;mobile fusion centers;wireless sensor network;sensor deployment area;mobility pattern;convex sets;oblivious routing;Routing;Sensor fusion;Wireless sensor networks;Peer to peer computing;Upper bound;Mobile computing;Communications Society;Computer science;Personal digital assistants;Cellular phones},
doi={10.1109/INFCOM.2007.181},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215764,
author={Y. Cai and W. Lou and M. Li and X. -. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Target-oriented scheduling in directional sensor networks},
year={2007},
volume={},
number={},
pages={1550-1558},
abstract={Unlike convectional omni-directional sensors that always have an omni-angle of sensing range, directional sensors may have a limited angle of sensing range due to technical constraints or cost considerations. A directional sensor network consists of a number of directional sensors, which can switch to several directions to extend their sensing ability to cover all the targets in a given area. Power conservation is still an important issue in such directional sensor networks. In this paper, we address the multiple directional cover sets problem (MDCS) of organizing the directions of sensors into a group of non-disjoint cover sets to extend the network lifetime. One cover set, in which the directions cover all the targets, is activated at one time. We prove the MDCS to be NP-complete and propose three heuristic algorithms for the MDCS. Simulation results are also presented to demonstrate the performance of these algorithms.},
keywords={computational complexity;distributed sensors;optimisation;scheduling;target-oriented scheduling;directional sensor network;power conservation;multiple directional cover set problem;NP-complete;heuristic algorithm;Sensor phenomena and characterization;Switches;Infrared sensors;Computer science;Costs;Communications Society;Scheduling;Organizing;Heuristic algorithms;Monitoring},
doi={10.1109/INFCOM.2007.182},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215765,
author={Y. Chen and E. Fleury},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Distributed Policy Scheduling for Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1559-1567},
abstract={We aim to save energy by scheduling periodic sensors' duty cycles. Different from existing works, we integrate two important tasks, collision avoidance and duty cycling, into one scheduling of sensors' activities. Our scheme consists of two parts: a <i>coloring scheme</i> that assigns a "color" to each sensor and a <i>color scheduling scheme</i> that associates each color with a schedule. Each sensor switches between sleep and active modes according to the schedule associated with its color. We propose a coloring definition. Theoretical analyses and simulation results show that, if this coloring is used by collision avoidance schemes such as TDMA or CDMA, connectivity can be guaranteed by using much less colors than traditional colorings. Theoretical analyses and simulation evaluations are presented for our scheduling. As compared to handling collision avoidance and duty cycling separately, performances can be improved by integrating these two tasks into one carefully designed schedule of sensors' activities. In particular, in duty cycled dense networks, in order to reduce packet latency and save energy, it is desirable to guarantee the communication connectivity of links only in a sparse connected subgraph.},
keywords={graph theory;scheduling;telecommunication congestion control;wireless sensor networks;distributed policy scheduling;wireless sensor network;collision avoidance;color scheduling scheme;sensor switch;active mode;sleep mode;TDMA;CDMA;duty cycled dense network;packet latency;sparse connected subgraph;Wireless sensor networks;Synchronization;Delay;Collision avoidance;Energy efficiency;Analytical models;Time division multiple access;Telecommunication traffic;Costs;Protocols},
doi={10.1109/INFCOM.2007.183},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215766,
author={Y. Wu and S. Fahmy and N. B. Shroff},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Energy Efficient Sleep/Wake Scheduling for Multi-Hop Sensor Networks: Non-Convexity and Approximation Algorithm},
year={2007},
volume={},
number={},
pages={1568-1576},
abstract={We study sleep/wake scheduling for low duty cycle sensor networks. Our work is different from prior work in that we explicitly consider the effect of synchronization error in the design of the sleep/wake scheduling algorithm. In our previous work, we have studied sleep/wake scheduling for single hop communications, e.g., intra-cluster communications between a cluster head and cluster members. We showed that the there is an inherent trade-off between energy consumption and message delivery performance (defined as the message capture probability). We proposed an optimal sleep/wake scheduling algorithm, which satisfies a message capture probability threshold (assumed to be given) with minimum energy consumption. In this work, we consider multi-hop communications. We remove the previous assumption that the capture probability threshold is already given, and study how to decide the per-hop capture probability thresholds to meet the quality of services (QoS) requirements of the application. In many sensor network applications, the QoS is decided by the amount of data delivered to the base station(s), i.e., the multi-hop delivery performance. We formulate an optimization problem, which aims to set the capture probability threshold at each hop such that the network lifetime is maximized, while the multi-hop delivery performance is guaranteed. The problem turns out to be non-convex and hard to solve exactly. By investigating the unique structure of the problem and using approximation techniques, we obtain a solution that achieves at least 0.73 of the optimal performance.},
keywords={approximation theory;concave programming;probability;quality of service;scheduling;wireless sensor networks;energy efficient sleep-wake scheduling;multihop sensor networks;nonconvexity algorithm;approximation algorithm;low duty cycle sensor networks;multihop communications;per-hop capture probability thresholds;quality of services;QoS;optimization problem;Energy efficiency;Sleep;Spread spectrum communication;Approximation algorithms;Scheduling algorithm;Synchronization;Wireless sensor networks;Energy consumption;Energy capture;Monitoring},
doi={10.1109/INFCOM.2007.184},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215767,
author={G. N. Rouskas and N. Baradwaj},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Framework for Tiered Service in MPLS Networks},
year={2007},
volume={},
number={},
pages={1577-1585},
abstract={Many network operators offer some type of tiered service, in which users may select only from a small set of service levels (tiers). Such a service has the potential to simplify a wide range of core network functions, allowing the providers to scale their operations efficiently. In this work, we provide a theoretical framework for reasoning about and tackling algorithmically the general problem of service tier selection. Drawing upon results from discrete location theory, we formulate the problem as a <i>p</i>-median problem under a new directional distance measure, and we develop efficient algorithms for a number of important variants. Our main finding is that, by appropriately selecting the set of service levels, network providers may realize the benefits of tiered service with only a small sacrifice in network resources.},
keywords={multiprotocol label switching;MPLS network;core network function;service tier selection;discrete location theory;multiprotocol label switching network;Multiprotocol label switching;Bandwidth;Telecommunication traffic;Time division multiplexing;Transfer functions;Communications Society;Optical fiber communication;Aggregates;Packaging;Tunneling},
doi={10.1109/INFCOM.2007.185},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215768,
author={M. Verloop and S. Borst},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Heavy-Traffic Delay Minimization in Bandwidth-Sharing Networks},
year={2007},
volume={},
number={},
pages={1586-1594},
abstract={Bandwidth-sharing networks as considered by Massoulie &amp; Roberts provide a natural modeling framework for describing the dynamic flow-level interaction among elastic data transfers. Although valuable stability results have been obtained, crucial performance metrics such as flow-level delays and throughputs in these models have remained intractable in all but a few special cases. In particular, it is not well understood to what extent flow-level delays and throughputs achieved by standard bandwidth-sharing mechanisms such as alpha-fair strategies leave potential room for improvement. In order to gain a better understanding of the latter issue, we set out to determine the scheduling policies that minimize the mean delay in some simple linear bandwidth-sharing networks. While admittedly simple, linear networks provide a useful model for flows that traverse several links and experience bandwidth contention from independent cross-traffic. Even for linear topologies it is rarely possible however to explicitly identify optimal policies except in a few limited cases with exponentially distributed flow sizes. Rather than aiming for strictly optimal policies, we therefore focus on a class of relatively simple priority-type strategies that only separate large flows from small ones. To benchmark the performance of these strategies, we compare them with proportional fair as the prototypical alpha-fair policy, and establish that the mean delay may be reduced by an arbitrarily large factor when the load is sufficiently high. In addition, we show the above strategies to be asymptotically optimal for flow size distributions with bounded support. Numerical experiments reveal that even at fairly moderate load values the performance gains can be significant.},
keywords={bandwidth allocation;minimisation;telecommunication traffic;heavy-traffic delay minimization;linear bandwidth-sharing network;elastic data transfer;flow-level delay;scheduling policy;Delay;Throughput;Bandwidth;Processor scheduling;Web server;Stability;Measurement;Performance gain;Communications Society;Mathematics},
doi={10.1109/INFCOM.2007.186},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215769,
author={N. Sarshar and X. Wu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Rate-Distortion Optimized Network Communication},
year={2007},
volume={},
number={},
pages={1595-1603},
abstract={Network information multicast has been considered extensively, either as a routing problem or more recently in the context of network coding. Most of the Internet bandwidth, however, is consumed by multimedia contents that are amenable to lossy reconstruction. In this paper, we investigate the following fundamental question: How does one communicate a media content from nodes (servers) that observe/supply the content to a set of sink nodes (clients) to realize the best possible reconstruction of the content in a rate-distortion sense? While this problem remains essentially open, this paper takes the first step by exploring the intricate entanglement of source coding and network communication, within an optimization framework. In particular, we investigate the joint optimization of network communication strategies (e.g., routing or network coding) and common source coding schemes (e.g., progressive coding or more general multiple description coding). We formulate several such problems for which we are able to develop efficient polynomial time solutions. In particular, we consider layered multicast of progressively encoded source code streams using network coding and optimal routing of balanced multiple description codes. Finally, the improvement in the overall quality of source reconstruction by using the proposed schemes is verified through simulations.},
keywords={client-server systems;media streaming;multicast communication;rate distortion theory;telecommunication network routing;rate-distortion optimized network communication;network information multicast;media content;client-server;source coding;network coding;optimal routing;Rate-distortion;Routing;Network coding;Source coding;Context;Internet;Bandwidth;Network servers;Web server;Polynomials},
doi={10.1109/INFCOM.2007.187},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215770,
author={G. Retvari and J. J. Biro and T. Cinkler},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Fairness in Capacitated Networks: A Polyhedral Approach},
year={2007},
volume={},
number={},
pages={1604-1612},
abstract={The problem of fair and feasible allocation of user throughputs in capacitated networks is investigated. The main contribution of the paper is a novel geometric approach, which facilitates to generalize several throughput allocation strategies, most importantly max-min fairness, from the traditional "fixed-path" model to a more versatile, routing-independent model. We show that the set of throughput configurations realizable in a capacitated network makes up a polyhedron, which gives rise to a max-min fair allocation completely analogous to the conventional one. An algorithm to compute this polyhedron is also presented, whose viability is demonstrated by comprehensive evaluation studies.},
keywords={computational geometry;minimax techniques;resource allocation;telecommunication network routing;capacitated network;geometric approach;polyhedral approach;max-min technique;network routing;resource allocation;Throughput;Solid modeling;Resource management;Computer networks;Communications Society;High-speed networks;Laboratories;Informatics;Electronic mail;Telecommunication computing},
doi={10.1109/INFCOM.2007.188},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215771,
author={C. Hu and Y. Tang and X. Chen and B. Liu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Per-Flow Queueing by Dynamic Queue Sharing},
year={2007},
volume={},
number={},
pages={1613-1621},
abstract={Per-flow queuing is believed to be able to guarantee advanced Quality of Service (QoS) for each flow. With the dramatic increase of link speed and number of traffic flows, per-flow queuing faces a great challenge since millions of queues need to be maintained for implementation in a traditional sense. In this paper, by setting only a small number of physical queues, we propose a Dynamic Queue Sharing (DQS) mechanism to achieve an equal performance to the pure per-flow queuing with a lower cost. The proposed mechanism is based on an interesting fact that the number of simultaneous active flows in the router buffer is far less than that of in-progress flows. In DQS, a physical queue is dynamically created on-demand when a new flow comes and then dynamically released when the flow temporarily pauses. Hashing and binary sorting tree (or linked list) are combined to manage the mapping between flows and queues, so as to isolate flows in different queues. Theoretical analysis and traces experiments are conducted to evaluate DQS. The results demonstrate that when the parameters are well set, the operation delay is less than two time cycles in average with an extra memory of 16k bits.},
keywords={quality of service;queueing theory;sorting;telecommunication traffic;trees (mathematics);per-flow queueing;dynamic queue sharing;quality of service;network traffic flow;hashing sorting tree;binary sorting tree;Traffic control;Buffer storage;Quality of service;Costs;Internet;Bandwidth;Spine;Educational programs;Communications Society;Computer science},
doi={10.1109/INFCOM.2007.189},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215772,
author={Y. Xu and B. Liu and G. Xia and D. Lin},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Iteration-Shared Scheduling Algorithms Abolishing the Departure-Time-Compatible Graph in Switch-Memory-Switch Switches},
year={2007},
volume={},
number={},
pages={1622-1630},
abstract={Switch-Memory-Switch (SMS) architecture exhibits an excellent performance due to its emulating the Output Queueing structure. However, in order to achieve the maximal matching, the first stage scheduling operates at a huge computational complexity, which blocks the SMS from practical implementation. In order to put SMS into more effective industrial applications, especially in super-large size switches/routers with multi-services environment, two parallel iterative scheduling algorithms, named IS-RRM and AIS-RRM respectively, are proposed in this paper. The algorithms abolish totally the traditional departure-time-compatible (DTC) graph, and by using iteration-sharing technology, greatly reduce the required iteration number in each time slot. Using a discrete-time Markov chain to model the AIS-RRM algorithm, we obtain its upper bound of cell loss rate. Meanwhile, experimental and theoretical results show that so long as the number of shared memories is twice the switch size, AIS-RRM algorithm can achieve a cell loss rate of 10 when the input buffer size is 15 and the iteration number of each time slot is 6, despite the arrival traffic pattern and the switch size. Furthermore, the iteration number required in each time slot can be further decreased by increasing the input buffer size.},
keywords={graph theory;iterative methods;Markov processes;queueing theory;scheduling;telecommunication network routing;telecommunication switching;iteration-shared scheduling algorithms;departure-time-compatible graph;switch-memory-switch switches;output queueing structure;iterative scheduling algorithms;discrete-time Markov chain;arrival traffic pattern;Scheduling algorithm;Switches;Computational complexity;Processor scheduling;Iterative algorithms;Traffic control;Communication switching;Job shop scheduling;Scalability;Fabrics},
doi={10.1109/INFCOM.2007.190},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215773,
author={A. Gupta and X. Lin and R. Srikant},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Low-Complexity Distributed Scheduling Algorithms for Wireless Networks},
year={2007},
volume={},
number={},
pages={1631-1639},
abstract={We consider the problem of distributed scheduling in wireless networks. We present two different algorithms whose performance is arbitrarily close to that of maximal schedules, but which require low complexity due to the fact that they do not necessarily attempt to find maximal schedules. The first algorithm requires each link to collect local queue-length information in its neighborhood, and its complexity is independent of the size and topology of the network. The second algorithm is presented for the node-exclusive interference model, does not require nodes to collect queue-length information even in their local neighborhoods, and its complexity depends only on the maximum node degree in the network.},
keywords={communication complexity;queueing theory;scheduling;telecommunication network topology;wireless channels;low-complexity distributed scheduling algorithms;wireless networks;local queue-length information;network topology;node-exclusive interference model;Scheduling algorithm;Wireless networks;Interference;Processor scheduling;Peer to peer computing;Distributed algorithms;Throughput;Computer networks;Distributed computing;Network topology},
doi={10.1109/INFCOM.2007.191},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215774,
author={K. Kar and X. Luo and S. Sarkar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Throughput-Optimal Scheduling in Multichannel Access Point Networks Under Infrequent Channel Measurements},
year={2007},
volume={},
number={},
pages={1640-1648},
abstract={We consider the problem of uplink/downlink scheduling in a multichannel wireless access point network where channel states differ across channels as well as users, vary with time, and can be measured only infrequently. We demonstrate that, unlike the infrequent measurement of queue lengths, infrequent measurement of channel states reduce the maximum attainable throughput. We then prove in frequency division multiplexing systems, a dynamic scheduling policy that depends on both the channel rates (averaged over the measurement interval) and the queue lengths, attains the maximum possible throughput. We also generalize the scheduling policy to solve the joint power allocation and scheduling problem in orthogonal frequency division multiplexing systems. In addition, we provide simulation studies that demonstrate the impact of the frequency of channel and queue state measurements on the average delay and attained throughput.},
keywords={frequency division multiplexing;queueing theory;radio access networks;scheduling;wireless channels;throughput-optimal scheduling;multichannel access point networks;infrequent channel measurements;uplink-downlink scheduling;wireless access point network;maximum attainable throughput;frequency division multiplexing systems;dynamic scheduling policy;queue lengths;power allocation;Optimal scheduling;Throughput;Length measurement;Frequency division multiplexing;OFDM;Processor scheduling;Electric variables measurement;Time measurement;Computer networks;Systems engineering and theory},
doi={10.1109/INFCOM.2007.192},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215775,
author={W. Zhang and G. Xue and S. Misra},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Fault-Tolerant Relay Node Placement in Wireless Sensor Networks: Problems and Algorithms},
year={2007},
volume={},
number={},
pages={1649-1657},
abstract={Two fundamental functions of the sensor nodes in a wireless sensor network are to sense its environment and to transmit sensed information to a basestation. One approach to prolong sensor network lifetime is to deploy some relay nodes whose main function is to communicate with the sensor nodes, other relay nodes, and the basestations. It is desirable to deploy a minimum number of relay nodes to achieve certain connectivity requirement. In this paper, we study four related fault-tolerant relay node placement problems, each of which has been previously studied only in some restricted form. For each of them, we discuss its computational complexity and present a polynomial time O(1)-approximation algorithm with a small approximation ratio. When the problem reduces to a previously studied form, our algorithm either improves the previous best algorithm or reduces to the previous best algorithm.},
keywords={approximation theory;computational complexity;fault tolerance;wireless sensor networks;fault-tolerant relay node placement;wireless sensor network;prolong sensor network lifetime;computational complexity;polynomial time approximation algorithm;Fault tolerance;Relays;Wireless sensor networks;Peer to peer computing;Polynomials;Approximation algorithms;Tin;Communications Society;Computational complexity;Routing},
doi={10.1109/INFCOM.2007.193},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215776,
author={Y. Lin and B. Liang and B. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Data Persistence in Large-Scale Sensor Networks with Decentralized Fountain Codes},
year={2007},
volume={},
number={},
pages={1658-1666},
abstract={It may not be feasible for sensor networks monitoring nature and inaccessible geographical regions to include powered sinks with Internet connections. We consider the scenario where sinks are not present in large-scale sensor networks, and unreliable sensors have to collectively resort to storing sensed data over time on themselves. At a time of convenience, such cached data from a small subset of live sensors may be collected by a centralized (possibly mobile) collector. In this paper, we propose a decentralized algorithm using fountain codes to guarantee the persistence and reliability of cached data on unreliable sensors. With fountain codes, the collector is able to recover all data as long as a sufficient number of sensors are alive. We use random walks to disseminate data from a sensor to a random subset of sensors in the network. Our algorithms take advantage of the low decoding complexity of fountain codes, as well as the scalability of the dissemination process via random walks. We have proposed two algorithms based on random walks. Our theoretical analysis and simulation-based studies have shown that, the first algorithm maintains the same level of fault tolerance as the original centralized fountain code, while introducing lower overhead than naive random-walk based implementation in the dissemination process. Our second algorithm has lower level of fault tolerance than the original centralized fountain code, but consumes much lower dissemination cost.},
keywords={cache storage;codes;Internet;sensor fusion;large-scale sensor networks;decentralized fountain codes;nature monitoring;powered sinks;Internet connections;sensed data storage;decentralized algorithm;cached data persistence;cached data reliability;unreliable sensors;data dissemination;fountain code low decoding complexity;random walks;fault tolerance;Large-scale systems;Wireless sensor networks;Fault tolerance;IP networks;Decoding;Time measurement;Routing protocols;Communications Society;Monitoring;Scalability},
doi={10.1109/INFCOM.2007.194},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215777,
author={X. Han and X. Cao and E. L. Lloyd and C. -. Shen},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Fault-Tolerant Relay Node Placement in Heterogeneous Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1667-1675},
abstract={Existing work on placing additional relay nodes in wireless sensor networks to improve network connectivity typically assumes homogeneous wireless sensor nodes with an identical transmission radius. In contrast, this paper addresses the problem of deploying relay nodes to provide fault-tolerance with higher network connectivity in heterogeneous wireless sensor networks, where sensor nodes possess different transmission radii. Depending on the level of desired fault-tolerance, such problems can be categorized as: (1) full fault-tolerance relay node placement, which aims to deploy a minimum number of relay nodes to establish k (k ges 1) vertex-disjoint paths between every pair of sensor and/or relay nodes; (2) partial fault-tolerance relay node placement, which aims to deploy a minimum number of relay nodes to establish k (k ges 1) vertex-disjoint paths only between every pair of sensor nodes. Due to the different transmission radii of sensor nodes, these problems are further complicated by the existence of two different kinds of communication paths in heterogeneous wireless sensor networks, namely two-way paths, along which wireless communications exist in both directions; and one-way paths, along which wireless communications exist in only one direction. Assuming that sensor nodes have different transmission radii, while relay nodes use the same transmission radius, this paper comprehensively analyzes the range of problems introduced by the different levels of fault-tolerance (full or partial) coupled with the different types of path (one-way or two-way). Since each of these problems is NP-hard, we develop O(sigmak<sup>2</sup>)-approximation algorithms for both one-way and two-way partial fault-tolerance relay node placement, as well as O(sigmak<sup>3</sup>)-approximation algorithms for both one-way and two-way full fault-tolerance relay node placement (sigma is the best performance ratio of existing approximation algorithms for finding a minimum k-vertex connected spanning graph). To facilitate the applications in higher dimensions, we also extend these algorithms and derive their performance ratios in d-dimensional heterogeneous wireless sensor networks (d ges 3). Finally, heuristic implementations of these algorithms are evaluated via simulations.},
keywords={approximation theory;fault tolerance;optimisation;wireless sensor networks;fault-tolerant relay node placement;heterogeneous wireless sensor networks;network connectivity;vertex-disjoint paths;communication paths;two-way paths;one-way paths;wireless communications;NP-hard problems;approximation algorithms;Fault tolerance;Relays;Wireless sensor networks;Peer to peer computing;Approximation algorithms;Partitioning algorithms;Sensor phenomena and characterization;Wireless communication;Military computing;Collaboration},
doi={10.1109/INFCOM.2007.195},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215778,
author={Z. Ye and A. A. Abouzeid and J. Ai},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Policies for Distributed Data Aggregation in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1676-1684},
abstract={We consider the scenario of distributed data aggregation in wireless sensor networks, where each sensor can obtain and estimate the information of the whole sensing field through local data exchange and aggregation. The intrinsic trade-off between energy and delay in aggregation operations imposes a crucial question on nodes to decide optimal instants for forwarding their samples. The samples could be composed of the information from their own sensor readings or an aggregation of information with other samples forwarded from neighboring nodes. By considering the randomness of the sample arrival instants and the uncertainty of the availability of the multiaccess communication channel due to the asynchronous nature of information exchange among neighboring nodes, we propose a decision process model to analyze this problem and determine the optimal decision policies at nodes with local information. We show that, once the statistics of the sample arrival and the availability of the channel satisfy certain conditions, there exist optimal control-limit type policies which are easy to implement in practice. In the case that the required conditions are not satisfied, we provide two learning algorithms to solve a finite-state approximation model of the decision problem. Simulations on a practical distributed data aggregation scenario demonstrate the effectiveness of the developed policies, which can also achieve a desired energy-delay tradeoff.},
keywords={approximation theory;decision theory;multipath channels;wireless channels;wireless sensor networks;distributed data aggregation;wireless sensor network;data exchange;multiaccess communication channel;decision process model;statistical analysis;learning algorithm;finite-state approximation model;Wireless sensor networks;Delay;Peer to peer computing;Optimal control;Availability;Information analysis;Statistics;Approximation algorithms;Communications Society;Computer networks},
doi={10.1109/INFCOM.2007.196},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215779,
author={L. Lin and X. Lin and N. B. Shroff},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Low-Complexity and Distributed Energy Minimization in Multi-Hop Wireless Networks},
year={2007},
volume={},
number={},
pages={1685-1693},
abstract={In this work, we study the problem of minimizing the total power consumption in a multi-hop wireless network subject to a given offered load. It is well-known that the total power consumption of multi-hop wireless networks can be substantially reduced by jointly optimizing power control, link scheduling, and routing. However, the known optimal cross-layer solution to this problem is centralized, and with high computational complexity. In this paper, we develop a low-complexity and distributed algorithm that is provably power-efficient. In particular, under the node exclusive interference model, we can show that the total power consumption of our algorithm is at most twice as large as the power consumption of the optimal (but centralized and complex) algorithm. Our algorithm is not only the first such distributed solution with provable performance bound, but its power-efficiency ratio is also tighter than that of another sub-optimal centralized algorithm in the literature.},
keywords={computational complexity;optimisation;power consumption;radio networks;distributed energy minimization;multi-hop wireless networks;power consumption;power control;link scheduling;computational complexity;Spread spectrum communication;Wireless networks;Energy consumption;Power control;Routing;Interference;Wireless sensor networks;Wireless mesh networks;Scheduling algorithm;Processor scheduling},
doi={10.1109/INFCOM.2007.197},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215780,
author={Y. Shi and Y. T. Hou},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Power Control for Multi-Hop Software Defined Radio Networks},
year={2007},
volume={},
number={},
pages={1694-1702},
abstract={Software defined radio (SDR) is a revolution in radio technology that promises unprecedented flexibility in radio communications and is viewed as an enabling technology for dynamic spectrum access. This paper investigates how to support user communication sessions by jointly considering power control, scheduling, and flow routing for an SDR-based multi-hop wireless network. We develop a formal mathematical model for scheduling feasibility under the influence of power control. This model extends existing protocol interference model for wireless networks and can be used for a broad class of problems where power control (and thus transmission range and interference range) is part of the optimization space. We formulate a cross-layer optimization problem encompassing power control, scheduling, and flow routing. Subsequently, we develop an efficient solution procedure based on branch-and-bound technique and convex hull relaxation. Using simulation results, we demonstrate the efficacy of the solution procedure and offer insights on the impact of power control on scheduling feasibility, bandwidth efficiency, and bandwidth-footprint product (BFP).},
keywords={convex programming;routing protocols;scheduling;software radio;telecommunication control;tree searching;optimal power control;multihop software defined radio network;radio communication;dynamic spectrum access;flow routing;formal mathematical model;protocol interference model;cross-layer optimization problem;convex hull relaxation;branch-and-bound technique;bandwidth-footprint product;scheduling;Power control;Spread spectrum communication;Software radio;Routing;Wireless networks;Interference;Radio communication;Mathematical model;Wireless application protocol;Access protocols},
doi={10.1109/INFCOM.2007.198},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215781,
author={A. Muqattash and M. Krunz},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Performance of Wireless CDMA Networks Under Optimal Link-Layer Adaptation},
year={2007},
volume={},
number={},
pages={1703-1711},
abstract={In this paper, we determine the maximum achievable "performance" of a wireless CDMA network that employs a conventional matched filter receiver and that operates under optimal link-layer adaptation where each user individually achieves the Shannon capacity. The derived bounds serve as benchmarks against which adaptive CDMA systems can be compared. We focus on two optimization criteria: minimizing the maximum service time and maximizing the sum of users rates (i.e., network throughput). We show that the problem of joint optimization of the transmission powers and rates so as to minimize the maximum service time can be formulated as a generalized geometric program (GGP), which can be transformed into a nonlinear convex problem and solved optimally and efficiently. When the goal is to maximize the sum of the rates, we show that the problem can be approximated as a GGP. Our derivation methodologies are applicable to both ad hoc and cellular networks. Numerical results are provided to show how well variable-rate, variable-power adaptation schemes perform relative to the performance bounds derived in this paper.},
keywords={ad hoc networks;code division multiple access;matched filters;optimisation;receivers;wireless CDMA networks;optimal link-layer adaptation;matched filter receiver;Shannon capacity;optimization;generalized geometric program;nonlinear convex problem;variable-rate adaptation;variable-power adaptation;ad hoc networks;Multiaccess communication;Bit error rate;Modulation coding;Telecommunication traffic;Matched filters;Throughput;Power control;Communications Society;Communications technology;Adaptive systems},
doi={10.1109/INFCOM.2007.199},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215782,
author={Y. Xu and W. -. Lee and J. Xu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Analysis of A Loss-Resilient Proactive Data Transmission Protocol in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1712-1720},
abstract={Many of sensor network applications require reliable data communication such that data packets can be delivered to the destination without loss. However, existing reliable transmission techniques either are too costly for resource-constrained sensor networks or have limited capabilities for achieving desirable reliability. In this paper, an effective coding scheme that exploits the tradeoff between redundant data transmission and encoding/decoding complexity is proposed, with an in-depth study on two key design parameters, the degree of repair packets and the number of repair packets. Furthermore, the expected probability of a destination obtaining all data packets under recoverable and permanent failure model for proactive transmission is analyzed, respectively. Simulations have been conducted to verify our theoretical results. The simulation results reveal profound insights in achieving high communication reliability in wireless sensor networks.},
keywords={packet radio networks;protocols;telecommunication network reliability;wireless sensor networks;proactive data transmission protocol;wireless sensor networks;encoding;decoding;repair packets;reliability;Propagation losses;Data communication;Wireless application protocol;Wireless sensor networks;Telecommunication network reliability;Computer networks;Failure analysis;Energy storage;Redundancy;Performance analysis},
doi={10.1109/INFCOM.2007.200},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215783,
author={J. Ghosh and H. Q. Ngo and S. Yoon and C. Qiao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On a Routing Problem Within Probabilistic Graphs and its Application to Intermittently Connected Networks},
year={2007},
volume={},
number={},
pages={1721-1729},
abstract={Given a probabilistic graph G representing an intermittently connected network and routing algorithm A, we wish to determine a delivery subgraph G[A] of G with at most k edges, such that the probability Conn<sub>2</sub> (G[A]) that there is a path from source s to destination t (in a graph H chosen randomly from the probability space defined by G[A]) is maximized. To the best of our knowledge, this problem and its complexity has not been addressed in the literature. Also, there is the corresponding distributed version of the problem where the delivery subgraph G[A] is to be constructed distributively, yielding a routing protocol. Our proposed solution to this routing problem is multi-fold: First, we prove the hardness of our optimization problem of finding a delivery subgraph that maximizes the delivery probability and discuss the hardness of computing the objective function Conn<sub>2</sub>(G[A]); Second, we present an algorithm to approximate Conn<sub>2</sub>(G[A]) and compare it with an optimal algorithm; Third, we focus on intermittently connected networks, and model the users' mobility within them; and Fourth, we propose an edge-constrained routing protocol (EC-SOLAR-KSP) based on the insights obtained from the first step and the contact probabilities computed in the third step. We then highlight the protocol's novelty and effectiveness by comparing it with a probabilistic routing protocol, and an epidemic routing protocol proposed in literature.},
keywords={graph theory;mobile radio;optimisation;probability;routing protocols;probabilistic graphs;intermittently connected networks;optimization problem;edge-constrained routing protocol;mobile wireless network;Routing protocols;Wireless networks;Computer networks;Communications Society;Application software;Network servers;Computer science;Wireless application protocol;Instruments;Libraries},
doi={10.1109/INFCOM.2007.201},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215784,
author={D. Tschopp and S. Diggavi and M. Grossglauser and J. Widmer},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Robust Geo-Routing on Embeddings of Dynamic Wireless Networks},
year={2007},
volume={},
number={},
pages={1730-1738},
abstract={Wireless routing based on an embedding of the connectivity graph is a very promising technique to overcome shortcomings of geographic routing and topology-based routing. This is of particular interest when either absolute coordinates for geographic routing are unavailable or when they poorly reflect the underlying connectivity in the network. We focus on dynamic networks induced by time-varying fading and mobility. This requires that the embedding is stable over time, whereas the focus of most existing embedding algorithms is on low distortion of single realizations of a graph. We develop a beacon-based distributed embedding algorithm that requires little control overhead, produces low distortion embeddings, and is stable. We also show that a low-dimensional embedding suffices, since at a sufficiently large scale, wireless connectivity graphs are dictated by geometry. The stability of the embedding allows us to combine geo-routing on the embedding with last encounter routing (LER) for node lookup, further reducing the control overhead. Our routing algorithm avoids dead ends through randomized greedy forwarding. We demonstrate through extensive simulations that our combined embedding and routing scheme outperforms existing algorithms.},
keywords={distributed algorithms;graph theory;greedy algorithms;mobile radio;radio networks;randomised algorithms;telecommunication network routing;telecommunication network topology;dynamic wireless networks;wireless routing;wireless connectivity graphs;geographic routing;topology-based routing;time-varying fading;time-varying mobility;beacon-based distributed embedding algorithm;control overhead;low distortion embeddings;geometry;last encounter routing;node lookup;randomized greedy routing algorithm;Robustness;Wireless networks;Network topology;Geometry;Personal digital assistants;Routing protocols;Computer networks;Embedded computing;Fading;Floods},
doi={10.1109/INFCOM.2007.202},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215785,
author={L. Li and R. Ramjee and M. Buddhikot and S. Miller},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Network Coding-Based Broadcast in Mobile Ad-hoc Networks},
year={2007},
volume={},
number={},
pages={1739-1747},
abstract={Broadcast operation, which disseminates information network-wide, is very important in multi-hop wireless networks. Due to the broadcast nature of wireless media, not all nodes need to transmit in order for the message to reach every node. Previous work on broadcast support can be classified as probabilistic (each node rebroadcasts a packet with a given probability) or deterministic approaches (nodes pre-select a few neighbors for rebroadcasting). In this paper, we show how network-coding can be applied to a deterministic broadcast approaches, resulting in significant reductions in the number of transmissions in the network. We propose two algorithms, that rely only on local two-hop topology information and makes extensive use of opportunistic listening to reduce the number of transmissions: 1) a simple XOR-based coding algorithm that provides up to 45% gains compared to a non-coding approach and 2) a Reed-Solomon based coding algorithm that determines the optimal coding gain achievable for a coding algorithm that relies only on local information, with gains up to 61% in our simulations. We also show that our coding-based deterministic approach outperforms the coding-based probabilistic approach presented in (C. Fragouli et al, 2006).},
keywords={ad hoc networks;mobile radio;probability;Reed-Solomon codes;telecommunication network topology;network coding-based broadcast operation;mobile ad hoc network;multihop wireless network;XOR-based coding algorithm;Reed-Solomon based coding algorithm;optimal coding gain;Broadcasting;Ad hoc networks;Mobile ad hoc networks;Peer to peer computing;Network coding;Network topology;Unicast;Wireless networks;Reed-Solomon codes;Mobile communication},
doi={10.1109/INFCOM.2007.203},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215786,
author={A. Ribeiro and G. B. Giannakis and Z. -. Luo and N. D. Sidiropoulos},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Modelling and Optimization of Stochastic Routing for Wireless Multi-Hop Networks},
year={2007},
volume={},
number={},
pages={1748-1756},
abstract={We introduce a novel approach to multi-hop routing in wireless networks. Instead of the usual graph description we characterize the network by the packet delivery ratio matrix whose entries represent the probability that a given node decodes the packet transmitted by any other node. The model lends itself naturally to the formulation of stochastic routing protocols in which packets are randomly routed to neighboring nodes; and routing algorithms search for a matrix of routing probabilities according to properly defined optimality criteria. The goal of the paper is to show that this novel framework offers a useful model to aid in the design of optimal routing algorithms. In particular, it is established that: (i) performance is improved with respect to graph descriptions; and (ii) optimal routes can be obtained as the solution of optimization problems, many of which turn out to be convex and can thus be solved in polynomial time using interior point methods.},
keywords={matrix algebra;optimisation;radio networks;routing protocols;stochastic routing modelling;stochastic routing optimization;wireless multihop networks;multihop routing;packet delivery ratio matrix;stochastic routing protocols;routing probabilities;optimal routing algorithms. design;interior point methods;Stochastic processes;Spread spectrum communication;Wireless networks;Routing protocols;Peer to peer computing;Collaborative work;Government;Telecommunication network reliability;Convergence;Delay},
doi={10.1109/INFCOM.2007.204},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215787,
author={S. Agrawal and K. V. M. Naidu and R. Rastogi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Diagnosing Link-Level Anomalies Using Passive Probes},
year={2007},
volume={},
number={},
pages={1757-1765},
abstract={In this paper, we develop passive network tomography techniques for inferring link-level anomalies like excessive loss rates and delay from path-level measurements. Our approach involves placing a few passive monitoring devices on strategic links within the network, and then passively monitoring the performance of network paths that pass through those links. In order to keep the monitoring infrastructure and communication costs low, we focus on minimizing (1) the number of passive probe devices deployed, and (2) the set of monitored paths. For mesh topologies, we show that the above two minimization problems are NP-hard, and consequently, devise polynomial-time greedy algorithms that achieve a logarithmic approximation factor, which is the best possible for any algorithm. We also consider tree topologies typical of Enterprise networks, and show that while similar NP-hardness results hold, constant factor approximation algorithms are possible for such topologies.},
keywords={computational complexity;passive networks;tomography;wide area networks;passive probes;diagnosing link-level anomalies;passive network tomography;path level measurements;passive monitoring devices;low communication costs;passive probe devices;mesh topology;NP-hard;logarithmic approximation factor;enterprise networks;Probes;Monitoring;Network topology;Approximation algorithms;Passive networks;Tomography;Loss measurement;Costs;Minimization methods;Polynomials},
doi={10.1109/INFCOM.2007.205},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215788,
author={Y. Cheng and V. Ravindran and A. Leon-Garcia},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Internet Traffic Characterization Using Packet-Pair Probing},
year={2007},
volume={},
number={},
pages={1766-1774},
abstract={This paper presents an edge-based Internet traffic characterization approach. Our objective is to estimate the marginal distribution and the correlation structure of the packet arrival process at a queue, by sending probe packet pairs with a specific dispersion to sample the traffic. The aggregate work load process inferred from the output dispersions is a compound process of the packet arrival process and the packet size distribution. We show that the packet arrival marginal distribution and the packet size distribution can be decoupled by using the probability generating function; given one of the distributions, the other can then be estimated. We use the fact that the Internet packet size follows a known multi-modal distribution. Moreover, multiple series of packet pairs with different input dispersions can be used to estimate the packet arrival process at different time scales, and therefore to estimate the Hurst parameter, which characterizes the long-range dependence, by generating the variance-time plot. While the traffic characterization techniques are developed and validated in a single-queue context, we indicate how the techniques can be applied to a black box system for end-to-end quality of service provisioning along a multi-hop path.},
keywords={correlation methods;Internet;probability;quality of service;queueing theory;telecommunication traffic;edge-based Internet traffic characterization;packet-pair probing;correlation structure;queue packet arrival marginal distribution;packet size distribution;multimodal distribution;Hurst parameter estimation;variance-time plot;black box system;end-to-end quality of service provisioning;multihop communication;Internet;Traffic control;Probes;Telecommunication traffic;Dispersion;Aggregates;Quality of service;Time measurement;Character generation;Hardware},
doi={10.1109/INFCOM.2007.206},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215789,
author={L. Yang and G. Michailidis},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Sampled Based Estimation of Network Traffic Flow Characteristics},
year={2007},
volume={},
number={},
pages={1775-1783},
abstract={In this paper, we consider the problem of non-parametric estimation of network flow characteristics, namely packet lengths and byte sizes, based on sampled flow data. We propose two different approaches to deal with the problem at hand. The first one is based on single stage Bernoulli sampling of packets and their corresponding byte sizes. Subsequently, the flow length distribution is estimated by an adaptive expectation- maximization (EM) algorithm that in addition provides an estimate for the number of active flows. The estimation of the flow sizes (in bytes) is accomplished through a random effects regression model that utilizes the flow length information previously obtained. A variation of this approach, particularly suited for mixture distributions that appear in real network traces, is also considered. The second approach relies on a two-stage sampling procedure, which in the first stage samples flows amongst the active ones, while in the second stage samples packets from the sampled flows. Subsequently, the flow length distribution is estimated using another EM algorithm and the flow byte sizes based on a regression model. The proposed approaches are illustrated and compared on a number of synthetic and real data sets.},
keywords={expectation-maximisation algorithm;Internet;nonparametric statistics;regression analysis;telecommunication traffic;sampled based estimation;network traffic flow;nonparametric estimation;Bernoulli sampling;adaptive expectation-maximization algorithm;regression model;two-stage sampling procedure;flow length distribution;Telecommunication traffic;Sampling methods;Maximum likelihood estimation;Internet;Maximum likelihood detection;Statistical distributions;Communication system traffic control;Bandwidth;Communications Society;Statistics},
doi={10.1109/INFCOM.2007.207},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215790,
author={G. Lu and Y. Chen and S. Birrer and F. E. Bustamante and C. Y. Cheung and X. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={End-to-End Inference of Router Packet Forwarding Priority},
year={2007},
volume={},
number={},
pages={1784-1792},
abstract={Packet forwarding prioritization (PFP) in routers is one of the mechanisms commonly available to network administrators. PFP can have a significant impact on the performance of applications, the accuracy of measurement tools' results and the effectiveness of network troubleshooting procedures. Despite their potential impact, no information on PFP settings is readily available to end users. In this paper, we present an end-to-end approach for packet forwarding priority inference and its associated tool, POPI. This is the first attempt to infer router packet-forwarding priority through end-to-end measurement. Our POPI tool enables users to discover such network policies through the monitoring and rank classification of loss rates for different packet types. We validated our approach via statistical analysis, simulation, and wide-area experimentation in PlanetLab. As part of our wide-area experiments, we employed POPI to analyze 156 random paths across 162 PlanetLab nodes. We discovered 15 paths flagged with multiple priorities, 13 of which were further validated through hop-by-hop loss rates measurements. In addition, we surveyed all related network operators and received responses for about half of them confirming our inferences.},
keywords={packet radio networks;statistical analysis;telecommunication network routing;end to end inference;router packet forwarding priority;network troubleshooting;statistical analysis;wide area experimentation;multiple priorities;hop by hop loss rates measurements;Traffic control;Extraterrestrial measurements;Protocols;Probes;Bandwidth;Statistical analysis;Analytical models;Peer to peer computing;Fluctuations;Electrical resistance measurement},
doi={10.1109/INFCOM.2007.208},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215791,
author={R. Cohen and G. Nakibly},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Traffic Engineering Approach for Placement and Selection of Network Services},
year={2007},
volume={},
number={},
pages={1793-1801},
abstract={Network services are provided by means of dedicated service gateways, through which traffic flows are directed. Existing work on service gateway placement has been primarily focused on minimizing the length of the routes through these gateways. Only limited attention has been paid to the effect these routes have on overall network performance. We propose a novel approach for the service placement problem, which takes into account traffic engineering considerations. Rather than trying to minimize the length of the traffic flow routes, we take advantage of these routes in order to enhance the overall network performance. We divide the problem into two sub-problems: finding the best location for each service gateway, and selecting the best service gateway for each flow. We propose efficient algorithms for both problems and study their performance. Our main contribution is showing that placement and selection of network services can be used as effective tools for traffic engineering.},
keywords={internetworking;network servers;telecommunication network routing;telecommunication traffic;traffic engineering approach;network services placement;network services selection;service gateway placement;traffic flow routes;telecommunication network routing;Telecommunication traffic;Communication system traffic control;Context-aware services;Communications Society;Computer science;Web and internet services;Video compression;Access protocols;Communication system control;Authentication},
doi={10.1109/INFCOM.2007.209},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215792,
author={L. Luo and C. Huang and T. Abdelzaher and J. Stankovic},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={EnviroStore: A Cooperative Storage System for Disconnected Operation in Sensor Networks},
year={2007},
volume={},
number={},
pages={1802-1810},
abstract={This paper presents a new cooperative storage system for sensor networks geared for disconnected operation (where sensor nodes do not have a connected path to a basestation). The goal of the system is to maximize its data storage capacity by appropriately distributing storage utilization and opportunistically offloading data to external devices when possible. The system is motivated by the observation that a large category of sensor network applications, such as environmental data logging, does not require real-time data access. Such networks generally operate in a disconnected mode. Rather than focusing on multihop routing to a basestation, an important concern becomes (i) to maximize the effective storage capacity of the disconnected sensor network such that it accommodates the most data, and (ii) to take the best advantage of data upload opportunities when they become available to relieve network storage. The storage system described in this paper achieves the above goals, leading to significant improvements in the amount of data collected compared to non-cooperative storage. It is implemented in nesC for TinyOS and evaluated in TOSSIM through various application scenarios.},
keywords={wireless sensor networks;EnviroStore cooperative storage system;disconnected wireless sensor network;nesC;TinyOS;Sensor systems;Flash memory;Computer science;Sensor systems and applications;Capacitive sensors;Springs;Energy consumption;Communications Society;Peer to peer computing;Real time systems},
doi={10.1109/INFCOM.2007.210},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215793,
author={X. Meng and P. Zerfos and V. Samanta and S. H. Y. Wong and S. Lu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Analysis of the Reliability of a Nationwide Short Message Service},
year={2007},
volume={},
number={},
pages={1811-1819},
abstract={SMS has been arguably the most popular wireless data service for cellular networks. Due to its ubiquitous availability and universal support by mobile handsets and cellular carriers, it is also being considered for emergency notification and other mission-critical applications. Despite its increased popularity, the reliability of SMS service in real-world operational networks has received little study so far. In this work, we investigate the reliability of SMS by analyzing traces collected from a nationwide cellular network over a period of three weeks. Although the SMS service incorporates a number of reliability mechanisms such as delivery acknowledgement and multiple retries, our study shows that its reliability is not as good as we expected. For example the message delivery failure ratio is as high as 5.1% during normal operation conditions. We also analyze the performance of the service under stressful conditions, and in particular during a "flash-crowd" event that occurred in New Year's Eve of 2005. Two important factors that adversely affect reliability of SMS are also examined: bulk message delivery that may induce network-wide congestion, and the topological structure of the social network formed by SMS users, which may facilitate quick propagation of viruses or other malware.},
keywords={cellular radio;electronic messaging;radio networks;telecommunication congestion control;telecommunication network reliability;telecommunication network topology;nationwide short message service reliability;SMS service reliability;wireless data service;cellular network;ubiquitous availability;mobile handset;emergency notification;mission-critical application;message delivery failure ratio;network-wide congestion;social network topology;Message service;Land mobile radio cellular systems;Availability;Laboratories;Mission critical systems;Social network services;Telephone sets;Communications Society;Computer science;National electric code},
doi={10.1109/INFCOM.2007.211},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215794,
author={A. Sprintson and M. Yannuzzi and A. Orda and X. Masip-Bruin},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Reliable Routing with QoS Guarantees for Multi-Domain IP/MPLS Networks},
year={2007},
volume={},
number={},
pages={1820-1828},
abstract={We present a distributed routing algorithm for finding two disjoint (primary and backup) QoS paths that run across multiple domains. Our work is inspired by the recent interest in establishing communication paths with QoS constrains spanning multiple IP/MPLS domains. In such settings, the routing decisions in each domain are made by the path computation element (PCE). We assume that the PCEs run a joint distributed routing protocol, decoupled from the BGP, which enables them to establish efficient paths across multiple domains. This study makes the following contributions. First, we present an aggregated representation of a multi-domain network that is small enough to minimize the link-state overhead, and, at the same time, is sufficiently accurate, so that the PCEs can find optimal disjoint QoS paths across multiple domains. Second, we present a distributed routing algorithm that uses the proposed representation to find disjoint paths in an efficient manner. Finally, we consider the problem of finding two disjoint paths subject to the export policy limitations, imposed by customer-provider and peer relationships between routing domains. We show that this problem can be efficiently solved by employing the concept of line graphs. To the best of our knowledge, this is the first scheme fully decoupled from BGP that enables to establish disjoint QoS IP/MPLS paths in a multi-domain environment with provable performance guarantees.},
keywords={IP networks;multiprotocol label switching;peer-to-peer computing;quality of service;routing protocols;reliable routing;multidomain IP networks;MPLS networks;distributed routing algorithm;QoS paths;communication paths;routing decisions;path computation element;distributed routing protocol;BGP;multidomain network;link-state overhead;customer-provider;peer relationships;Multiprotocol label switching;Telecommunication network reliability;Computer architecture;Communications Society;Routing protocols;IP networks;Communication switching;Resilience;Application software;Contracts},
doi={10.1109/INFCOM.2007.212},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215795,
author={R. M. de Moraes and H. R. Sadjadpour and J. J. Garcia-Luna-Aceves},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Many-to-Many Communication: A New Approach for Collaboration in MANETs},
year={2007},
volume={},
number={},
pages={1829-1837},
abstract={We introduce a collaboration-driven approach to the sharing of the available bandwidth in wireless ad hoc networks, which we call many-to-many cooperation, that allows concurrent many-to-many communication. This scheme is based on the integration of multi-user detection and position-location information with frequency and code division in mobile ad hoc networks (MANETs). Transmissions are divided in frequency and codes according to nodal locations, and successive interference cancellation (SIC) is used at receivers to allow them to decode and use all transmissions from strong interfering sources. Consequently, the interference is divided into constructive interference (COI) and destructive interference (DEI). We show that, if each node is allowed to expand its bandwidth, both the link's Shannon capacity and the per source-destination throughput scale like <i>O</i>(n<sup>alpha/2</sup> ) (upper-bound) and Omega[f(n)] (lower-bound), for n nodes in the network, a path loss parameter alpha &gt; 2, and 1 les f(n) &lt; n<sup>alpha/2</sup>. Many-to-many cooperation allows multi-copy relaying of the same packet, which reduces the packet delivery delay compared to single-copy relaying without any penalty in capacity.},
keywords={ad hoc networks;channel capacity;code division multiple access;frequency division multiple access;interference suppression;mobile radio;multiuser detection;concurrent many-to-many communication;MANET;collaboration-driven approach;mobile ad hoc networks;integration of multiuser detection;position-location information;successive interference cancellation;constructive interference;destructive interference;Shannon capacity;source-destination throughput scale;multicopy relaying;packet delivery delay;frequency division multiple access;code division multiple access;Collaboration;Bandwidth;Mobile ad hoc networks;Frequency conversion;Relays;Mobile communication;Multiuser detection;Interference cancellation;Silicon carbide;Decoding},
doi={10.1109/INFCOM.2007.213},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215796,
author={X. Zhu and R. Sarkar and J. Gao},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Shape Segmentation and Applications in Sensor Networks},
year={2007},
volume={},
number={},
pages={1838-1846},
abstract={Many sensor network protocols in the literature implicitly assume that sensor nodes are deployed uniformly inside a simple geometric region. When the real deployment deviates from that, we often observe degraded performance. It is desirable to have a generic approach to handle a sensor field with complex shape. In this paper, we propose a segmentation algorithm that partitions an irregular sensor field into nicely shaped pieces such that algorithms and protocols that assume a nice sensor field can be applied inside each piece. Across the segments, problem dependent structures specify how the segments and data collected in these segments are integrated. This unified topology-adaptive spatial partitioning would benefit many settings that currently assume a nicely shaped sensor field. Our segmentation algorithm does not require sensor locations and only uses network connectivity information. Each node is given a 'flow direction' that directs away from the network boundary. A node with no flow direction becomes a sink, and attracts other nodes in the same segment. We evaluate the performance improvements by integrating shape segmentation with applications such as distributed indices and random sampling.},
keywords={protocols;wireless sensor networks;shape segmentation;sensor network protocols;adaptive spatial partitioning;Shape;Partitioning algorithms;Routing;Peer to peer computing;Sampling methods;Protocols;Geometry;Network topology;Degradation;Information processing},
doi={10.1109/INFCOM.2007.214},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215797,
author={C. Westphal},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Little Tom Thumb Went Straight Home: Asymptotic Behavior of a Routing Protocol in Ad-hoc Networks with a Mobile Access Point},
year={2007},
volume={},
number={},
pages={1847-1856},
abstract={The task of routing streaming data in a sensor network is made arduous by the resource constraints imposed on each node. The control overhead of a routing protocol has to be minimized in order to preserve limited resources at the node. Furthermore, it is widely expected that the gateway of the sensor network will not be static in many application scenarios, but will be moving around the network. The gateway could move to collect data, or because it is not associated with a specific location, but with a specific mobile user. We study a simple protocol and consider the cost it imposes on the networks in terms of number of messages sent, or equivalently, bandwidth or power usage. We study the scaling behavior of the so-called bread crumbs (BC) protocol, and show that it is optimal in its scaling behavior in one-and two-dimensional graphs. The BC protocol is thus named as the mobile gateway leaves a trail in the network as it moves about, as Little Tom Thumb, or Hansel and Gretel do in the forest, in the well-known fairy tales. The BC protocol routes packets along the path followed by the mobile sink, taking short cuts whenever possible. We compare this protocol with the cost of routing on the shortest path from the sensor node to the mobile sink, and with the cost of flooding the network in the hope of finding the sink. We show that the path attained with the BC protocol is asymptotically optimal, and scales as the shortest path. We support the analysis with some simulations and also consider a one step diffusion extension of the bread crumbs protocol as well.},
keywords={ad hoc networks;mobile radio;routing protocols;wireless sensor networks;asymptotic behavior;routing protocol;ad hoc networks;mobile access point;streaming data routing;sensor network;resource constraints;control overhead;mobile user;bread crumbs protocol;mobile gateway;mobile sink;sensor node;Thumb;Routing protocols;Ad hoc networks;Costs;Peer to peer computing;Bandwidth;Remote monitoring;Home automation;Communications Society;Laboratories},
doi={10.1109/INFCOM.2007.215},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215798,
author={A. de Baynast and O. Gurewitz and E. W. Knightly},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Cooperative Strategies and Optimal Scheduling for Tree Networks},
year={2007},
volume={},
number={},
pages={1857-1865},
abstract={In this paper, we develop and analyze a low-complexity cooperative protocol that significantly increases the average throughput of multi-hop upstream transmissions for wireless tree networks. We consider a system in which transmissions are assigned to nodes in a collision free, spatial time division fashion. This protocol exploits the broadcast nature of wireless networks where the communication channel is shared between multiple adjacent nodes within interference range. For any upstream end-to-end flow in the tree, each intermediate node receives information from both one-hop and two-hop neighbors and transmits only sufficient information such that the next upstream one-hop neighbor will be able to decode the packet. This approach can be viewed as the generalization of the classical three node relay channel for end-to-end flows in which each intermediate node becomes successively source, relay and destination. We derive the achievable rate and propose an optimal schedule that realizes this rate for any regular tree network. We show that our protocol dramatically outperforms the conventional scheme where intermediate nodes simply forward the packets hop by hop. At high signal-to-noise ratio, it yields approximatively 80% throughput gain.},
keywords={protocols;radio networks;scheduling;telecommunication channels;trees (mathematics);cooperative protocol;wireless tree network;communication channel;optimal scheduling;Optimal scheduling;Wireless application protocol;Throughput;Relays;Spread spectrum communication;Broadcasting;Wireless networks;Communication channels;Interference;Decoding},
doi={10.1109/INFCOM.2007.216},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215799,
author={A. Burchard and J. Liebeherr and F. Ciucu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Q(H log H) Scaling of Network Delays},
year={2007},
volume={},
number={},
pages={1866-1874},
abstract={A recent result in network calculus theory provided statistical delay bounds for exponentially bounded traffic that grow as O(H log H) with the number of nodes on the network path. In this paper we establish the corresponding lower bound which shows that for such such types of traffic, typical end-to-end delays can indeed grow as Theta (H log H). The lower bound is obtained by analyzing the end-to-end delay in a tandem network where each packet maintains the same service time at each traversed node. The results of this paper provide conclusive evidence that, in general, delays have a qualitatively different scaling behavior than is suggested by a worst-case analysis or by an analysis that assumes independent service times at network nodes.},
keywords={statistical analysis;telecommunication networks;telecommunication traffic;network calculus theory;statistical delay bound;exponentially bounded traffic;tandem network;end-to-end network delay;Telecommunication traffic;Calculus;Traffic control;Stochastic processes;Delay effects;Peer to peer computing;Convolution;Communications Society;Mathematics;Computer science},
doi={10.1109/INFCOM.2007.217},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215800,
author={A. Chen and J. Cao and T. Bu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Network Tomography: Identifiability and Fourier Domain Estimation},
year={2007},
volume={},
number={},
pages={1875-1883},
abstract={Network tomography has been regarded as one of the most promising methodologies for performance evaluation and diagnosis of the massive and decentralized Internet. It can be used to infer unobservable network behaviors from directly measurable metrics and it does not require cooperation between the network internal elements and the end users. For instance, the Internet users may estimate the link level characteristics such as loss and delay from end-to-end measurements, whereas the network operators can evaluate the Internet path-level traffic intensity based on link-level traffic measurements. In this paper, we present a novel estimation approach for the network tomography problem. Unlike previous likelihood based methods, our approach is based on characteristic functions, i.e. the Fourier transform, of the distributions of observed measurements. We focus on network delay tomography and develop a Fourier domain inference algorithm based on flexible mixture models of link delays. Through extensive model simulation and simulation using real Internet trace, we are able to demonstrate that the new algorithm is computationally more efficient and yields more accurate estimates than previous methods, especially for a network with heterogeneous link delays. In addition, we obtain some identifiability results that can be applied to general distribution models for link delays.},
keywords={estimation theory;Fourier transforms;Internet;performance evaluation;telecommunication links;telecommunication traffic;tomography;network tomography;performance evaluation;decentralized Internet diagnosis;unobservable network behavior;Fourier transform;Fourier domain inference algorithm;heterogeneous link delay;Tomography;IP networks;Delay estimation;Loss measurement;Telecommunication traffic;Inference algorithms;Computational modeling;Fourier transforms;Computer networks;Yield estimation},
doi={10.1109/INFCOM.2007.218},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215801,
author={S. Borst and N. Hegde},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Integration of Streaming and Elastic Traffic in Wireless Networks},
year={2007},
volume={},
number={},
pages={1884-1892},
abstract={Channel-aware scheduling strategies have emerged as an effective mechanism for improving the throughput of wireless data users by exploiting rate variations. The improvement in throughput comes however at the expense of an increase in the variability of the service rate received over time. While the larger variability only has a limited impact on delay-tolerant data transfers, it does severely affect delay-sensitive applications. In order to examine the merits of channel-aware scheduling for the latter users, we consider a wireless system supporting a combination of streaming and elastic traffic. We first examine a scenario with rate-adaptive streaming traffic, and analyze the flow-level performance in terms of transfer delays and user throughputs for various canonical resource sharing schemes. Simulation experiments demonstrate that the analytical results yield remarkably accurate estimates, and indicate that channel-aware scheduling achieves significant performance gains. Next we investigate a scenario where the streaming sources have an intrinsic rate profile and stringent delay requirements. In that case, channel-aware scheduling yields only modest performance gains, and may even be harmful.},
keywords={data communication;media streaming;telecommunication traffic;wireless channels;streaming;elastic traffic;wireless networks;channel-aware scheduling;delay-tolerant data transfers;delay-sensitive applications;transfer delays;canonical resource sharing;flow-level performance;Telecommunication traffic;Wireless networks;Delay;Throughput;Traffic control;Performance analysis;Performance gain;Resource management;Analytical models;Yield estimation},
doi={10.1109/INFCOM.2007.219},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215802,
author={T. Bu and J. Cao and A. Chen and P. P. C. Lee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Fast and Compact Method for Unveiling Significant Patterns in High Speed Networks},
year={2007},
volume={},
number={},
pages={1893-1901},
abstract={Identification of significant patterns in network traffic, such as IPs or flows that contribute large volume (heavy hitters) or introduce large changes (heavy changers), has many applications in accounting and network anomaly detection. As network speed and the number of flows grow rapidly, tracking per-IP or per-flow statistics becomes infeasible due to both the computational overhead and memory requirements. In this paper, we propose a novel sequential hashing scheme that requires only O(H log N) both in memory and computational overhead that are close to being optimal, where N is the the number of all possible keys (e.g., flows, IPs) and H is the maximum number of heavy keys. Moreover, the generalized sequential hashing scheme makes it possible to trade off among memory, update cost, and detection cost in a large range that can be utilized by different computer architectures for optimizing the overall performance. In addition, we also propose statistically efficient algorithms for estimating the values of heavy hitters and heavy changers. Using both theoretical analysis and experimental studies of Internet traces, we demonstrate that our approach can achieve the same accuracy as the existing methods do but using much less memory and computational overhead.},
keywords={computer architecture;file organisation;Internet;statistical analysis;telecommunication traffic;high speed networks;network traffic pattern identification;network anomaly detection;per-IP statistics tracking;per-flow statistics tracking;computational overhead;memory overhead;generalized sequential hashing;computer architectures;heavy hitters;heavy changers;Internet traces;High-speed networks;Monitoring;Telecommunication traffic;Bandwidth;USA Councils;Computer networks;Cost function;Event detection;Traffic control;Predictive models},
doi={10.1109/INFCOM.2007.220},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215803,
author={R. Kleinberg},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Geographic Routing Using Hyperbolic Space},
year={2007},
volume={},
number={},
pages={1902-1909},
abstract={We propose a scalable and reliable point-to-point routing algorithm for ad hoc wireless networks and sensor-nets. Our algorithm assigns to each node of the network a virtual coordinate in the hyperbolic plane, and performs greedy geographic routing with respect to these virtual coordinates. Unlike other proposed greedy routing algorithms based on virtual coordinates, our embedding guarantees that the greedy algorithm is always successful in finding a route to the destination, if such a route exists. We describe a distributed algorithm for computing each node's virtual coordinates in the hyperbolic plane, and for greedily routing packets to a destination point in the hyperbolic plane. (This destination may be the address of another node of the network, or it may be an address associated to a piece of content in a Distributed Hash Table. In the latter case we prove that the greedy routing strategy makes a consistent choice of the node responsible for the address, irrespective of the source address of the request.) We evaluate the resulting algorithm in terms of both path stretch and node congestion.},
keywords={ad hoc networks;greedy algorithms;telecommunication network routing;wireless sensor networks;hyperbolic space;geographic routing;point-to-point routing algorithm;ad hoc wireless sensor network;greedy geographic routing;virtual coordinate;distributed algorithm;Routing;Peer to peer computing;Extraterrestrial measurements;Wireless sensor networks;Communications Society;Computer science;Fellows;Computer network reliability;Greedy algorithms;Distributed algorithms},
doi={10.1109/INFCOM.2007.221},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215804,
author={A. Bar-Noy and Y. Feng and M. J. Golin},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Paging Mobile Users Efficiently and Optimally},
year={2007},
volume={},
number={},
pages={1910-1918},
abstract={A mobile user is roaming in a zone composed of N cells in a cellular network system. When a call to the mobile user arrives, the system pages the mobile user in these cells since it never reports its location unless it leaves the zone. The N cells are associated with a probability vector (p<sub>1</sub>, ...,p<sub>N</sub>) where p<sub>i</sub> is the probability that the mobile user resides in the ith cell and all the probabilities are independent. A delay constraint paging strategy must find the mobile user within D (1 les D les N) paging rounds; in each round a subset of the N cells is paged. The goal is to minimize the expected number of paged cells until the mobile user is found. Solutions based on dynamic programming that yield optimal strategies are known. The running time of the known implementations is Theta(N<sup>2</sup>D). Our first contribution is to improve the running time to Theta(ND) by proving that the dynamic programming recursive formulation satisfies the Monge property, permitting us to use various dynamic programming speedup techniques. A Theta(N) heuristic solution is also known. Our second contribution is a heuristic whose running time is Theta(N log D). Our heuristic outperforms the known heuristic while running faster for D &lt;&lt; N. We compare the non-optimal heuristics with the optimal solution demonstrating the tradeoff between optimality and running time efficiency of various solutions.},
keywords={cellular radio;computational complexity;dynamic programming;probability;recursive functions;mobile user paging strategy;cellular network system;probability vector;delay constraint paging strategy;dynamic programming recursive formulation;Monge property;Paging strategies;Bandwidth;Dynamic programming;Mobile computing;Computer science;Land mobile radio cellular systems;Delay;Roaming;Communications Society;Computer networks},
doi={10.1109/INFCOM.2007.222},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215805,
author={V. Naumov and T. R. Gross},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Connectivity-Aware Routing (CAR) in Vehicular Ad-hoc Networks},
year={2007},
volume={},
number={},
pages={1919-1927},
abstract={Vehicular ad hoc networks using WLAN technology have recently received considerable attention. We present a position-based routing scheme called Connectivity-Aware Routing (CAR) designed specifically for inter-vehicle communication in a city and/or highway environment. A distinguishing property of CAR is the ability to not only locate positions of destinations but also to find connected paths between source and destination pairs. These paths are auto-adjusted on the fly, without a new discovery process. "Guards" help to track the current position of a destination, even if it traveled a substantial distance from its initially known location. For the evaluation of the CAR protocol we use realistic mobility traces obtained from a microscopic vehicular traffic simulator that is based on a model of driver behavior and the real road maps of Switzerland.},
keywords={ad hoc networks;road traffic;road vehicles;routing protocols;wireless LAN;connectivity-aware routing protocol;vehicular ad hoc networks;WLAN technology;CAR position-based routing scheme;inter-vehicle communication;highway environment;CAR protocol;realistic mobility traces;microscopic vehicular traffic simulator;Ad hoc networks;Cities and towns;Traffic control;Routing protocols;Road transportation;Wireless LAN;Microscopy;Broadcasting;Communications Society;Telecommunication traffic},
doi={10.1109/INFCOM.2007.223},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215806,
author={Q. Cao and T. Abdelzaher and T. He and R. Kravets},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Cluster-Based Forwarding for Reliable End-to-End Delivery in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1928-1936},
abstract={Providing efficient and reliable communication in wireless sensor networks is a challenging problem. To recover from corrupted packets, previous approaches have tried to use retransmissions and FEC mechanisms. The energy efficiency of these mechanisms, however, is very sensitive to unreliable links. In this paper, we present cluster-based forwarding, where each node forms a cluster such that any node in the next-hop's cluster can take forwarding responsibility. This architecture, designed specifically for wireless sensor networks, achieves better energy-efficiency by reducing retransmissions. Cluster-based forwarding is not a routing protocol. Rather, it is designed as an extension layer that can augment existing routing protocols. Using simulations, we demonstrate that cluster-based forwarding is effective in improving both end-to-end energy efficiency and latency of current routing protocols.},
keywords={forward error correction;wireless sensor networks;cluster-based forwarding;end-to-end delivery;wireless sensor networks;packet recovery;energy efficiency;forward error correction;retransmission reduction;extension layer;routing protocols;Wireless sensor networks;Routing protocols;Mobile ad hoc networks;Forward error correction;Energy efficiency;Telecommunication network reliability;Wireless application protocol;Access protocols;Computer network reliability;Computer science},
doi={10.1109/INFCOM.2007.224},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215807,
author={F. Liu and X. Cheng and D. Chen},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Insider Attacker Detection in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1937-1945},
abstract={Though destructive to network functions, insider attackers are not detectable with only the classic cryptography-based techniques. Many mission-critic sensor network applications demand an effective, light, flexible algorithm for internal adversary identification with only localized information available. The insider attacker detection scheme proposed in this paper meets all the requirements by exploring the spatial correlation existent among the networking behaviors of sensors in close proximity. Our work is exploratory in that the proposed algorithm considers multiple attributes simultaneously in node behavior evaluation, with no requirement on a prior knowledge about normal/malicious sensor activities. Moreover, it is application-friendly, which employs original measurements from sensors and can be employed to monitor many aspects of sensor networking behaviors. Our algorithm is purely localized, fitting well to the large-scale sensor networks. Simulation results indicate that internal adversaries can be identified with a high accuracy and a low false alarm rate when as many as 25% sensors are misbehaving.},
keywords={telecommunication security;wireless sensor networks;attacker detection;wireless sensor networks;cryptography-based techniques;internal adversary identification;spatial correlation;large-scale sensor networks;Wireless sensor networks;Cryptography;Intelligent sensors;Sensor phenomena and characterization;Authentication;Monitoring;Batteries;Communication system security;Collaborative work;Data security},
doi={10.1109/INFCOM.2007.225},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215808,
author={F. Li and J. Wu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Mobility Reduces Uncertainty in MANETs},
year={2007},
volume={},
number={},
pages={1946-1954},
abstract={Evaluating and quantifying trust stimulates collaboration in mobile ad hoc networks (MANETs). Many existing reputation systems sharply divide the trust value into right or wrong, thus ignoring another core dimension of trust: uncertainty. As uncertainty deeply impacts a node's anticipation of others' behavior and decisions during interaction, we include uncertainty in the reputation system. Specifically, we use an uncertainty metric to directly reflect a node's confidence in the sufficiency of its past experience, and study how the collection of trust information may affect uncertainty in nodes' opinions. Higher uncertainty leads to higher transaction cost and reduced acceptance of communication and cooperation. After defining a way to reveal and compute the uncertainty in trust opinions, we exploit mobility, one of the important characteristics of MANETs, to efficiently reduce uncertainty and to speed up trust convergence. A two-level mobility assisted uncertainty reduction scheme (MAURS) that offers controllable trade-off between time and cost to achieve a convergence objective of trust is also provided. Extensive analytical and simulation results are presented to support our proposal.},
keywords={ad hoc networks;mobile radio;telecommunication security;MANET;mobile ad hoc network;reputation system;mobility assisted uncertainty reduction scheme;Uncertainty;Costs;Mobile ad hoc networks;Convergence;Collaboration;Peer to peer computing;Communications Society;Computer science;Communication system control;Analytical models},
doi={10.1109/INFCOM.2007.226},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215809,
author={Y. Jian and S. Chen and Z. Zhang and L. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Protecting Receiver-Location Privacy in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={1955-1963},
abstract={Due to the open nature of a sensor network, it is relatively easy for an adversary to eavesdrop and trace packet movement in the network in order to capture the receiver physically. After studying the adversary's behavior patterns, we present countermeasures to this problem. We propose a location-privacy routing protocol (LPR) that is easy to implement and provides path diversity. Combining with fake packet injection, LPR is able to minimize the traffic direction information that an adversary can retrieve from eavesdropping. By making the directions of both incoming and outgoing traffic at a sensor node uniformly distributed, the new defense system makes it very hard for an adversary to perform analysis on locally gathered information and infer the direction to which the receiver locates. We evaluate our defense system based on three criteria: delivery time, privacy protection strength, and energy cost. The simulation results show that LPR with fake packet injection is capable of providing strong protection for the receiver's location privacy. Under similar energy cost, the safe time of the receiver provided by LPR is much longer than other methods, including Phantom routing (Kamat et al., 2005) and DEFP (Deng et al., 2005). The performance of our system can be tuned through a couple of parameters that determine the tradeoff between energy cost and the strength of location-privacy protection.},
keywords={data privacy;routing protocols;telecommunication security;wireless sensor networks;receiver-location privacy protection;wireless sensor networks;packet movement eavesdropping;location-privacy routing protocol;path diversity;fake packet injection;traffic direction information;sensor node;defense system;Phantom routing;DEFP;Protection;Privacy;Wireless sensor networks;Costs;Routing protocols;Diversity reception;Telecommunication traffic;Information retrieval;Sensor systems;Information analysis},
doi={10.1109/INFCOM.2007.227},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215810,
author={Y. Chen and W. Trappe and R. P. Martin},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Attack Detection in Wireless Localization},
year={2007},
volume={},
number={},
pages={1964-1972},
abstract={Accurately positioning nodes in wireless and sensor networks is important because the location of sensors is a critical input to many higher-level networking tasks. However, the localization infrastructure can be subjected to non-cryptographic attacks, such as signal attenuation and amplification, that cannot be addressed by traditional security services. We propose several attack detection schemes for wireless localization systems. We first formulate a theoretical foundation for the attack detection problem using statistical significance testing. Next, we define test metrics for two broad localization approaches: multilateration and signal strength. We then derived both mathematical models and analytic solutions for attack detection for any system that utilizes those approaches. We also studied additional test statistics that are specific to a diverse set of algorithms. Our trace-driven experimental results provide strong evidence of the effectiveness of our attack detection schemes with high detection rates and low false positive rates across both an 802.11 (WiFi) network as well as an 802.15.4 (ZigBee) network in two real office buildings. Surprisingly, we found that of the several methods we describe, all provide qualitatively similar detection rates which indicate that the different localization systems all contain similar attack detection capability.},
keywords={statistical testing;telecommunication security;wireless LAN;wireless sensor networks;wireless localization infrastructure;attack detection;wireless sensor network;traditional security service;statistical significance testing;WiFi network;802.11 network;802.15.4 network;ZigBee network;Wireless sensor networks;Testing;Statistical analysis;Least squares methods;Communication system security;Attenuation;Mathematical model;ZigBee;Inference algorithms;Communications Society},
doi={10.1109/INFCOM.2007.228},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215811,
author={J. Kangasharju and K. W. Ross and D. A. Turner},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimizing File Availability in Peer-to-Peer Content Distribution},
year={2007},
volume={},
number={},
pages={1973-1981},
abstract={A fundamental paradigm in peer-to-peer (P2P) content distribution is that of a large community of intermittently-connected nodes that cooperate to share files. Because nodes are intermittently connected, the P2P community must replicate and replace files as a function of their popularity to achieve satisfactory performance. In this paper, we develop an analytical optimization theory for benchmarking the performance of replication/replacement algorithms, including algorithms that employ erasure codes. We also consider a content management algorithm, the Top-K Most Frequently Requested algorithm, and show that in most cases this algorithm converges to an optimal replica profile. Finally, we present two approaches for achieving an evenly balanced load over all the peers in the community.},
keywords={content management;optimisation;peer-to-peer computing;resource allocation;peer-to-peer content distribution;P2P community;analytical optimization theory;replication-replacement algorithm;content management algorithm;top-K most frequently requested algorithm;optimal replica profile;load balancing;Peer to peer computing;Content management;Computer science;Performance analysis;Algorithm design and analysis;Load management;Bandwidth;Local area networks;Internet;Telecommunication traffic},
doi={10.1109/INFCOM.2007.229},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215812,
author={Y. Xia and A. Dobra and S. C. Han},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Multiple-Choice Random Network for Server Load Balancing},
year={2007},
volume={},
number={},
pages={1982-1990},
abstract={In many networking applications such as file sharing, structured peer-to-peer networks are increasingly used in dynamic situations with fluctuating load, which require proper load balancing. The relationship between the network structure and its load-balancing properties has not been fully understood. In this paper, we focus on the Plaxton-type networks, which are broad enough to include Pastry, Tapestry, and hypercube. We first use hypercube as an example and demonstrate that replicating files at nodes in decreasing order of the length of the common prefix with the original server leads to perfectly balanced load, and does so fast and efficiently. Moreover, this replication strategy coincides with a simple on-demand replication/caching strategy based on the observed load. One of our main contributions is to show that such desirable properties also exist for a large class of random networks, which are less restrictive and more practical than the hypercube. More importantly, we have discovered a multiple-choice random network, which drastically reduces the statistical fluctuation of the load: The maximum load over all replication servers is at most three times the average load for systems of practical sizes. The main insight is that this algorithm is related to a variant of the multiple-choice balls-in-bins problem.},
keywords={peer-to-peer computing;multiple-choice random network;server load balancing;file sharing;structured peer-to-peer networks;Plaxton-type networks;Network servers;Load management;Peer to peer computing;Hypercubes;File servers;Network topology;Computer networks;Fluctuations;Resource management;Streaming media},
doi={10.1109/INFCOM.2007.230},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215814,
author={A. G. Dimakis and P. B. Godfrey and M. J. Wainwright and K. Ramchandran},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Network Coding for Distributed Storage Systems},
year={2007},
volume={},
number={},
pages={2000-2008},
abstract={Peer-to-peer distributed storage systems provide reliable access to data through redundancy spread over nodes across the Internet. A key goal is to minimize the amount of bandwidth used to maintain that redundancy. Storing a file using an erasure code, in fragments spread across nodes, promises to require less redundancy and hence less maintenance bandwidth than simple replication to provide the same level of reliability. However, since fragments must be periodically replaced as nodes fail, a key question is how to generate a new fragment in a distributed way while transferring as little data as possible across the network. In this paper, we introduce a general technique to analyze storage architectures that combine any form of coding and replication, as well as presenting two new schemes for maintaining redundancy using erasure codes. First, we show how to optimally generate MDS fragments directly from existing fragments in the system. Second, we introduce a new scheme called regenerating codes which use slightly larger fragments than MDS but have lower overall bandwidth use. We also show through simulation that in realistic environments, regenerating codes can reduce maintenance bandwidth use by 25% or more compared with the best previous design - a hybrid of replication and erasure codes - while simplifying system architecture.},
keywords={file organisation;Internet;peer-to-peer computing;network coding;distributed storage systems;peer-to-peer distributed storage systems;Internet;erasure code;storage architectures;Network coding;Bandwidth;Redundancy;Peer to peer computing;Maintenance;Internet;Communications Society;Computer network reliability;Information theory},
doi={10.1109/INFCOM.2007.232},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215815,
author={H. V. Balan and L. Eggert and S. Niccolini and M. Brunner},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Experimental Evaluation of Voice Quality Over the Datagram Congestion Control Protocol},
year={2007},
volume={},
number={},
pages={2009-2017},
abstract={Most Internet telephony applications currently use either TCP or UDP to carry their voice-over-IP (VoIP) traffic. This choice can be problematic, because TCP is not well suited for interactive traffic and UDP is unresponsive to congestion. The IETF has recently standardized the new Datagram Congestion Control Protocol (DCCP). DCCP has been designed to carry media traffic and is congestion-controlled. This paper experimentally evaluates the voice quality that Internet telephony calls achieve over prototype implementations of basic DCCP and several DCCP variants, under different network conditions and with different codecs. It finds that the currently-specified DCCP variants perform less well than expected when compared to UDP and TCP. Based on an analysis of these results, the paper suggests several improvements to DCCP and experimentally validates that a prototype implementation of these modifications can significantly increase voice quality.},
keywords={Internet telephony;telecommunication congestion control;telecommunication traffic;transport protocols;Internet telephony;datagram congestion control protocol;voice quality;voice-over-IP traffic;transmission control protocol;Protocols;Communication system traffic control;Internet telephony;Prototypes;National electric code;Laboratories;Delay;Traffic control;Speech analysis;Communications Society},
doi={10.1109/INFCOM.2007.233},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215816,
author={S. Shin and H. Schulzrinne},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Experimental Measurement of the Capacity for VoIP Traffic in IEEE 802.11 WLANs},
year={2007},
volume={},
number={},
pages={2018-2026},
abstract={We measured the capacity for VoIP traffic in an 802.11b test-bed and compared it with the theoretical capacity and our simulation results. We identified factors that have been commonly overlooked in past studies but affect experiments and simulations. We found that in many papers the capacity for VoIP traffic has been measured via simulations or experiments without considering those factors, showing different capacity in each paper. After these corrections, simulations and experiments yielded a capacity estimate of 15 calls for 64 kb/s CBR VoIP traffic with 20 ms packetization interval and 34 calls to 36 calls for VBR VoIP traffic with 0.39 activity ratio.},
keywords={Internet telephony;telecommunication traffic;wireless LAN;VoIP traffic;IEEE 802.11 WLAN;capacity estimation;packetization interval;Traffic control;Telecommunication traffic;Wireless networks;Testing;Computational modeling;Size control;Probes;Communications Society;Computer science;Computer simulation},
doi={10.1109/INFCOM.2007.234},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215817,
author={R. Birke and M. Mellia and M. Petracca and D. Rossi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Understanding VoIP from Backbone Measurements},
year={2007},
volume={},
number={},
pages={2027-2035},
abstract={VoIP has widely been addressed as the technology that will change the Telecommunication model opening the path for convergence. Still today this revolution is far from being complete, since the majority of telephone calls are originated by circuit-oriented networks. In this paper for the first time to the best of our knowledge, we present a large dataset of measurements collected from the FastWeb backbone, which is one of the first worldwide Telecom operator to offer VoIP and high-speed data access to the end-user. Traffic characterization will focus on several layers, focusing on both end-user and ISP perspective. In particular, we highlight that, among loss, delay and jitter, only the first index may affect the VoIP call quality. Results show that the technology is mature to make the final step, allowing the integration of data and real-time services over the Internet.},
keywords={Internet telephony;telecommunication traffic;telecommunication model;FastWeb backbone;high-speed data access;VoIP traffic characterization;VoIP call quality;Internet;Spine;Telecommunication traffic;Monitoring;Internet telephony;Circuits;Local area networks;Time measurement;Jitter;Web and internet services;IP networks},
doi={10.1109/INFCOM.2007.235},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215818,
author={A. Kashyap and S. Ganguly and S. R. Das and S. Banerjee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={VoIP on Wireless Meshes: Models, Algorithms and Evaluation},
year={2007},
volume={},
number={},
pages={2036-2044},
abstract={We study the problem of supporting VoIP calls in a wireless mesh network. Specifically, we propose solutions for call admission control (CAC) and route selection for VoIP calls. Call admission decisions must evaluate how the capacity of the mesh network is utilized by the existing calls. We address this issue via a measurement-based modeling effort to model mutual interference between wireless links. The modeling approach evaluates whether capacity constraints (or, required QoS metrics) will be satisfied if a new call is admitted with a given route. Evaluations with a 6-node 802.11a testbed demonstrate excellent accuracy of the model and thus also the CAC performance. We address the issue of route selection by also using a modeling approach that considers models of transmission and interference ranges to develop a polynomial-time algorithm to search for feasible routes. This problem takes exponential time for wireless networks without such modeling. In addition to studying feasibility, we study several routing metrics such as shortest feasible path and maximum residual feasible path. Finally, we develop a new method for routing using call statistics that uses prior calling patterns to avoid potentially critical links. We evaluate the performance of these route selection techniques via extensive simulations and demonstrate the superiority of using max residual feasible path over simply shortest feasible path, and routing using call statistics over max residual feasible path.},
keywords={Internet telephony;radio networks;statistical analysis;telecommunication congestion control;telecommunication network routing;telecommunication network topology;VoIP;wireless mesh network;call admission control;route selection;wireless link;6-node 802.11a testbed;shortest feasible path;maximum residual feasible path;call statistics;Mesh networks;Interference;Routing;Quality of service;Wireless LAN;USA Councils;Wireless mesh networks;Statistics;Call admission control;Backplanes},
doi={10.1109/INFCOM.2007.236},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215819,
author={W. He and X. Liu and H. Nguyen and K. Nahrstedt and T. Abdelzaher},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={PDA: Privacy-Preserving Data Aggregation in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={2045-2053},
abstract={Providing efficient data aggregation while preserving data privacy is a challenging problem in wireless sensor networks research. In this paper, we present two privacy-preserving data aggregation schemes for additive aggregation functions. The first scheme -cluster-based private data aggregation (CPDA)-leverages clustering protocol and algebraic properties of polynomials. It has the advantage of incurring less communication overhead. The second scheme -Slice-Mix-AggRegaTe (SMART)-builds on slicing techniques and the associative property of addition. It has the advantage of incurring less computation overhead. The goal of our work is to bridge the gap between collaborative data collection by wireless sensor networks and data privacy. We assess the two schemes by privacy-preservation efficacy, communication overhead, and data aggregation accuracy. We present simulation results of our schemes and compare their performance to a typical data aggregation scheme -TAG, where no data privacy protection is provided. Results show the efficacy and efficiency of our schemes. To the best of our knowledge, this paper is among the first on privacy-preserving data aggregation in wireless sensor networks.},
keywords={data privacy;polynomials;protocols;telecommunication security;wireless sensor networks;wireless sensor network;privacy-preserving data aggregation scheme;cluster-based private data aggregation;clustering protocol;polynomial;Slice-Mix-AggRegaTe scheme;Wireless sensor networks;Data privacy;Personal digital assistants;Additives;Protocols;Polynomials;Bridges;Collaborative work;Computational modeling;Protection},
doi={10.1109/INFCOM.2007.237},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215820,
author={J. Robinson and E. W. Knightly},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Performance Study of Deployment Factors in Wireless Mesh Networks},
year={2007},
volume={},
number={},
pages={2054-2062},
abstract={We present a measurement-parameterized performance study of deployment factors in wireless mesh networks using three performance metrics: client coverage area, backhaul tier connectivity, and fair mesh capacity. For each metric, we identify and study topology factors and architectural features which strongly influence mesh performance via an extensive set of Monte Carlo simulations capturing realistic physical layer behavior. Our findings include: (i) A random topology is unsuitable for a large-scale mesh deployment due to doubled node density requirements, yet a moderate level of perturbations from ideal grid placement has a minor impact on performance. (ii) Multiple backhaul radios per mesh node is a cost-effective deployment strategy as it leads to mesh deployments costing 50% less than with a single-radio architecture, (iii) Dividing access and backhaul connections onto two separate radios does not use the second radio efficiently as it only improves fair mesh capacity 40% to 80% for most users. This is in contrast to using the second radio to move half the user population to a new network operated on the second radio. This work adds to the understanding of mesh deployment factors and their general impact on performance, providing further insight into practical mesh deployments.},
keywords={Monte Carlo methods;radio networks;telecommunication network topology;wireless mesh network;measurement-parameterized performance study;client coverage area;backhaul tier connectivity;Monte Carlo simulation;Wireless mesh networks;Network topology;Costs;Mesh networks;Area measurement;Large-scale systems;Peer to peer computing;IP networks;Telecommunication traffic;Degradation},
doi={10.1109/INFCOM.2007.238},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215821,
author={A. Kabbani and T. Salonidis and E. W. Knightly},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Distributed Low-Complexity Maximum-Throughput Scheduling for Wireless Backhaul Networks},
year={2007},
volume={},
number={},
pages={2063-2071},
abstract={We introduce a low-complexity distributed slotted MAC protocol that can support all feasible arrival rates in a wireless backhaul network (WBN). For arbitrary wireless networks, such a maximum throughput protocol has been notoriously hard to realize because even if global topology information is available, the problem of computing the optimal link transmission set at each slot is NP-complete. For the logical tree structures induced by WBN traffic matrices, we first introduce a centralized algorithm that solves the optimal scheduling problem in a number of steps at most linear in the number of nodes in the network. This is achieved by discovering and exploiting a novel set of graph-theoretical properties of WBN contention graph. Guided by the centralized algorithm, we design a distributed protocol where, at the beginning of each slot, nodes coordinate and incrementally compute the optimal link transmission set. We then introduce an algorithm to compute the minimum number of steps to complete this computation, thus minimizing the per-slot overhead. Using both analysis and simulations, we show that in practice our protocol yields low overhead when implemented over existing wireless technologies and significantly outperforms existing suboptimal distributed slotted scheduling mechanisms.},
keywords={access protocols;computational complexity;minimisation;radio networks;scheduling;telecommunication congestion control;telecommunication network topology;telecommunication traffic;trees (mathematics);distributed low-complexity maximum-throughput scheduling;wireless backhaul network;distributed slotted MAC protocol;wireless network;network topology information;optimal link transmission set;NP-complete problem;logical tree structures;WBN traffic matrices;WBN contention graph;Optimal scheduling;Wireless application protocol;Media Access Protocol;Wireless networks;Throughput;Network topology;Computer networks;Tree data structures;Telecommunication traffic;Scheduling algorithm},
doi={10.1109/INFCOM.2007.239},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215822,
author={G. Sharma and N. B. Shroff and R. R. Mazumdar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Joint Congestion Control and Distributed Scheduling for Throughput Guarantees in Wireless Networks},
year={2007},
volume={},
number={},
pages={2072-2080},
abstract={We consider the problem of throughput-optimal cross-layer design of wireless networks. We propose a joint congestion control and scheduling algorithm that achieves a fraction 1/d<sub>I</sub>(G) of the capacity region, where d<sub>I</sub>(G) depends on certain structural properties of the underlying connectivity graph G of the wireless network and also on the type of interference constraints. For a wide range of wireless networks, d<sub>I</sub>(G) can be upper bounded by a constant, independent of the number of nodes in the network. The scheduling element of our algorithm is the maximal scheduling policy. Although maximal scheduling policy has been considered in many of the previous works, the difficulties that arise in implementing it in a distributed fashion in the presence of interference have not been dealt with previously. In this paper, we propose two novel randomized distributed algorithms for implementing the maximal scheduling policy under the 1-hop and 2-hop interference models.},
keywords={distributed algorithms;graph theory;interference (signal);randomised algorithms;scheduling;telecommunication congestion control;wireless sensor networks;joint congestion control;distributed scheduling;wireless network;throughput-optimal cross-layer design;connectivity graph;interference constraint;maximal scheduling policy;randomized distributed algorithm;Distributed control;Throughput;Wireless networks;Scheduling algorithm;Interference constraints;Network topology;Routing;Intelligent networks;Power control;Communications Society},
doi={10.1109/INFCOM.2007.240},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215823,
author={W. -. Tam and Y. -. Tseng},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Joint Multi-Channel Link Layer and Multi-Path Routing Design for Wireless Mesh Networks},
year={2007},
volume={},
number={},
pages={2081-2089},
abstract={In recent years, the wireless mesh network (WMN) attracts the interest of many people as a new broadband Internet access technology. However, increasing throughput is still an open and challenging research issue. One potential solution is to enable transceivers to utilize multiple channels dynamically. However, most of existing works do not consider the routing issue, and trivially use some popular single-path routing protocols like AODV and DSR. In this paper, we exploit the benefit of multi-path routing in multi-channel WMNs from the aspect of end-to-end throughput. Between medium access control and network layers, we propose a novel protocol named Joint Multi-channel and Multi-path control (JMM) which combines multi-channel link layer with multi-path routing. Dividing time into slots, JMM coordinates channel usage among slots and schedules traffic flows on dual paths. Our scheme efficiently and intelligently decomposes contending traffics over different channels, different time, and different paths, and hence leads to significant throughput improvement. To the best of our knowledge, this is the first work discussing the joint design of multi-channel control and multi-path routing for WMNs.},
keywords={access protocols;Internet;multipath channels;routing protocols;telecommunication network topology;joint multichannel link layer;multipath routing design;wireless mesh network;broadband Internet access technology;routing protocol;medium access control;Routing;Wireless mesh networks;Throughput;Peer to peer computing;Communication system traffic control;Spine;Road accidents;Communications Society;IP networks;Transceivers},
doi={10.1109/INFCOM.2007.241},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215824,
author={G. Athanasiou and T. Korakis and O. Ercetin and L. Tassiulas},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Dynamic Cross-Layer Association in 802.11-Based Mesh Networks},
year={2007},
volume={},
number={},
pages={2090-2098},
abstract={In IEEE 802.11-based wireless mesh networks a user is associated with an access point (AP) in order to communicate and be part of the overall network. The association mechanism specified by the IEEE 802.11 standard does not consider the channel conditions and the AP load in the association process. Employing the mechanism in its plain form in wireless mesh networks we may only achieve low throughput and low user transmission rates. In this paper, we propose an association mechanism that is aware of the uplink and downlink channel conditions. We introduce a metric that captures the channel conditions and the load of the APs in the network. The users use this metric in order to optimally associate with the available APs. We then extend the functionality of this mechanism in a cross-layer manner taking into account information from the routing layer. The novelty of the mechanism is that the routing QoS information of the back haul is available to the end users. This information can be combined with the uplink and downlink channel information for the purpose of supporting optimal end-to-end communication and providing high end-to-end throughput values. We evaluate the performance of our system through simulations and we show that 802.11-based mesh networks that use the proposed association mechanism are more capable in meeting the needs of QoS-sensitive applications.},
keywords={quality of service;telecommunication network routing;wireless channels;wireless LAN;dynamic cross-layer association;802.11-based mesh networks;access point;low throughput;low user transmission rates;uplink channel;downlink channel;routing layer;QoS information;end-to-end communication;Mesh networks;Wireless mesh networks;Spine;Throughput;Data engineering;Downlink;Wireless LAN;Computer networks;Routing protocols;Costs},
doi={10.1109/INFCOM.2007.242},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215825,
author={S. Bohacek and P. Wang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Toward Tractable Computation of the Capacity of Multi-Hop Wireless Networks},
year={2007},
volume={},
number={},
pages={2099-2107},
abstract={By posing the problem of bandwidth allocation as a constrained maximization problem, it is possible to study various features of optimal bandwidth allocation, and hence the capacity of the network. However, since the typical approach to this problem requires optimizing over a space that is exponential in the number of links, the problem has appeared to be computationally intractable for all but small networks. In this paper, the problem of computing optimal bandwidth allocation is examined and a new approach is presented. While the resulting allocation cannot be guaranteed to be optimal, we find that in the networks where checking optimality is computationally feasible (i.e., networks with fewer than 23 links), the performance of the found allocation is indistinguishable from the optimal allocation. In essence, the proposed iterative scheme focuses on the space of useful bandwidth allocations. The Lagrange multipliers are used to find useful allocations.},
keywords={bandwidth allocation;iterative methods;optimisation;radio networks;scheduling;tractable computation;multihop wireless network capacity;optimal bandwidth allocation problem;constrained maximization problem;iterative scheme;Lagrange multipliers;optimal schedule estimation;Computer networks;Spread spectrum communication;Wireless networks;Optimal scheduling;Channel allocation;Power control;Interference constraints;Mesh networks;Collaborative work;Government},
doi={10.1109/INFCOM.2007.243},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215826,
author={C. Cicconetti and I. F. Akyildiz and L. Lenzini},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Bandwidth Balancing in Multi-Channel IEEE 802.16 Wireless Mesh Networks},
year={2007},
volume={},
number={},
pages={2108-2116},
abstract={In wireless mesh networks, the end-to-end throughput of traffic flows depends on the path length, i.e. the higher the number of hops, the lower becomes the throughput. In this paper, a Fair End-to-end Bandwidth Allocation (FEBA) algorithm is introduced to solve this problem. FEBA is implemented at the Medium Access Control (MAC) layer of single-radio, multiple channels IEEE 802.16 mesh nodes, operated in a distributed coordinated scheduling mode. FEBA negotiates bandwidth among neighbors to assign a fair share to each end-to-end traffic flow. This is carried out in two steps. First, bandwidth is requested and granted in a round-robin fashion where heavily loaded links are provided with a proportionally higher amount of service than the lightly loaded links at each round. Second, at each output link, packets from different traffic flows are buffered in separate queues which are served by the Deficit Round Robin (DRR) scheduling algorithm. If multiple channels are available, all of them are shared evenly in order to increase the network capacity due to frequency reuse. The performance of FEBA is evaluated by extensive simulations and is shown to provide fairness by balancing the bandwidth among traffic flows.},
keywords={access protocols;bandwidth allocation;scheduling;telecommunication traffic;WiMax;wireless channels;bandwidth balancing;multichannel IEEE 802.16 wireless mesh networks;traffic flows;end-to-end bandwidth allocation;medium access control;MAC layer;deficit round robin scheduling algorithm;multiple channels;Bandwidth;Wireless mesh networks;Traffic control;Throughput;Telecommunication traffic;Communication system traffic control;Channel allocation;Media Access Protocol;Round robin;Scheduling algorithm},
doi={10.1109/INFCOM.2007.244},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215827,
author={H. X. Nguyen and P. Thiran},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={The Boolean Solution to the Congested IP Link Location Problem: Theory and Practice},
year={2007},
volume={},
number={},
pages={2117-2125},
abstract={Like other problems in network tomography or traffic matrix estimation, the location of congested IP links from end-to-end measurements requires solving a system of equations that relate the measurement outcomes with the variables representing the status of the IP links. In most networks, this system of equations does not have a unique solution. To overcome this critical problem, current methods use the unrealistic assumption that all IP links have the same prior probability of being congested. We find that this assumption is not needed, because these probabilities can be uniquely identified from a small set of measurements by using properties of Boolean algebra. We can then use the learnt probabilities as priors to find rapidly the congested links at any time, with an order of magnitude gain in accuracy over existing algorithms. We validate our results both by simulation and real implementation in the PlanetLab network.},
keywords={Boolean algebra;IP networks;congested IP link location problem;traffic matrix estimation;network tomography;Boolean algebra;learnt probabilities;Extraterrestrial measurements;Equations;Boolean algebra;Telecommunication traffic;IP networks;Probability;Tomography;Traffic control;Inverse problems;Switches},
doi={10.1109/INFCOM.2007.245},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215828,
author={Z. Yao and X. Wang and D. Leonard and D. Loguinov},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Node Isolation Under Churn in Unstructured P2P Networks with Heavy-Tailed Lifetimes},
year={2007},
volume={},
number={},
pages={2126-2134},
abstract={Previous analytical studies [12], [18] of unstructured P2P resilience have assumed exponential user lifetimes and only considered age-independent neighbor replacement. In this paper, we overcome these limitations by introducing a general node-isolation model for heavy-tailed user lifetimes and arbitrary neighbor-selection algorithms. Using this model, we analyze two age-biased neighbor-selection strategies and show that they significantly improve the residual lifetimes of chosen users, which dramatically reduces the probability of user isolation and graph partitioning compared to uniform selection of neighbors. In fact, the second strategy based on random walks on age-weighted graphs demonstrates that for lifetimes with infinite variance, the system monotonically increases its resilience as its age and size grow. Specifically, we show that the probability of isolation converges to zero as these two metrics tend to infinity. We finish the paper with simulations in finite-size graphs that demonstrate the effect of this result in practice.},
keywords={graph theory;peer-to-peer computing;probability;unstructured P2P network;age-independent neighbor replacement;node-isolation model;probability;age-weighted graph partitioning;infinite variance;Resilience;Peer to peer computing;Computational modeling;Communications Society;Computer science;USA Councils;Partitioning algorithms;H infinity control;Event detection;Delay effects},
doi={10.1109/INFCOM.2007.246},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215829,
author={S. Sanghavi and B. Hajek and L. Massoulie},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Gossiping with Multiple Messages},
year={2007},
volume={},
number={},
pages={2135-2143},
abstract={This paper investigates the dissemination of multiple pieces of information in large networks where users contact each other in a random uncoordinated manner, and users upload one piece per unit time. The underlying motivation is the design and analysis of piece selection protocols for peer-to-peer networks which disseminate files by dividing them into pieces. We first investigate one-sided protocols, where piece selection is based on the states of either the transmitter or the receiver. We show that any such protocol relying only on pushes, or alternatively only on pulls, will be inefficient in disseminating all pieces to all users. We propose a hybrid one-sided piece selection protocol -INTERLEAVE -and show that by using both pushes and pulls it disseminates k pieces from a single source to n users in 10(k + log n) time, while obeying the constraint that each user can upload at most one piece in one unit of time. An optimal, unrealistic centralized protocol would take k + log<sub>2</sub> n time in this setting. Moreover, efficient dissemination is also possible if the source implements forward erasure coding, and users push the latest-released coded pieces (but do not pull). We also investigate two-sided protocols where piece selection is based on the states of both the trasmitter and the receiver. We show that it is possible to disseminate n pieces to n users in + O(log n) time, starting from an initial state where each user has a unique piece.},
keywords={peer-to-peer computing;one-sided piece selection protocol;peer-to-peer network;unrealistic centralized protocol;forward erasure coding;information dissemination;Protocols;Peer to peer computing;Scalability;Robustness;Communications Society;Transmitters;IP networks;Telecommunication traffic;Load management;Relays},
doi={10.1109/INFCOM.2007.247},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215830,
author={N. Laoutaris and G. Smaragdakis and K. Oikonomou and I. Stavrakakis and A. Bestavros},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Distributed Placement of Service Facilities in Large-Scale Networks},
year={2007},
volume={},
number={},
pages={2144-2152},
abstract={The effectiveness of service provisioning in large-scale networks is highly dependent on the number and location of service facilities deployed at various hosts. The classical, centralized approach to determining the latter would amount to formulating and solving the <i>uncapacitated k-median</i> (UKM) problem (if the requested number of facilities is fixed), or the <i>uncapacitated facility location </i>(UFL) problem (if the number of facilities is also to be optimized). Clearly, such centralized approaches require knowledge of global topological and demand information, and thus do not scale and are not practical for large networks. The key question posed and answered in this paper is the following: "How can we determine in a distributed and scalable manner the <i>number</i> and <i>location</i> of service facilities?" We propose an innovative approach in which topology and demand information is limited to neighborhoods, or balls of small radius around selected facilities, whereas demand information is captured implicitly for the remaining (remote) clients outside these neighborhoods, by mapping them to clients on the edge of the neighborhood; the ball radius regulates the trade-off between scalability and performance. We develop a scalable, distributed approach that answers our key question through an iterative re-optimization of the location and the number of facilities within such balls. We show that even for small values of the radius (1 or 2), our distributed approach achieves performance under various synthetic and real Internet topologies that is comparable to that of optimal, centralized approaches requiring full topology and demand information.},
keywords={Internet;iterative methods;telecommunication network topology;distributed placement;service facilities;large-scale networks;uncapacitated k-median problem;uncapacitated facility location;iterative reoptimization;Internet topologies;Large-scale systems;Informatics;Communications Society;Telecommunication network topology;Scalability;Iterative methods;Internet;Bandwidth;Computer science;Computer architecture},
doi={10.1109/INFCOM.2007.248},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215831,
author={R. Stanojevic},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Small Active Counters},
year={2007},
volume={},
number={},
pages={2153-2161},
abstract={The need for efficient counter architecture has arisen for the following two reasons. Firstly, a number of data streaming algorithms and network management applications require a large number of counters in order to identify important traffic characteristics. And secondly, at high speeds, current memory devices have significant limitations in terms of speed (DRAM) and size (SRAM). For some applications no information on counters is needed on a per-packet basis and several methods have been proposed to handle this problem with low SRAM memory requirements. However, for a number of applications it is essential to have the counter information on every packet arrival. In this paper we propose two, computationally and memory efficient, randomized algorithms for approximating the counter values. We prove that proposed estimators are unbiased and give variance bounds. A case study on multistage filters (MSF) over the real Internet traces shows a significant improvement by using the active counters architecture.},
keywords={Internet;counter architecture;data streaming algorithms;network management;randomized algorithms;multistage filters;Internet;Counting circuits;Random access memory;Filters;Statistics;Sampling methods;Computer architecture;Proposals;Communications Society;Telecommunication traffic;Information filtering},
doi={10.1109/INFCOM.2007.249},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215832,
author={A. Shriram and J. Kaur},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Empirical Evaluation of Techniques for Measuring Available Bandwidth},
year={2007},
volume={},
number={},
pages={2162-2170},
abstract={The ability to measure end-to-end available bandwidth (AB) on a network path is useful in several domains, including overlay-routing infrastructure, network monitoring, and design of transport protocols. Several tools have, consequently, been proposed to estimate end-to-end AB. Unfortunately, existing evaluations of these tools are either not comprehensive or are biased by the current state of implementation technology. In this paper, we conduct a comprehensive empirical evaluation of algorithmic techniques for measuring AB. In order to eliminate implementation-related biases, we rely on a simulated network environment and develop a generic implementation framework for instantiating different tools. We implement our framework in NS-2 and reproduce traffic from real Internet links in order to evaluate tools under different conditions of (i) traffic load, (ii) sampling intensities, (iii) measurement timescales, (iv) number of bottleneck links, and (iv) location of bottleneck. We evaluate the tools for their accuracy, run-time, overhead, intrusiveness, and impact on responsive traffic. Our results contradict some of those in prior work that does not eliminate implementation biases.},
keywords={bandwidth allocation;Internet;telecommunication links;telecommunication network routing;telecommunication traffic;transport protocols;available bandwidth measuring;end-to-end available bandwidth;network path;overlay-routing infrastructure;network monitoring;transport protocols;simulated network environment;generic implementation framework;NS-2;Internet links;traffic load;bottleneck links;Bandwidth;Probes;Delay estimation;Dispersion;Monitoring;Transport protocols;Telecommunication traffic;Algorithm design and analysis;Inference algorithms;Communications Society},
doi={10.1109/INFCOM.2007.250},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215833,
author={Y. Zhao and Y. Chen},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Suite of Schemes for User-Level Network Diagnosis without Infrastructure},
year={2007},
volume={},
number={},
pages={2171-2179},
abstract={It is highly desirable and important for end users, with no special privileges, identify and pinpoint faults inside the network that degrade the performance of their applications. However, existing tools are inaccurate to infer the link-level loss rates and have large diagnosis granularity (in terms of the number of hops). To address these problems, we propose a suite of user-level diagnosis approaches in two categories: (1) only need to be deployed at the source and (2) deployed at both source and destination. For the former, we propose two fragmentation aided diagnosis approaches (FAD), Algebraic FAD and Opportunistic FAD, which uses IP fragmentation to enable accurate link-level loss rate inference. For the latter category, we propose Striped Probe Analysis (SPA) which significantly improves the diagnosis granularity over those of the source-only approaches. Internet experiments are applied to evaluate each individual schemes (including an improved version of the state-of-the-art tool, Tulip [1]) and various hybrid approaches. The results indicate that our approaches dramatically outperform existing work (especially for diagnosis granularity) and provide not only the best performance but also smooth tradeoff among deployment requirement, diagnosis accuracy and granularity.},
keywords={fault diagnosis;Internet;IP networks;quality of service;telecommunication network reliability;telecommunication traffic;user-level network fault diagnosis;link-level loss rate inference;fragmentation aided diagnosis approach;IP fragmentation;striped probe analysis;Internet tomography;Internet traffic measurement;QoS metric;Fault diagnosis;Internet;Tomography;Extraterrestrial measurements;Degradation;Probes;Loss measurement;Communications Society;Application software;Network servers},
doi={10.1109/INFCOM.2007.251},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215834,
author={R. R. Kompella and J. Yates and A. Greenberg and A. C. Snoeren},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Detection and Localization of Network Black Holes},
year={2007},
volume={},
number={},
pages={2180-2188},
abstract={Internet backbone networks are under constant flux, struggling to keep up with increasing demand. The pace of technology change often outstrips the deployment of associated fault monitoring capabilities that are built into today's IP protocols and routers. Moreover, some of these new technologies cross networking layers, raising the potential for unanticipated interactions and service disruptions that the built-in monitoring systems cannot detect. In such instances, failures may cause data packets to be silently dropped inside the network without triggering any alarms or responses (e.g., the failure is not routed around). So-called "silent failures" or "black holes" represent a critical threat to today's rapidly evolving networks. In this paper, we present a simple and effective method to detect and diagnose such silent failures. Our method uses active measurement between edge routers to raise alarms whenever end-to-end connectivity is disrupted, regardless of the cause. These alarms feed localization agents that employ spatial correlation techniques to isolate the root-cause of failure. Using data from two real systems deployed on sections of a tier-I ISP network, we successfully detect and localize three known black holes. Further, we present simulation results demonstrating that our system accurately and precisely (both greater than 80% according to our metrics) localizes a variety of failures classes.},
keywords={fault diagnosis;Internet;telecommunication network reliability;telecommunication network routing;transport protocols;network black holes;Internet backbone networks;fault monitoring;IP protocols;silent failure detection;silent failure diagnosis;edge routers;Spine;Internet;Fault detection;Multiprotocol label switching;Condition monitoring;Routing protocols;Failure analysis;Communications Society;IP networks;Feeds},
doi={10.1109/INFCOM.2007.252},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215835,
author={H. Zhang and G. Neglia and D. Towsley and G. Lo Presti},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Unstructured File Sharing Networks},
year={2007},
volume={},
number={},
pages={2189-2197},
abstract={We study the interaction among users of unstructured file sharing applications, who compete for available network resources (link bandwidth or capacity) by opening multiple connections on multiple paths so as to accelerate data transfer. We model this interaction with an unstructured file sharing game. Users are players and their strategies are the numbers of sessions on available paths. We consider a general bandwidth sharing framework proposed by Kelly [1] and Mo and Walrand [2], with TCP as a special case. Furthermore, we incorporate the Tit-for-Tat strategy (adopted by BitTorrent [3] networks) into the unstructured file sharing game to model the competition in which a connection can be set up only when both users find this connection beneficial. We refer to this as an overlay formation game. We prove the existence of Nash equilibrium in several variants of both games, and quantify the losses of efficiency of Nash equilibria. We find that the loss of efficiency due to selfish behavior is still unbounded even when the Tit-for-Tat strategy is believed to prevent selfish behavior.},
keywords={bandwidth allocation;decision theory;game theory;peer-to-peer computing;resource allocation;transport protocols;unstructured file sharing networks;network resources;data transfer;unstructured file sharing game;bandwidth sharing framework;TCP;Tit-for-Tat strategy;overlay formation game;Nash equilibrium;Peer to peer computing;Costs;Bandwidth;Network topology;Telecommunication traffic;Acceleration;Nash equilibrium;Internet;Relays;Communication system traffic control},
doi={10.1109/INFCOM.2007.253},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215836,
author={G. Tan and S. A. Jarvis},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Stochastic Analysis and Improvement of the Reliability of DHT-Based Multicast},
year={2007},
volume={},
number={},
pages={2198-2206},
abstract={This paper investigates the reliability of application-level multicast based on a distributed hash table (DHT) in a highly dynamic network. Using a node residual lifetime model, we derive the stationary end-to-end delivery ratio of data streaming between a pair of nodes in the worst case, and show through numerical examples that in a practical DHT network, this ratio can be very low (e.g., less than 50%). Leveraging the property of heavy-tailed lifetime distribution, we then consider three optimizing techniques, namely senior member overlay (SMO), longer-lived neighbor selection (LNS), and reliable route selection (RRS), and present quantitative analysis of data delivery reliability under these schemes. In particular, we discuss the tradeoff between delivery ratio and the load imbalance among nodes. Simulation experiments are also used to evaluate the multicast performance under practical settings. Our model and analytic results provide useful tools for reliability analysis for other overlay-based applications (e.g., those involving persistent data transfers).},
keywords={multicast communication;stochastic processes;telecommunication network reliability;telecommunication network routing;stochastic analysis;DHT-based multicast reliability;distributed hash table;highly dynamic network;node residual lifetime model;stationary end-to-end delivery ratio;data streaming;heavy-tailed lifetime distribution;senior member overlay;longer-lived neighbor selection;reliable route selection;data delivery reliability;Stochastic processes;Peer to peer computing;Multicast protocols;Computer network reliability;Senior members;Application software;Communications Society;Speech analysis;Telecommunication network reliability;Computer science},
doi={10.1109/INFCOM.2007.254},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215837,
author={C. -. Wang and K. Harfoush},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Stability-Scalability Tradeoff of DHT Deployment},
year={2007},
volume={},
number={},
pages={2207-2215},
abstract={Distributed hash tables (DHTs) provide efficient data naming and location with simple hash-table-like primitives, upon which sophisticated distributed applications can be built. DHT users provide <i>free</i> but <i>unstable</i> peer-to-peer (P2P) capacity. With stable DHT nodes being relatively scarce, a DHT can either rely on a small set of stable nodes with limited collective capacity, or a larger set of potentially less stable nodes and suffer maintenance and data redundancy overhead. In this paper, we provide an analytical model that captures the tradeoff between the stability and the scalability in DHT-based P2P systems. We use the model to demonstrate that the DHT throughput can be optimized through careful engineering of DHT node selection and data redundancy parameters.},
keywords={file organisation;peer-to-peer computing;DHT;distributed hash table;data naming;data location;peer-to-peer network;data redundancy;Stability;Peer to peer computing;Costs;Scalability;Throughput;Availability;Control systems;Maintenance;Constraint optimization;Communications Society},
doi={10.1109/INFCOM.2007.255},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215838,
author={G. Neglia and G. Reina and H. Zhang and D. Towsley and A. Venkataramani and J. Danaher},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Availability in BitTorrent Systems},
year={2007},
volume={},
number={},
pages={2216-2224},
abstract={In this paper, we investigate the problem of highly available, massive-scale file distribution in the Internet. To this end, we conduct a large-scale measurement study of BitTorrent, a popular class of systems that use swarms of actively downloading peers to assist each other in file distribution. The first generation of BitTorrent systems used a central tracker to enable coordination among peers, resulting in low availability due to the tracker's single point of failure. Our study analyzes the prevalence and impact of two recent trends to improve BitTorrent availability: (i) use of multiple trackers, and (ii) use of Distributed Hash Tables (DHTs), both of which also help to balance load better. The study considered more than 1,400 trackers and 24,000 DHT nodes (extracted from about 20,000 torrents) over a period of two months. We find that both trends improve availability, but for different and somewhat unexpected reasons. Our findings include: (i) multiple trackers improve availability, but the improvement largely comes from the choice of a single highly available tracker, (ii) such improvement is reduced by the presence of correlated failures, (iii) multiple trackers can significantly reduce the connectivity of the overlay formed by peers, (iv) the DHT improves information availability, but induces a higher response latency to peer queries.},
keywords={file organisation;Internet;peer-to-peer computing;query processing;resource allocation;table lookup;BitTorrent system;massive-scale file distribution;Internet;downloading peers;distributed hash tables;load balancing;peer query;Availability;Peer to peer computing;Internet;Delay;Computer science;Security;Communications Society;Large-scale systems;Spine;File servers},
doi={10.1109/INFCOM.2007.256},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215839,
author={J. Chen and A. Jiang and I. A. Kanj and G. Xia and F. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Separability and Topology Control of Quasi Unit Disk Graphs},
year={2007},
volume={},
number={},
pages={2225-2233},
abstract={A deep understanding of the structural properties of wireless networks is critical for evaluating the performance of network protocols and improving their designs. Many protocols for wireless networks - routing, topology control, information storage/retrieval and numerous other applications - have been based on the idealized unit-disk graph (UDG) network model. The significant deviation of the UDG model from many real wireless networks is substantially limiting the applicability of such protocols. A more general network model, the quasi unit-disk graph (quasi-UDG) model, captures much better the characteristics of wireless networks. However, the understanding of the properties of general quasi-UDGs has been very limited, which is impeding the designs of key network protocols and algorithms. In this paper, we present results on two important properties of quasi-UDGs: separability and the existence of power efficient spanners. Network separability is a fundamental property leading to efficient network algorithms and fast parallel computation. We prove that every quasi-UDG has a corresponding grid graph with small balanced separators that captures its connectivity properties. We also study the problem of constructing an energy-efficient backbone for a quasi-UDG. We present a distributed localized algorithm that, given a quasi-UDG, constructs a nearly planar backbone with a constant stretch factor and a bounded degree. We demonstrate the excellent performance of these auxiliary graphs through simulations and show their applications in efficient routing.},
keywords={graph theory;protocols;radio networks;telecommunication network routing;telecommunication network topology;topology control;quasi unit disk graph network model;wireless networks;structural properties;network protocols;network routing;information storage;information retrieval;network separability;parallel computation;grid graph;balanced separators;connectivity properties;distributed localized algorithm;constant stretch factor;auxiliary graphs;Wireless networks;Wireless application protocol;Network topology;Spine;Routing protocols;Information retrieval;Impedance;Algorithm design and analysis;Computer networks;Concurrent computing},
doi={10.1109/INFCOM.2007.257},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215840,
author={M. -. Tsai and H. -. Yang and W. -. Huang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Axis-Based Virtual Coordinate Assignment Protocol and Delivery-Guaranteed Routing Protocol in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={2234-2242},
abstract={In this paper, we propose a method of constructing a virtual coordinate system (ABVCap) in wireless sensor networks where location information is not available. A routing protocol based on ABVCap virtual coordinates is also introduced. Our routing protocol guarantees packet delivery and does not require computing and storing of the global topological features. Using simulations, we evaluate the performance of the proposed routing protocol (ABVCap routing), the greedy routing protocol based on VCap virtual coordinates (VCap routing), the greedy routing protocol based on physical coordinates (Euclidean routing), greedy perimeter stateless routing (GPSR routing), and geometric spanner routing (GSR routing). The simulations show that our method guarantees packet delivery while ensuring moderate routing path length overhead costs.},
keywords={routing protocols;telecommunication network topology;wireless sensor networks;axis-based virtual coordinate assignment protocol;delivery-guaranteed routing protocol;wireless sensor network;ABVCap virtual coordinate;packet delivery;greedy routing protocol;greedy perimeter stateless routing;geometric spanner routing;Routing protocols;Wireless application protocol;Wireless sensor networks;Chemical technology;Global Positioning System;Iterative algorithms;Communications Society;Computer science;Electronic mail;Computational modeling},
doi={10.1109/INFCOM.2007.258},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215841,
author={F. Zhang and H. Li and A. Jiang and J. Chen and P. Luo},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Face Tracing Based Geographic Routing in Nonplanar Wireless Networks},
year={2007},
volume={},
number={},
pages={2243-2251},
abstract={Scalable and efficient routing is a main challenge in the deployment of large ad hoc wireless networks. An essential element of practical routing protocols is their accommodation of realistic network topologies. In this paper, we study geographic routing in general large wireless networks. Geographic routing is a celebrated idea that uses the locations of nodes to effectively support routing. However, to guarantee delivery, recent geographic routing algorithms usually resort to perimeter routing, which requires the removal of communication links to get a planar sub-network on which perimeter routing is performed. Localized network planarization requires the wireless network to be a unit-disk graph (UDG) or its close approximation. For networks that significantly deviate from the UDG model, a common case in practice, substantially more expensive and non-localized network planarization methods have to be used. How to make such methods efficiently adaptable to network dynamics, and how to avoid the removal of an excessive number of links that leads to lowered routing performance, are still open problems. To enable efficient geographic routing in general wireless networks, we present face-tracing based routing, a novel approach that routes the message in the faces of the network that are virtually embedded in a topological surface. Such faces are easily recognizable and constructible, and adaptively capture the important geometric features in wireless networks - in particular, holes, -thus leading to very efficient routing. We show by both analysis and si mulations that the face-tracing based routing is a highly scalable routing protocol that generates short routes, incurs low overhead, adapts quickly to network dynamics, and is very robust to variations in network models.},
keywords={ad hoc networks;graph theory;routing protocols;telecommunication network topology;face tracing based geographic routing algorithm;nonplanar wireless ad hoc network;routing protocols;realistic network topology;localized network planarization;unit-disk graph;Wireless networks;Planarization;Peer to peer computing;Semiconductor device modeling;Partitioning algorithms;Routing protocols;Communications Society;Computer science;Floods;Euclidean distance},
doi={10.1109/INFCOM.2007.259},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215842,
author={T. Stathopoulos and M. Lukac and D. McIntire and J. Heidemann and D. Estrin and W. J. Kaiser},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={End-to-End Routing for Dual-Radio Sensor Networks},
year={2007},
volume={},
number={},
pages={2252-2260},
abstract={Dual-radio, dual-processor nodes are an emerging class of wireless sensor network devices that provide both low-energy operation as well as substantially increased computational performance and communication bandwidth for applications. In such systems, the secondary radio and processor operates with sufficiently low power that it may remain always vigilant, while the main processor and primary, high-bandwidth radio remain off until triggered by the application. By exploiting the high energy efficiency of the main processor and primary radio along with proper usage, net operating energy benefits are enabled for applications. The secondary radio provides a constantly available multi-hop network, while paths in the primary network exist only when required. This paper describes a topology control mechanism for establishing an end-to-end path in a network of dual-radio nodes using the secondary radios as a control channel to <i>selectively</i> wake up nodes along the required end-to-end path. Using numerical models as well as testbed experimentation, we show that our proposed mechanism provides significant energy savings of more than 60% compared to alternative approaches, and that it incurs only moderately greater application latency.},
keywords={microprocessor chips;telecommunication network routing;telecommunication network topology;wireless channels;wireless sensor networks;end-to-end routing;dual-radio sensor network;dual-processor nodes;energy efficiency;multi hop network;topology control mechanism;radio channel;selectively wake up nodes;Routing;Radio control;Wireless sensor networks;Computer networks;Bandwidth;Energy efficiency;Spread spectrum communication;Network topology;Numerical models;Testing},
doi={10.1109/INFCOM.2007.260},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215843,
author={J. A. Patel and H. Luo and I. Gupta},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Cross-Layer Architecture to Exploit Multi-Channel Diversity with a Single Transceiver},
year={2007},
volume={},
number={},
pages={2261-2265},
abstract={The design of multi-channel multi-hop wireless mesh networks is centered around the way nodes synchronize when they need to communicate. However, existing designs are confined to the MAC layer -they are based on either negotiation on a rendezvous control channel, or on optimistic synchronization. Both approaches scale poorly as the network grows in coverage and density. The rendezvous control channel may become the bottleneck, while optimistic synchronization may incur substantial overhead - especially amongst nodes close to a gateway, where the mesh traffic converges. In this paper, we describe Dominion - a cross-layer architecture that includes both medium access control and routing. At the MAC layer, a node switches channels in a deterministic manner to address the scalability issue. At the network layer, a Dominion node routes traffic along the shortest distance across both spatial and frequency domains, based on the deterministic channel-hopping schedule and network connectivity. Since the shortest distance path across the frequency domain is time variant, Dominion naturally spreads the packets of the same flow across multiple paths, relieving the intra-flow and inter-flow contention, and improving throughput. Through QualNet simulations we show that Dominion is able to achieve, on average, 1813% higher aggregate distance-normalized throughput than IEEE 802.11, while being 1730% fairer (using Jain's fairness index) with 50 simultaneous random flows.},
keywords={access protocols;radio networks;routing protocols;synchronisation;telecommunication network topology;telecommunication traffic;transceivers;wireless channels;multichannel multihop wireless mesh network;cross-layer architecture;multichannel diversity;single transceiver;MAC layer;rendezvous control channel;optimistic synchronization;medium access control;deterministic channel-hopping schedule;routing protocols;Transceivers;Frequency synchronization;Communication system traffic control;Frequency domain analysis;Throughput;Spread spectrum communication;Wireless mesh networks;Design optimization;Media Access Protocol;Routing},
doi={10.1109/INFCOM.2007.261},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215844,
author={D. Zheng and J. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Joint Optimal Channel Probing and Transmission in Collocated Wireless Networks},
year={2007},
volume={},
number={},
pages={2266-2270},
abstract={We consider a collocated wireless network where all links contend for a given channel and each link can hear others' transmissions. Due to channel fading, the link condition corresponding to a successful channel probing could be either good or bad. In the latter case, further channel probing may lead to better channel conditions, which in turn yields higher throughput. There is clearly a tradeoff between the throughput gain from better channel conditions and the cost for further channel probing. The desired tradeoff can be achieved by choosing the optimal stopping time for channel probing and the transmission rate, in the sense of maximizing the overall average throughput. Using optimal stopping theory, we show that the joint optimal channel probing and transmission (JOCPT) strategy is a pure threshold policy, and interestingly, the threshold turns out to be the optimal average throughput, which is the solution to a fixed point equation. Since the optimal throughput usually cannot be obtained in closed form, we derive a lower bound and an upper bound on the optimal throughput, and devise an iterative algorithm to compute it. Finally, we use numerical examples to show that significant throughput gain can be achieved by the JOCPT strategy.},
keywords={channel allocation;iterative methods;statistical distributions;wireless channels;optimal channel probing;optimal transmission rate;collocated wireless networks;channel conditions;optimal stopping time;optimal stopping theory;pure threshold policy;optimal average throughput;fixed point equation;iterative algorithm;throughput gain;Wireless networks;Throughput;Costs;Fading;Communications Society;USA Councils;Distributed algorithms;Diversity methods;Communication networks;Stochastic processes},
doi={10.1109/INFCOM.2007.262},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215845,
author={N. Chirdchoo and W. -. Soh and K. C. Chua},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Aloha-Based MAC Protocols with Collision Avoidance for Underwater Acoustic Networks},
year={2007},
volume={},
number={},
pages={2271-2275},
abstract={Unlike terrestrial networks that mainly rely on radio waves for communications, underwater networks utilize acoustic waves, which have comparatively lower loss and longer range in underwater environments. However, the use of acoustic waves pose a new research challenge in the networking area. While existing network schemes for terrestrial sensor networks are mainly designed for negligible propagation delay and high data rate, underwater acoustic communications are characterized by high propagation delay and low data rate. These terrestrial schemes, when directly applied to the underwater channel, will under-utilize its already limited capacity. We investigate how the underwater channel's throughput may be enhanced via medium access control (MAC) techniques that consider its unique characteristics. Specifically, we study the performance of Aloha-based protocols in underwater networks, and propose two enhanced schemes, namely, Aloha with collision avoidance (Aloha-CA), and Aloha with advance notification (Aloha-AN), which are capable of using the long propagation delays to their advantage. Simulation results have shown that both schemes can boost the throughput by reducing the number of collisions, and, for the case of Aloha-AN, also by significantly reducing the number of unproductive transmissions.},
keywords={access protocols;acoustic wave propagation;collision avoidance;telecommunication channels;underwater acoustic communication;wireless sensor networks;Aloha-based MAC protocol;collision avoidance;acoustic waves;terrestrial sensor network;propagation delay;underwater acoustic communications;underwater channel;medium access control;underwater network;Media Access Protocol;Collision avoidance;Underwater acoustics;Propagation delay;Underwater communication;Acoustic waves;Throughput;Sensor phenomena and characterization;Acoustic sensors;Access protocols},
doi={10.1109/INFCOM.2007.263},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215846,
author={I. Cerutti and A. Fumagalli and P. Gupta},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Delay Model of Single-Relay Cooperative ARQ Protocols in Slotted Radio Networks with Non-Instantaneous Feedback and Poisson Frame Arrivals},
year={2007},
volume={},
number={},
pages={2276-2280},
abstract={In cooperative ARQ protocols, data frame retransmissions may be performed by a neighboring node (the relay) that has successfully overheard the source's frame transmission. One advantage is the diversity provided by the relay. The three-way (source, destination, relay) frame exchange sequence required in the cooperative ARQ protocols may however introduce extra latency when compared to non-cooperative ARQ protocols. To take advantage of cooperative ARQ protocols, it is then necessary to resort to selective repeat solutions. The focus of the paper is to derive a delay model for cooperative selective repeat ARQ protocols in slotted radio networks. The derived analytical model quantifies, with closed formulas, the queueing and transmission delay experienced by Poisson arriving data frames, whose retransmissions are performed by a single relay.},
keywords={automatic repeat request;delays;feedback;Poisson distribution;radio networks;delay model;single-relay cooperative ARQ protocol;slotted radio network;noninstantaneous feedback;Poisson frame arrival;data frame retransmission;three-way frame exchange sequence;Automatic repeat request;Protocols;Radio network;Feedback;Frame relay;Peer to peer computing;Delay effects;Communications Society;Electronic mail;Analytical models},
doi={10.1109/INFCOM.2007.264},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215847,
author={Q. Dong and A. Shukla and V. Shrivastava and D. Agrawal and S. Banerjee and K. Kar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Load Balancing in Large-Scale RFID Systems},
year={2007},
volume={},
number={},
pages={2281-2285},
abstract={A radio frequency identifier (RFID) system consists of inexpensive, uniquely-identifiable tags that are mounted on physical objects, and readers that track these tags (and hence these physical objects) through RF communication. In this paper we, therefore, address this load balancing problem for readers - given a set of tags that are within range of each reader, which of these tags should each reader be responsible for such that the cost for monitoring tags across the different readers is balanced, while guaranteeing that each tag is monitored by at least one reader. We show that a generalized variant of the load balancing problem is NP-hard and hence present a 2-approximation centralized algorithm. We next present an optimal centralized solution for a specialized variant. Subsequently, we present a localized distributed algorithm that is probabilistic in nature and closely matches the performance of the centralized algorithms. Our results demonstrate that our schemes achieve very good performance even in highly dynamic large-scale RFID systems.},
keywords={distributed algorithms;radiocommunication;radiofrequency identification;load balancing;large-scale RFID systems;radio frequency identifier;RF communication;2-approximation centralized algorithm;localized distributed algorithm;probabilistic algorithm;Load management;Large-scale systems;Radiofrequency identification;Monitoring;Costs;Radio frequency;USA Councils;Peer to peer computing;RFID tags;Information retrieval},
doi={10.1109/INFCOM.2007.265},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215848,
author={L. -. Chen and Y. -. Chen and T. Sun and P. Sreedevi and K. -. Chen and C. -. Yu and H. -. Chu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Finding Self-Similarities in Opportunistic People Networks},
year={2007},
volume={},
number={},
pages={2286-2290},
abstract={Opportunistic network is a type of delay tolerant networks (DTN) where network communication opportunities appear opportunistic. In this study, we investigate opportunistic network scenarios based on public network traces, and our contributions are the following: First, we identify the censorship issue in network traces that usually leads to strongly skewed distribution of the measurements. Based on this knowledge, we then apply the Kaplan-Meier Estimator to calculate the survivorship of network measurements, which is used in designing our proposed censorship removal algorithm (CRA) that is used to recover censored data. Second, we perform a rich set of analysis illustrating that UCSD and Dartmouth network traces show strong self-similarity, and can be modeled as such. Third, we pointed out the importance of these newly revealed characteristics in future development and evaluation of opportunistic networks.},
keywords={telecommunication network routing;opportunistic people networks;delay tolerant networks;Kaplan-Meier estimator;censorship removal algorithm;DTN network;Performance analysis;Wireless sensor networks;Computer science;Disruption tolerant networking;Algorithm design and analysis;IP networks;Statistical analysis;Communications Society;Information science;Ad hoc networks},
doi={10.1109/INFCOM.2007.266},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215849,
author={N. Wisitpongphan and F. Bai and P. Mudalige and O. K. Tonguz},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Routing Problem in Disconnected Vehicular Ad-hoc Networks},
year={2007},
volume={},
number={},
pages={2291-2295},
abstract={Vehicular ad hoc wireless network (VANET) exhibits a bipolar behavior in terms of network topology: fully connected topology with high traffic volume or sparsely connected topology when traffic volume is low. In this work, we develop a statistical traffic model based on the data collected on 1-80 freeway in California in order to study key performance metrics of interest in disconnected VANETs, such as average re-healing time (or the network restoration time). Our results show that, depending on the sparsity of vehicles, the network re-healing time can vary from a few seconds to several minutes. This suggests that, a new ad hoc routing protocol will be needed as the conventional ad hoc routing protocols such as dynamic source routing (DSR) and ad hoc on-demand distance vector routing (AODV) will not work with such long re-healing times.},
keywords={ad hoc networks;statistical analysis;telecommunication network routing;telecommunication network topology;telecommunication traffic;ad hoc routing;vehicular ad hoc network;network topology;statistical traffic model;VANET;network rehealing time;Ad hoc networks;Traffic control;Telecommunication traffic;Network topology;Routing protocols;Vehicle safety;USA Councils;Wireless networks;Vehicles;Vehicle driving},
doi={10.1109/INFCOM.2007.267},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215850,
author={X. Xiang and Z. Zhou and X. Wang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Self-Adaptive On Demand Geographic Routing Protocols for Mobile Ad-hoc Networks},
year={2007},
volume={},
number={},
pages={2296-2300},
abstract={It has been a big challenge to develop routing protocol that can meet different application needs and optimize routing paths according to the topology change in mobile ad hoc networks. Basing their forwarding decisions only on the local topology, geographic routing protocols have drawn a lot of attentions in recent years. However, inaccurate local topology knowledge and the outdated destination position information can lead to inefficient geographic forwarding and even routing failure. Proactive local position distribution can hardly adapt to the traffic demand. It is also difficult to pre-set protocol parameters correctly to fit in different environments. We have developed two self-adaptive on-demand geographic routing schemes. The local topology is updated in a timely manner according to network dynamics and traffic demands. Our route optimization scheme adapts the routing path according to both topology changes and actual data traffic requirements. Each node can determine and adjust the protocol parameter values independently according to different network environments, data traffic conditions and node's own requirements. Our simulation studies have shown that the proposed routing protocols are more robust and outperform the existing geographic routing protocol. Specifically, the packet delivery latency is reduced almost four times as compared to GPSR at high mobility.},
keywords={ad hoc networks;mobile radio;routing protocols;telecommunication network topology;telecommunication traffic;mobile ad hoc network;network topology;proactive local position distribution;network traffic;self-adaptive on demand geographic routing protocol;packet delivery latency;Routing protocols;Ad hoc networks;Network topology;Mobile ad hoc networks;Telecommunication traffic;Traffic control;USA Councils;Peer to peer computing;Robustness;Communication system traffic control},
doi={10.1109/INFCOM.2007.268},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215851,
author={X. Xiang and Z. Zhou and X. Wang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Robust and Scalable Geographic Multicast Protocol for Mobile Ad-hoc Networks},
year={2007},
volume={},
number={},
pages={2301-2305},
abstract={Group communications are important in mobile ad hoc networks (MANET). Multicast is an efficient method to implement the group communications. However, it is challenging to implement scalable, robust and efficient multicast in MANET due to the difficulty in group membership management, multicast packet forwarding and the maintenance of a tree-or mesh-based multicast structure over the dynamic topology for a large group size or network size. We propose a novel robust and scalable geographic multicast protocol (RSGM). Scalable and efficient group membership management has been performed through zone-based structure, and the location service for group members is combined with membership management. Both the control messages and data packets are forwarded along efficient tree-shape paths, but there is no need to actively maintain a tree structure, which efficiently reduces the maintenance overhead and makes the transmissions more robust to dynamics. Geographic forwarding is used to achieve further scalability and robustness. To avoid periodic flooding-based sources' announcements, an efficient source tracking mechanism is designed. Furthermore, we handle the empty zone problem faced by most zone-based routing protocols. Our simulation studies show that RSGM can scale to large group size and large network size, and a high delivery ratio is achieved by RSGM even under high dynamics.},
keywords={ad hoc networks;mobility management (mobile radio);multicast protocols;routing protocols;telecommunication network topology;robust and scalable geographic multicast protocol;mobile ad hoc networks;MANET;group communications;group membership management;multicast packet forwarding;mesh-based multicast structure;tree-based multicast structure;dynamic topology;zone-based structure;data packets;periodic flooding-based sources;source tracking mechanism;routing protocols;Robustness;Multicast protocols;Ad hoc networks;Mobile ad hoc networks;Mobile communication;Network topology;Tree data structures;Robust control;Scalability;IEEE news},
doi={10.1109/INFCOM.2007.269},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215852,
author={A. Uchiyama and S. Fujii and K. Maeda and T. Umedu and H. Yamaguchi and T. Higashino},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Ad-hoc Localization in Urban District},
year={2007},
volume={},
number={},
pages={2306-2310},
abstract={In this paper, we present a range-free ad-hoc localization algorithm called UPL (Urban Pedestrians Localization), for positioning mobile nodes in urban district. The design principle of UPL is two-fold. (1) We assume that location seeds are deployed sparsely due to deployment-cost constraints. Thus most mobile nodes cannot expect to meet these location seeds frequently. Therefore, each mobile node in UPL relies on location information received from its neighboring mobile nodes in order to estimate its area of presence. The area of presence of each mobile node becomes inexact as it moves, but it is helpful to reduce the areas of presence of the other mobile nodes. (2) To predict the area of presence of mobile nodes accurately under mobility, we employ information about obstacles such as walls, and present an algorithm to calculate the movable areas of mobile nodes considering obstacles. This also helps to reduce each node's area of presence. The experimental results have shown that by the above two ideas UPL could achieve 8 <i>m</i> positioning error in average with 10 <i>m</i> of radio range.},
keywords={ad hoc networks;mobile radio;range-free ad-hoc localization;urban pedestrians localization;mobile node positioning;Peer to peer computing;Cities and towns;Mobile ad hoc networks;Hardware;Communications Society;Information science;Radio navigation;Global Positioning System;Region 1;Collaboration},
doi={10.1109/INFCOM.2007.270},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215853,
author={M. Pandey and R. Pack and L. Wang and Q. Duan and D. Zappala},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={To Repair or Not To Repair: Helping Ad-hoc Routing Protocols to Distinguish Mobility from Congestion},
year={2007},
volume={},
number={},
pages={2311-2315},
abstract={In this paper we consider the problem of distinguishing whether frame loss at the MAC layer has occurred due to mobility or congestion. Most ad hoc routing protocols make the faulty assumption that all frame loss means the destination node has moved, resulting in significant overhead as they initiate the repair of routes that have not been broken. We design a mobility detection algorithm, MDA, that properly detects the cause of a lost frame, then coordinates with the routing protocol so that it reacts properly. This approach dramatically reduces routing protocol overhead and significantly increases application throughput. We use a simulation study to demonstrate the effectiveness of MDA and to determine the proper setting for MDA parameters.},
keywords={access protocols;ad hoc networks;mobile radio;routing protocols;ad hoc routing protocol;MAC layer;mobility detection algorithm;access protocol;mobile radio;Routing protocols;Transport protocols;Peer to peer computing;Throughput;Media Access Protocol;Algorithm design and analysis;Detection algorithms;Availability;Communications Society;Computer science},
doi={10.1109/INFCOM.2007.271},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215854,
author={U. C. Kozat and S. A. Ramprashad},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Unequal Error Protection Rateless Codes for Scalable Information Delivery in Mobile Networks},
year={2007},
volume={},
number={},
pages={2316-2320},
abstract={In this paper, we are interested in the design and performance of unequal error protection (UEP) rateless codes. These codes have interesting properties in the deployment of mobile peer to peer (MP2P) and mobile broadcast systems. As our main contribution, we propose a new UEP rateless code structure that is composed of a bank of precoders and a common rateless code. Through the bank of precoders, information layers are first expanded into encoded layers with a diminishing coding rate as the priority of the layer increases. The output of precoders are then concatenated and fed into a rateless encoder. The output of the rateless encoder naturally constitutes UEP encoding blocks carrying disproportionately more information on the higher priority layers. The decoder at the receiver end performs the inverse operations to recover each layer separately. We evaluate our proposed scheme comparing against the alternative solutions. Results show that over a broad class of rateless code structures the proposed scheme can substantially reduce the time required to recover higher priority layers while minimally impacting the time required to recover the lower priority layers.},
keywords={broadcasting;encoding;mobile communication;peer-to-peer computing;unequal error protection rateless codes;information delivery;mobile networks;mobile peer to peer system;mobile broadcast system;Error correction codes;Broadcasting;Concatenated codes;Decoding;Streaming media;Communications Society;USA Councils;Character generation;Security;Mobile communication},
doi={10.1109/INFCOM.2007.272},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215855,
author={P. Marbach},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Distributed Scheduling and Active Queue Management in Wireless Networks},
year={2007},
volume={},
number={},
pages={2321-2325},
abstract={We propose a distributed scheduling and active queue management mechanism for wireless ad hoc networks. The approach is based on a random access scheduler where the transmission attempt probabilities depend on the local backlog. The resulting mechanism is simple and can be implemented in a distributed fashion. The performance of the resulting protocol can be modelled as a utility maximization problem to establish that it indeed leads to a high throughput and fair bandwidth allocation.},
keywords={ad hoc networks;bandwidth allocation;queueing theory;scheduling;distributed scheduling;active queue management;wireless ad hoc networks;random access scheduler;utility maximization problem;bandwidth allocation;Wireless networks;Peer to peer computing;Throughput;Processor scheduling;Channel allocation;Computer network management;Access protocols;Interference;Communications Society;Computer science},
doi={10.1109/INFCOM.2007.273},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215856,
author={R. Bhatia and L. Li},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Throughput Optimization of Wireless Mesh Networks with MIMO Links},
year={2007},
volume={},
number={},
pages={2326-2330},
abstract={Multiple input multiple output (MIMO) antennas use sophisticated physical layer techniques to provide significant benefits over conventional antenna technology. Multiple independent data streams can be sent over the MIMO antenna elements. MIMO link can also suppress interference from neighboring links as long as the total useful streams and interfering streams are no greater than the number of receiving antenna elements. For these reasons MIMO antennas are increasingly being considered for use in interference limited wireless mesh networks and have been adopted by WLAN and WIMAX standards. However, the benefits of the MIMO technology in improving network performance are limited unless the higher layer protocols also exploit these capabilities. In this paper we are interested in characterizing the benefits of cross-layer optimizations in interference limited wireless mesh networks with MIMO links. We formulate a framework where data routing at the protocol layer, link scheduling at the MAC layer and stream control at the physical layer can be jointly optimized for throughput maximization in the presence of interference. We then develop an efficient algorithm to solve the resulting throughput optimization problem subject to fairness constraints.},
keywords={interference suppression;MIMO communication;optimisation;receiving antennas;wireless LAN;wireless mesh networks;MIMO links;multiple input multiple output antennas;sophisticated physical layer techniques;interference suppression;WLAN;WIMAX;layer protocols;Throughput;Wireless mesh networks;MIMO;Physical layer;Interference suppression;Receiving antennas;Wireless LAN;WiMAX;Routing protocols;Media Access Protocol},
doi={10.1109/INFCOM.2007.274},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215857,
author={Y. Yang and J. C. Hou and L. -. Kung},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Modeling the Effect of Transmit Power and Physical Carrier Sense in Multi-Hop Wireless Networks},
year={2007},
volume={},
number={},
pages={2331-2335},
abstract={In this paper, we extend both Bianchi's and Kumar's models and characterize the channel activities governed by IEEE 802.11 DCF in multi-hop wireless networks from the perspective of an individual sender. In particular, we incorporate the effect of PHY/MAC attributes (such as transmit power and physical carrier sense) that need not be considered in WLANs but become extraordinarily important in multi-hop wireless networks, and derive the throughput attained by each sender. With the use of the analytical model derived, we investigate the impact of transmit power and carrier sense threshold on network capacity, and identify a simple operating condition under which the network may attain throughput that is close to its optimal value.},
keywords={channel capacity;radio networks;wireless channels;multihop wireless network;transmit power modeling;physical carrier sense modeling;network capacity;Bianchi-Kumar model;channel activity characterization;Spread spectrum communication;Wireless networks;Throughput;Interference;Physical layer;Aggregates;Wireless sensor networks;Laser sintering;Power system modeling;Communications Society},
doi={10.1109/INFCOM.2007.275},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215858,
author={S. Singh and F. Ziliotto and U. Madhow and E. M. Belding and M. J. W. Rodwell},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Millimeter Wave WPAN: Cross-Layer Modeling and Multi-Hop Architecture},
year={2007},
volume={},
number={},
pages={2336-2340},
abstract={The 7 GHz of unlicensed spectrum in the 60 GHz band offers the potential for multiGigabit indoor wireless personal area networking (WPAN). With recent advances in the speed of silicon (CMOS and SiGe) processes, low-cost transceiver realizations in this "millimeter (mm) wave" band are within reach. However, mm wave communication links are more fragile than those at lower frequencies (e.g., 2.4 or 5 GHz) because of larger propagation losses and reduced diffraction around obstacles. On the other hand, directional antennas that provide directivity gains and reduction in delay spread are far easier to implement at mm-scale wavelengths. In this paper, we present a cross-layer modeling methodology and a novel multihop medium access control (MAC) architecture for efficient utilization of 60 GHz spectrum, taking into account the preceding physical characteristics. We propose an in-room WPAN architecture in which every link is constrained to be directional, for improved power efficiency (due to directivity gains) and simplicity of implementation (due to reduced delay spread). We develop an elementary diffraction-based model to determine network link connectivity, and define a multihop MAC protocol that accounts for directional transmission/reception, procedures for topology discovery and recovery from link blockages.},
keywords={access protocols;directive antennas;indoor radio;millimetre wave antennas;millimetre wave propagation;personal area networks;radio links;telecommunication network topology;transceivers;millimeter wave WPAN;cross-layer modeling;multihop MAC architecture;multigigabit indoor wireless personal area networking;low-cost transceiver realizations;mm wave communication links;multihop medium access control;in-room WPAN architecture;elementary diffraction-based model;network link connectivity;directional transmission-reception;topology discovery;topology recovery;link blockages;frequency 60 GHz;Diffraction;Media Access Protocol;Millimeter wave communication;Millimeter wave technology;Semiconductor device modeling;CMOS process;Silicon germanium;Germanium silicon alloys;Transceivers;Frequency},
doi={10.1109/INFCOM.2007.276},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215859,
author={X. Zhang and H. Zhu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Two-Tier Load Balancing in OSPF Wireless Back-Hauls},
year={2007},
volume={},
number={},
pages={2341-2345},
abstract={High-speed wireless communication technology (e.g. WiMAX) makes it feasible and cost-effective to build wireless back-hauls for Internet access. Compared to wired counterparts, it is challenging to optimize the performance of wireless backhaul due to the dynamic nature of wireless channels. In this paper, we propose a two-tier optimization scheme for load balancing objective. We use linear programming techniques to find the optimal routing policy for load balancing of each source-destination traffic by setting an appropriate weight to each link. Since current OSPF routers only support discrete traffic splitting, we propose a greedy min-max congestion algorithm to find a shortest-path set in order to approximate the optimal routing policy within a certain bound. Due to the impact of dynamic channel conditions, we propose the second tier adaptation scheme which runs frequently enough to refine the routing policy to balance the overall traffic according to the channel condition. We conduct thorough theoretical analysis to show the correctness of our design and give the properties of our scheme. Our solution is also evaluated via simulations and the simulation results show that our work can effectively lower maximum congestion level of the network to a near-optimal value.},
keywords={Internet;linear programming;minimax techniques;telecommunication network routing;telecommunication traffic;wireless channels;two-tier load balancing;OSPF wireless back-hauls;high-speed wireless communication technology;Internet;wireless channels;linear programming techniques;optimal routing policy;source-destination traffic;greedy min-max congestion algorithm;discrete traffic splitting;dynamic channel conditions;Load management;Routing;WiMAX;Telecommunication traffic;Costs;Internet;Traffic control;Communications Society;Wireless communication;Communications technology},
doi={10.1109/INFCOM.2007.277},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215860,
author={A. Abdrabou and W. Zhuang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Service Time Approximation in IEEE 802.11 Single-Hop Ad-hoc Networks},
year={2007},
volume={},
number={},
pages={2346-2350},
abstract={This paper investigates the near-memoryless behavior of the service time for IEEE 802.11 saturated single-hop ad hoc networks. We show that the number of packets successfully transmitted by any node over a time interval follows a general distribution, which is close to a Poisson distribution with an upper bounded distribution distance. We also show that the service time distribution can be approximated by a geometric distribution. We illustrate that the usage of discrete-time queuing analysis (M/Geo/1) near network saturation greatly simplifies the queuing analysis and leads to sufficiently accurate results for both the first order statistics and the probability distribution of the number of packets in the queuing system.},
keywords={ad hoc networks;discrete time systems;IEEE standards;Poisson distribution;probability;wireless LAN;service time approximation;IEEE 802.11;single-hop ad hoc networks;Poisson distribution;geometric distribution;discrete-time queuing analysis;probability distribution;Ad hoc networks;Queueing analysis;Resource management;Statistical analysis;Communications Society;Peer to peer computing;Statistical distributions;Probability distribution;Call admission control;Performance analysis},
doi={10.1109/INFCOM.2007.278},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215861,
author={Y. Zhu and Q. Zhang and Z. Niu and J. Zhu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Optimal Physical Carrier Sensing: Theoretical Analysis and Protocol Design},
year={2007},
volume={},
number={},
pages={2351-2355},
abstract={Traditional Physical Carrier Sensing (PCS), which aims at eliminating hidden terminals in wireless networks, causes too many exposed terminals and deteriorates the throughput per user seriously. Some existing work has proven that an aggressive PCS can improve the throughput by balancing the tradeoff between hidden terminals and exposed terminals. However, little work has been conducted to optimize the PCS according to the network conditions. In this paper, we develop an analytical model to study the behaviors of a user in the aggressive PCS scenario, with which the optimal PCS threshold can be derived. Then, to avoid the complicated computation, we present a heuristic algorithm, in which the parameters required for PCS tuning are estimated by the carrier sensing mechanism employed in IEEE 802.11. Simulation results show that the proposed heuristic algorithm can make the PCS threshold approach to the theoretical optimal one. Moreover, the proposed heuristic algorithm can obtain significant throughput gain compared to the traditional PCS threshold setting solutions.},
keywords={protocols;radio networks;wireless LAN;optimal physical carrier sensing;wireless networks;heuristic algorithm;carrier sensing mechanism;IEEE 802.11;threshold approach;Protocols;Personal communication networks;Throughput;Heuristic algorithms;Multiaccess communication;Wireless networks;Analytical models;Design engineering;Computational modeling;Equations},
doi={10.1109/INFCOM.2007.279},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215862,
author={M. Durvy and O. Dousse and P. Thiran},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Modeling the 802.11 Protocol Under Different Capture and Sensing Capabilities},
year={2007},
volume={},
number={},
pages={2356-2360},
abstract={Decentralized medium access control schemes for wireless networks based on CSMA/CA, such as the 802.11 protocol, are known to be unfair. In multi-hop networks, they can even favor some connections to such an extent that the others suffer from virtually complete starvation. This observation has been reported in quite a few works, but the factors causing it are still not well understood. We find that the capture effect and the relative values of the receiving and carrier sensing ranges play a crucial role in the unfairness of these protocols. We show that an idealized 802.11 protocol does suffer from starvation when the receiving and sensing ranges are equal, but quite surprisingly this unfairness is reduced or even disappears when these two ranges are sufficiently different. Using a Markovian model, we explain why apparently benign variations in these ranges have such a dramatic impact on the 802.11 protocol performance.},
keywords={carrier sense multiple access;Markov processes;wireless LAN;802.11 protocol modeling;decentralized medium access control;wireless networks;CSMA/CA;multihop networks;Markovian model;Access protocols;Media Access Protocol;Spread spectrum communication;Wireless application protocol;Network topology;Communications Society;Laboratories;Wireless networks;Multiaccess communication;Peer to peer computing},
doi={10.1109/INFCOM.2007.280},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215863,
author={A. Raniwala and P. De and S. Sharma and R. Krishnan and T. -. Chiueh},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={End-to-End Flow Fairness Over IEEE 802.11-Based Wireless Mesh Networks},
year={2007},
volume={},
number={},
pages={2361-2365},
abstract={Economies of scale make IEEE 802.11 an attractive technology for building wireless mesh networks (WMNs). However, the IEEE 802.11 protocol exhibits serious link-layer unfairness when used in multi-hop networks. Existing fairness solutions either do not address this problem, or require proprietary MAC protocol to provide fairness. In this paper, we argue that an ideal transport protocol should be able to achieve fairness even on top of an unfair MAC layer such as 802.11. Towards this end, we propose a co-ordinated <i>congestion</i> <i>control</i> algorithm that performs global bandwidth allocation and provides end-to-end flow-level max-min fairness despite weaknesses in the MAC layer. The proposed algorithm features an advanced topology discovery mechanism that detects the inhibition of wireless communication links, and a general collision domain capacity re-estimation mechanism that effectively addresses such inhibition. Through an ns-2-based simulation study we demonstrate that the proposed algorithm substantially improves the fairness across flows, eliminates starvation problem, and simultaneously maintains a high overall network throughput.},
keywords={access protocols;radio networks;telecommunication congestion control;transport protocols;wireless LAN;end-to-end flow fairness;IEEE 802.11-based wireless mesh networks;link-layer unfairness;multihop networks;MAC protocol;transport protocol;coordinated congestion control algorithm;bandwidth allocation;wireless communication links;ns-2-based simulation;starvation problem;Wireless mesh networks;Media Access Protocol;Economies of scale;Spread spectrum communication;Transport protocols;Communication system control;Channel allocation;Network topology;Wireless communication;Throughput},
doi={10.1109/INFCOM.2007.281},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215864,
author={F. Guo and T. -. Chiueh},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Software TDMA for VoIP Applications Over IEEE802.11 Wireless LAN},
year={2007},
volume={},
number={},
pages={2366-2370},
abstract={An emerging killer application for enterprise wireless LANs (WLANs) is voice over IP (VoIP) telephony, which promises to greatly improve the reachability and mobility of enterprise telephony service at low cost. Most commercial IEEE802.11 WLAN-based VoIP products cannot support more than ten voice conversations over a single IEEE 802.11b channel, even though its peak transmission rate is more than two orders of magnitude higher than an individual VoIP connection's bandwidth requirement. There are two main reasons why these VoIP systems' effective capacity is lower than expected: stringent latency requirement and substantial per-WLAN-packet overhead. Time-Division Multiple Access (TDMA) is a well-known technique that provides per-connection QoS guarantee as well as maximizes the radio channel utilization efficiency. This paper presents a software-based TDMA (STDMA) protocol that is designed to support VoIP applications and successfully works on commodity IEEE802.11 WLAN interfaces. The resulting STDMA prototype can support more than 50 two-way G.729 voice conversations over a single IEEE 802.11b channel.},
keywords={business communication;channel allocation;Internet telephony;intranets;network interfaces;quality of service;time division multiple access;wireless channels;wireless LAN;software TDMA protocol application;enterprise wireless LAN;voice over IP telephony;enterprise telephony service;packet overhead;time-division multiple access;QoS guarantee;radio channel utilization;IEEE 802.11 WLAN interface;Time division multiple access;Application software;Wireless LAN;Internet telephony;Costs;Bandwidth;Delay;Access protocols;Software prototyping;Prototypes},
doi={10.1109/INFCOM.2007.282},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215865,
author={J. Jeong and T. Hwang and T. He and D. Du},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={MCTA: Target Tracking Algorithm Based on Minimal Contour in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={2371-2375},
abstract={This paper proposes a minimal contour tracking algorithm (MCTA) that reduces energy consumption for tracking mobile targets in wireless sensor networks in terms of sensing and communication energy consumption. MCTA conserves energy by letting only a minimum number of sensor nodes participate in communication and perform sensing for target tracking. MCTA uses the minimal tracking area based on the vehicular kinematics. The modeling of target's kinematics allows for pruning out part of the tracking area that cannot be mechanically visited by the mobile target within scheduled time. So, MCTA sends the tracking area information to only the sensor nodes within minimal tracking area and wakes them up. Compared to the legacy scheme which uses circle-based tracking area, our proposed scheme uses less number of sensors for tracking in both communication and sensing without target missing. Through simulation, we show that MCTA outperforms the circle-based scheme with about 60% energy saving under certain ideal situations.},
keywords={target tracking;wireless sensor networks;target tracking algorithm;wireless sensor networks;minimal contour tracking algorithm;mobile targets;vehicular kinematics;circle-based tracking;Target tracking;Wireless sensor networks;Kinematics;Mobile communication;Energy consumption;Vehicles;Peer to peer computing;Energy efficiency;Measurement errors;Radio frequency},
doi={10.1109/INFCOM.2007.283},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215866,
author={M. Hefeeda and M. Bagheri},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Randomized k-Coverage Algorithms For Dense Sensor Networks},
year={2007},
volume={},
number={},
pages={2376-2380},
abstract={We propose new algorithms to achieve <i>k</i>-coverage in dense sensor networks. In such networks, covering sensor locations approximates covering the whole area. However, it has been shown before that selecting the minimum set of sensors to activate from an already deployed set of sensors is NP-hard. We propose an efficient approximation algorithm which achieves a solution of size within a logarithmic factor of the optimal. We prove that our algorithm is correct and analyze its complexity. We implement our algorithm and compare it against two others in the literature. Our results show that the logarithmic factor is only a worst-case upper bound and the solution size is close to the optimal in most cases. A key feature of our algorithm is that it can be implemented in a distributed manner with local information and low message complexity. We design and implement a fully distributed version of our algorithm. Our distributed algorithm does not require that sensors know their locations. Comparison with two other distributed algorithms in the literature indicates that our algorithm: (i) converges much faster than the others, (ii) activates near-optimal number of sensors, and (iii) significantly prolongs (almost doubles) the network lifetime because it consumes much less energy than the other algorithms.},
keywords={approximation theory;computational complexity;distributed algorithms;optimisation;randomised algorithms;wireless sensor networks;randomized k-coverage algorithms;dense sensor networks;NP-hard sensors;approximation algorithm;logarithmic factor;message complexity;distributed algorithm;Approximation algorithms;Algorithm design and analysis;Distributed algorithms;Monitoring;Computer networks;Upper bound;Vehicle detection;Communications Society;Mass production;Costs},
doi={10.1109/INFCOM.2007.284},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215867,
author={Y. Wu and S. M. Das and R. Chandra},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Routing with a Markovian Metric to Promote Local Mixing},
year={2007},
volume={},
number={},
pages={2381-2385},
abstract={Routing protocols have traditionally been based on finding shortest paths under certain cost metrics. A conventional routing metric models the cost of a path as the sum of the costs on the constituting links. This paper introduces the concept of a Markovian metric, which models the cost of a path as the cost of the first hop plus the cost of the second hop conditioned on the first hop, and so on. The notion of the Markovian metric is fairly general. It is potentially applicable to scenarios where the cost of sending a packet (or a stream of packets) over a link may depend on the previous hop of the packet (or the stream). Such scenario arises, for instance, in a wireless mesh network equipped with local mixing, a recent link layer advance. This scenario is examined as a case study for the Markovian metric. The local mixing engine sits between the routing and MAC layers. It maintains information about the packets each neighbor has, and identifies opportunities to mix the outgoing packets via network coding to reduce the transmissions in the air. We use a Markovian metric to model the reduction of channel resource consumption due to local mixing. This leads to routing decisions that can better take advantage of local mixing. We have implemented a system that incorporates local mixing and source routing using a Markovian metric in Qualnet. The experimental results demonstrate significant throughput gain and resource saving.},
keywords={access protocols;encoding;graph theory;Markov processes;routing protocols;telecommunication network topology;routing protocol;Markovian metric;shortest path;wireless mesh network;MAC layer;channel resource consumption;Costs;Engines;Network coding;Wireless mesh networks;Routing protocols;Broadcasting;Spread spectrum communication;Communications Society;Throughput;Relays},
doi={10.1109/INFCOM.2007.285},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215868,
author={D. Pendarakis and N. Shrivastava and Z. Liu and R. Ambrosio},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Information Aggregation and Optimized Actuation in Sensor Networks: Enabling Smart Electrical Grids},
year={2007},
volume={},
number={},
pages={2386-2390},
abstract={A large number of potential applications of sensor and actuator networks (SANETs) have emerged recently, for example in the areas of energy production and distribution and health care and telemedicine. SANETs integrate the tasks of sensing and actuation, the process of controlling the operation of a physical system by setting values for parameters of interest. Of particular importance in SANETs is the ability to set actuator parameters, typically depending on values observed by the sensors, so as to achieve a system-wide objective. However, SANETs with large number of nodes or covering wide geographical areas present scalability challenges that necessitate the use of summarization techniques resulting in sub-optimal actuation values. There is therefore a clear trade-off between the level of summarization and the quality of the computed actuation parameters. This paper focuses on two interdependent problems. The first is the issue of efficient aggregation and summarization of the measurements. The second is the distributed computation of optimal actuation parameters to achieve a system-wide objective. We first consider the problem under the assumption of semi-static sensed values and then extend our model to cover the general case where sensor state changes, triggering update events. We develop algorithms for efficient summarization of these events and demonstrate that they minimally impact optimal actuation. Our work is motivated by the domain of energy distribution networks and, in particular, intelligent electrical grids.},
keywords={actuators;intelligent networks;wireless sensor networks;sensor networks;smart electrical grids;actuator networks;SANET;scalability;energy distribution networks;Intelligent sensors;Actuators;Production;Medical services;Telemedicine;Process control;Control systems;Sensor systems;Scalability;Distributed computing},
doi={10.1109/INFCOM.2007.286},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215869,
author={J. Hwang and T. He and Y. Kim},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Detecting Phantom Nodes in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={2391-2395},
abstract={In an adversarial environment, various kinds of security attacks become possible if malicious nodes could claim fake locations that are different from where they are physically located. In this paper, we propose a secure localization mechanism that detects the existence of these nodes, termed as phantom nodes, without relying on any trusted entities, an approach significantly different from the existing ones. The proposed mechanism enjoys a set of nice features. First, it does not have any central point of attack. All nodes play the role of verifier, by generating local map, i.e. a view constructed based on ranging information from its neighbors. Second, this distributed and localized construction results in quite strong results: even when the number of phantom nodes is greater than that of honest nodes, we can Alter out most phantom nodes. Our analysis and simulations under realistic noisy settings demonstrate our scheme is effective in the presence of a large number of phantom nodes.},
keywords={phantoms;telecommunication security;wireless sensor networks;phantom node detection;wireless sensor network;malicious node;secure localization mechanism;realistic noisy setting;Imaging phantoms;Wireless sensor networks;Peer to peer computing;Filters;Surveillance;Routing;Communications Society;Helium;Computer science;Computer security},
doi={10.1109/INFCOM.2007.287},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215870,
author={Z. Yang and E. Ekici and D. Xuan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Localization-Based Anti-Sensor Network System},
year={2007},
volume={},
number={},
pages={2396-2400},
abstract={In this paper, an anti-sensor network system is proposed, aiming to protect an important area from being under surveillance by an adversary's sensor nodes. The major components of the system are a set of observing points (monitors) deployed in the area of importance. The observers try to localize sensor positions using antenna arrays to measure direction of arrival (DoA) and received signal strength of the signals emitted by sensors. Once sensors are localized, additional measures are taken to physically remove or disable localized sensors. The proposed anti-sensor network system is designed to handle additional counter-measures that can be employed by sensors, including message encryption and non-uniform transmission power levels. The simulation results show the effectiveness of the proposed system and effects of counter-measures on sensor localization performance.},
keywords={antenna arrays;surveillance;wireless sensor networks;localization-based wireless antisensor network system;antenna array;message encryption;Sensor arrays;Sensor systems;Antenna measurements;Protection;Surveillance;Directive antennas;Receiving antennas;Antenna arrays;Position measurement;Cryptography},
doi={10.1109/INFCOM.2007.288},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215871,
author={Y. Zhu and Y. Liu and L. M. Ni and Z. Zhang},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Low-Power Distributed Event Detection in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={2401-2405},
abstract={In this paper we address the problem of energy-efficient event detection in wireless sensor networks (WSNs). Duty cycling is a fundamental approach to conserving energy in WSNs. However, it brings challenges to event detection in the sense that an event may be undetected or undergo a certain delay before it is detected, in particular when sensors are low duty-cycled. We investigate the fundamental relationship between event detection and energy efficiency. Based on a simplified network model, we quantify event detection performance by deriving the closed forms of detection delay and detectability. We also characterize the intrinsic tradeoff that exists between detection performance and system lifetime, which helps flexible design decisions for WSNs. In addition, we propose a completely localized algorithm, CAS, to cooperatively determine sensor wakeups. Without relying on location information, CAS is easy to implement and scalable to network density. Theoretical bounds of event detection are also studied to facilitate the comparative study. Comprehensive experiments are conducted and results demonstrate that CAS significantly improves detection performance.},
keywords={delays;wireless sensor networks;low-power distributed event detection;wireless sensor network;duty cycling;intrinsic tradeoff;completely localized algorithm;delay detection;Event detection;Wireless sensor networks;Delay;Sensor phenomena and characterization;Energy efficiency;Content addressable storage;Distributed algorithms;Monitoring;Fires;Pollution},
doi={10.1109/INFCOM.2007.289},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215872,
author={A. Nordio and C. -. Chiasserini and E. Viterbo},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Quality of Field Reconstruction in Sensor Networks},
year={2007},
volume={},
number={},
pages={2406-2410},
abstract={We consider the problem of obtaining a high quality estimates of band-limited sensor fields when sensor measurements are noisy and the nodes are irregularly deployed and subject to random motion. We consider the mean square error (MSE) of the estimate and we analytically derive the performance of several reconstruction/estimation techniques based on linear filtering. For each technique, we obtain the mean value of the MSE, as well as its asymptotic expression in the case where the field bandwidth and the number of sensors grow to infinity, while their ratio is kept constant. Our results provide useful guidelines for the design of sensor networks when many system parameters have to be traded off.},
keywords={filtering theory;mean square error methods;signal reconstruction;wireless sensor networks;field reconstruction;sensor networks;band-limited sensor fields;sensor measurements;mean square error;linear filtering;asymptotic expression;field bandwidth;Sensor phenomena and characterization;Sensor systems;Bandwidth;Sampling methods;Peer to peer computing;Mean square error methods;Performance analysis;H infinity control;Wireless sensor networks;Monitoring},
doi={10.1109/INFCOM.2007.290},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215873,
author={Y. Ling and C. -. Chen},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Energy Saving via Power-Aware Buffering in Wireless Sensor Networks},
year={2007},
volume={},
number={},
pages={2411-2415},
abstract={This paper presents a study on the impact of buffering schemes on wireless sensor power consumption. Two common buffering paradigms are studied: fixed-size buffering and fixed-interval buffering. We present theoretical analyses of the power consumption of the buffering schemes, in relation to parameters of the sensor node's wireless radio and memory modules, as well as the sensor data arrival rate. Our results indicate that, under the same circumstances, the optimal fixed-size buffering scheme outperforms the optimal fixed-interval scheme in terms of overall power conservation. We also show that a power-aware buffering scheme can save significant energy consumption over a power-oblivious buffering scheme, thus prolonging the useful lifespan of the sensor nodes.},
keywords={buffer circuits;power aware computing;wireless sensor networks;energy saving;power aware buffering;wireless sensor networks;fixed size buffering;fixed interval buffering;power consumption;Wireless sensor networks;Energy consumption;Sensor arrays;Peer to peer computing;Microcontrollers;Master-slave;Energy conservation;Energy management;Power system management;Biomedical monitoring},
doi={10.1109/INFCOM.2007.291},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215874,
author={A. Gallais and F. Ingelrest and J. Carle and D. Simplot-Ryl},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Preserving Area Coverage in Sensor Networks with a Realistic Physical Layer},
year={2007},
volume={},
number={},
pages={2416-2420},
abstract={We consider the problem of activity scheduling and area coverage in sensor networks, and especially focus on problems that arise when using a more realistic physical layer. Indeed, most of the previous work in this area has been studied within an ideal environment, where messages are always correctly received. In this paper, we argue that protocols developed with such an assumption can hardly provide satisfying results in a more realistic world. To show this, we replace the classic unit disk graph model by the lognormal shadowing one. The results show that either the resulting area coverage is not sufficient or the percentage of active nodes is very high. We thus present an original method, where a node decides to turn off when there exists in its vicinity a sufficiently reliable covering set of neighbors. We show that our solution is very efficient as it preserves area coverage while minimizing the quantity of active nodes.},
keywords={log normal distribution;protocols;wireless sensor networks;area coverage;sensor networks;realistic physical layer;activity scheduling;protocols;unit disk graph model;lognormal shadowing;Physical layer;Wireless sensor networks;Monitoring;Processor scheduling;Military computing;Communications Society;Peer to peer computing;Performance analysis;Probes;Sensor phenomena and characterization},
doi={10.1109/INFCOM.2007.292},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215875,
author={J. Hwang and Y. Gu and T. He and Y. Kim},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Realistic Sensing Area Modeling},
year={2007},
volume={},
number={},
pages={2421-2425},
abstract={Despite the well-known fact that sensing patterns in reality are highly irregular, researchers continue to develop protocols with simplifying assumptions about the sensing. For example, a circular 0/1 sensing model is widely used in most existing simulators and analysis. While this model provides high-level guidelines, it could cause wrong estimation of system performance in the real world. In this project, we design and implement a practical Sensing Area Modeling technique, called SAM. By injecting events through regular and hierarchical training, SAM estimates the sensing areas of individual sensor nodes accurately. Especially, this work is the first to investigate the impact of irregular sensing area on application performance, such as coverage scheduling. We evaluate SAM using outdoor experiments with XSM motes, indoor experiment with 40 MicaZ motes as well as an extensive 1000-node simulation. Our evaluation results reveal serious problems caused by circular sensing model, while demonstrating significant performance improvements in major applications when SAM is used.},
keywords={protocols;wireless sensor networks;realistic sensing area modeling;protocol;circular sensing model;wireless sensor network;Analytical models;Protocols;Sensor systems;Sensor phenomena and characterization;Helium;Peer to peer computing;Bridges;Event detection;Communications Society;Computer science},
doi={10.1109/INFCOM.2007.293},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215876,
author={Z. Li and D. Zheng and Y. Ma},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Tree, Segment Table, and Route Bucket: A Multi-Stage Algorithm for IPv6 Routing Table Lookup},
year={2007},
volume={},
number={},
pages={2426-2430},
abstract={Next generation internet protocol, IPv6, has attracted growing attention and has been deploying worldwide. With 128-bit address, IPv6 provides an extremely large address space and poses a great challenge to the routing table lookup algorithms. Today's efficient IPv4 routing table lookup schemes can hardly be competent for IPv6. In this paper, we propose a multi-stage IPv6 routing table lookup algorithm based on a sufficient study on the characteristics of the IPv6 address structure, the IPv6 address allocation policies, and the real world IPv6 backbone BGP routing tables. The proposed algorithm combines the binary tree, the segment table, and the route bucket other than adopting single technique as previous schemes do. Compared with previous algorithms, the proposed algorithm performs faster, occupies less memory, scales better, and supports incremental update.},
keywords={Internet;routing protocols;table lookup;transport protocols;trees (mathematics);next generation Internet protocol;multistage IPv6 routing table lookup algorithm;IPv6 address allocation policy;binary tree;Routing;Table lookup;IP networks;Spine;Space technology;Binary trees;Internet;Scalability;Communications Society;Computer science},
doi={10.1109/INFCOM.2007.294},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215877,
author={C. Maindorfer and K. A. Mohamed and T. Ottmann and A. Datta},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A New Output-Sensitive Algorithm to Detect and Resolve Conflicts in Internet Router Tables},
year={2007},
volume={},
number={},
pages={2431-2435},
abstract={Packet Alters are rules for classifying packets based on their header fields. In order to avoid ambiguities in packet classification, the set of filters in a router table must be conflict-free, i.e. for any incoming packet p, there must be a unique best matching filter which applies to p. We present the first output-sensitive solution for the offline version of the conflict detection and resolving problem for 1-dimensional arbitrary range filters under the most-specific tie breaking rule. The algorithm achieves a worst case time complexity of O(n log n) and uses space O(n). Instead of reporting and resolving all pairs of conflicting filters, we straight away report those resolve filters that are necessary to make the set conflict-free.},
keywords={computational complexity;filtering theory;Internet;telecommunication network routing;Internet router tables;output-sensitive algorithm;conflict resolution-detection;packet alters rule;packet classification;1D arbitrary range filter;worst case time complexity;Internet;Matched filters;Information filtering;Information filters;Routing;Communications Society;Software algorithms;Computer science;Software engineering;Databases},
doi={10.1109/INFCOM.2007.295},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215878,
author={V. Tabatabaee and A. Kashyap and B. Bhattacharjee and R. J. La and M. A. Shayman},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Robust Routing with Unknown Traffic Matrices},
year={2007},
volume={},
number={},
pages={2436-2440},
abstract={In this paper, we present an algorithm for intra-domain traffic engineering. We assume that the traffic matrix, which specifies traffic load between every source-destination pair in the network, is unknown and varies with time, but that always lies inside an explicitly defined region. Our goal is to compute a fixed robust routing with best worst case performance for all traffic matrices inside the bounding region. We formulate this problem as a semi-infinite programming problem. Then, we focus on a special case with practical merits, where (1) the traffic matrix region is assumed to be a polytope specified by a finite set of linear inequalities, and (2) our objective is to find the routing that minimizes the maximum link utilization. Under these assumptions, the problem can be formulated as a polynomial size linear programming (LP) problem with finite number of constraints. We further consider two specific set of constraints for the traffic matrix region. The first set is based on the hose model and limits the total traffic rate of network point of presence (PoP) nodes. The second set is based on the pipe model and limits the traffic between source-destination pairs. We study the effectiveness of each set of constraints using extensive simulations.},
keywords={linear programming;telecommunication network routing;telecommunication traffic;unknown traffic matrices;intradomain traffic engineering;semiinfinite programming problem;linear inequalities;maximum link utilization;polynomial size linear programming;traffic matrix region;network point of presence nodes;Robustness;Routing;Telecommunication traffic;Traffic control;Hoses;Linear matrix inequalities;Cost function;Aggregates;Communications Society;Educational institutions},
doi={10.1109/INFCOM.2007.296},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215879,
author={S. Kim and K. Harfoush},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={The Causal Factors Behind Internet Power-Law Connectivity},
year={2007},
volume={},
number={},
pages={2441-2445},
abstract={In this paper, we investigate the impact of layer-2 devices on our perception of the Internet IP topology and on the performance and security of the Internet. We make the case that a power law connectivity observed in the Internet IP topology is not an illusion as suggested by some researchers. It is mainly manifested due to the blindness of traceroute to layer-2 devices, and this manifestation will persist independent of the nature of the underlying physical topology. Furthermore, we make the case that the Internet physical topology is not likely to have a power law connectivity. Our conclusions challenge common wisdom about the Internet topology and highlight the need for more thorough investigations.},
keywords={Internet;network topology;telecommunication security;Internet power-law connectivity;Internet IP topology;router-level topology;Internet;Network topology;Blindness;Switches;Power measurement;Complex networks;Erbium;Communications Society;Computer science;Electronic mail},
doi={10.1109/INFCOM.2007.297},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215880,
author={J. Sommers and P. Barford and N. Duffield and A. Ron},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Framework for Multi-Objective SLA Compliance Monitoring},
year={2007},
volume={},
number={},
pages={2446-2450},
abstract={Service level agreements (SLAs) specify performance guarantees made by service providers, typically in terms of packet loss, delay, delay variation, and network availability. While many tools have been developed to measure individual aspects of network performance, there has been little work to directly address the issue of SLA compliance monitoring in an operational setting where accuracy, parsimony, and other related issues are of vital importance. This paper takes the following steps toward addressing this problem: (1) we introduce an architectural framework for integrating multiple discrete-time active measurement algorithms, an architecture that we call multi-objective monitoring; and (2) we introduce a new active measurement methodology to monitor the packet loss rate along a network path for determining compliance with specified performance targets which significantly improves accuracy over existing techniques. We present a prototype implementation of our monitoring framework, and demonstrate how a unified probe stream can consume lower overall bandwidth than if individual streams are used to measure different path properties. We demonstrate the accuracy and convergence properties of our new loss rate monitoring methodology in a controlled laboratory environment using a range of background traffic scenarios and examine its accuracy improvements over existing techniques.},
keywords={computer network management;IP networks;monitoring;telecommunication traffic;multiobjective SLA compliance monitoring;service level agreements;service providers;packet loss;delay variation;network availability;discrete-time active measurement algorithms;convergence properties;loss rate monitoring methodology;background traffic scenarios;IP networks;Monitoring;Probes;Performance loss;Loss measurement;Availability;Bandwidth;Convergence;Communications Society;Prototypes;Mechanical factors},
doi={10.1109/INFCOM.2007.298},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215881,
author={M. Gupta and S. Singh},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Using Low-Power Modes for Energy Conservation in Ethernet LANs},
year={2007},
volume={},
number={},
pages={2451-2455},
abstract={Most Ethernet interfaces available for deployment in switches and hosts today can operate in a variety of different low power modes. However, currently these modes have very limited usage models. They do not take advantage of periods of inactivity, when the links remain idle or under-utilized. In this study, we propose methods that allow for detection of such periods to obtain energy savings with little impact on loss or delay. We evaluate our methods on a wide range of real-time traffic traces collected at a high-speed backbone switch within our campus LAN. Our results show that Ethernet interfaces at both ends can be put in extremely low power modes anywhere from 40%-98% of the time observed. In addition, we found that approximately 37% of interfaces studied (on the same switch) can be put in low power modes simultaneously which opens the potential for further energy savings in the switching fabric within the switch.},
keywords={local area networks;real-time systems;telecommunication traffic;low-power modes;energy conservation;Ethernet LAN;realtime traffic traces;Energy conservation;Ethernet networks;Switches;Costs;Transceivers;Computer science;Delay;Local area networks;Energy consumption;Communications Society},
doi={10.1109/INFCOM.2007.299},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215882,
author={J. Jiang and R. Jain},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Analysis of Backward Congestion Notification (BCN) for Ethernet In Datacenter Applications},
year={2007},
volume={},
number={},
pages={2456-2460},
abstract={IEEE 802.1 standards committee is working on a new specification for congestion notification in Ethernet networks. The goal of this work is to enable application of Ethernet in backend datacenter applications. Such applications typically use fiber channel and infiniband due to their loss-free characteristics. A backward congestion notification (BCN) scheme is one of the candidate schemes proposed to avoid long delays and minimize loss in Ethernet networks. This paper presents an analysis of this scheme. We develop an analytical model to analyze the stability and the rate of convergence of the scheme. It is shown that BCN achieves proportional fairness and not max-min fairness under certain circumstances. Simulation results are presented that validate the analytical results.},
keywords={local area networks;telecommunication channels;telecommunication congestion control;telecommunication services;backward congestion notification;Ethernet;IEEE 802.1 standard;backend datacenter application;fiber channel;infiniband;loss-free characteristics;Ethernet networks;Switches;Delay;Traffic control;Analytical models;Throughput;Packet switching;Regulators;Communication system traffic control;TCPIP},
doi={10.1109/INFCOM.2007.300},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215883,
author={K. B. Kim},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Analysis of Impact on Random Packet Losses in Congestion Control: Explicit Form},
year={2007},
volume={},
number={},
pages={2461-2465},
abstract={This paper studies a set of transport equations arising from stochastic models in congestion control. First, we introduce a general framework including both of mixed and extended Markovian loss models. Then we show that there is a unique density solving the general differential equation. For the first time, we provide an explicit form expression for this density and for its mean value. We propose a novel approach to solve a class of associated differential equations.},
keywords={differential equations;Markov processes;radio networks;telecommunication congestion control;random packet losses;congestion control;transport equations;stochastic models;extended Markovian loss models;general differential equation;associated differential equations;Propagation losses;Throughput;DSL;Differential equations;Telecommunication congestion control;Telecommunication control;TCPIP;Bandwidth;Gaussian noise;Predictive models},
doi={10.1109/INFCOM.2007.301},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215884,
author={M. Podlesny and S. Gorinsky},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Multimodal Congestion Control for Low Stable-State Queuing},
year={2007},
volume={},
number={},
pages={2466-2470},
abstract={To discover an efficient fair sending rate for a flow, Transmission Control Protocol (TCP) saturates the bottleneck link and its buffer until the router discards a packet. Such TCP-caused queuing is detrimental for interactive and other delay-sensitive applications. In this paper, we present Multimodal Control Protocol (MCP) which strives to maintain low queues and avoid congestion losses at network links. The multimodal MCP engages routers and hosts in limited explicit communication. A distinguishing property of MCP is stable transmission after converging to efficient fair states. To ensure convergence to fairness, MCP incorporates an innovative mechanism that enables a flow to urge all flows sharing its bottleneck links to operate in a fairing mode, dedicated to fairness improvement. To make the stable fair rates independent of round-trip times and packet sizes, MCP employs rate-based control and uniform timing of adjustments.},
keywords={queueing theory;telecommunication congestion control;telecommunication links;telecommunication network routing;transport protocols;multimodal congestion control;low stable-state queuing;transmission control protocol;TCP;delay-sensitive application;multimodal control protocol;network routing;network link;Protocols;Delay;Size control;Communication system control;Convergence;Timing;Buffer overflow;Feedback;Communications Society;Laboratories},
doi={10.1109/INFCOM.2007.302},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215885,
author={H. Wang and B. Lin},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Pipelined van Emde Boas Tree: Algorithms, Analysis, and Applications},
year={2007},
volume={},
number={},
pages={2471-2475},
abstract={Priority queues are essential for various network processing applications, including per-flow queueing with quality-of-service (QoS) guarantees, management of large fast packet buffers, and management of statistics counters. In this paper, we propose a new data structure for implementing high-performance priority queues based on a pipelined version of the van Emde Boas tree. We show that we can achieve O(1) amortized time operations using our architecture, but we can achieve this algorithmic efficiency using only O (log log u) number of pipelined stages, where u is the size of the universe used to represent the priority keys.},
keywords={data structures;quality of service;queueing theory;trees (mathematics);pipelined van emde boas tree:;priority queues;quality-of-service;network processing applications;packet buffers;data structure;Algorithm design and analysis;Data structures;Tree data structures;Hardware;Quality management;Statistics;Counting circuits;Communications Society;Quality of service;Delay},
doi={10.1109/INFCOM.2007.303},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215886,
author={J. Liu and S. Mann and N. Van Vorst and K. Hellman},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={An Open and Scalable Emulation Infrastructure for Large-Scale Real-Time Network Simulations},
year={2007},
volume={},
number={},
pages={2476-2480},
abstract={We present a software infrastructure that embeds physical hosts in a simulated network. Aiming to create a large-scale real-time virtual network testbed, our real-time interactive simulation approach combines the advantages of both simulation and emulation, by maintaining flexibility of the simulation models and increasing fidelity as real systems are included in the simulation. In our approach, real-world distributed applications and network services can run together with the real-time simulator; real packets are injected into the simulation and subject to the simulated network conditions computed as a result of both real and virtual traffic competing for network resources. A prototype of the proposed emulation infrastructure has been implemented based on virtual private network (VPN). One distinct advantage of our approach is that it does not require special hardware. Furthermore, it is flexible, secure, and scalable-attributes inherited directly from the VPN implementation. We conducted a set of preliminary experiments to assess the performance limitations of our emulation infrastructure. We also present an interesting case study to demonstrate the capability of our approach.},
keywords={large-scale systems;telecommunication computing;telecommunication traffic;virtual private networks;large-scale real-time network simulations;network traffic;virtual private network;Emulation;Large-scale systems;Computational modeling;Virtual private networks;Real time systems;Embedded software;System testing;Computer networks;Distributed computing;Telecommunication traffic},
doi={10.1109/INFCOM.2007.304},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215887,
author={N. Kamiyama and T. Mori and R. Kawahara},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Simple and Adaptive Identification of Superspreaders by Flow Sampling},
year={2007},
volume={},
number={},
pages={2481-2485},
abstract={Abusive traffic caused by worms is increasing severely in the Internet. In many cases, worm-infected hosts generate a huge number of flows of small size during a short time. To suppress the abusive traffic and prevent worms from spreading, identifying these "superspreaders" as soon as possible and coping with them, e.g, disconnecting them from the network, is important. This paper proposes a simple and adaptive method of identifying superspreaders by flow sampling. By satisfying the given memory size and the requirement for the processing time, the proposed method can adaptively optimize parameters according to changes in traffic patterns.},
keywords={Internet;invasive software;telecommunication traffic;adaptive superspreader identification;flow sampling;abusive traffic pattern;worms;Internet;worm-infected host;Sampling methods;Laboratories;Electronic mail;Upper bound;Telecommunication traffic;Monitoring;Random number generation;Communications Society;Web and internet services;Optimization methods},
doi={10.1109/INFCOM.2007.305},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215888,
author={Y. Pointurier and M. Brandt-Pearce and S. Subramaniam},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Analysis of Blocking Probability in Noise and Crosstalk Impaired All-Optical Networks},
year={2007},
volume={},
number={},
pages={2486-2490},
abstract={In all-optical networks with no wavelength converters, signals are switched optically inside the nodes and therefore propagate over hundreds or thousands of kilometers with no electrical regeneration. Over such distances, physical impairments accumulate and can lead to serious signal degradation, resulting in poor quality of transmission (QoT) as measured by signal bit-error rates. The role of routing and wavelength assignment (RWA) algorithms is to accommodate incoming calls in optical networks over a route and a wavelength. RWA algorithms block calls if a continuous wavelength from source to destination cannot be found (wavelength blocking), or when the QoT of the call is not acceptable (QoT blocking). In this paper, we present an analytical method to evaluate blocking probability in all-optical networks, accounting for several physical layer impairments: intersymbol interference (ISI), amplifier noise (both are static effects that only depend on the network topology only) and node crosstalk (a dynamic effect that depends on the network status). We successfully validate our model through simulations on large scale networks with realistic physical layer parameters.},
keywords={error statistics;intersymbol interference;optical fibre networks;probability;telecommunication network routing;telecommunication network topology;wavelength assignment;blocking probability;crosstalk;all-optical networks;quality of transmission;signal bit-error rates;routing and wavelength assignment;RWA;wavelength blocking;intersymbol interference;ISI;amplifier noise;network topology;All-optical networks;Optical noise;Optical fiber networks;Physical layer;Intersymbol interference;Optical wavelength conversion;Optical crosstalk;Optical propagation;Repeaters;Degradation},
doi={10.1109/INFCOM.2007.306},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215889,
author={A. Firoozshahian and V. Manshadi and A. Goel and B. Prabhakar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Efficient, Fully Local Algorithms for CIOQ Switches},
year={2007},
volume={},
number={},
pages={2491-2495},
abstract={A number of algorithms have been proposed in the literature for scheduling CIOQ switches. The algorithms which have been proven to provide strict performance guarantees on delay (via the emulation of an output-queued switch) have been too complicated to implement because they require the exchange of a large amount of information between inputs and outputs. With implementation as our primary focus, we consider scheduling algorithms that are "fully local." This means inputs and outputs must be able to make decisions regarding matchings using only local information (except requests, grants and accepts). This constraint, which is essentially necessary for high-speed implementations, appears too restrictive for designing algorithms which enable the emulation of an output-queued switch. Rather surprisingly, we find a very simple and fully local algorithm FLGS (for fully local Gale-Shapley) which, at a speedup of 2, emulates an output-queued switch implementing a number of different output link scheduling algorithms such as weighted round robin and strict priority. We explore the performance of the algorithm at speedups between 1 and 2 using simulations and find that it partitions the bandwidth nearly as well as an output-queued switch at speedups 1.2 or higher.},
keywords={queueing theory;scheduling;telecommunication switching;CIOQ switch;output-queued switch;fully local Gale-Shapley algorithm;output link scheduling algorithm;weighted round robin;Switches;Scheduling algorithm;Emulation;Delay;Round robin;Throughput;Bandwidth;Fabrics;Communication switching;Algorithm design and analysis},
doi={10.1109/INFCOM.2007.307},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215890,
author={J. Liu and T. T. Lee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Blocking and Delay Analysis of Optical Buffer with General Packet Length Distribution},
year={2007},
volume={},
number={},
pages={2496-2500},
abstract={Buffers are essential components of any packet switches for resolving contentions among arriving packets. Currently, optical buffers are composed of Fiber Delay Lines (FDL), whose blocking and delay behavior differ drastically from that of conventional RAM in at least two folds: (i) only multiples of discrete time delays can be offered to arriving packets; (ii) a packet must be dropped if the maximum delay provided by optical buffer is not sufficient to avoid contention, this property is called balking. As a result, optical buffers only have finite time resolution, which may lead to excess load and prolong the packet delay. In this paper, the closed-form expressions of blocking probability and mean delay are derived to explore the tradeoff between buffer performance and system parameters, such as the length of the optical buffer, the time granularity of FDLs, and to evaluate the overall impact of packet length distribution on the buffer performance.},
keywords={buffer storage;optical delay lines;optical storage;optical switches;packet switching;probability;queueing theory;blocking probability analysis;discrete time delay analysis;optical buffer;packet length distribution;packet switching;fiber delay line;queueing model;Optical buffering;Delay effects;Optical packet switching;Optical switches;Delay lines;Read-write memory;Buffer storage;Optical losses;Communications Society;Information analysis},
doi={10.1109/INFCOM.2007.308},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215891,
author={H. -. Chiu and C. -. Chang and J. Cheng and D. -. Lee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Using a Single Switch with O(M) Inputs/Outputs for the Construction of an Optical Priority Queue with O(M lt;sup gt;3 lt;/sup gt;) Buffer},
year={2007},
volume={},
number={},
pages={2501-2505},
abstract={In this paper, we consider the construction of an optical priority queue with a single (M+1)times(M+1) switch and M fiber delay lines. The M fiber delay lines are connected from M outputs of the switch back to M inputs of the switch, leaving one input (resp. output) of the switch for the input (resp. output) of the priority queue. It was known that with an appropriate choice of the lengths of the delay lines, such a construction can be used for exact emulation of an optical priority queue with O(M<sup>2</sup>) buffer size. In this paper, we show that the buffer size can be further extended to O(M<sup>3</sup>) using the same construction. The improvement relies on establishing a partial ordering for all the packets stored in the delay lines.},
keywords={optical communication equipment;optical delay lines;optical fibre communication;optical switches;packet switching;queueing theory;single switch;optical priority queue;O(M3) buffer;fiber delay lines;optical packet switching;optical buffers;partial ordering;Optical switches;Optical buffering;Optical feedback;Delay lines;Optical packet switching;Buffer storage;Emulation;Communication switching;Optical fiber communication;Communications Society},
doi={10.1109/INFCOM.2007.309},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215892,
author={H. Kogan and I. Keslassy},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Fundamental Complexity of Optical Systems},
year={2007},
volume={},
number={},
pages={2506-2510},
abstract={It is often claimed that future systems will necessarily be all-optical, because electronic devices are not fast enough to keep up with the increase in fiber capacity. However, two objections are commonly raised: first, optical systems need many basic optical components, which are typically very expensive; and second, optical systems need many switch reconfigurations, which are typically very slow. In this paper, we examine whether these two costs can be fundamentally bounded. First, we develop the equivalence between coding theory and optical system design by introducing the concept of super switches. Then, we show how the minimal expected number of switch reconfigurations is almost equal to the state space entropy of the optical system. Finally, we point out the trade-off between the two types of costs.},
keywords={optical communication;optical switches;optical systems;electronic devices;fiber capacity;optical components;coding theory;state space entropy;Optical switches;Optical buffering;Optical devices;Costs;State-space methods;Codes;Entropy;Optical design;Optical packet switching;Communications Society},
doi={10.1109/INFCOM.2007.310},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215893,
author={Y. Ohsita and T. Miyamura and S. Arakawa and S. Ata and E. Oki and K. Shiomoto and M. Murata},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Gradually Reconfiguring Virtual Network Topologies Based on Estimated Traffic Matrices},
year={2007},
volume={},
number={},
pages={2511-2515},
abstract={In this paper, we present a practical VNT (virtual network topology) reconfiguration method for large-scale IP and optical networks with traffic matrix estimation considerations. We newly introduce a partial VNT reconfiguration algorithm with multiple transition stages. By dividing the whole VNT transition sequence into multiple transitions, estimation errors are calibrated at each stage by using network state information of prior stages. Because estimation errors are mainly due to the fewer information in the estimated traffic matrix calculation, our approach tries to increase the constraint conditions for traffic matrix estimation by introducing partial reconfiguration, and to relax the impact of estimation errors by limiting the number of optical-paths reconfigured at each stage. We also investigate the effectiveness of our proposal through simulations and clarify the robustness against estimation errors by using partial reconfiguration.},
keywords={IP networks;matrix algebra;optical fibre networks;telecommunication network routing;telecommunication traffic;virtual network topologies;large-scale IP networks;optical networks;traffic matrix estimation;transition sequence;network state information;optical-paths;partial reconfiguration;Network topology;Telecommunication traffic;Estimation error;Optical sensors;Traffic control;Optical fiber networks;Robustness;Tellurium;Large-scale systems;State estimation},
doi={10.1109/INFCOM.2007.311},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215894,
author={K. Ramachandran and B. Sikdar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Modeling Malware Propagation in Networks of Smart Cell Phones with Spatial Dynamics},
year={2007},
volume={},
number={},
pages={2516-2520},
abstract={Recent outbreaks of virus and worm attacks targeted at cell phones have have bought to the forefront the seriousness of the security threat to this increasingly popular means of communication. The ability of smart cell phones to communicate through both the Internet and the telecom networks along with the presence of a number of communication interfaces makes them vulnerable to attacks from a number of sources which can then propagate at extremely fast rates. In this paper we develop an analytic framework for modeling the dynamics of malware propagation in networks of smart phones that specifically accounts for the mobile nature of these devices. We also characterize the conditions under which the network may reach a malware free equilibrium and derive the necessary conditions for its global asymptotic stability. The model accounts for malware transfers through the Internet and peer to peer networks, through the telephone network and through Bluetooth and WLAN interfaces.},
keywords={cellular radio;computer viruses;Internet;network interfaces;malware propagation;smart cell phone network;spatial dynamics;computer virus;worm attack;Internet;communication interface;global asymptotic stability;peer to peer network;telephone network;Bluetooth;WLAN;Cellular phones;IP networks;Computer worms;Telecommunications;Mobile communication;Smart phones;Asymptotic stability;Peer to peer computing;Internet telephony;Bluetooth},
doi={10.1109/INFCOM.2007.312},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215895,
author={F. Armknecht and J. Girao and A. Matos and R. L. Aguiar},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Who Said That? Privacy at Link Layer},
year={2007},
volume={},
number={},
pages={2521-2525},
abstract={Wireless LAN and other radio broadcast technologies are now in full swing. However, the widespread usage of these technologies comes at the price of location privacy, be it by observing the communication patterns or the interface identifiers. Although a number of network level solutions have been proposed , this paper describes a novel approach to location privacy at the link layer level. We present a generic mechanism and then map it to a real protocol, IEEE 802.11. The work also provides an analysis of the protocol in terms of privacy and performance considerations.},
keywords={data privacy;protocols;radio links;telecommunication security;wireless LAN;wireless LAN;radio broadcast technology;location privacy;communication pattern;interface identifier;link layer level;protocol;Privacy;Peer to peer computing;Protection;Routing;Wireless LAN;Broadcast technology;Protocols;Network address translation;Communications Society;National electric code},
doi={10.1109/INFCOM.2007.313},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215896,
author={V. Navda and A. Bohra and S. Ganguly and D. Rubenstein},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Using Channel Hopping to Increase 802.11 Resilience to Jamming Attacks},
year={2007},
volume={},
number={},
pages={2526-2530},
abstract={802.11a, b, and g standards were designed for deployment in cooperative environments, and hence do not include mechanisms to protect from jamming attacks. In this paper, we explore how to protect 802.11 networks from jamming attacks by having the legitimate transmission hop among channels to hide the transmission from the jammer. Using a combination of mathematical analysis and prototype experimentation in an 802.11a environment, we explore how much throughput can be maintained in comparison to the maintainable throughput in a cooperative, jam-free environment. Our experimental and analytical results show that in today's conventional 802.11a networks, we can achieve up to 60% of the original throughput. Our mathematical analysis allows us to extrapolate the throughput that can be maintained when the constraint on the number of orthogonal channels used for both legitimate communication and for jamming is relaxed.},
keywords={jamming;mathematical analysis;protocols;telecommunication channels;telecommunication security;wireless LAN;802.11 network resilience;jamming attack protection;legitimate transmission channel hopping;mathematical analysis;wireless LAN;Resilience;Jamming;Protocols;Throughput;Mathematical analysis;Hardware;Protection;Peer to peer computing;Frequency;Floods},
doi={10.1109/INFCOM.2007.314},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215897,
author={Z. Wang and J. Deng and R. B. Lee},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Mutual Anonymous Communications: A New Covert Channel Based on Splitting Tree MAC},
year={2007},
volume={},
number={},
pages={2531-2535},
abstract={Known covert channel based on splitting algorithms in Medium Access Control (MAC) protocols requires the receiver's knowledge of the sender's identity. In this paper we present a new covert channel that does not have this restriction. In such a channel, multiple senders may operate independently without knowing each other, and the receiver can learn the transmitted information without knowing the identity of any covert sender a priori. These properties make the channel robust to malfunctioning senders, and more importantly help protect the secrecy of senders' identity which is essential for covert communications. We also analyze the capacity of our proposed covert channel.},
keywords={access protocols;telecommunication channels;telecommunication security;mutual anonymous communications;covert channel;medium access control;splitting tree;receivers;sender identity secrecy;telecommunication security;Media Access Protocol;Information security;Access protocols;Communication channels;Computer security;Delay;Resilience;Communications Society;Robustness;Protection},
doi={10.1109/INFCOM.2007.315},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215898,
author={X. Liu and G. Noubir and R. Sundaram and S. Tan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={SPREAD: Foiling Smart Jammers Using Multi-Layer Agility},
year={2007},
volume={},
number={},
pages={2536-2540},
abstract={In this paper, we address the problem of cross-layer denial of service attack in wireless data networks. We introduce SPREAD -a novel adaptive diversification approach to provide resiliency against such attacks. SPREAD relies on a mechanism-hopping technique, which can be seen as a multi-layer extension of the frequency-hopping technique. We apply a game-theoretic framework for modeling the interaction of the communicating nodes and the adversaries and analyze the proposed approach. We reason about the advantages of SPREAD against various types of jammers and demonstrate the effectiveness of our approach in the case of IEEE 802.11 protocol stack by studying the EIFS attack, periodical jamming and a Packet-Size Game. As an example, we show that mechanism-hopping over two instances of IEEE 802.11 can achieve several orders of magnitude gain in throughput over a single-instance network under the EIFS attack.},
keywords={frequency hop communication;game theory;telecommunication services;wireless LAN;smart jammers;multilayer agility;denial of service;wireless data networks;adaptive diversification approach;mechanism-hopping technique;multilayer extension;frequency-hopping technique;game-theoretic framework;IEEE 802.11 protocol;packet-size game;periodical jamming;Jamming;Game theory;Computer crime;Frequency;Protocols;Wireless networks;Wireless communication;Spread spectrum communication;Telecommunication traffic;Communication switching},
doi={10.1109/INFCOM.2007.316},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215899,
author={S. Ranjan and S. Shah and A. Nucci and M. Munafo and R. Cruz and S. Muthukrishnan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={DoWitcher: Effective Worm Detection and Containment in the Internet Core},
year={2007},
volume={},
number={},
pages={2541-2545},
abstract={Enterprise networks are increasingly offloading the responsibility for worm detection and containment to the carrier networks. However, current approaches to the zero-day worm detection problem such as those based on content similarity of packet payloads are not scalable to the carrier link speeds (OC-48 and up-wards). In this paper, we introduce a new system, namely DoWitcher, which in contrast to previous approaches is scalable as well as able to detect the stealthiest worms that employ low-propagation rates or polymorphisms to evade detection. DoWitcher uses an incremental approach toward worm detection: First, it examines the layer-4 traffic features to discern the presence of a worm anomaly; Next, it determines a flow-filter mask that can be applied to isolate the suspect worm flows and; Finally, it enables full-packet capture of only those flows that match the mask, which are then processed by a longest common subsequence algorithm to extract the worm content signature. Via a proof-of-concept implementation on a commercially available network analyzer processing raw packets from an OC-48 link, we demonstrate the capability of DoWitcher to detect low-rate worms and extract signatures for even the polymorphic worms.},
keywords={computer viruses;Internet;telecommunication security;telecommunication traffic;DoWitcher;worm detection;worm containment;Internet core;polymorphisms;layer-4 traffic;worm anomaly;flow-filter mask;full-packet capture;longest common subsequence algorithm;worm content signature;proof-of-concept implementation;network analyzer;polymorphic worms;Internet;Computer worms;Telecommunication traffic;Intrusion detection;USA Councils;Payloads;Communications Society;IP networks;Computer networks;Gain control},
doi={10.1109/INFCOM.2007.317},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215900,
author={D. E. Smith},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={IP TV Bandwidth Demand: Multicast and Channel Surfing},
year={2007},
volume={},
number={},
pages={2546-2550},
abstract={IP networks may soon become a delivery mechanism for broadcast television content. Multicast can reduce the steady state bandwidth demand on network links from one stream per viewer to one stream per watched program. However, channel surfing at commercial breaks can periodically increase the bandwidth demand. In the channel change mechanism we study, surfers leave multicast groups and receive unicast streams at higher than usual bandwidth. This paper builds a mathematical model to determine the net bandwidth demand of multicast and surfing during commercial breaks. In one example, we find that the peak demand during a commercial break is twice the steady state multicast demand.},
keywords={IP networks;multicast communication;telecommunication links;television broadcasting;IP TV bandwidth demand;multicast surfing;channel surfing;IP networks;delivery mechanism;broadcast television content;steady state bandwidth demand;network links;stream per viewer;stream per watched program;channel change mechanism;unicast streams;mathematical model;commercial break;steady state multicast demand;Bandwidth;Steady-state;Video sharing;Telecommunication traffic;Streaming media;Passive optical networks;Optical fiber networks;IP networks;TV broadcasting;Peer to peer computing},
doi={10.1109/INFCOM.2007.318},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215901,
author={M. C. M. Tsang and C. -. Wang and K. C. K. Tsang and F. C. M. Lau},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Receiver-Coordinated Approach for Throughput Aggregation in High Bandwidth Multicast},
year={2007},
volume={},
number={},
pages={2551-2555},
abstract={In application-level high bandwidth multicast (HBM), physical links can be shared by multiple long-lived unicast flows. We identify several data transfer patterns which can cause suboptimal bandwidth usage of narrow links and which have not been clearly identified in previous solutions for application-level HBM. We propose a distributed solution to avoid these problematic patterns, with which end systems are coordinated and each is responsible to forward a bounded amount of data. Consequently, the outgoing traffic of each end system is balanced and limited. It avoids congestion due to merging unicast flows, which increases the utilization of the narrow links. Receivers that are close by topologically request their data in a disjoint and coordinated fashion, which leads to much reduced duplicated data at the narrow links. Simulation results show that our solution can achieve higher throughputs at the receivers, which is due to more efficient utilization of the narrow links' bandwidth, than mesh-based or multiple-tree approaches.},
keywords={data communication;IP networks;multicast communication;radio receivers;telecommunication congestion control;telecommunication traffic;receiver-coordinated approach;throughput aggregation;high bandwidth multicast;multiple unicast flows;long-lived unicast flows;data transfer patterns;suboptimal bandwidth usage;narrow links;outgoing traffic;telecommunication congestion;mesh-based approach;multiple-tree approach;IP-multicast tree;Throughput;Bandwidth;Unicast;Streaming media;Communications Society;Computer science;Aggregates;Upper bound;Merging;Displays},
doi={10.1109/INFCOM.2007.319},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215902,
author={G. Dan and V. Fodor and I. Chatzidrossos},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On the Performance of Multiple-Tree-Based Peer-to-Peer Live Streaming},
year={2007},
volume={},
number={},
pages={2556-2560},
abstract={In this paper we propose and analyze a generalized multiple-tree-based overlay architecture for peer-to-peer live streaming that employs multipath transmission and forward error correction. We give mathematical models to describe the stability properties of the overlay and evaluate the error recovery in the presence of node dynamics and packet losses. We show how the stability of the overlay improves with the proper allocation of the outgoing bandwidths of the peers among the trees without compromising its error correcting capability.},
keywords={bandwidth allocation;forward error correction;multipath channels;peer-to-peer computing;trees (mathematics);multiple-tree-based peer-to-peer live streaming;multiple-tree-based overlay architecture;multipath transmission;forward error correction;stability property;error recovery;packet losses;bandwidth allocation;Peer to peer computing;Forward error correction;Mathematical model;Stability;Bandwidth;Communications Society;Performance evaluation;Analytical models;Error correction;IP networks},
doi={10.1109/INFCOM.2007.320},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215903,
author={L. Dai and Y. Cui and Y. Xue},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={On Scalability of Proximity-Aware Peer-to-Peer Streaming},
year={2007},
volume={},
number={},
pages={2561-2565},
abstract={P2P (peer-to-peer) technology has proved itself an efficient and cost-effective solution to support large-scale multimedia streaming. Different from traditional P2P applications, the quality of P2P streaming is strictly determined by performance metrics such as streaming delay. To meet these requirements, previous studies resorted to intuitions and heuristics to construct peer selection solutions incorporating topology and proximity concerns. However, the impact of proximity-aware methodology and delay tolerance of peers on the scalability of P2P system remains an unanswered question. In this paper, we study this problem via an analytical approach. To address the challenge of incorporating Internet topology into P2P streaming analysis, we construct a H-sphere network model which maps the network topology from the space of discrete graph to the continuous geometric domain, meanwhile capturing the the power-law property of Internet. Based on this model, we analyze a series of peer selection methods by evaluating their performance via key scalability metrics. Our analytical observations are further verified via simulation on Internet topologies.},
keywords={graph theory;Internet;media streaming;peer-to-peer computing;telecommunication network topology;proximity-aware peer-to-peer streaming;multimedia streaming;Internet topology;H-sphere network model;network topology;discrete graph;power-law property;Scalability;Peer to peer computing;Streaming media;Delay;IP networks;Network topology;Large-scale systems;Measurement;Solid modeling;Power system modeling},
doi={10.1109/INFCOM.2007.321},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215904,
author={D. Wang and G. Li and R. Doverspike},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={IGP Weight Setting in Multimedia IP Networks},
year={2007},
volume={},
number={},
pages={2566-2570},
abstract={With more service providers making considerable investments to roll out multimedia services using IP technology, live TV distribution on IP network is expected to grow impressively over next few years. To make efficient use of IP network infrastructure, service providers use multicast to transmit broadcast video content to the receiving nodes while simultaneously using unicast to transport other services on the same network, such as video on demand (VoD), high-speed Internet (HIS) etc. How to engineer different traffic flows on the same network to avoid traffic congestion becomes a major design issue. Although the service traffic flows are from source to receivers, the IP multicast tree is calculated using IGP shortest path from the receivers to the source (backwards from the flow), while the unicast path is calculated from the source to the receivers (same direction as the flow). To minimize congestion, we take advantage of this property and propose an algorithm to tune IGP link weights (such as OSPF) such that the traffic flows for multicast and unicast don't overlap. This proposal provides a natural way for service providers to use the spare capacity on the opposite direction of multicast traffic flow to roll out additional services in the same IP networks without impacting existing multicast services.},
keywords={IP networks;multicast communication;multimedia communication;telecommunication congestion control;telecommunication links;telecommunication network routing;telecommunication network topology;telecommunication traffic;trees (mathematics);IGP link weight setting;multimedia IP network;network traffic congestion;multicast tree;network routing;IP networks;Telecommunication traffic;Unicast;Video on demand;Investments;Multimedia communication;TV broadcasting;Web and internet services;Design engineering;Multicast algorithms},
doi={10.1109/INFCOM.2007.322},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215905,
author={S. Annapureddy and S. Guha and C. Gkantsidis and D. Gunawardena and P. Rodriguez},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Exploring VoD in P2P Swarming Systems},
year={2007},
volume={},
number={},
pages={2571-2575},
abstract={Digital media companies have recently started embracing P2P networks as an alternative distribution mechanism. However, with current P2P swarming systems users need to download the full video, and hence have to wait a long time before they can start watching it. While a lot of effort has gone into optimizing the distribution of large files, little research has been done on enabling Video-on-Demand (VoD) functionality with P2P swarming systems. The main challenges reside in ensuring that users can start watching a movie at any point in time, with small start-up times and sustainable playback rates. In this work, we address the issues of providing VoD using P2P mesh-based networks. We investigate scheduling techniques, and network coding in particular. Using both simulations and a prototype implementation, we show that high-quality VoD is feasible, and give guidelines to build play-as-you-download P2P swarming systems with high playback rates and low start-up delays.},
keywords={encoding;peer-to-peer computing;scheduling;video on demand;P2P swarming system;peer-to-peer network coding;video on demand;digital media;Network coding;Motion pictures;Delay;Peer to peer computing;Watches;USA Councils;Streaming media;Video sharing;Scalability;Scheduling algorithm},
doi={10.1109/INFCOM.2007.323},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215906,
author={E. Hyytia and T. Tirronen and J. Virtamo},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Optimal Degree Distribution for LT Codes with Small Message Length},
year={2007},
volume={},
number={},
pages={2576-2580},
abstract={Fountain codes provide an efficient way to transfer information over erasure channels. We give an exact performance analysis of a specific type of fountain codes, called LT codes, when the message length N is small. Two different approaches are developed. In a Markov chain approach the state space explosion, even with reduction based on permutation isomorphism, limits the analysis to very short messages, N &lt; 4. An alternative combinatorial method allows recursive calculation of the probability of decoding after N received packets. The recursion can be solved symbolically for values of N &lt; 10 and numerically up to N ap30. Examples of optimization results give insight into the nature of the problem. In particular, we argue that a few conditions are sufficient to define an almost optimal LT encoding.},
keywords={channel coding;combinatorial mathematics;electronic messaging;iterative decoding;Markov processes;probability;optimal degree distribution;LT codes;small message length;fountain codes;erasure channels;Markov chain approach;state space explosion;permutation isomorphism;combinatorial method;recursive calculation;probability;iterative decoding;State-space methods;Encoding;Laboratories;Explosions;Spraying;Councils;Iterative decoding;Communications Society;Performance analysis;Probability},
doi={10.1109/INFCOM.2007.324},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215907,
author={X. Jin and Q. Xia and S. -. G. Chan},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={A Cost-Based Evaluation of End-to-End Network Measurements in Overlay Multicast},
year={2007},
volume={},
number={},
pages={2581-2585},
abstract={Application-layer multicast (ALM, or overlay multicast) has been proposed to overcome limitations in IP multicast. While much measurement work (such as delay or connectivity measurement) has been conducted to build efficient ALM trees, several interesting questions therein are left unclear: (1) What are the measurement costs of the different measurement methods? (2) What is the major improvement to an ALM tree by using a certain measurement method? (3) To achieve the target tree performance, what is the most cost-efficient measurement method? In this paper, we study three representative measurement methods, i.e., delay measurement, connectivity measurement and available bandwidth measurement. We select six typical ALM protocols each adopting at least one of the measurement methods and evaluate their performance on Internet-like topologies. Our study shows that delay and connectivity measurements can effectively reduce end-to-end delay in overlay trees with low measurement costs. Only using delay measurement may lead to a tree consuming much network resource. The use of connectivity and bandwidth measurements can build a tree with low resource consumption.},
keywords={Internet;IP networks;multicast protocols;trees (mathematics);cost-based evaluation;end-to-end network measurement;IP multicast;ALM trees;cost-efficient measurement method;delay measurement;connectivity measurement;bandwidth measurement;ALM protocol;application layer multicast;Costs;Bandwidth;Protocols;Internet;Delay effects;Unicast;Communications Society;Computer science;Network topology;Large-scale systems},
doi={10.1109/INFCOM.2007.325},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215908,
author={X. Gu and Z. Wen and P. S. Yu},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={BridgeNet: An Adaptive Multi-Source Stream Dissemination Overlay Network},
year={2007},
volume={},
number={},
pages={2586-2590},
abstract={Emerging stream processing applications such as on-line data analysis often need to collect streaming information from geographically dispersed locations (e.g., different sensor networks). Different from conventional discrete data (e.g., messages), streaming data are <i>time-varying</i> and <i>long-lived</i>, which provides both new challenges and opportunities for optimizing wide-area continuous data dissemination. In this paper, we present <i>BridgeNet</i>, a novel biology-inspired stream dissemination overlay network that can dynamically learn stream patterns to achieve efficient multi-source stream dissemination. We propose a new distributed cell tree structure that can adaptively expand or contract itself in response to workload changes. BridgeNet performs <i>pattern-based</i> adaptations to deliver efficient stream disseminations without losing system stability. We have implemented a prototype of BridgeNet and conducted extensive experiments using both simulations and Planetlab deployment. The experimental results based on both synthetic workload and real data streams show that BridgeNet outperforms existing schemes for efficient multi-source stream dissemination.},
keywords={Internet;tree data structures;BridgeNet;stream dissemination overlay network;distributed cell tree structure;Data analysis;Tree data structures;Contracts;Telecommunication traffic;Network servers;Communications Society;Biosensors;Stability;Virtual prototyping;Search engines},
doi={10.1109/INFCOM.2007.326},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215909,
author={C. Gkantsidis and G. Goel and M. Mihail and A. Saberi},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Towards Topology Aware Networks},
year={2007},
volume={},
number={},
pages={2591-2595},
abstract={We focus on efficient protocols that enhance a network with topology awareness. We discuss centralized algorithms with provable performance, and introduce decentralized asynchronous heuristics that use only local information and local computations. These algorithms are based on distributed solutions of convex programs expressing optimization of various spectral properties of the matrix associated with the graph of the network topology. For example, these algorithms assign special weights to links crossing or directed towards small cuts by minimizing the second eigenvalue. Our main technical ingredient is to perform the decentralized asynchronous computations in a manner that preserves critical invariants of the exact second eigenvalue of the adjacency matrix associated with the network topology.},
keywords={protocols;telecommunication network topology;topology aware network;protocol;decentralized asynchronous heuristics;convex program;Network topology;Computer networks;Protocols;Eigenvalues and eigenfunctions;USA Councils;Distributed computing;Convergence;Communications Society;Educational institutions;IP networks},
doi={10.1109/INFCOM.2007.327},
ISSN={0743-166X},
month={May},}
@INPROCEEDINGS{4215910,
author={H. Rowaihy and W. Enck and P. McDaniel and T. La Porta},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Limiting Sybil Attacks in Structured P2P Networks},
year={2007},
volume={},
number={},
pages={2596-2600},
abstract={One practical limitation of structured peer-to-peer (P2P) networks is that they are frequently subject to Sybil attacks: malicious parties can compromise the network by generating and controlling large numbers of shadow identities. In this paper, we propose an admission control system that mitigates Sybil attacks by adaptively constructing a hierarchy of cooperative peers. The admission control system vets joining nodes via client puzzles. A node wishing to join the network is serially challenged by the nodes from a leaf to the root of the hierarchy. Nodes completing the puzzles of all nodes in the chain are provided a cryptographic proof of the vetted identity. We evaluate our solution and show that an adversary must perform days or weeks of effort to obtain even a small percentage of nodes in small P2P networks, and that this effort increases linearly with the size of the network. We further show that we can place a ceiling on the number of IDs any adversary may obtain by requiring periodic reassertion of the IDs continued validity.},
keywords={client-server systems;cryptography;peer-to-peer computing;telecommunication congestion control;telecommunication security;Sybil attacks;structured P2P networks;peer-to-peer networks;admission control system;client puzzles;cryptographic proof;Peer to peer computing;Intrusion detection;Admission control;Authentication;Public key cryptography;Communications Society;Computer science;Performance evaluation;Robustness;Content based retrieval},
doi={10.1109/INFCOM.2007.328},
ISSN={0743-166X},
month={May},}

