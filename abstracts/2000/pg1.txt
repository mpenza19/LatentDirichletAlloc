@INPROCEEDINGS{832457,
author={A. Stamoulis and G. B. Giannakis},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Packet fair queueing scheduling based on multirate multipath-transparent CDMA for wireless networks},
year={2000},
volume={3},
number={},
pages={1067-1076 vol.3},
abstract={The traditional layered approach to wireless networks (network, data link, and physical layer) suboptimally utilizes the limited available capacity. We propose a quality of service wireless framework based on the joint design of a packet fair queuing scheduler, demand assignment medium access control (MAC) protocol, and multirate multipath-transparent CDMA-based physical layer. The unique code assignment procedure allows a direct mapping of the packet fair schedule to the physical layer transmission/reception, and supports transmission (service) rates of arbitrarily fine resolution. Judiciously designed user codes combat the harsh time-varying fading environment, and parsimonious code description minimizes overhead in the MAC. Simulations illustrate the merits of our designs.},
keywords={scheduling;queueing theory;code division multiple access;multipath channels;quality of service;packet radio networks;time-varying channels;fading channels;access protocols;telecommunication control;mobile radio;packet fair queueing scheduling;multirate multipath-transparent CDMA;wireless networks;limited available capacity;quality of service wireless framework;packet fair queuing scheduler;demand assignment medium access control;MAC protocol;multirate multipath-transparent CDMA-based physical layer;code assignment procedure;packet fair schedule;physical layer transmission/reception;user codes;time-varying fading environment;parsimonious code description;mobile users;Multiaccess communication;Wireless networks;Physical layer;Media Access Protocol;Quality of service;Wireless application protocol;Access protocols;Fading;Global Positioning System;Processor scheduling},
doi={10.1109/INFCOM.2000.832457},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832460,
author={Dongxu Shen and Chuanyi Ji},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Admission control of multimedia traffic for third generation CDMA network},
year={2000},
volume={3},
number={},
pages={1077-1086 vol.3},
abstract={As CDMA is to be used for the third generation wireless networks to provide integrated services, it is important to study how the quality of service, such as packet loss and delay, should be guaranteed. To accomplish this, we develop a cell-wise model in which user's resource consumption is characterized, and the constraint between system bandwidth and resource consumptions of users is given. This model incorporates important factors that affect user's quality of service, including the aggregation of user traffic, user the power constraint, path loss and interference. Based on this model, we develop an admission control procedure. We further study transmission schemes using one and two channels. Numerical results show the two-channel scheme can have more users admitted, especially under heavy interference from other cells and when users' traffic is bursty.},
keywords={code division multiple access;telecommunication traffic;telecommunication congestion control;multimedia communication;quality of service;packet switching;cellular radio;radiofrequency interference;telecommunication channels;admission control;multimedia traffic;third generation CDMA network;integrated services;quality of service;packet loss;packet delay;cell-wise model;user resource consumption;system bandwidth;user traffic aggregation;power constraint;path loss;interference;bursty traffic;cellular radio;cell model;Admission control;Multiaccess communication;Traffic control;Power system modeling;Quality of service;Interference constraints;Communication system traffic control;Wireless networks;Intserv networks;Bandwidth},
doi={10.1109/INFCOM.2000.832460},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832462,
author={Zhimei Jiang and Li Fung Chang and N. K. Shankaranarayanan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Providing multiple service classes for bursty data traffic in cellular networks},
year={2000},
volume={3},
number={},
pages={1087-1096 vol.3},
abstract={This paper evaluates the use of packet scheduling to provide multiple service classes for bursty data traffic. In particular, we study the performance of the weighted fair queueing algorithm by simulating various scenarios in a packet cellular wireless network similar to an EDGE (Enhanced data rate for GSM evolution) system. The results show that, due to the burstiness of data traffic, traditional work-conserving packet scheduling algorithms such as weighted fair queueing cannot achieve the desired performance unless the system is heavily loaded. Similar results hold even when using priority queueing, which is an extreme form of weighted fair queueing. We also find that best effort traffic should be managed carefully to avoid inefficient usage of the network, especially in a low capacity cellular environment.},
keywords={telecommunication traffic;data communication;cellular radio;telecommunication services;packet radio networks;queueing theory;scheduling;Internet;multiple service classes;bursty data traffic;cellular networks;packet scheduling;weighted fair queueing algorithm;packet cellular wireless network;EDGE system;priority queueing;best effort traffic;low capacity cellular environment;Enhanced data rate for GSM Evolution;Internet users;Telecommunication traffic;Intelligent networks;Land mobile radio cellular systems;Scheduling algorithm;Traffic control;Cellular networks;Wireless networks;Delay;Communication system traffic control;Quality of service},
doi={10.1109/INFCOM.2000.832462},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832465,
author={D. A. Eckhardt and P. Steenkiste},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Effort-limited fair (ELF) scheduling for wireless networks},
year={2000},
volume={3},
number={},
pages={1097-1106 vol.3},
abstract={While packet scheduling for wired links is a maturing area, scheduling of wireless links is less mature. A fundamental difference between wired and wireless links is that wireless media can exhibit substantial rates of link errors, resulting in significant and unpredictable loss of link capacity. This capacity loss results in a special challenge for wireless schedulers. For example, a weighted fair queue (WFQ) scheduler assumes an error free link and specifies how flows should share the link capacity. However, this specification is not sufficient to determine the correct outcome when link capacity is sharply reduced, because flows that have been allocated the same weights may differ greatly in their ability to tolerate throughput loss. In this paper, we first describe the wireless scheduling challenge in terms of an effort-outcome disconnection. Next we propose a novel notion of fairness for wireless links, effort-limited fairness (ELF), which extends WFQ via dynamic weight adjustments. ELF guarantees that all flows experiencing an error rate below a per flow threshold receive their expected service, defined as a specified rate for reserved flows or a specified share of best-effort capacity for best effort flows. After motivating and defining ELF, we present a practical approximation algorithm, which we evaluate through both trace-driven simulation and measurement of a prototype wireless radio network based on the WaveLAN physical layer.},
keywords={scheduling;packet radio networks;channel capacity;queueing theory;error statistics;wireless LAN;effort-limited fair scheduling;ELF scheduling;wireless networks;packet scheduling;wireless links;link errors;link capacity;capacity loss;wireless schedulers;throughput loss;effort-outcome disconnection;effort-limited fairness;weighted fair queue;WFQ;ELF;dynamic weight adjustments;trace-driven simulation;prototype wireless radio network;WaveLAN physical layer;Ground penetrating radar;Geophysical measurement techniques;Wireless networks;Scheduling algorithm;Throughput;Error analysis;Approximation algorithms;Virtual prototyping;Radio network;Physical layer},
doi={10.1109/INFCOM.2000.832465},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832468,
author={R. Bhatia and J. Lobo and M. Kohli},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Policy evaluation for network management},
year={2000},
volume={3},
number={},
pages={1107-1116 vol.3},
abstract={Policies are increasingly being used to manage complex communication networks. In this paper we present our work on a "policy server" which is being used to provide centralized administration of packet voice gateways and "soft switches" in next generation circuit and packet telephony networks. The policies running in the policy server are specified using a domain independent policy description language (PDL). This paper is motivated by the problem of evaluating policies specified in PDL. We present an algorithm for evaluating policies and study both its theoretical and empirical behavior. We show that the problem of evaluating policies is quite intractable. However we note that the hard instances of the policy evaluation problem are quite rare in real world networks. Under some very realistic assumptions we are able to show that our policy evaluation algorithm is quite efficient and is well suited for enforcing policies in complex networks. These results constitute the first attempt to develop a formal framework to study the informal concepts of policy based network management.},
keywords={telecommunication network management;packet switching;voice communication;circuit switching;telephony;telecommunication computing;policy evaluation;network management;complex communication networks;policy server;centralized administration;packet voice gateways;soft switches;next generation circuit telephony networks;next generation packet telephony networks;domain independent policy description language;PDL;policy based network management;Modems;Java;Communication networks;Switching circuits;Packet switching;Communication switching;Next generation networking;Network servers;Internet telephony;Page description languages},
doi={10.1109/INFCOM.2000.832468},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832470,
author={G. Apostolopoulos and D. Aubespin and V. Peris and P. Pradham and D. Saha},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Design, implementation and performance of a content-based switch},
year={2000},
volume={3},
number={},
pages={1117-1126 vol.3},
abstract={In this paper, we share our experience in designing and building a content-based switch which we call L5. In addition to the layer 2-3-4 information available in the packet, a content-based switch uses application level information to route traffic in the network. Making routing decisions based on information contained in the payload is not a new idea. In fact application level proxies which are functionally equivalent to a content-based switch, have been around for years. Our contribution is in combining the functionalities of an application level proxy with the data handling capabilities of a switch into a single system. In this paper, we describe the architecture of the L5 system along with the details of how application level information can be efficiently processed in the switch hardware. We cover two specific application examples that we believe are ideal candidates for content-based switching: one is routing HTTP sessions based on uniform resource locators (URL) and the other is session-aware dispatching of secure socket layer (SSL) connections.},
keywords={telecommunication network routing;packet switching;telecommunication traffic;transport protocols;electronic switching systems;telecommunication security;content-based switch;L5 switch;layer 2-3-4 information;application level information;traffic routing;application level proxies;switch hardware;HTTP sessions;uniform resource locators;session-aware dispatching;secure socket layer;URL;SSL connections;Switches;Packet switching;Routing;Uniform resource locators;Buildings;Telecommunication traffic;Payloads;Data handling;Hardware;Dispatching},
doi={10.1109/INFCOM.2000.832470},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832473,
author={S. Merugu and S. Bhattacharjee and E. Zegura and K. Calvert},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Bowman: a node OS for active networks},
year={2000},
volume={3},
number={},
pages={1127-1136 vol.3},
abstract={Bowman is an extensible platform for active networking: it layers active networking functionality in user space software over variants of the System V UNIX operating system. The packet processing path implemented in Bowman incorporates an efficient and flexible packet classification algorithm, supports multi-threaded per-flow processing, and utilizes real time processor scheduling to achieve deterministic performance in the user-space. In this paper we describe the design and implementation of Bowman; discuss the support that Bowman provides for implementing execution environments for active networking; discuss the network-level architecture of Bowman that can be used to implement virtual networks; and present performance data showing that Bowman is able to sustain 100 Mbps throughput while forwarding IP packets over fast Ethernets.},
keywords={telecommunication computing;Unix;network operating systems;packet switching;scheduling;network topology;local area networks;network interfaces;active networks;extensible platform;Bowman;active networking functionality;user space software;System V UNIX operating system;packet processing path;flexible packet classification algorithm;multi-threaded per-flow processing;real time processor scheduling;execution environments;network-level architecture;virtual networks;fast Ethernets;100 Mbit/s;Operating systems;Computer science;Educational institutions;Processor scheduling;Routing protocols;Computer networks;Scheduling algorithm;Throughput;Ethernet networks;Virtual machining},
doi={10.1109/INFCOM.2000.832473},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832477,
author={R. Keller and Sumi Choi and M. Dasen and D. Decasper and G. Fankhauser and B. Plattner},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An active router architecture for multicast video distribution},
year={2000},
volume={3},
number={},
pages={1137-1146 vol.3},
abstract={Video distribution over the Internet poses many challenges. Due to the best-effort nature of today's public data networks, end system applications cannot rely on either bandwidth or delay guarantees. We designed and implemented a prototype of a multicast video distribution architecture involving knowledgeable active routers, a scalable video codec based on the wavelet transformation, and a high-performance video scaling algorithm implemented as a router plug-in. The plug-in scales the video with an average overhead of only 22 /spl mu/s per video datagram and is installed on-the-fly on the routers after the sender starts transmitting video for the first time. Through experiments on our test network, we show that we can dramatically improve the video quality on the receivers (up to 15 dB PSNR) by scaling the video on the routers to almost any target bandwidth. The target bandwidth is evaluated by the router solely based on monitoring of the load situation of the router's downstream links and can be adjusted within 50 ms.},
keywords={telecommunication network routing;multicast communication;visual communication;Internet;data communication;video codecs;active router architecture;multicast video distribution;Internet;public data networks;end system applications;knowledgeable active routers;scalable video codec;wavelet transformation;high-performance video scaling algorithm;router plug-in;video datagram;target bandwidth;downstream links;videoconferencing;video-on-demand;22 mus;Bandwidth;Video on demand;Videoconference;Internet;Feedback;Laboratories;IP networks;Multimedia communication;Broadcasting;Unicast},
doi={10.1109/INFCOM.2000.832477},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832480,
author={S. Nagata and N. Morita and H. Noguchi and K. Miyake},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An analysis of the impact of suspending cell discarding in TCP-over-ATM},
year={2000},
volume={3},
number={},
pages={1147-1156 vol.3},
abstract={A cell-discard method has been developed for use in networks supporting TCP-over-ATM traffic with an unspecified bit rate. In this "concentrated cell discard" (CCD) method, when an ATM switch becomes congested, consecutive cells are discarded from the front of the buffer, and cell discarding is suspended for a specified period of time. This method prevents TCP timeouts, which are the main reason for the decreasing TCP throughput in today's TCP-over-ATM networks, and shortens the duration of the congestion by avoiding the long delay experienced with the TCP fast-retransmission algorithm before the sender's TCP receives duplicate acknowledgments. Even though CCD does not consider TCP packet size or boundaries, the throughput with CCD was found by computer simulation to actually be higher than with early packet discard.},
keywords={transport protocols;asynchronous transfer mode;telecommunication traffic;buffer storage;telecommunication congestion control;Internet;packet switching;TCP-over-ATM;cell-discard method;concentrated cell discard;congested ATM switch;consecutive cells;cell discarding;TCP timeouts;TCP fast-retransmission algorithm;buffer;Internet;Switches;Asynchronous transfer mode;Throughput;Charge coupled devices;Delay;IP networks;Intelligent networks;Electronic mail;Telecommunication traffic;Bit rate},
doi={10.1109/INFCOM.2000.832480},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832483,
author={A. Aggarwal and S. Savage and T. Anderson},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Understanding the performance of TCP pacing},
year={2000},
volume={3},
number={},
pages={1157-1165 vol.3},
abstract={Many researchers have observed that TCP's congestion control mechanisms can lead to bursty traffic flows on modern high-speed networks, with a negative impact on overall network efficiency. A proposed solution to this problem is to evenly space, or "pace", data sent into the network over an entire round-trip time, so that data is not sent in a burst. In this paper, we quantitatively evaluate this approach. Pacing offers better fairness, throughput, and lower drop rates in some situations. However, we show that contrary to intuition, pacing often has significantly worse throughput than regular TCP because it is susceptible to synchronized losses and it delays congestion signals. We propose and evaluate approaches for eliminating this effect.},
keywords={transport protocols;telecommunication congestion control;telecommunication traffic;TCP pacing;congestion control mechanisms;bursty traffic flows;modern high-speed networks;overall network efficiency;round-trip time;fairness;throughput;drop rates;synchronized losses;congestion signals;Traffic control;Throughput;Communication system traffic control;Queueing analysis;Computer science;Telecommunication traffic;High-speed networks;Delay effects;Bandwidth;Smoothing methods},
doi={10.1109/INFCOM.2000.832483},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832485,
author={R. J. La and V. Anantharam},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Charge-sensitive TCP and rate control in the Internet},
year={2000},
volume={3},
number={},
pages={1166-1175 vol.3},
abstract={We investigate the fundamental problem of achieving the system optimal rates in a distributed environment, which maximize the total user utility, using only the information available at the end hosts. This is done by decomposing the system problem into two subproblems-network and user problems-and introducing an incentive-compatible pricing scheme, while maintaining proportional fairness. We demonstrate that when users update their parameters by solving their own optimization problem, at an equilibrium the system optimum is achieved. Furthermore, this algorithm does not require any explicit feedback from the network and can be deployed over the Internet with modifications only on the end hosts. In the second part of the paper we model as a noncooperative game the case where the choice of each user's action has nonnegligible effect on the price per unit flow at the resources and investigate the Nash equilibria of the game. We show, in the simple case of a single bottleneck, that there exists a unique Nash equilibrium of the game. Further, as the number of users increases, the unique Nash equilibrium approaches the system optimum.},
keywords={transport protocols;telecommunication control;Internet;optimisation;costing;game theory;charge-sensitive TCP;rate control;Internet;system optimal rates;distributed environment;total user utility;end hosts;incentive-compatible pricing scheme;proportional fairness;optimization problem;noncooperative game;Nash equilibria;single bottleneck;Internet;IP networks;Nash equilibrium;Pricing;Feedback;Protocols;Bandwidth;Current measurement;Charge measurement;Volume measurement},
doi={10.1109/INFCOM.2000.832485},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832487,
author={R. Morris},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Scalable TCP congestion control},
year={2000},
volume={3},
number={},
pages={1176-1183 vol.3},
abstract={The packet losses imposed by IP networks can cause long and erratic recovery delays, since senders must often use conservative loss detection and retransmission mechanisms. This paper proposes a model to explain and predict loss rates for TCP traffic. Based on that model, the paper describes a new router buffering algorithm, flow-proportional queuing (FPQ), that handles heavy TCP loads without imposing high loss rates. FPQ controls TCP by varying the router's queue length in proportion to the number of active TCP connections. Simulation results show that FPQ produces the same average transfer delays as existing schemes, but makes the delays more predictable and fairer.},
keywords={transport protocols;telecommunication congestion control;packet switching;Internet;telecommunication traffic;telecommunication network routing;buffer storage;queueing theory;scalable TCP congestion control;packet losses;IP networks;erratic recovery delays;conservative loss detection;retransmission mechanisms;loss rate prediction;TCP traffic;router buffering algorithm;flow-proportional queuing;FPQ;router queue length;active TCP connections;average transfer delays;Delay;Feedback;TCPIP;Predictive models;Traffic control;Proportional control;Internet;IP networks;Communication system traffic control;Art},
doi={10.1109/INFCOM.2000.832487},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832490,
author={P. Gupta and B. Prabhakar and S. Boyd},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Near-optimal routing lookups with bounded worst case performance},
year={2000},
volume={3},
number={},
pages={1184-1192 vol.3},
abstract={The problem of route address lookup has received much attention recently and several algorithms and data structures for performing address lookups at high speeds have been proposed. In this paper we consider one such data structure-a binary search tree built on the intervals created by the routing table prefixes. We wish to exploit the difference in the probabilities with which the various leaves of the tree (where the intervals are stored) are accessed by incoming packets in order to speedup the lookup process. More precisely, we seek an answer to the question: How can the search tree be drawn so as to minimize the average packet lookup time while keeping the worst-case lookup time within a fixed bound?" We use ideas from information theory to derive efficient algorithms for computing near-optimal routing lookup trees. Finally, we consider the practicality of our algorithms through analysis and simulation.},
keywords={tree data structures;telecommunication network routing;table lookup;optimisation;packet switching;minimisation;correlation theory;Internet;near-optimal routing lookup;bounded worst case performance;route address lookup;data structure;binary search tree;routing table prefixes;incoming packets;average packet lookup time;information theory;Internet;Routing;Computer aided software engineering;Data structures;Tree data structures;Binary search trees;Internet;Memory management;Frequency;Binary trees;Information theory},
doi={10.1109/INFCOM.2000.832490},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832493,
author={A. Feldman and S. Muthukrishnan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Tradeoffs for packet classification},
year={2000},
volume={3},
number={},
pages={1193-1202 vol.3},
abstract={We present an algorithmic framework for solving the packet classification problem that allows various access time versus memory tradeoffs. It reduces the multidimensional packet classification problem to solving a few instances of the one-dimensional IP lookup problem. It gives the best known lookup performance with moderately large memory space. Furthermore, it efficiently supports a reasonable number of additions and deletions to the rulesets without degrading the lookup performance. We perform a thorough experimental study of the tradeoffs for the two-dimensional packet classification problem on rulesets derived from datasets collected from AT&T WorldNet, an Internet service provider.},
keywords={packet switching;table lookup;Internet;tree data structures;packet classification;algorithmic framework;memory tradeoffs;multi dimensional packet classification;one-dimensional IP lookup problem;lookup performance;moderately large memory space;rulesets;two-dimensional packet classification problem;AT&T WorldNet;Internet service provider;fat inverted segment tree;IP networks;IP networks;Virtual private networks;Web and internet services;Quality of service;Telecommunication traffic;Traffic control;Degradation;Routing;Access protocols;Multiprotocol label switching},
doi={10.1109/INFCOM.2000.832493},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832496,
author={A. Hari and S. Suri and G. Parulkar},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Detecting and resolving packet filter conflicts},
year={2000},
volume={3},
number={},
pages={1203-1212 vol.3},
abstract={Packet filters are rules for classifying packets based on their header fields. Packet classification is essential to routers supporting services such as quality of service (QoS), virtual private networks (VPNs), and firewalls. A filter conflict occurs when two or more filters overlap, creating an ambiguity in packet classification. Current techniques for resolving filter conflicts are based on prioritizing conflicting filters, and choosing the higher priority filter. We show that such ordering does not always work. Instead, we propose a new scheme for conflict resolution, which is based on the idea of adding resolve filters. Our main results are algorithms for detecting and resolving conflicts in a filter database. We have tried our algorithm on 3 existing firewall databases, and have found conflicts, which are potential security holes, in each of them.},
keywords={packet switching;telecommunication network routing;database management systems;telecommunication security;Internet;filtering theory;packet filter conflicts;packet classification;header fields;routers;quality of service;QoS;virtual private networks;VPN;firewalls;conflicting filters;conflict resolution;resolve filters;filter database;firewall databases;security holes;Internet;Information filtering;Information filters;Quality of service;Web and internet services;Matched filters;Virtual private networks;Databases;TCPIP;Protocols;Data security},
doi={10.1109/INFCOM.2000.832496},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832499,
author={T. Y. C. Woo},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A modular approach to packet classification: algorithms and results},
year={2000},
volume={3},
number={},
pages={1213-1222 vol.3},
abstract={The ability to classify packets according to pre-defined rules is critical to providing many sophisticated value-added services, such as security, QoS, load balancing, traffic accounting, etc. Various approaches to packet classification have been studied in the literature with accompanying theoretical bounds. Practical studies with results applying to large number of filters (from 8K to 1 million) are rare. In this paper, we take a practical approach to the problem of packet classification. Specifically, we propose and study a novel approach to packet classification which combines a heuristic tree search with the use of filter buckets. Besides high performance and a reasonable storage requirement, our algorithm is unique in the sense that it can adapt to the input packet distribution by taking into account the relative filter usage. To evaluate our algorithms, we have developed realistic models of large scale filter tables, and used them to drive extensive experimentation. The results demonstrate the practicality of our algorithms for up to even 1 million filters.},
keywords={packet switching;tree data structures;search problems;divide and conquer methods;digital filters;packet classification;pre-defined rules;value-added services;security;QoS;load balancing;traffic accounting;heuristic tree search;filter buckets;input packet distribution;realistic models;large scale filter tables;divide and conquer approach;Classification algorithms;Matched filters;Load management;Classification tree analysis;Large-scale systems;Computational geometry;Explosions;Nonlinear filters;Data structures;Software algorithms},
doi={10.1109/INFCOM.2000.832499},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832502,
author={R. Boorstyn and A. Burchard and J. Liebeherr and C. Oottamakorn},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Effective envelopes: statistical bounds on multiplexed traffic in packet networks},
year={2000},
volume={3},
number={},
pages={1223-1232 vol.3},
abstract={A statistical network service which allows a certain fraction of traffic to not meet its QoS guarantees can extract additional capacity from a network by exploiting the statistical properties of the traffic. Here we consider a statistical service which assumes statistical independence of flows, but does not make any assumptions on the statistics of traffic sources, other than that they are regulated, e.g., by a leaky bucket. Under these conditions, we present functions, so-called local effective envelopes and global effective envelopes, which are, with high certainty, upper bounds of multiplexed traffic. We show that these envelopes can be used to obtain bounds on the amount of traffic on a link that can be provisioned with statistical QoS. A key advantage of our bounds is that they can be applied with a variety of scheduling algorithms. In fact, we show that one can reuse existing admission control functions that are available for scheduling algorithms with a deterministic service. We present numerical examples which compare the number of flows with statistical QoS guarantees that can be admitted with our effective envelope approach to those achieved with existing methods.},
keywords={telecommunication traffic;packet switching;statistical analysis;multiplexing;quality of service;scheduling;statistical QoS;statistical bounds;multiplexed traffic;packet networks;statistical network service;QoS guarantees;traffic sources;leaky bucket;local effective envelopes;scheduling algorithms;admission control functions;deterministic service;Telecommunication traffic;Intelligent networks;Scheduling algorithm;Admission control;Statistics;Upper bound;Traffic control;Mathematics;Computer science;Random processes},
doi={10.1109/INFCOM.2000.832502},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832506,
author={L. Breslau and S. Jamin and S. Shenker},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Comments on the performance of measurement-based admission control algorithms},
year={2000},
volume={3},
number={},
pages={1233-1242 vol.3},
abstract={Relaxed real time services that do not provide guaranteed loss rates or delay bounds are of considerable interest in the Internet, since these services can achieve higher utilization than hard real time services while still providing adequate service to adaptive real-time applications. Achieving this higher level of utilization depends on an admission control algorithm that does not rely on worst-case bounds to guide its admission decisions. Measurement-based admission control is one such approach, and several measurement-based admission control algorithms have been proposed in the literature. In this paper, we use simulations to compare the performance of several of these algorithms. We find that all of them achieve nearly the same utilization for a given packet loss rate, and that none of them are capable of accurately meeting loss targets.},
keywords={Internet;telecommunication congestion control;telecommunication services;measurement-based admission control algorithms;relaxed real time services;Internet;admission decisions;packet loss rate;loss targets;Admission control;Delay;Communication system traffic control;Loss measurement;Web and internet services;Engineering profession;Computer science;Programmable control;Adaptive control;Performance loss},
doi={10.1109/INFCOM.2000.832506},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832509,
author={R. Szabo and P. Barta and F. Nemeth and J. Biro and C. -. Perntz},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Call admission control in generalized processor sharing (GPS) schedulers using non-rate proportional weighting of sessions},
year={2000},
volume={3},
number={},
pages={1243-1252 vol.3},
abstract={Generalized processor sharing (GPS) is an ideal fluid scheduling discipline that supports well defined delay and loss bounds on leaky-bucket constrained traffic. Its packetized versions (WFQ, WF2Q, PGPS etc.) are considered as the packet scheduler of choice in IP routers and ATM switches of the future. The currently accepted approach for the design of GPS schedulers is based on deterministic QoS guarantees, which is overly conservative due to the applied loose bounds and leads to limitations on capacity. We developed a framework for the computation of tighter delay bounds, bandwidth and delay de-coupling in GPS systems. In this paper, we propose several effective call admission control (CAC) algorithms that work in the bandwidth and delay de-coupled system while using the tighter delay bounds presented herein. One of the proposed CAC algorithms also handles the best-effort service class beside the QoS guaranteed service classes. Performance evaluation of several CAC algorithms are presented.},
keywords={telecommunication congestion control;processor scheduling;telecommunication traffic;queueing theory;call admission control;generalized processor sharing schedulers;GPS schedulers;non-rate proportional session weighting;ideal fluid scheduling discipline;delay bounds;loss bounds;leaky-bucket constrained traffic;WFQ;WF2Q;PGPS;IP routers;ATM switches;CAC algorithms;best-effort service class;Call admission control;Global Positioning System;Processor scheduling;Bandwidth;Delay effects;Scheduling algorithm;Asynchronous transfer mode;Packet switching;Switches;Delay systems},
doi={10.1109/INFCOM.2000.832509},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832512,
author={G. Hasegawa and T. Matsuo and M. Murata and H. Miyahara},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Comparisons of packet scheduling algorithms for fair service among connections on the Internet},
year={2000},
volume={3},
number={},
pages={1253-1262 vol.3},
abstract={We investigate the performance of TCP under three representatives of packet scheduling algorithms at the router. Our main focus is to investigate how fair service can be provided for elastic applications sharing the link. Packet scheduling algorithms that we consider are FIFO (first in first out), RED (random early detection), and DRR (deficit round robin). Through simulation and analysis results, we discuss the degree of achieved fairness in those scheduling algorithms. Furthermore, we propose a new algorithm which combines RED and DRR algorithms in order to prevent the unfairness property of the original DRR algorithm, which appears in some circumstances where we want to resolve the scalability problem of the DRR algorithm. In addition to the TCP Reno version, we consider TCP Vegas to investigate its capability of providing fairness. The results show that the principle of TCP Vegas conforms to DRR, but it cannot help improving the fairness among connections in FIFO and RED cases, which seems to be a substantial obstacle for the deployment of TCP Vegas.},
keywords={packet switching;Internet;scheduling;transport protocols;telecommunication network routing;queueing theory;packet scheduling algorithms;fair service;Internet connections;TCP performance;router;elastic applications;FIFO;first in first out;RED;random early detection;DRR;deficit round robin;scalability problem;TCP Reno version;TCP Vegas;Scheduling algorithm;Web and internet services;Round robin;Protocols;Throughput;Electronic mail;Analytical models;Algorithm design and analysis;Vents;Delay},
doi={10.1109/INFCOM.2000.832512},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832513,
author={M. Meo and M. A. Marsan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Approximate analytical models for dual-band GSM networks design and planning},
year={2000},
volume={3},
number={},
pages={1263-1272 vol.3},
abstract={In this paper we consider dual-band GSM networks, where voice and data services are offered to users moving over an area covered with overlapping macrocells and microcells. For this wireless network context we develop simple approximate analytical models of the system dynamics, and we exploit such analytical models for the design and planning of the critical system parameters, with particular attention to the number of traffic channels to be activated within macrocells.},
keywords={approximation theory;telecommunication network planning;microcellular radio;cellular radio;telecommunication traffic;telecommunication channels;frequency allocation;integrated voice/data communication;approximate analytical models;dual-band GSM networks;voice services;data services;overlapping macrocells;overlapping microcells;wireless network;system dynamics;critical system parameters;traffic channels;GSM network design;GSM network planning;Analytical models;Dual band;GSM;Frequency;Macrocell networks;Microcell networks;Telephony;Telecommunication traffic;Meeting planning;Cellular networks},
doi={10.1109/INFCOM.2000.832513},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832516,
author={Ying-Dar Lin and Yu-Ching Hsu},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Multihop cellular: a new architecture for wireless communications},
year={2000},
volume={3},
number={},
pages={1273-1282 vol.3},
abstract={This work presents a new architecture, multihop cellular network (MCN), for wireless communications. MCN preserves the benefit of conventional single-hop cellular networks (SCN) where the service infrastructure is constructed by fixed bases, and it also incorporates the flexibility of ad-hoc networks where wireless transmission through mobile stations in multiple hops is allowed. MCN can reduce the required number of bases or improve the throughput performance, while limiting path vulnerability encountered in ad-hoc networks. In addition, MCN and SCN are analyzed, in terms of mean hop count, hop-by-hop throughput, end-to-end throughput, and mean number of channels (i.e. simultaneous transmissions) under different traffic localities and transmission ranges. Numerical results demonstrate that the throughput of MCN exceeds that of SCN, the former also increases as the transmission range decreases. The above results can be accounted for by the different orders, linear and square, at which the mean hop count and mean number of channels increase, respectively.},
keywords={cellular radio;network topology;telecommunication traffic;telecommunication channels;packet radio networks;wireless communication architecture;multihop cellular network;service infrastructure;ad-hoc networks;wireless transmission;mobile stations;multiple hops;throughput performance;single-hop cellular networks;SCN;MCN;mean hop count;hop-by-hop throughput;end-to-end throughput;traffic localities;packet radio;Wireless communication;Ad hoc networks;Throughput;Cellular networks;Packet radio networks;Spread spectrum communication;Telephony;GSM;Costs;Computer architecture},
doi={10.1109/INFCOM.2000.832516},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832519,
author={Wen-Tsuen Chen and Li-Chi Huang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={RSVP mobility support: a signaling protocol for integrated services Internet with mobile hosts},
year={2000},
volume={3},
number={},
pages={1283-1292 vol.3},
abstract={The resource reservation mechanism is essential for QoS provisioning in integrated services networks. The resource reservation protocol (RSVP) is a receiver oriented resource reservation protocol, and an Internet standard approved by the Internet Engineering Task Force (IETF). However, the RSVP designed for the fixed network has been facing a great challenge owing to the participation of wireless networks. In this paper, we describe a new signaling protocol for mobile hosts to reserve resources in the integrated services Internet. Under our approach, we extend the RSVP model based on IP multicast to support mobile hosts. The mobility of a host is modeled as a transition in multicast group membership. Provision of QoS in wireless networks is more complex than in wired networks due to user mobility. To overcome the mobility impact on service guarantees, mobile hosts need to make resource reservation in advance at the locations it may visit during the lifetime of the connections. These locations become the leaves of the multicast tree in our design. To obtain more efficient use of scarce wireless bandwidth, we propose the extended reservation model. A mobile proxy in a cell is required to manage resource reservations and other mobility related tasks on behalf of mobile hosts. The mobility impacts on packet delay, bandwidth utilization and packet loss rate are investigated via simulations.},
keywords={Internet;telecommunication signalling;protocols;quality of service;multicast communication;cellular radio;packet switching;RSVP mobility support;signaling protocol;integrated services Internet;mobile hosts;resource reservation mechanism;QoS provisioning;integrated services networks;resource reservation protocol;receiver oriented resource reservation protocol;Internet standard;Internet Engineering Task Force;IETF;IP multicast;multicast group membership;service guarantees;multicast tree;scarce wireless bandwidth;extended reservation model;mobile proxy;packet delay;bandwidth utilization;packet loss rate;Protocols;Intserv networks;Web and internet services;Quality of service;Wireless networks;Delay;Bandwidth;IP networks;Mobile computing;Computer science},
doi={10.1109/INFCOM.2000.832519},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832522,
author={B. Liang and Z. J. Haas},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Virtual backbone generation and maintenance in ad hoc network mobility management},
year={2000},
volume={3},
number={},
pages={1293-1302 vol.3},
abstract={In this paper, we present the implementation issues of a virtual backbone that supports the operations of the uniform quorum system (UQS) and the randomized database group (RDG) mobility management schemes in an ad hoc network. The virtual backbone comprises nodes that are dynamically selected to contain databases that store the location information of the network nodes. Together with the UQS and RDG schemes, the virtual backbone allows both dynamic database residence and dynamic database access, which provide high degree of location data availability and reliability. We introduce a distributed database coverage heuristic (DDCH), which is equivalent to the centralized greedy algorithm for virtual backbone generation, but only requires local information exchange and local computation. We show how DDCH can be employed to dynamically maintain the structure of the virtual backbone, along with database merging, as the network topology changes. We also provide a means to maintain connectivity among the virtual backbone nodes. We discuss optimization issues of DDCH through simulations. Simulation results suggest that the cost of ad hoc mobility management with a virtual backbone can be far below that of the conventional link-state routing.},
keywords={maintenance engineering;telecommunication network management;distributed databases;network topology;telecommunication network routing;optimisation;mobile radio;telecommunication computing;virtual backbone generation;virtual backbone maintenance;ad hoc network mobility management;uniform quorum system;UQS;randomized database group;RDG;mobility management schemes;distributed database coverage heuristic;location information;dynamic database residence;dynamic database access;centralized greedy algorithm;local information exchange;database merging;network topology;optimization;ad hoc mobility management;Spine;Ad hoc networks;Mobile radio mobility management;Computational modeling;Availability;Distributed databases;Greedy algorithms;Distributed computing;Maintenance;Merging},
doi={10.1109/INFCOM.2000.832522},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832524,
author={M. Vojnovic and J. -. Le Boudec and C. Boutremans},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Global fairness of additive-increase and multiplicative-decrease with heterogeneous round-trip times},
year={2000},
volume={3},
number={},
pages={1303-1312 vol.3},
abstract={Consider a network with an arbitrary topology and arbitrary communication delays, in which congestion control is based on additive-increase and multiplicative-decrease. We show that the source rates tend to be distributed in order to maximize an objective function called F/sub A//sup h/ ("F/sub A//sup h/ fairness"). We derive this result under the assumption of rate proportional negative feedback and for the regime of rare negative feedback. This applies to TCP in moderately loaded networks, and to those TCP implementations that are designed to interpret multiple packet losses within one RTT as a single congestion indication and do not rely on re-transmission timeout. This result provides some insight into the distribution of rates, and hence of packet loss ratios, which can be expected in a given network with a number of competing TCP or TCP-friendly sources. We validate our findings by analyzing a multiple-bottleneck scenario, and comparing with previous results (Floyd, 1991, Mathis et al, 1997) and an extensive numerical simulation with realistic parameter settings. We apply F/sub A//sup h/ fairness to gain a more accurate understanding of the bias of TCP against long round-trip times.},
keywords={network topology;telecommunication congestion control;feedback;transport protocols;packet switching;proportional control;global fairness;additive-increase;multiplicative-decrease;heterogeneous round-trip times;arbitrary communication delays;arbitrary network topology;congestion control;source rates;objective function;rate proportional negative feedback;rare negative feedback;moderately loaded networks;multiple packet losses;RTT;single congestion indication;packet loss ratios;TCP sources;TCP-friendly sources;multiple-bottleneck scenario;long round-trip times;Negative feedback;Network topology;Internet;Computer applications;Computer networks;Application software;Communication system control;Numerical simulation;Stochastic processes;Throughput},
doi={10.1109/INFCOM.2000.832524},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832528,
author={R. Muthukrishnan and S. Dasgupta and A. Varma and L. Kalampoukas and K. K. Ramakrishnan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Design, implementation and evaluation of an explicit rate allocation algorithm in an ATM switch},
year={2000},
volume={3},
number={},
pages={1313-1322 vol.3},
abstract={We discuss a hardware implementation of an explicit rate allocation algorithm for support of available bit rate (ABR) service in ATM switches. We then demonstrate the effectiveness of the algorithm at the network-level through measurements on the actual implementation in a network testbed. The rate allocation algorithm has several desirable properties, such as exact computation of the max-min rates, O(1) computations per resource management (RM) cell received, and the ability to provide minimum cell rate (MCR) guarantees. We show that the algorithm can be implemented with a modest amount of hardware (64,000 gates in an Altera 10K100 programmable logic device and 16 bytes of SRAM storage per VC), and that even a slow FPGA-based implementation with a 20 MHz internal clock rate can process RM cells within one cell time at an OC-3 port. We also outline the design for supporting OC-12 and OC-48 links. We present results from measurements of ABR traffic in network configurations with up to four bottlenecks and 100 connections. The results show that the algorithm is able to converge to the exact max-min fair allocations with no oscillations after convergence, maintains minimum rate guarantees, and is also able to maintain high link utilization in the presence of on-off traffic.},
keywords={asynchronous transfer mode;telecommunication equipment testing;field programmable gate arrays;telecommunication traffic recording;minimax techniques;convergence of numerical methods;bandwidth allocation;telecommunication network management;electronic switching systems;explicit rate allocation algorithm;ATM switch;hardware implementation;available bit rate;ABR service;max-min rates;minimum cell rate guarantees;Altera 10K100 programmable logic device;SRAM storage;internal clock rate;OC-3 port;OC-12 links;OC-48 links;ABR traffic;network configurations;convergence;on-off traffic;resource management cell;20 MHz;Hardware;Resource management;Telecommunication traffic;Bit rate;Asynchronous transfer mode;Switches;Testing;Programmable logic devices;Random access memory;Virtual colonoscopy},
doi={10.1109/INFCOM.2000.832528},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832529,
author={S. Kunniyur and R. Srikant},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={End-to-end congestion control schemes: utility functions, random losses and ECN marks},
year={2000},
volume={3},
number={},
pages={1323-1332 vol.3},
abstract={We present a framework for designing end-to-end congestion control schemes in a network where each user may have a different utility function. We first show that there exists an additive increase-multiplicative decrease scheme using only end-to-end measurable losses such that a socially-optimal solution can be reached. We incorporate non-congestion-related random losses and round-trip delay in this model, and show that one can generalize observations regarding TCP-type congestion avoidance to more general window flow control schemes. We then consider explicit congestion notification (ECN) as an alternate mechanism (instead of losses) for signaling congestion and show that ECN marking levels can be designed to nearly eliminate losses in the network by choosing the marking level independently for each node in the network. While the ECN marking level at each node may depend on the number of flows through the node, the appropriate marking level can be estimated using only aggregate flow measurements, i.e., per-flow measurements are not required.},
keywords={telecommunication congestion control;telecommunication signalling;end-to-end congestion control schemes;utility functions;random losses;ECN marks;additive increase-multiplicative decrease scheme;end-to-end measurable losses;socially-optimal solution;non-congestion-related random losses;TCP-type congestion avoidance;general window flow control schemes;explicit congestion notification;signaling congestion;ECN marking levels;aggregate flow measurements;per-flow measurements;Loss measurement;Fluid flow measurement;Pricing;Delay;Signal design;Aggregates;Surges;Admission control;Error correction;Fluid flow control},
doi={10.1109/INFCOM.2000.832529},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832530,
author={M. Karol and S. J. Golestani and D. Lee},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Prevention of deadlocks and livelocks in lossless, backpressured packet networks},
year={2000},
volume={3},
number={},
pages={1333-1342 vol.3},
abstract={When congestion builds up in a packet network, two general approaches are possible to cope with the shortage of buffer space. One approach is to drop incoming packets for the buffer that is not available and to rely on the end-to-end protocols for the recovery of lost packets. The alternative approach is to insist that no packets should be dropped inside a packet network, even when congestion builds up. One way to accomplish this goal is to have the congested nodes send backpressure feedback to neighboring nodes, informing them of unavailability of buffering capacity and in effect stopping them from forwarding packets until enough buffer becomes available. While there are potential advantages in backpressured networks that do not allow packet dropping, such networks are susceptible to a condition known as deadlock in which throughput of the network or part of the network goes to zero (i.e., no packets are transmitted). In this paper, we describe a simple, lossless method of preventing deadlocks and livelocks in backpressured packet networks. In contrast with prior approaches, our proposed technique does not introduce any packet losses, does not corrupt the packet sequence, and does not require any changes to packet headers. In addition to presenting the new congestion control protocol in a general context, we describe an important application of the technique to Gigabit Ethernet (IEEE 802.3z).},
keywords={packet switching;buffer storage;telecommunication congestion control;protocols;local area networks;deadlock prevention;livelock prevention;lossless backpressured packet networks;buffer space;end-to-end protocols;congested nodes;backpressure feedback;buffering capacity;packet dropping;congestion control protocol;Gigabit Ethernet;IEEE 802.3;System recovery;Intelligent networks;Protocols;Local area networks;Space technology;Feedback;Throughput;Ethernet networks;Availability;Quality of service},
doi={10.1109/INFCOM.2000.832530},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832531,
author={V. Ozdemir and S. Muthukrishnan and I. Rhee},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Scalable, low-overhead network delay estimation},
year={2000},
volume={3},
number={},
pages={1343-1350 vol.3},
abstract={The round trip network delay times between pairs of nodes in a multicast session is a key parameter; it is used in suppressing the implosion of request and repair packets, in detecting congestion, etc. This paper presents a protocol to estimate the delays between every pair of nodes in a multicast group. While existing protocols use O(n) multicast messages with O(n) size each (total of O(n/sup 2/) bits), our protocol requires O(n) multicasts with only O(1) size each (total of O(n) bits); here, n is the session size. It does not require clocks to be synchronized, or any knowledge of network topology and the session size. We incorporate our protocol into the SRM (scalable reliable multicast) protocol (Rhee et al., 1999) and show by our simulations that, (i) our delay estimation protocol is reasonably accurate, (ii) it is just as effective as existing delay estimation protocols in suppressing repair and request traffic in SRM, and (iii) it has significantly lower overhead than the existing delay estimation protocols. Furthermore, our protocol can be extended to run within a hierarchically structured multicast protocol such as RMTP (reliable multicast transport protocol) (Paul et al., 1996). Here the goal is to estimate round trip delays from a sender to each receiver. Our protocol ensures that only the immediate children of the sender send feedback messages directly to the sender, thereby avoiding feedback implosion. Our delay estimation protocols therefore significantly enhance the scalability of unstructured multicast protocols such as SRM, as well as tree-structured multicast protocols such as RMTP.},
keywords={delay estimation;multicast communication;packet switching;transport protocols;telecommunication traffic;feedback;telecommunication congestion control;scalable low-overhead network delay estimation;round trip network delay times;multicast session;request packets;repair packets;protocol;multicast group;multicast messages;SRM protocol;delay estimation protocol;feedback messages;feedback implosion;delay estimation protocols;unstructured multicast protocols;tree-structured multicast protocols;RMTP;reliable multicast transport protocol;Delay estimation;Multicast protocols;Clocks;Synchronization;Delay effects;Telecommunication traffic;Feedback;Unicast;Computer science;Network topology},
doi={10.1109/INFCOM.2000.832531},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832532,
author={N. G. Duffield and F. Lo Presti},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Multicast inference of packet delay variance at interior network links},
year={2000},
volume={3},
number={},
pages={1351-1360 vol.3},
abstract={End to end measurement is a common tool for network performance diagnosis, primarily because it can reflect user experience and typically requires minimal support from intervening network elements. Challenges in this approach are: (i) to identify the locale of performance degradation; and (ii) to perform measurements in a scalable manner for large and complex networks. In this paper we show how end-to end delay measurements of multicast traffic can be used to estimate packet delay variance on each link of a logical multicast tree. The method does not depend on cooperation from intervening network elements; multicast probing is bandwidth efficient. We establish desirable statistical properties of the estimator, namely consistency and asymptotic normality. We evaluate the approach through model based and network simulations. The approach extends to the estimation of higher order moments of the link delay distribution.},
keywords={multicast communication;packet switching;telecommunication traffic;statistical analysis;delay estimation;estimation theory;multicast inference;packet delay variance;interior network links;end to end measurement;network performance diagnosis;intervening network elements;performance degradation;end-to end delay measurements;multicast traffic;logical multicast tree;multicast probing;desirable statistical properties;consistency;asymptotic normality;model based simulations;network simulations;higher order moments;link delay distribution;Delay estimation;Loss measurement;Degradation;Telecommunication traffic;Force measurement;Probes;Performance evaluation;Complex networks;Queueing analysis;Estimation theory},
doi={10.1109/INFCOM.2000.832532},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832533,
author={S. G. Dykes and K. A. Robbins and C. L. Jeffery},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An empirical evaluation of client-side server selection algorithms},
year={2000},
volume={3},
number={},
pages={1361-1370 vol.3},
abstract={Efficient server selection algorithms reduce retrieval time for objects replicated on different servers and are an important component of Internet cache architectures. This paper empirically evaluates six client-side server selection algorithms. The study compares two statistical algorithms, one using median bandwidth and the other median latency, a dynamic probe algorithm, two hybrid algorithms, and random selection. The server pool includes a topologically dispersed set of United States state government Web servers. Experiments were run on three clients in different cities and on different regional networks. The study examines the effects of time-of day, client resources, and server proximity. Differences in performance highlight the degree of algorithm adaptability and the effect that network upgrades can have on statistical estimators. Dynamic network probing performs as well or better than the statistical bandwidth algorithm and the two probe bandwidth hybrid algorithms. The statistical latency algorithm is clearly worse, but does outperform random selection.},
keywords={network servers;Internet;cache storage;statistical analysis;search engines;parameter estimation;client-side server selection algorithms;retrieval time;Internet cache architectures;statistical algorithms;median bandwidth;median latency;dynamic probe algorithm;hybrid algorithms;random selection;server pool;United States state government Web servers;regional networks;client resources;server proximity;algorithm adaptability;network upgrades;statistical estimators;statistical latency algorithm;Network servers;Web server;Delay;Bandwidth;Internet;Probes;Computer science;Telecommunication traffic;Hardware;Availability},
doi={10.1109/INFCOM.2000.832533},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832534,
author={R. Govindan and H. Tangmunarunkit},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Heuristics for Internet map discovery},
year={2000},
volume={3},
number={},
pages={1371-1380 vol.3},
abstract={Mercator is a program that uses hop-limited probes-the same primitive used in traceroute-to infer an Internet map. It uses informed random address probing to carefully exploring the IP address space when determining router adjacencies, uses source-route capable routers wherever possible to enhance the fidelity of the resulting map, and employs novel mechanisms for resolving aliases (interfaces belonging to the same router). This paper describes the design of these heuristics and our experiences with Mercator, and presents some preliminary analysis of the resulting Internet map.},
keywords={Internet;telecommunication network routing;telecommunication computing;network topology;Internet map discovery heuristics;Mercator;hop-limited probes;informed random address probing;IP address space;router adjacencies;source-route capable routers;Internet;Probes;Databases;Routing;IP networks;Web server},
doi={10.1109/INFCOM.2000.832534},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832535,
author={G. R. Malan and D. Watson and F. Jahanian and P. Howell},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Transport and application protocol scrubbing},
year={2000},
volume={3},
number={},
pages={1381-1390 vol.3},
abstract={This paper describes the design and implementation of a protocol scrubber, a transparent interposition mechanism for explicitly removing network attacks at both the transport and application protocol layers. The transport scrubber supports downstream passive network-based intrusion detection systems; whereas the application scrubbing mechanism supports transparent fail-closed active network-based intrusion detection systems. The transport scrubber's role is to convert ambiguous network flows into well-behaved flows that are unequivocally interpreted by all downstream endpoints. As an example, this paper presents the implementation of a TCP/IP scrubber that eliminates insertion and evasion attacks-attacks that use ambiguities to subvert detection-on passive network-based intrusion detection systems, while preserving high performance. The application protocol scrubbing mechanism is used as a substrate for building fail-closed active network based intrusion detections systems that can respond to attacks by eluding or modifying application data flows in real-time. This paper presents the high performance implementation of a general purpose transparent application-level scrubbing toolkit in the FreeBSD kernel.},
keywords={transport protocols;protocols;telecommunication security;software tools;telecommunication computing;Internet;security of data;transport protocol scrubbing;application protocol scrubbing;transparent interposition mechanism;network attacks;protocol layers;downstream passive network-based intrusion detection;transparent fail-closed active network-based intrusion detection;ambiguous network flows;downstream endpoints;TCP/IP scrubber;insertion attacks;evasion attacks;FreeBSD kernel;transparent application-level scrubbing toolkit;Internet;Transport protocols;Intrusion detection;Application software;Real time systems;Kernel;Business;Banking;Mission critical systems;Monitoring;Pattern recognition},
doi={10.1109/INFCOM.2000.832535},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832536,
author={A. Dailianas and Y. Yemini and D. Florissi and H. Huang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={MarketNet: market-based protection of network systems and services-an application to SNMP protection},
year={2000},
volume={3},
number={},
pages={1391-1400 vol.3},
abstract={This paper describes novel protection technologies, developed by the MarketNet project at Columbia University, that shifts power from attackers to defenders, giving the defenders control over the exposure to attacks and over detectability and accountability of attackers. MarketNet uses market-based techniques to regulate access to resources. Access to a resource must be paid-for with currency issued by its domain. Domains can control the power of attackers by limiting the budgets allocated to them, and control the exposure of resources by setting their prices, effectively providing a quantifiable access control mechanism. Domains can monitor currency flows and use uniform resource-independent statistical algorithms to correlate and detect access anomalies indicating potential attacks. Currency is marked with unique identifiers that permit domains to establish verifiable accountability in accessing their resources. Domains control and fine tune their exposure to attacks; adjust this exposure in response to emerging risks; detect intrusion attacks through automated, uniform statistical analysis of currency flows; and establish coordinated response to attacks. MarketNet mechanisms unify and kernelize global information systems protection by containing all protection logic in a small core of software components. The paper presents the architecture and operation of MarketNet along with the design and implementation of the main architectural components. The paper illustrates the application of MarketNet to the protection of the simple network management protocol (SNMP) and compares it with the security features offered by SNMPv3.},
keywords={telecommunication security;security of data;statistical analysis;network topology;telecommunication network management;protocols;authorisation;information systems;Internet;Columbia University;market-based protection;network systems;network services;SNMP protection;MarketNet project;quantifiable access control mechanism;currency flows;uniform resource-independent statistical algorithm;access anomalies;verifiable accountability;emerging risks;intrusion attacks;global information systems protection;protection logic;simple network management protocol;SNMPv3;Internet;Power system protection;Resource management;Access control;Monitoring;Automatic control;Statistical analysis;Management information systems;Logic;Computer architecture;Application software},
doi={10.1109/INFCOM.2000.832536},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832537,
author={M. Mut Puigserver and J. L. Ferrer Gomila and L. Huguet i Rotger},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Certified electronic mail protocol resistant to a minority of malicious third parties},
year={2000},
volume={3},
number={},
pages={1401-1405 vol.3},
abstract={We present the design of a protocol for certified e-mail. Some proposed certified e-mail protocols involve a third party in order to guarantee a fair exchange. Users, therefore, have to deposit a great amount of trust in a remote third party. In addition to that, the third party can become a communication bottleneck. We propose a protocol that involves an organisation of third parties, but only in case of exception. It reduces the amount of trust deposited in the third parties, because a minority of malicious third parties cannot compromise the fairness of the exchange, since all the third parties make a decision voted on by members.},
keywords={electronic mail;protocols;telecommunication security;public key cryptography;certified electronic mail protocol;malicious third parties;certified e-mail protocols;remote third party;communication bottleneck;public-key cryptographic primitives;Electronic mail;Public key cryptography;Cryptographic protocols;Postal services;Protection;Security;Concrete;Public key},
doi={10.1109/INFCOM.2000.832537},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832538,
author={P. McDaniel and S. Jamin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Windowed certificate revocation},
year={2000},
volume={3},
number={},
pages={1406-1414 vol.3},
abstract={The advent of electronic commerce and personal communications on the Internet has heightened concern over lack of privacy and security. Network services providing a wide range of security related guarantees are increasingly based on public key certificates. A fundamental problem inhibiting the wide acceptance of existing certificate distribution services is the lack of a scalable certificate revocation mechanism. We argue in this paper that the resource requirements of extant revocation mechanisms place a significant burden on certificate servers and network resources. We propose a novel mechanism called windowed revocation that satisfies the security policies and requirements of existing mechanisms and, at the same time, reduces the burden on certificate servers and network resources. We include a proof of correctness of windowed revocation and analyze worst case performance scenarios.},
keywords={electronic commerce;personal communication networks;Internet;data privacy;telecommunication security;public key cryptography;network servers;windowed certificate revocation;electronic commerce;personal communications;Internet;privacy;security;security related guarantees;public key certificates;certificate distribution services;scalable certificate revocation mechanism;certificate servers;network resources;security policies;worst case performance scenarios;Public key;Internet;Privacy;Network servers;Security;Sun;Engineering profession;Electronic commerce;Web server;Performance analysis},
doi={10.1109/INFCOM.2000.832538},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832539,
author={T. Bonald and M. May and J. -. Bolot},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Analytic evaluation of RED performance},
year={2000},
volume={3},
number={},
pages={1415-1424 vol.3},
abstract={End-to-end congestion control mechanisms such as those in TCP are not enough to prevent congestion collapse in the Internet, and they must be supplemented by control mechanisms inside the network. The IRTF has singled out random early detection (RED) as one queue management scheme recommended for rapid deployment throughout the Internet. However, RED is not a thoroughly understood scheme-witness for example how the recommended parameter setting, or even the various benefits RED is claimed to provide, have changed over the past few years. In this paper, we describe simple analytic models for RED, and use these models to quantify the benefits (or lack thereof) brought about by RED. In particular, we examine the impact of RED on the loss and delay suffered by bursty and less bursty traffic (such as TCP and UDP traffic, respectively). We find that: (i) RED does eliminate the higher loss bias against bursty traffic observed with tail drop, but not by decreasing the loss rate of bursty traffic, rather by increasing that of non bursty traffic; (ii) the number of consecutive packet drops is higher with RED than tail drop, suggesting RED might not help as anticipated with the global synchronization of TCP flows; (iii) RED can be used to control the average queueing delay in routers and hence the end to end delay, but increases the jitter of non bursty streams. Thus, applications that generate smooth traffic, such as interactive audio applications, will suffer higher loss rates and require large playout buffers, thereby negating at least in part the lower mean delay brought about by RED.},
keywords={Internet;telecommunication congestion control;queueing theory;telecommunication traffic;packet switching;synchronisation;telecommunication network routing;jitter;transport protocols;RED performance;end-to-end congestion control mechanisms;TCP;Internet;bursty traffic;IRTF;random early detection;queue management scheme;TCP traffic;UDP traffic;loss rate;consecutive packet drops;global synchronization;average queueing delay;end to end delay;jitter;interactive audio applications;large playout buffers;Performance analysis;Delay;Tail;Traffic control;Telecommunication congestion control;IP networks;TCPIP;Telecommunication control;Jitter;Streaming media},
doi={10.1109/INFCOM.2000.832539},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832540,
author={S. Athuraliya and D. Lapsley and S. Low},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An enhanced random early marking algorithm for Internet flow control},
year={2000},
volume={3},
number={},
pages={1425-1434 vol.3},
abstract={We propose an optimization based flow control for the Internet called random early marking (REM). In this paper we propose and evaluate an enhancement that attempts to speed up the convergence of REM in the face of large feedback delays. REM can be regarded as an implementation of an optimization algorithm in a distributed network. The basic idea is to treat the optimization algorithm as a discrete time system and apply linear control techniques to stabilize its transient. We show that the modified algorithm is stable globally and converges exponentially locally. This algorithm translates into an enhanced REM scheme and we illustrate the performance improvement through simulation.},
keywords={Internet;telecommunication control;optimisation;convergence;feedback;discrete time systems;stability;enhanced random early marking algorithm;Internet flow control;optimization based flow control;random early marking;REM;convergence;large feedback delays;distributed network;discrete time system;linear control techniques;global stability;Internet;Feedback;Convergence;Delay;Control systems;Communication system control;Aggregates;Design optimization;Australia;Projection algorithms},
doi={10.1109/INFCOM.2000.832540},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832541,
author={V. Firoiu and M. Borden},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A study of active queue management for congestion control},
year={2000},
volume={3},
number={},
pages={1435-1444 vol.3},
abstract={In this work, we investigate mechanisms for Internet congestion control in general, and random early detection (RED) in particular. We first study the current proposals for RED implementation and identify several structural problems such as producing large traffic oscillations and introducing unnecessary overhead in the fast path forwarding. We model RED as a feedback control system and discover fundamental laws governing the traffic dynamics in TCP/IP networks. Based on this understanding, we derive a set of recommendations for the architecture and implementation of congestion control modules in routers, such as RED.},
keywords={queueing theory;telecommunication congestion control;computer network management;Internet;telecommunication traffic;feedback;transport protocols;telecommunication network routing;active queue management;random early detection;Internet congestion control;RED implementation;large traffic oscillations;unnecessary overhead;fast path forwarding;feedback control system;traffic dynamics;TCP/IP networks;congestion control modules;routers;Traffic control;Feedback control;IP networks;Proposals;Communication system traffic control;Control systems;TCPIP;Stability;Queueing analysis;Protocols},
doi={10.1109/INFCOM.2000.832541},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832542,
author={Jun Xu and M. Singhal and J. Degroat},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A novel cache architecture to support layer-four packet classification at memory access speeds},
year={2000},
volume={3},
number={},
pages={1445-1454 vol.3},
abstract={Existing and emerging layer-4 switching technologies require packet classification to be performed on more than one header field, known as layer-4 lookup. Currently, the fastest general layer-8 lookup scheme delivers a throughput of 1 million lookups per second (MLPS), far off from 25/75 MLPS needed to support 50/150 Gbps layer-4 router. We propose the use of route caching to speed up layer-4 lookup, and design and implement a cache architecture for this purpose. We investigated the locality behavior of the Interent traffic (at layer-4) and propose a near-LRU algorithm that can best harness this behavior. In implementation, to best approximate fully-associative near-LRU using relatively inexpensive set-associative hardware, we invented a dynamic set-associative scheme that exploits the nice properties of N-universal hash functions. The cache architecture achieves a high and stable hit ratio above 90 percent and a fast throughput up to 75 MLPS at a reasonable cost.},
keywords={cache storage;packet switching;table lookup;telecommunication network routing;Internet;telecommunication traffic;cache architecture;layer-four packet classification;memory access speeds;layer-4 switching technologies;layer-4 lookup;locality behavior;Interent traffic;near-LRU algorithm;fully-associative near-LRU;set-associative hardware;dynamic set-associative scheme;N-universal hash functions;hit ratio;Throughput;Packet switching;Internet;Random access memory;Computational Intelligence Society;Hardware;Costs;Bandwidth;Virtual private networks;Multicast protocols},
doi={10.1109/INFCOM.2000.832542},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832543,
author={C. Adjih and P. Jacquet and P. Robert},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Differentiated admission control in large networks},
year={2000},
volume={3},
number={},
pages={1455-1460 vol.3},
abstract={This paper proposes a simple but effective admission control algorithm for integrated services packet networks. The admission control scheme, based on stochastic control, aims at ensuring user discrimination, by enforcing different call blocking probabilities. The queueing behavior of reservations is analytically characterized in the absence of admission control. From this, call blocking probabilities and analytical estimates of the performance of admission control are derived, allowing proper tuning of the algorithm. Simulations illustrate the effectiveness of the algorithm.},
keywords={telecommunication congestion control;packet switching;stochastic processes;telecommunication control;queueing theory;probability;computer networks;differentiated admission control;large networks;integrated services packet networks;stochastic control;call blocking probabilities;queueing behavior;computer networks;Admission control;Intelligent networks;Bandwidth;Quality of service;Intserv networks;Stochastic processes;Performance analysis;Cable TV;Queueing analysis;Algorithm design and analysis},
doi={10.1109/INFCOM.2000.832543},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832544,
author={G. Bianchi and A. Capone and C. Petrioli},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Throughput analysis of end-to-end measurement-based admission control in IP},
year={2000},
volume={3},
number={},
pages={1461-1470 vol.3},
abstract={This paper introduces approximate analytical models to evaluate the performance of end-to-end measurement based connection admission control (EMBAC) mechanisms, devised for the setup of real time flows over the Internet. These mechanisms rely on users probing the current congestion status of their required network path using a succession of probing packets. If the probing rate measured at the end receivers is greater than a certain threshold, users are allowed to switch to a phase of data exchange; otherwise they abort the call setup attempts. In conformance with the differentiated services framework, routers are oblivious to individual flows, and only need to give higher priority to data packets than to probing traffic. Despite the approximations introduced to make the analysis tractable, our model appears to be extremely accurate for a scenario of constant rate connections. Much less accurate, but useful as a possible starting point for future work, is the extension of the model to a scenario of variable rate connections. Simulation results are also presented in the paper to gain additional quantitative insights on the effectiveness of EMBAC to provide support for tight QoS requirements.},
keywords={telecommunication congestion control;Internet;approximation theory;packet switching;quality of service;throughput analysis;end-to-end measurement-based admission control;IP;approximate analytical models;EMBAC;Internet;required network path;probing packets;data exchange;call setup;differentiated services framework;probing traffic;constant rate connections;variable rate connections;QoS requirements;Throughput;Admission control;Quality of service;Web and internet services;Analytical models;Phase measurement;Switches;Performance analysis;Traffic control;Mouth},
doi={10.1109/INFCOM.2000.832544},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832545,
author={C. Cetinkaya and E. W. Knightly},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Egress admission control},
year={2000},
volume={3},
number={},
pages={1471-1480 vol.3},
abstract={Provisioning multiple service classes with different performance characteristics (e.g., throughput and delay) is an important challenge for future packet networks. However, in large-scale networks, individually managing each traffic flow on each of its traversed routers has fundamental scalability limitations, in both the control plane's requirements for signaling, state management, and admission control, and the data plane's requirements for per-flow scheduling mechanisms. In this paper, we develop a scalable technique for quality-of-service management termed egress admission control. In our approach, resource management and admission control are performed only at egress routers, without any coordination among backbone nodes or per-flow management. Our key technique is to develop a framework for admission control under a general "black box" model, which allows for cross traffic that cannot be directly measured, and scheduling policies that may be ill-described across many network nodes. By monitoring and controlling egress routers' class-based arrival and service envelopes, we show how network services can be provisioned via scalable control at the network edge. We illustrate the performance of our approach with a set of simulation experiments using highly bursty traffic flows and find that despite our use of coarse-grained system control, our approach is able to accurately control the system's admissible region under a wide range of conditions.},
keywords={telecommunication congestion control;packet switching;quality of service;telecommunication network management;telecommunication traffic;scheduling;telecommunication network routing;egress admission control;multiple service classes;performance characteristics;future packet networks;large-scale networks;coarse-grained system control;signaling;state management;admission control;scheduling mechanisms;quality-of-service management;resource management;egress router;black box model;class-based arrival envelopes;class-based service envelopes;network edge;bursty traffic flows;Admission control;Communication system traffic control;Resource management;Traffic control;Control system synthesis;Throughput;Large-scale systems;Scalability;Quality of service;Quality management},
doi={10.1109/INFCOM.2000.832545},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832546,
author={Yue Ma and J. J. Han and K. S. Trivedi},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Call admission control for reducing dropped calls in code division multiple access (CDMA) cellular systems},
year={2000},
volume={3},
number={},
pages={1481-1490 vol.3},
abstract={Call admission control algorithms that reduce dropped calls in CDMA cellular systems are discussed in this paper. The capacity of a CDMA system is confined by the interference of users from both inside and outside of the target cell. Earlier algorithms for call admission control have been based on the effective traffic load for the target cell if one call is accepted. These algorithms ignore the interference effect of the to-be-accepted call on the neighboring cells. In our algorithms, the call admission decision is based on the effective traffic loads for both the target cell and the neighboring cells. In addition, to prioritize handoff calls, we also introduce the idea of a soft guard channel, which reserves some traffic load exclusively for handoff calls. Stochastic reward net (SRN) models are constructed to compare the performance of the algorithms. The numerical results show that our algorithms can significantly reduce the dropped calls with a price of increasing the blocked calls. To show the potential gain due to our algorithms, we introduce two new metrics: the increased blocking ratio for our algorithms and the increased dropping ratio for the conventional algorithms. From the numerical results, it is shown that our algorithms can reduce the dropped calls significantly while the blocked calls are increased at a relatively small rate under both homogeneous and hot spot traffic loads.},
keywords={telecommunication congestion control;code division multiple access;cellular radio;radiofrequency interference;telecommunication traffic;telecommunication channels;stochastic processes;personal communication networks;call admission control;dropped calls;code division multiple access;CDMA cellular systems;target cell;interference effect;to-be-accepted call;neighboring cells;call admission decision;effective traffic loads;handoff calls;soft guard channel;stochastic reward net;SRN models;blocked calls;blocking ratio;dropping ratio;homogeneous traffic loads;hot spot traffic loads;personal communications services;Multiaccess communication;Call admission control;Telecommunication traffic;Stochastic processes;Personal communication networks;Radio frequency;Radiofrequency interference;Radio spectrum management;Software algorithms;Explosives},
doi={10.1109/INFCOM.2000.832546},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832547,
author={S. Sarkar and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Fair allocation of discrete bandwidth layers in multicast networks},
year={2000},
volume={3},
number={},
pages={1491-1500 vol.3},
abstract={We study fairness when receivers in a multicast network can not subscribe to fractional layers. This case arises when the source hierarchically encodes its signal and the hierarchical structure is predetermined. Unlike the case of the fractional layer allocation, which has been studied extensively in (Sarkar and Tassiulas, 1999), bandwidth can be allocated in discrete chunks only. Fairness issues become vastly different. Computation of lexicographic optimal rate allocation becomes NP-hard in this case, while lexicographic optimal rate allocation is polynomial complexity computable when fractional layers can be allocated. Furthermore, the maxmin fair rate vector may not exist in this case. We introduce a new notion of fairness, maximal fairness. We propose a polynomial complexity algorithm for computation of maximally fair rates allocated to various source-destination pairs. Even though maximal fairness is a weaker notion of fairness, it coincides with lexicographic optimality and maxmin fairness, when maxmin fair rate allocation exists. So the algorithm for computing maximally fair rate allocation computes maxmin fair rate allocation, when the latter exists.},
keywords={bandwidth allocation;multicast communication;computational complexity;polynomials;minimax techniques;optimisation;discrete bandwidth layers;multicast networks;hierarchical structure;lexicographic optimal rate allocation;polynomial complexity;maxmin fair rate vector;maximal fairness;source-destination pairs;maxmin fairness;maxmin fair rate allocation;Bandwidth;Intelligent networks;Polynomials;Computer networks;Educational institutions;Multicast algorithms;Counting circuits;NP-hard problem},
doi={10.1109/INFCOM.2000.832547},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832548,
author={A. Pitsillides and G. Stylianou and C. S. Pattichis and A. Sekercioglu and A. Vasilakos},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Bandwidth allocation for virtual paths (BAVP): investigation of performance of classical constrained and genetic algorithm based optimisation techniques},
year={2000},
volume={3},
number={},
pages={1501-1510 vol.3},
abstract={We investigate the performance of a classical constrained optimisation (CCO) algorithm and a constrained optimisation genetic algorithm (GA) for solving the bandwidth allocation for virtual paths (BAVP) problem. We compare throughput, fairness and time complexity of GA-BAVP and CCO-BAVP for several node topologies. The results on maximising the throughput obtained with GA-BAVP and CCO-BAVP are in close agreement, however when considering fairness GA-BAVP outperforms CCO-BAVP, especially for more complex topologies, like the 7-node network, without abundant link capacity. Convergence of the two algorithms appears similar, with GA-BAVP outperforming CCO-BAVP in initial stages, and vice-versa for longer time scales. However as the problem complexity increases the solution time for the genetic algorithm does not increase as fast as the classical constrained optimisation algorithm. A hybrid scheme is also introduced, combining the benefits of both algorithms. It exhibited better overall convergence rate but the same solution as CCO-BAVP.},
keywords={bandwidth allocation;genetic algorithms;constraint theory;optimisation;network topology;convergence of numerical methods;computational complexity;bandwidth allocation;virtual paths;BAVP;classical constrained optimisation algorithm;CCO;constrained optimisation genetic algorithm;throughput;fairness;time complexity;node topologies;7-node network;complex topologies;link capacity;solution time;hybrid scheme;overall convergence rate;Channel allocation;Bandwidth;Resource management;Constraint optimization;Genetic algorithms;Throughput;Asynchronous transfer mode;IP networks;Traffic control;Computer science},
doi={10.1109/INFCOM.2000.832548},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832549,
author={H. Yaiche and R. R. Mazumdar and C. Rosenberg},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Distributed algorithms for fair bandwidth allocation to elastic services in broadband networks},
year={2000},
volume={3},
number={},
pages={1511-1517 vol.3},
abstract={The Nash arbitration scheme from cooperative game theory provides a natural framework to address the allocation of available bandwidth in network links which is network (Pareto) optimal and satisfies precise notions of fairness. In this paper we propose two distributed bandwidth allocation schemes that allocate available bandwidths to elastic sources according to the Nash arbitration scheme. We prove convergence to the desired allocations for both algorithms. Finally we show how such a scheme can be implemented in a real network.},
keywords={distributed algorithms;bandwidth allocation;broadband networks;game theory;optimisation;convergence;telecommunication control;distributed algorithms;fair bandwidth allocation;elastic services;broadband networks;Nash arbitration scheme;cooperative game theory;network links;Pareto optimal allocation;convergence;rate flow control;Distributed algorithms;Channel allocation;Intelligent networks;Broadband communication;Bandwidth;Game theory;Convergence;Communication system control;Context-aware services;Bit rate},
doi={10.1109/INFCOM.2000.832549},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832550,
author={M. Charikar and J. Naor and B. Schieber},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Resource optimization in QoS multicast routing of real-time multimedia},
year={2000},
volume={3},
number={},
pages={1518-1527 vol.3},
abstract={We consider a network design problem, where applications require various levels of quality-of-service (QoS) while connections have limited performance. Suppose that a source needs to send a message to a heterogeneous set of receivers. The objective is to design a low cost multicast tree from the source that would provide the QoS levels (e.g., bandwidth) requested by the receivers. We assume that the QoS level required on a link is the maximum among the QoS levels of the receivers that are connected to the source through the link. In accordance, we define the cost of a link to be a function of the QoS level that it provides. This definition of cost makes this optimization problem more general than the classical Steiner tree problem. We consider several variants of this problem all of which are proved to be NP-hard. For the variant where QoS levels of a link can vary arbitrarily and the cost function is linear in its QoS level, we give a heuristic that achieves a multicast tree with cost at most a constant times the cost of an optimal multicast tree. The constant depends on the best constant approximation ratio of the classical Steiner tree problem. For the more general variant, where each link has a given QoS level and cost we present a heuristic that generates a multicast tree with cost O(min{logr,k}) times the cost of an optimal tree, where r denotes the number of receivers, and k denotes the number of different levels of QoS required. We generalize this result to hold for the case of many multicast groups.},
keywords={optimisation;quality of service;multicast communication;telecommunication network routing;multimedia communication;tree data structures;computational complexity;resource optimization;QoS multicast routing;real-time multimedia;network design problem;quality-of-service;low cost multicast tree;optimization problem;NP-hard problem;constant approximation ratio;classical Steiner tree problem;optimal tree;multicast groups;Routing;Cost function;Bandwidth;Quality of service;Computer science;Computer networks;Design optimization;Intelligent networks;Steiner trees;Helium},
doi={10.1109/INFCOM.2000.832550},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832551,
author={T. Hamann and J. Walrand},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A new fair window algorithm for ECN capable TCP (new-ECN)},
year={2000},
volume={3},
number={},
pages={1528-1536 vol.3},
abstract={In this paper we propose a modification of the explicit congestion notification (ECN) to correct the bias against connections with long round trip times (RTT) of TCP. The new-ECN algorithm achieves a fair sharing of the available bandwidth of a bottleneck gateway. The idea is to prevent a fast connection from opening its congestion window too quickly and to enable a slow connection to open its window more aggressively. This is done by modifying not only the congestion window size but also by modifying its rate of increase. Both are reduced while receiving marked packets and are increased during times of no congestion. We demonstrate the effect and performance of the new-ECN algorithm with the network simulator "ns" for different network topologies. Additionally, we study the TCP and ECN-TCP friendliness of the new-ECN algorithm. In this paper we only focus on the single bottleneck case. The behavior of new-ECN with multiple congested gateways needs further research.},
keywords={transport protocols;bandwidth allocation;telecommunication congestion control;network topology;computer networks;fair window algorithm;ECN capable TCP;new-ECN;explicit congestion notification;round trip times;available bandwidth;bottleneck gateway;congestion window;marked packets;network simulator;network topologies;ns simulator;computer networks;Bandwidth;Protocols;Computer network reliability;Jacobian matrices;Digital communication;Network topology;Programmable control;Adaptive control;Buffer overflow;Lead time reduction},
doi={10.1109/INFCOM.2000.832551},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832552,
author={T. Goff and J. Moronski and D. S. Phatak and V. Gupta},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Freeze-TCP: a true end-to-end TCP enhancement mechanism for mobile environments},
year={2000},
volume={3},
number={},
pages={1537-1545 vol.3},
abstract={Optimizing TCP (transport layer) for mobility has been researched extensively. We present a brief summary of existing results which indicates that most schemes require intermediaries (such as base stations) to monitor the TCP traffic and actively participate in flow control in order to enhance performance. Although these methods simulate end-to-end semantics, they do not comprise true end-to-end signaling. As a result, these techniques are not applicable when the IP payload is encrypted. For instance IPSEC, which is expected to be standard under IPv6, encrypts the entire IP payload making it impossible for intermediaries to monitor TCP traffic unless those entities are part of the security association. In addition, these schemes require changes (in the TCP/IP code) at intermediate nodes making it difficult for the mobile clients to inter-operate with the existing infrastructure. In this paper we explore the "freeze-TCP" mechanism which is a true end-to-end scheme and does not require the involvement of any intermediaries (such as base stations) for flow control. Furthermore, this scheme does not require any changes on the "sender side" or intermediate routers; changes in TCP code are restricted to the mobile client side, making it possible to fully inter-operate with the existing infrastructure. We then outline a method which integrates the best attributes of freeze-TCP and some existing solutions. Performance results highlight the importance of pro-active action/signaling by the mobile-host. The data indicate that in most cases, simply reacting to disconnections tends to yield lower performance than pro-active mechanisms such as freeze-TCP.},
keywords={transport protocols;mobile radio;telecommunication traffic;telecommunication control;telecommunication signalling;Internet;freeze-TCP;end-to-end TCP enhancement mechanism;mobile environments;transport layer;TCP traffic;flow control;end-to-end semantics;end-to-end signaling;IP payload;IPSEC;IPv6;security association;encryption;TCP/IP code;mobile clients;pro-active action/signaling;Internet;TCPIP;Base stations;Monitoring;Traffic control;Payloads;Cryptography;Sun;Security;Wireless networks;Wireless application protocol},
doi={10.1109/INFCOM.2000.832552},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832553,
author={U. Hengartner and J. Bolliger and T. Gross},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={TCP Vegas revisited},
year={2000},
volume={3},
number={},
pages={1546-1555 vol.3},
abstract={The innovative techniques of TCP Vegas have been the subject of much debate in recent years. Several studies have reported that TCP Vegas provides better performance than TCP Reno. However, the question of which of the new techniques are responsible for the impressive performance gains remains unanswered so far. This paper presents a detailed performance evaluation of TCP Vegas. By decomposing TCP Vegas into the various novel mechanisms proposed and assessing the effect of each of these mechanisms on performance, we show that the reported performance gains are achieved primarily by TCP Vegas's new techniques for slow start and congestion recovery. TCP Vegas's innovative congestion avoidance mechanism is shown to have only a minor influence on throughput. Furthermore, we find that the congestion avoidance mechanism exhibits fairness problems even if all competing connections operate with the same round trip time.},
keywords={transport protocols;software performance evaluation;telecommunication congestion control;telecommunication traffic;TCP Vegas;TCP Reno;performance evaluation;slow start;congestion recovery;congestion avoidance mechanism;throughput;fairness problems;round trip time;Throughput;Performance gain;Computer science;Protocols;Time measurement;Technological innovation;Bandwidth;Loss measurement},
doi={10.1109/INFCOM.2000.832553},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832554,
author={R. Cohen and Y. Hamo},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Balanced packet discard for improving TCP performance in ATM networks},
year={2000},
volume={3},
number={},
pages={1556-1565 vol.3},
abstract={TCP suffers from low performance over asynchronous transfer mode (ATM) networks. This is mainly because during phases of congestion, ATM drops cells without taking into account the effect this has on the upper layer protocols. Two main algorithms, called PPD and EPD, were proposed in the past for improving TCP performance. However they address one aspect of the problem, that has only small effect on the final performance. In this paper we propose an enhanced method for packet discard, called balanced packet discard (BPD), that improves TCP performance dramatically on congested networks and guarantees fairness among multiple connections. We show that BPD increases TCP throughput by more than 25% compared to EPD/PPD.},
keywords={asynchronous transfer mode;transport protocols;software performance evaluation;telecommunication congestion control;telecommunication traffic;packet switching;balanced packet discard;TCP;performance;ATM networks;asynchronous transfer mode;congestion;fairness guarantee;multiple connections;throughput;Intelligent networks;Asynchronous transfer mode;Switches;Transport protocols;Bandwidth;Internet;Performance loss;Computer science;Throughput;Degradation},
doi={10.1109/INFCOM.2000.832554},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832555,
author={S. Nelakuditi and Zhi-Li Zhang and R. P. Tsang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Adaptive proportional routing: a localized QoS routing approach},
year={2000},
volume={3},
number={},
pages={1566-1575 vol.3},
abstract={Most of the QoS routing schemes proposed so far require periodic exchange of QoS state information among routers, imposing both communication overhead on the network and processing overhead on core routers. Furthermore, stale QoS state information causes the performance of these QoS routing schemes to degrade drastically. In order to circumvent these problems, we focus on localized QoS routing schemes where the edge routers make routing decisions using only "local" information and thus reducing the overhead at core routers. We first describe virtual capacity-based routing (VCR), a theoretical scheme based on the notion of virtual capacity of a route. We then propose proportional sticky routing (PSR), an easily realizable approximation of VCR and analyze its performance. We demonstrate through extensive simulations that adaptive proportional routing is indeed a viable alternative to the global QoS routing approach.},
keywords={telecommunication network routing;simulation;quality of service;adaptive proportional routing;localized QoS routing;state information;edge routers;virtual capacity-based routing;proportional sticky routing;performance analysis;simulations;Routing;Degradation;Video recording;Performance analysis;Quality of service;Availability;Bandwidth;System performance;Statistics;Databases},
doi={10.1109/INFCOM.2000.832555},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832556,
author={D. Zappala},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Alternate path routing for multicast},
year={2000},
volume={3},
number={},
pages={1576-1585 vol.3},
abstract={Alternate path routing has been well-explored in telecommunication networks as a means of decreasing the call blocking rate and increasing network utility. However, aside from some work applying these concepts to unicast flows, alternate path routing has received little attention in the Internet community. We describe and evaluate an architecture for alternate path routing for multicast flows. For path installation, we design a receiver-oriented alternate path protocol and prove that it reconfigures multicast trees without introducing loops. For path computation, we propose a scalable local search heuristic that allows receivers to find alternate paths using only partial network information. We use a simulation study to demonstrate the ability of local search to find alternate paths approximately as well as a link-state protocol, with much lower overhead.},
keywords={telecommunication network routing;Internet;telecommunication congestion control;multicast communication;telecommunication traffic;protocols;trees (mathematics);search problems;network topology;simulation;alternate path routing;telecommunication networks;call blocking rate;Internet;multicast flows;path installation;receiver-oriented alternate path protocol;multicast tree reconfiguration;path computation;scalable local search heuristic;partial network information;simulation;link-state protocol;Internet;Routing protocols;Unicast;Multicast protocols;Computer networks;Bandwidth;Telecommunication computing;Information science;Utility programs;Computer architecture},
doi={10.1109/INFCOM.2000.832556},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832557,
author={E. Altman and T. Jimenez and T. Basar and N. Shimkin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Competitive routing in networks with polynomial cost},
year={2000},
volume={3},
number={},
pages={1586-1593 vol.3},
abstract={We study a class of noncooperative general topology networks shared by N users. Each user has a given flow which it has to ship from a source to a destination. We consider a class of polynomial link cost functions, adopted originally in the context of road traffic modeling, and show that these costs have appealing properties that lead to predictable and efficient network flows. In particular, we show that the Nash equilibrium is unique, and is moreover efficient, i.e., it coincides with the solution of a corresponding global optimization problem with a single user. These properties make the cost structure attractive for traffic regulation and link pricing in telecommunication networks. We finally discuss the computation of the equilibrium in the special case of the affine cost structure for a topology of parallel links.},
keywords={telecommunication network routing;competitive algorithms;network topology;telecommunication congestion control;telecommunication traffic;optimisation;costing;computational complexity;competitive routing;noncooperative general topology networks;polynomial link cost function;predictable network flows;Nash equilibrium;global optimization problem;traffic regulation;link pricing;telecommunication networks;affine cost structure;parallel link topology;Routing;Polynomials;Telecommunication network topology;Cost function;Telecommunication traffic;Marine vehicles;Roads;Traffic control;Context modeling;Predictive models},
doi={10.1109/INFCOM.2000.832557},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832558,
author={Shigang Chen and K. Nahrstedt and Y. Shavitt},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A QoS-aware multicast routing protocol},
year={2000},
volume={3},
number={},
pages={1594-1603 vol.3},
abstract={The future Internet is expected to support multicast applications with quality of service (QoS) requirements. To facilitate this, QoS multicast routing protocols are pivotal in enabling new receivers to join a multicast group. However, current routing protocols are either too restrictive in their search for a feasible path between a new receiver and the multicast tree, or burden the network with excessive overhead. We propose QMRP, a new Qos-aware multicast routing protocol. QMRP achieves scalability by significantly reducing the communication overhead in constructing a multicast tree, yet it retains a high chance of success. This is achieved by switching between single-path routing and multiple-path routing according to the current network conditions. The high-level design of QMRP makes it operable on top of any unicast routing algorithm both intra-domain and inter-domain. Its responsiveness is improved by using a termination mechanism which detects the failure as well as the success of routing without the use of timeout. In addition, QMRP always constructs loop-free multicast trees.},
keywords={quality of service;telecommunication network routing;Internet;protocols;multicast communication;trees (mathematics);network topology;telecommunication traffic;QoS;multicast routing protocol;Internet;quality of service;multicast group;QMRP;scalability;communication overhead;single-path routing;multiple-path routing;high-level design;intra-domain operation;inter-domain operation;termination mechanism;loop-free multicast trees;Multicast protocols;Routing protocols;Quality of service;Web and internet services;Scalability;Communication switching;Algorithm design and analysis;Unicast;Multicast algorithms;Delay},
doi={10.1109/INFCOM.2000.832558},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832559,
author={M. Ajmone Marsan and E. Leonardi and M. Mellia and F. Neri},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On the stability of input-buffer cell switches with speed-up},
year={2000},
volume={3},
number={},
pages={1604-1613 vol.3},
abstract={We consider cell-based switch architectures, whose internal switching matrix does not provide enough speed to avoid input buffering. These architectures require a scheduling algorithm to select at each slot a subset of input buffered cells which can be transferred towards output ports. The stability properties of several classes of scheduling algorithms are studied in the paper, using analytical techniques mainly based upon Lyapunov functions. Original stability conditions are derived for some scheduling algorithms that are being used today in high-performance switch architectures.},
keywords={stability;telecommunication switching;buffer storage;scheduling;Lyapunov methods;stability;input-buffer cell switches;speed-up;cell-based switch architectures;internal switching matrix;scheduling algorithm;Lyapunov functions;high-performance switch architectures;Switches;Fabrics;Scheduling algorithm;Packet switching;Buffer storage;Computer architecture;Stability analysis;Lyapunov method;Asynchronous transfer mode;IP networks},
doi={10.1109/INFCOM.2000.832559},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832560,
author={Cheng-Shang Chang and Wen-Jyh Chen and Hsiang-Yi Huang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Birkhoff-von Neumann input buffered crossbar switches},
year={2000},
volume={3},
number={},
pages={1614-1623 vol.3},
abstract={Previously, we proposed a scheduling algorithm that is capable of providing rate guarantees for input-buffered crossbar switches. The algorithm is based on a decomposition result by Birkhoff (1945) and von Neumann (1953) for a doubly substochastic matrix. An input buffered crossbar switch that uses such an algorithm is called the Birkhoff-von Neumann switch in this paper. For the Birkhoff-von Neumann switch, the rate guarantees are uniformly good for all non-uniform traffic, and it does not require framing or internal speedup. Our objective of this paper is to make the Birkhoff-von Neumann switch more complete and practical. We do so by addressing three topics: providing best-effort services in the Birkhoff-von Neumann switch, hardware implementation of the switch fabric, and multistage Birkhoff-von Neumann switches.},
keywords={multistage interconnection networks;scheduling;telecommunication traffic;matrix decomposition;buffer storage;stochastic processes;Birkhoff-von Neumann switches;input-buffered crossbar switches;decomposition result;doubly substochastic matrix;rate guarantees;non-uniform traffic;best-effort services;hardware implementation;multistage switches;scheduling algorithm;Switches;Delay;Throughput;Scheduling algorithm;Matrix decomposition;Hardware;Packet switching;Fabrics;Processor scheduling;Scalability},
doi={10.1109/INFCOM.2000.832560},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832561,
author={V. Tabatabaee and L. Georgiadis and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={QoS provisioning and tracking fluid policies in input queueing switches},
year={2000},
volume={3},
number={},
pages={1624-1633 vol.3},
abstract={The concept of tracking policies for fluid policies is extended to input queueing switches. It is considered that the speed up of the switch is 1. For the special case of 2/spl times/2 switches it is shown that tracking policy always exists. One of the interesting applications of the tracking policy in TDMA satellite switches is elaborated upon. For the general case of N/spl times/N switches a heuristic tracking policy is provided. The heuristic algorithm is based on two notions of port tracking and critical links. These notions can be employed in derivation of other heuristic tracking policies as well. Simulation results present the usefulness of the heuristic algorithm and the two basic concepts it relies upon.},
keywords={quality of service;queueing theory;telecommunication switching;tracking;time division multiple access;QoS provisioning;fluid policies;input queueing switches;tracking policies;TDMA;satellite switches;heuristic algorithm;port tracking;critical links;simulation;Switches;Scheduling;Packet switching;Jitter;Telecommunication traffic;Traffic control;Performance analysis;Educational institutions;Time division multiple access;Intserv networks},
doi={10.1109/INFCOM.2000.832561},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832562,
author={M. W. Goudreau and S. G. Kolliopoulos and S. B. Rao},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Scheduling algorithms for input-queued switches: randomized techniques and experimental evaluation},
year={2000},
volume={3},
number={},
pages={1634-1643 vol.3},
abstract={A basic problem faced by designers of high-bandwidth switches and routers is to provide effective techniques for scheduling the routing of cells through crossbars. The problem is particularly important under heavy loads or when quality-of-service (QoS) is to be supported. Much previous work on scheduling has focused on maximum bipartite matching (MBM), maximum weight bipartite matching (MWBM), and heuristics to approximate MBM and MWBM solutions. In this paper, we introduce the shakeup technique: a randomized approach that can be used in conjunction with a number of existing heuristics to substantially improve solution quality. The shakeup approach is conceptually simple and is supported by both theoretical and experimental results. In addition, this paper provides for the first time a framework for experimental scheduler analysis. We give extensive head-to-head comparisons of stability ranges for a number of previously proposed schedulers, and work towards the development of benchmark traffic types.},
keywords={scheduling;queueing theory;telecommunication switching;randomised algorithms;telecommunication network routing;telecommunication traffic;quality of service;stability;scheduling algorithms;input-queued switches;randomized techniques;high-bandwidth switches;cell routing;crossbars;heavy loads;quality of service;QoS;shakeup technique;stability ranges;benchmark traffic types;Scheduling algorithm;Switches;Quality of service;Traffic control;Bandwidth;Stability;Internet;Jitter;Fabrics;Routing},
doi={10.1109/INFCOM.2000.832562},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832563,
author={I. Stoica and T. S. E. Ng and Hui Zhang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={REUNITE: a recursive unicast approach to multicast},
year={2000},
volume={3},
number={},
pages={1644-1653 vol.3},
abstract={We propose a new multicast protocol called REUNITE. The key idea of REUNITE is to use recursive unicast trees to implement multicast service. REUNITE does not use class D IP addresses. Instead, both group identification and data forwarding are based on unicast IP addresses. Compared with existing IP multicast protocols, REUNITE has several unique properties. First, only routers that are acting as multicast tree branching points for a group need to keep the multicast forwarding state of the group. All other non-branching-point routers simply forward data packets by unicast routing. In addition, REUNITE can be incrementally deployed in the sense that it works even if only a subset of the routers implement the protocol. Furthermore, REUNITE supports load balancing and graceful degradation such that when a router does not have resources (forwarding table entry, buffer space, processing power) to support additional multicast groups, the branching can be automatically migrated to other less-loaded routers. Finally, sender access control can be easily supported in REUNITE.},
keywords={protocols;telecommunication network routing;multicast communication;telecommunication traffic;trees (mathematics);REUNITE;multicast protocol;recursive unicast trees;multicast service;group identification;data forwarding;routers;load balancing;graceful degradation;traffic load;sender access control;Unicast;Multicast protocols;Routing protocols;Access control;Access protocols;Load management;Degradation;Research and development;Internet;Costs},
doi={10.1109/INFCOM.2000.832563},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832564,
author={D. Thaler and M. Handley},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On the aggregatability of multicast forwarding state},
year={2000},
volume={3},
number={},
pages={1654-1663 vol.3},
abstract={It has been claimed that multicast state cannot be aggregated. In this paper, we will debunk this myth and present a simple technique that can be used to aggregate multicast forwarding state. In particular, we present an interface-centric data structure model which allows aggregation of ranges of multicast addresses in the forwarding table. Understanding the limits of possible aggregation is critical to our knowledge of how IP multicast will scale as it becomes widely deployed. We show through analysis and simulation that some aggregation is possible, even under purely random address allocation and purely random group membership distribution. We further show how other methods of allocation can significantly improve the ability to aggregate, and how non-random distributions of membership can affect aggregation both positively and negatively.},
keywords={multicast communication;data structures;protocols;telecommunication network routing;Internet;aggregatability;multicast forwarding state;interface-centric data structure;multicast addresses;forwarding table;IP multicast;scalability;simulation;random address allocation;random group membership distribution;non-random distributions;Multicast protocols;Aggregates;Internet;Routing protocols;Interface states;Scalability;Marine vehicles;Traffic control},
doi={10.1109/INFCOM.2000.832564},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832565,
author={C. R. Lin and Kai-Min Wang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Mobile multicast support in IP networks},
year={2000},
volume={3},
number={},
pages={1664-1672 vol.3},
abstract={In this paper, we present an alternative design, RBMoM (Range-Based Mobile Multicast), for efficiently supporting multicast for mobile hosts on the Internet. The current version of Mobile IP proposes two approaches to supporting mobile multicast, which are remote subscription and bi-directional tunneling. The former provides the shortest routes for delivery of multicast datagrams to mobile hosts; the latter hides host mobility from all other members of the group (therefore, no any overhead in the multicast tree maintenance). RBMoM intends to trade off between the shortest delivery path and the frequency of the multicast tree reconfiguration by controlling the service range of the multicast home agent (MHA). Actually, we find that remote subscription and bi-directional tunneling are the extremes of RBMoM. From the point of view of the MHA and the service range concepts, RBMoM is a generalization of both approaches and a unifying mobile multicast approach. The simulation results show that RBMoM can adapt to the fluctuation of both host movement and the number of mobile group members, and has much better performance than the two current IP mobile multicast solutions.},
keywords={multicast communication;protocols;Internet;telecommunication network routing;mobile computing;trees (mathematics);simulation;performance evaluation;quality of service;IP networks;RBMoM;Range-Based Mobile Multicast;mobile hosts;Internet;shortest delivery path;multicast tree reconfiguration;service range control;multicast home agent;remote subscription;bi-directional tunneling;simulation;performance;Intelligent networks;IP networks;Subscriptions;Tunneling;Multicast protocols;Internet;Bidirectional control;Mobile computing;Frequency;Unicast},
doi={10.1109/INFCOM.2000.832565},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832566,
author={R. Cohen and E. Felstaine and R. Emek},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Framework for multicast in hierarchical networks},
year={2000},
volume={3},
number={},
pages={1673-1682 vol.3},
abstract={We propose a framework for the creation and maintenance of multicast trees in hierarchical ATM networks. This framework aims at coping with an inherent difficulty of topology aggregation in such networks. The main idea of the proposed framework is to distribute the tree topology information among a set of hierarchical multicast group servers (MGS) nominated for each multicast tree, while keeping regions that do not have a member in the multicast group unaware of the tree. The framework can be employed with every multicast routing algorithm designed for non-hierarchical networks.},
keywords={asynchronous transfer mode;multicast communication;trees (mathematics);network topology;telecommunication network routing;hierarchical networks;multicast trees;ATM networks;topology aggregation;tree topology information;multicast group servers;multicast routing;Intelligent networks;Peer to peer computing;Asynchronous transfer mode;Network topology;Switches;Tree graphs;Routing;Communication switching;Packet switching;Computer science},
doi={10.1109/INFCOM.2000.832566},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832567,
author={Tsunyi Tuan and Kihong Park},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Multiple time scale redundancy control for QoS-sensitive transport of real-time traffic},
year={2000},
volume={3},
number={},
pages={1683-1692 vol.3},
abstract={End-to-end QoS control over best-effort and differentiated service networks which exhibit variability in their exported service properties looms as an important challenge. In previous work, we have shown how packet-level adaptive FEC can be used in dynamic networks to facilitate invariant user-specified QoS in an end-to-end manner. This paper addresses two important problems-self-similar burstiness and performance degradation of reactive controls subject to long feedback loops-complementing the stability/optimality considerations studied earlier. First, for adaptive redundancy control to be effective, its susceptibility to correlated packet drops and queueing delays stemming from self-similar burstiness must be fortified. Second, to preserve FEC's viability over ARQ when transporting real-time traffic in WAN, preactivity must be injected to offset the performance degradation of reactive feedback controls when subject to long RTT. In this paper, we use the recently advanced multiple-time-scale congestion control framework-first investigated in the throughput maximization context-to endow adaptive redundancy control with both selective protection against self-similar burstiness as well as preactivity to feedback redundancy control. We analyze, implement, and benchmark our protocol-AFEC-MT-in the context of transporting periodic real-time traffic, in particular, MPEG video.},
keywords={quality of service;telecommunication traffic;redundancy;telecommunication congestion control;queueing theory;adaptive control;performance evaluation;transport protocols;feedback;delays;forward error correction;automatic repeat request;wide area networks;visual communication;QoS-sensitive transport;real-time traffic;end-to-end QoS control;best-effort networks;differentiated service networks;self-similar burstiness;performance degradation;feedback loops;adaptive redundancy control;correlated packet drops;queueing delays;FEC;ARQ;WAN;preactivity;multiple-time-scale congestion control;AFEC-MT protocol;MPEG video;Redundancy;Degradation;Programmable control;Adaptive control;Traffic control;Diffserv networks;Optimal control;Feedback loop;Stability;Delay effects},
doi={10.1109/INFCOM.2000.832567},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832568,
author={Z. Sun and S. Kimura and Y. Ebihara},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Adaptive two-level unequal error protection convolutional code scheme for wireless ATM networks},
year={2000},
volume={3},
number={},
pages={1693-1697 vol.3},
abstract={Because the wireless asynchronous transfer mode (ATM) networks are often constrained with the limited link bandwidth and error-prone characteristics, forward error correction (FEC) is needed to improve their bit error rate performance. In this paper, a two-level punctured convolutional code (PCC) scheme is constructed to apply to a wireless ATM cell header and various payloads with the flexible unequal error protection (UEP). Since their perforation matrices can be programmable, the code rates of PCC are applicable to the different sensitivity of source-encoded symbols, even if only the same encoding and decoding hardware is used. Finally, the performance on Gaussian and fading channels is analyzed, which shows significant reductions in cell loss rate (CLR) and good balances for CLR and the payload bit error rate (BER).},
keywords={adaptive codes;channel coding;convolutional codes;error correction codes;forward error correction;asynchronous transfer mode;mobile radio;error statistics;source coding;Gaussian channels;fading channels;matrix algebra;adaptive code;two-level code;unequal error protection code;wireless ATM networks;asynchronous transfer mode;forward error correction;FEC;bit error rate performance;punctured convolutional code;cell header;perforation matrices;code rates;source-encoded symbols;Gaussian channels;fading channels;cell loss rate;BER;CLR;Error correction codes;Convolutional codes;Asynchronous transfer mode;Bit error rate;Forward error correction;Payloads;Bandwidth;Error correction;Wireless sensor networks;Linear matrix inequalities},
doi={10.1109/INFCOM.2000.832568},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832569,
author={Daji Qiao and K. G. Shin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A two-step adaptive error recovery scheme for video transmission over wireless networks},
year={2000},
volume={3},
number={},
pages={1698-1704 vol.3},
abstract={In this paper, we investigate the transmission of H.263 video sequences over wireless networks with error recovery provided by a two-step adaptive hybrid ARQ scheme using RS codes. Each video frame is divided into data packets for transmission. For each packet transmission, by using a simple table-driven approach, the best RS code is selected from a given set of codes to minimize the transmission overhead. Further, an additional adaptation step is used to guarantee certain QoS requirement. Simulation results show that the proposed error recovery scheme outperforms the traditional single-code schemes and the single-step error recovery schemes thanks to its adaptability to both the wireless channel conditions and the actual frame loss events.},
keywords={adaptive codes;channel coding;error correction codes;visual communication;packet radio networks;data communication;image sequences;Reed-Solomon codes;automatic repeat request;minimisation;table lookup;mobile radio;video coding;two-step adaptive error recovery;video transmission;wireless networks;H.263;video sequences;hybrid ARQ;RS codes;data packets;packet transmission;table-driven approach;transmission overhead minimization;QoS;frame loss events;wireless channel conditions;Wireless networks;Automatic repeat request;Forward error correction;Delay;Throughput;Video sequences;Quality of service;Error correction;Error correction codes;Redundancy},
doi={10.1109/INFCOM.2000.832569},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832570,
author={J. Rosenberg and Lili Qiu and H. Schulzrinne},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Integrating packet FEC into adaptive voice playout buffer algorithms on the Internet},
year={2000},
volume={3},
number={},
pages={1705-1714 vol.3},
abstract={Transport of real-time voice traffic on the Internet is difficult due to packet loss and jitter. Packet loss is handled primarily through a variety of different forward error correction (FEC) algorithms and local repair at the receiver. Jitter is compensated for by means of adaptive playout buffer algorithms at the receiver. Traditionally, these two mechanisms have been investigated in isolation. In this paper, we show the interactions between adaptive playout buffer algorithms and FEC, and demonstrate the need for coupling. We propose a number of novel playout buffer algorithms which provide this coupling, and demonstrate their effectiveness through simulations based on both network models and real network traces.},
keywords={telecommunication traffic;forward error correction;jitter;voice communication;buffer storage;packet switching;Internet telephony;packet FEC;adaptive voice playout buffer;Internet;real-time voice traffic;packet loss;jitter;forward error correction;local repair;coupling;Delay;Jitter;Forward error correction;Internet telephony;Reed-Solomon codes;Streaming media;Web and internet services;Circuits;Traffic control;Speech},
doi={10.1109/INFCOM.2000.832570},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832571,
author={A. Veres and M. Boda},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={The chaotic nature of TCP congestion control},
year={2000},
volume={3},
number={},
pages={1715-1723 vol.3},
abstract={In this paper we demonstrate how TCP congestion control can show chaotic behavior. We demonstrate the major features of chaotic systems in TCP/IP networks with examples. These features include unpredictability, extreme sensitivity to initial conditions and odd periodicity. Previous work has shown the fractal nature of aggregate TCP/IP traffic and one explanation to this phenomenon was that traffic can be approximated by a large number of ON/OFF sources where the random ON and/or OFF periods are of length described by a heavy-tailed distribution. In this paper we show that this argument is not necessary to explain self-similarity, neither is randomness is required. Rather, TCP itself as a deterministic process creates chaos, which generates self-similarity. This property is inherent in today's TCP/IP networks and it is independent of higher layer applications or protocols. The two causes, heavy-tailed ON/OFF and chaotic TCP together contribute to the phenomenon, called the fractal nature of Internet traffic.},
keywords={transport protocols;telecommunication congestion control;chaos;telecommunication traffic;fractals;Internet;congestion control;chaotic systems;TCP/IP networks;unpredictability;sensitivity;periodicity;self-similarity;fractal;deterministic process;heavy-tailed ON/OFF sources;Internet traffic;Chaos;Traffic control;Communication system traffic control;Telecommunication traffic;Fractals;Internet;Electronic mail;Aggregates;Protocols;World Wide Web},
doi={10.1109/INFCOM.2000.832571},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832572,
author={A. A. Abouzeid and S. Roy and M. Azizoglu},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Stochastic modeling of TCP over lossy links},
year={2000},
volume={3},
number={},
pages={1724-1733 vol.3},
abstract={An analytical framework for modeling the performance of a single TCP session in the presence of random packet loss is presented. A Markovian approach is developed that allows us to study both memoryless channels (IID packet loss) and channels with memory (correlated packet loss) modeled by a two-state continuous-time Gilbert model. The analytical results are validated against results using the ns simulator. It is shown that the model predicts throughput for LAN/WAN (low and high bandwidth-delay products) with good accuracy. Further, throughput for the IID loss model is found to be relatively insensitive to the probability density function (PDF) of the loss inter-arrival process. For channels with memory, we present an empirically validated rule of thumb to categorize the channel transition frequency.},
keywords={Markov processes;transport protocols;performance evaluation;probability;continuous time systems;memoryless systems;correlation theory;telecommunication traffic;local area networks;wide area networks;packet radio networks;queueing theory;stochastic modeling;TCP;lossy links;performance;random packet loss;Markovian approach;memoryless channels;correlated packet loss;two-state continuous-time Gilbert model;ns simulator;throughput;LAN;WAN;IID packet loss;probability density function;PDF;loss inter-arrival process;channel transition frequency;Stochastic processes;Analytical models;Throughput;Performance analysis;Performance loss;Memoryless systems;Predictive models;Local area networks;Wide area networks;Probability density function},
doi={10.1109/INFCOM.2000.832572},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832573,
author={P. Brown},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Resource sharing of TCP connections with different round trip times},
year={2000},
volume={3},
number={},
pages={1734-1741 vol.3},
abstract={The performance of TCP connections sharing a common link and the resulting link usage depends on the various round trip times along the connections. Expressions exist for these values only in the homogenous case and heuristics for the general case give uncertain results. In this paper we first derive an exact expression (in the setting of fluid models) for the window evolution of TCP connections with different round trip delays. We next apply this result in a particular context to derive expressions for the maximum window sizes and the throughput of TCP connections as well the idle periods and the utilization of the shared link. We show that a bias in favor of connections with short round trip delays persists even for large buffer sizes. First- and second-order approximations in buffer size are given respectively for small and large buffers. These expressions show that for small buffers small round trip times predominate in global performance while the opposite is true for large buffers.},
keywords={resource allocation;transport protocols;queueing theory;performance evaluation;telecommunication congestion control;optimisation;telecommunication traffic;buffer storage;approximation theory;resource sharing;TCP connections;round trip times;performance;common link;link usage;fluid models;window evolution;maximum window sizes;throughput;idle periods;buffer sizes;first-order approximations;second-order approximations;Resource management;Throughput;Fluid dynamics;Propagation delay;Telecommunications;Delay effects;Robustness;Genetic expression;System performance;Bandwidth},
doi={10.1109/INFCOM.2000.832573},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832574,
author={N. Cardwell and S. Savage and T. Anderson},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Modeling TCP latency},
year={2000},
volume={3},
number={},
pages={1742-1751 vol.3},
abstract={Several analytic models describe the steady-state throughput of bulk transfer TCP flows as a function of round trip time and packet loss rate. These models describe flows based on the assumption that they are long enough to sustain many packet losses. However, most TCP transfers across today's Internet are short enough to see few, if any, losses and consequently their performance is dominated by startup effects such as connection establishment and slow start. This paper extends the steady-state model proposed in Padhye et al. (1998), in order to capture these startup effects. The extended model characterizes the expected value and distribution of TCP connection establishment and data transfer latency as a function of transfer size, round trip time, and packet loss rate. Using simulations, controlled measurements of TCP transfers, and live Web measurements we show that, unlike earlier steady-state models for TCP performance, our extended model describes connection establishment and data transfer latency under a range of packet loss conditions, including no loss.},
keywords={transport protocols;delay estimation;telecommunication traffic;Internet;performance evaluation;TCP latency;modeling;steady-state throughput;startup effects;connection establishment;slow start;Internet;performance;data transfer latency;transfer size;packet loss rate;round trip time;Web measurements;Transport protocols},
doi={10.1109/INFCOM.2000.832574},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832575,
author={B. Schein and E. Modiano},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Quantifying the benefit of configurability in circuit-switched WDM ring networks},
year={2000},
volume={3},
number={},
pages={1752-1760 vol.3},
abstract={We attempt to characterize the gain in traffic capacity that a reconfigurable network offers over a fixed topology network. We define the gain as the ratio of the maximum offered loads that the two systems can support for a given blocking probability. We develop a system model to analytically predict the blocking probability for both the fixed and reconfigurable systems. This model is different from previous models developed to analyze the blocking probability in WDM networks in that it accounts for a port limitation at the nodes. We study high-bandwidth calls, where each call requires an entire wavelength. We find that reconfigurability offers a substantial performance improvement, particularly when the number of available wavelengths significantly exceeds the number of ports per node. In this case, we find that the gain approaches a factor of N/2 over a fixed topology unidirectional ring, and N/4 over a fixed topology bi-directional ring (where N is the number of nodes in the ring). We validate our model via simulation, and we find that it agrees strongly with the simulation results, particularly for a large number of ports per node. We also obtain upper and lower bounds on capacity for various ring topologies that give additional insight into the benefits of configurability.},
keywords={wavelength division multiplexing;circuit switching;telecommunication traffic;network topology;channel capacity;probability;telecommunication congestion control;optical fibre networks;configurability;circuit-switched networks;WDM;ring networks;reconfigurable network topology;traffic capacity;maximum offered loads;blocking probability;port limitation;high-bandwidth calls;performance;simulation;Intelligent networks;Wavelength division multiplexing;WDM networks;Network topology;Telecommunication traffic;Circuit topology;Optical fiber networks;Laboratories;Traffic control;Predictive models},
doi={10.1109/INFCOM.2000.832575},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832576,
author={G. Mohan and A. K. Somani},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Routing dependable connections with specified failure restoration guarantees in WDM networks},
year={2000},
volume={3},
number={},
pages={1761-1770 vol.3},
abstract={This paper considers the problem of dynamically establishing dependable connections (D-connections) with specified failure restoration guarantees in wavelength-routed wavelength division multiplexed (WDM) networks. We call a connection with fault-tolerant requirements a D-connection. We recommend using a proactive approach to fault-tolerance wherein a D-connection is identified with the establishment of a primary and a backup lightpath at the time of honoring the connection request. However, the backup lightpath may not be available to a connection throughout its existence. Upon occurrence of a fault, a failed connection is likely to find its backup path available with a certain specified guarantee. We develop algorithms to select routes and wavelengths to establish D-connections with specified failure restoration guarantees. The algorithms are based on a technique called primary-backup multiplexing. We present an efficient and computationally simple method to estimate the average number of connections per link for which the backup paths are not readily available upon occurrence of a link failure. This measure is used for selecting suitable primary and backup lightpaths for a connection. We conduct extensive simulation experiments to evaluate the effectiveness of the proposed algorithms on different networks. The results show that the blocking performance gain is attractive enough to allow some reduction in guarantee. In particular, under the light load conditions, more than 90% performance gain is achieved at the expense of less than 10% guarantee reduction.},
keywords={telecommunication network routing;fault tolerance;telecommunication network reliability;wavelength division multiplexing;optical fibre networks;telecommunication congestion control;telecommunication traffic;dependable connections;failure restoration guarantees;WDM networks;wavelength routing;wavelength division multiplexing;fault-tolerant requirements;backup lightpath;primary-backup multiplexing;primary lightpaths;simulation;blocking performance;load conditions;Intelligent networks;WDM networks;Fault tolerance;Wavelength routing;Wavelength division multiplexing;Performance gain;Optical buffering;Telecommunication traffic;Fault diagnosis;Computational modeling},
doi={10.1109/INFCOM.2000.832576},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832577,
author={Guangzhi Li and Rahul Simha},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On the wavelength assignment problem in multifiber WDM star and ring networks},
year={2000},
volume={3},
number={},
pages={1771-1780 vol.3},
abstract={This paper studies the off-line wavelength assignment problem in star and ring networks that deploy multiple fibers between nodes and use wavelength division multiplexing (WDM) for transmission. The results in this paper show that the ability to switch between fibers increases wavelength utilization. In particular, sharper per-fiber bounds on the number of required wavelengths are derived for the multifiber version of the assignment problem in star and ring networks. Additionally, the complexity of the problem is studied and several constrained versions of the problem are also considered for star and ring networks. A summary of contributions is provided in the first section.},
keywords={wavelength division multiplexing;optical fibre networks;network topology;constraint theory;multifiber networks;star networks;ring networks;WDM;off-line wavelength assignment problem;wavelength division multiplexing;wavelength utilization;per-fiber bounds;constrained versions;Wavelength assignment;Intelligent networks;Wavelength division multiplexing;Switches;Wavelength routing;Optical fiber networks;Upper bound;Computer science;Educational institutions;Bandwidth},
doi={10.1109/INFCOM.2000.832577},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832578,
author={Xijun Zhang and J. Wei and Chunming Qiao},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Constrained multicast routing in WDM networks with sparse light splitting},
year={2000},
volume={3},
number={},
pages={1781-1790 vol.3},
abstract={As WDM technology matures and multicast applications become increasingly popular, supporting multicast at the WDM layer becomes an important and yet challenging topic. In this paper, we study constrained multicast routing in WDM networks with sparse light splitting, i.e., where some switches are incapable of splitting light (or copying data in the optical domain). Specifically, we propose four WDM multicast routing algorithms, namely, Re-route-to Source, Re-route-to-Any, Member-First, and Member-Only. Given the network topology, multicast membership information, and light splitting capability of the switches, these algorithms construct a source-based multicast light-forest (consisting one or more multicast trees) for each multicast session. The performance of these algorithms are compared in terms of the average number of wavelengths used per forest (or multicast session), average number of branches involved (bandwidth) per forest as well as average number of hops encountered (delay) from a multicast source to a multicast member.},
keywords={wavelength division multiplexing;multicast communication;constraint theory;telecommunication network routing;optical fibre networks;network topology;trees (mathematics);constrained multicast routing;WDM networks;sparse light splitting;Re-route-to Source algorithm;Re-route-to-Any algorithm;Member-First algorithm;Member-Only algorithm;network topology;multicast membership information;multicast light-forest;multicast trees;performance;Routing;Intelligent networks;WDM networks;Wavelength division multiplexing;Bandwidth;Optical fiber networks;Optical switches;Multicast algorithms;Network topology;Propagation delay},
doi={10.1109/INFCOM.2000.832578},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832579,
author={A. Vidacs and J. T. Virtamo},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Parameter estimation of geometrically sampled fractional Brownian traffic},
year={2000},
volume={3},
number={},
pages={1791-1796 vol.3},
abstract={The parameter estimation of a traffic model based on the fractional Brownian motion (FBM) is studied. The model has three parameters: the mean rate m, variance parameter a and the Hurst parameter H. Explicit expressions for the maximum likelihood (ML) estimates m/spl circ/ and a/spl circ/ in terms of H are given, as well as the expression for the log likelihood function from which the estimate H/spl circ/ is obtained as the maximizing argument. A geometric sequence of sampling points, t/sub i/=/spl alpha//sup i/, is introduced, which fits neatly into the self-similar property of the process and also reduces the number of samples needed to cover several time scales. It is shown that by a proper 'descaling' the traffic process is stationary on this grid leading to a Toeplitz-type covariance matrix. Approximations for the inverted covariance matrix and its determinant are introduced. The accuracy of the estimations is studied by simulations. Comparisons with estimates obtained with linear sampling and with the wavelet-based A-V estimator show that the geometrical sampling indeed improves the accuracy of the estimate H/spl circ/ with a given number of samples.},
keywords={maximum likelihood estimation;Brownian motion;telecommunication traffic;fractals;sequences;approximation theory;Toeplitz matrices;covariance matrices;matrix inversion;determinants;sampling methods;parameter estimation;geometrically sampled traffic;fractional Brownian motion;Hurst parameter;maximum likelihood estimates;ML estimates;log likelihood function;geometric sequence;self-similar property;descaling;Toeplitz-type covariance matrix;approximations;inverted covariance matrix;determinant;simulations;Parameter estimation;Traffic control;Sampling methods;Maximum likelihood estimation;Covariance matrix;Telecommunication traffic;High-speed networks;Telematics;Brownian motion;Time measurement},
doi={10.1109/INFCOM.2000.832579},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832580,
author={S. Wright and Y. Viniotis},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Burstiness-class based queuing in ATM networks supporting delay QoS bounds},
year={2000},
volume={3},
number={},
pages={1797-1806 vol.3},
abstract={We propose a burstiness-class-based queuing (B-CBQ) scheme where connections are allocated to their classes based on a "burstiness" parameter derived from the leaky bucket source specifications. We derive delay bounds for burstiness-classes on per-switch and end-to-end basis. An optimization problem is defined and solved to find the optimal number of classes in order to minimize the delay bound through a switch for a connection admitted to the lowest burstiness-class. Finally, some simulation results are provided to illustrate the behavior of a B-CBQ switch.},
keywords={queueing theory;telecommunication traffic;asynchronous transfer mode;quality of service;delay estimation;minimisation;burstiness-class-based queuing;B-CBQ scheme;ATM networks;delay QoS bounds;leaky bucket source specifications;optimization problem;delay bound minimization;simulation;Intelligent networks;Delay;Asynchronous transfer mode;Switches;Traffic control;Telecommunication traffic;Resource management;Network servers;IP networks;Switching circuits},
doi={10.1109/INFCOM.2000.832580},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832581,
author={N. Modani and P. Dube and A. Kumar},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Measurement based optimal source shaping with a shaping + multiplexing delay constraint},
year={2000},
volume={3},
number={},
pages={1807-1816 vol.3},
abstract={Most on-line (i.e., not stored) variable bit rate sources would find it difficult to a priori declare the traffic parameters required by a connection admission control strategy. There is thus the problem of measurement-based on-line estimation of source parameters. In this paper we address the problem of selection of source parameters based on minimising a buffer-bandwidth cost function in the network, for a specified delay QoS violation probability. We consider the shaping delay plus first-hop multiplexing delay; this is adequate, for example, for n statistically identical packet voice sources being multiplexed at a PBX, or in approaches where the end-to-end delay bound is broken into per-hop delay bounds. Our approach yields a leaky bucket rate parameter /spl rho//sup */, and the sum of the shaper buffer and leaky bucket depth (B/sub s/+/spl sigma/). We show that, for a fluid source model, for a linear buffer-bandwidth cost function, and for lossless multiplexing, a sustainable rate parameter of /spl rho//sup */ and burst parameter of 0 yields the minimum cost. We propose and study a stochastic approximation algorithm for on-line estimation of /spl rho//sup */. We then use buffer-bandwidth cost considerations to arrive at an optimal leaky bucket depth /spl sigma//sup */>0 for lossy multiplexing of several statistically identical sources. The computation of /spl sigma//sup */ must be done at the network node. We show, by an example, the improvement in cost that is possible by lossy multiplexing and a positive /spl sigma//sup */.},
keywords={asynchronous transfer mode;minimisation;delay estimation;constraint theory;telecommunication congestion control;telecommunication traffic;stochastic processes;approximation theory;quality of service;buffer storage;probability;measurement-based source shaping;optimal source shaping;delay constraint;variable bit rate sources;connection admission control;on-line estimation;source parameters;buffer-bandwidth cost function;minimisation;QoS;violation probability;shaping delay;first-hop multiplexing delay;packet voice sources;PBX;end-to-end delay bound;leaky bucket rate parameter;fluid source model;lossless multiplexing;stochastic approximation algorithm;renegotiation;ATM;Cost function;Delay;Bit rate;Communication system traffic control;Admission control;Parameter estimation;Probability;Stochastic processes;Approximation algorithms;Computer networks},
doi={10.1109/INFCOM.2000.832581},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832582,
author={Y. Birk and N. Bloch},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Improving network performance with prioritized dispersal},
year={2000},
volume={3},
number={},
pages={1817-1826 vol.3},
abstract={Redundant traffic dispersal exploits the topological redundancy of networks and improves load balancing by replicating each message or partitioning it into several "data" packets and generating several "redundant" ones; all are then sent over different paths to the destination. The redundancy overcomes the "weakest link" problem, but increases the load. This paper introduces "prioritized dispersal", whereby "redundant" packets receive lower priority than the "data" ones. Moreover, the use of non-FCFS queuing policies for the redundant packets leads to the timely arrival of at least a fraction of them even under heavy load. Queuing-theoretic analysis shows the new schemes to substantially outperform non-prioritized ones in terms of both the blocking probability and that of delay exceeding a specified limit. One possible use of prioritized dispersal, which is discussed in this paper, is to improve the quality of service for best-effort traffic in ATM networks with multiple paths between nodes. Another is in conjunction with ad hoc path trunking. Additional likely uses include parallel access to mirrored data sites and reliable multicast.},
keywords={telecommunication traffic;redundancy;network topology;probability;quality of service;asynchronous transfer mode;queueing theory;data communication;telecommunication congestion control;delays;telecommunication network routing;network performance;prioritized dispersal;redundant traffic dispersal;topological redundancy;load balancing;network topology;data packets;load;non-FCFS queuing policies;queuing theory;performance;blocking probability;delay;quality of service;best-effort traffic;ATM networks;multiple paths;ad hoc path trunking;mirrored data sites;reliable multicast;Telecommunication traffic;Routing;Redundancy;Delay;Quality of service;Traffic control;Payloads;Error correction codes;Load management;Distributed power generation},
doi={10.1109/INFCOM.2000.832582},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832210,
author={Seong-Jun Oh and T. L. Olsen and K. M. Wasserman},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Distributed power control and spreading gain allocation in CDMA data networks},
year={2000},
volume={2},
number={},
pages={379-385 vol.2},
abstract={We study the radio resource allocation problem of distributed joint transmission power control and spreading gain allocation in a DS-CDMA mobile data network. The network consists of K base stations and M wireless data users. The data streams generated by the users are treated as best-effort traffic, in the sense that there are no pre-specified constraints on the quality of the radio channels. We are interested in designing a distributed algorithm that achieves maximal (or near-maximal in some reasonable sense) aggregate throughput, subject to peak power constraints. We provide an algorithm where base stations coordinate in a distributed fashion to control the powers and spreading gains of the users, and show that it converges to a Nash equilibrium point. In general, there may be multiple equilibrium points; however, certain structural properties of the throughput expression can be exploited to significantly trim the search space and induce an ordering on the users in each cell. The numerical results indicate that with these modifications, the algorithm frequently converges in just a few iterations to the throughput maximizing (globally optimal) power and spreading gain allocation.},
keywords={power control;distributed control;code division multiple access;spread spectrum communication;cellular radio;packet radio networks;telecommunication traffic;data communication;search problems;distributed algorithms;optimisation;telecommunication control;distributed power control;spreading gain allocation;radio resource allocation;DS-CDMA;mobile data network;base stations;wireless data users;best-effort traffic;distributed algorithm;maximal aggregate throughput;peak power constraints;Nash equilibrium point;convergence;multiple equilibrium points;search space;user ordering;cellular radio;Power control;Multiaccess communication;Throughput;Resource management;Base stations;Wireless sensor networks;Communication system traffic control;Algorithm design and analysis;Distributed algorithms;Aggregates},
doi={10.1109/INFCOM.2000.832210},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832211,
author={N. Bambos and S. Kandukuri},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Power controlled multiple access (PCMA) in wireless communication networks},
year={2000},
volume={2},
number={},
pages={386-395 vol.2},
abstract={We address the issue of power-controlled shared channel access in future wireless networks supporting packetized data traffic, beyond the voice-oriented continuous traffic primarily supported by current-generation networks. First, some novel formulations of the power control problem are introduced, which become progressively more general by incorporating various relevant costs. The analysis of the models under simple, yet natural, assumptions yields certain ubiquitous structural properties of 'optimal' power control algorithms. Based on such structural properties, we design a new family of distributed and asynchronous PCMA algorithms and evaluate them experimentally by simulation. They are found to perform substantially better than a standard benchmark algorithm for power control. This is a first step towards the design of full PCMA protocols for autonomous channel access in high-performance wireless networks.},
keywords={access protocols;power control;telecommunication control;cellular radio;telecommunication traffic;optimal control;channel allocation;packet radio networks;data communication;distributed algorithms;simulation;power-controlled multiple access;wireless communication networks;PCMA;shared channel access;packetized data traffic;optimal power control;distributed algorithms;asynchronous algorithms;simulation;performance evaluation;protocols;autonomous channel access;high-performance wireless networks;Communication system control;Wireless communication;Power control;Wireless networks;Communication system traffic control;Traffic control;Algorithm design and analysis;Costs;Wireless application protocol;Access protocols},
doi={10.1109/INFCOM.2000.832211},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832212,
author={C. F. Chiasserini and R. R. Rao},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Energy efficient battery management},
year={2000},
volume={2},
number={},
pages={396-403 vol.2},
abstract={A challenging aspect of mobile communications consists of exploring ways in which the available run time of the terminals can be maximized. In this paper we investigate battery management techniques that can dramatically improve the energy efficiency of radio communication devices. We consider an array of electrochemical cells connected in parallel. Through simple scheduling algorithms the discharge from each cell is properly shaped to optimize the charge recovery mechanism, without introducing any additional delay in supplying the required power. Then, a traffic management scheme, that exploits the knowledge of the cells' state of charge, is implemented to achieve a further improvement in the battery performance. In this case, the discharge demand may be delayed. Results indicate that the proposed battery management techniques improve system performance no matter which parameter values are chosen to characterize the cell behavior.},
keywords={secondary cells;telecommunication power supplies;cellular radio;scheduling;optimisation;telecommunication traffic;telecommunication network management;energy-efficient battery management;mobile communications;radio communication devices;electrochemical cell array;scheduling algorithms;cell discharge shaping;optimization;charge recovery mechanism;traffic management scheme;system performance;Energy efficiency;Battery management systems;Energy management;Power system management;Mobile communication;Radio spectrum management;Radio communication;Scheduling algorithm;Added delay;Power supplies},
doi={10.1109/INFCOM.2000.832212},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832213,
author={R. Ramanathan and R. Rosales-Hain},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Topology control of multihop wireless networks using transmit power adjustment},
year={2000},
volume={2},
number={},
pages={404-413 vol.2},
abstract={We consider the problem of adjusting the transmit powers of nodes in a multihop wireless network (also called an ad hoc network) to create a desired topology. We formulate it as a constrained optimization problem with two constraints-connectivity and biconnectivity, and one optimization objective-maximum power used. We present two centralized algorithms for use in static networks, and prove their optimality. For mobile networks, we present two distributed heuristics that adaptively adjust node transmit powers in response to topological changes and attempt to maintain a connected topology using minimum power. We analyze the throughput, delay, and power consumption of our algorithms using a prototype software implementation, an emulation of a power-controllable radio, and a detailed channel model. Our results show that the performance of multihop wireless networks in practice can be substantially increased with topology control.},
keywords={packet radio networks;network topology;telecommunication control;power control;optimisation;power consumption;constraint theory;mobile radio;distributed algorithms;distributed control;adaptive control;telecommunication traffic;delay estimation;topology control;multihop wireless networks;transmit power adjustment;ad hoc network;constrained optimization problem;connectivity;biconnectivity;maximum power;centralized algorithms;static networks;optimality;mobile networks;distributed heuristics;adaptive control;node transmit powers;minimum power;throughput;delay;power consumption;prototype software implementation;power-controllable radio emulation;channel model;performance;Network topology;Spread spectrum communication;Wireless networks;Constraint optimization;Ad hoc networks;Algorithm design and analysis;Throughput;Delay;Energy consumption;Software algorithms},
doi={10.1109/INFCOM.2000.832213},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832214,
author={N. Semret and R. R. -. Liao and A. T. Campbell and A. A. Lazar},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Peering and provisioning of differentiated Internet services},
year={2000},
volume={2},
number={},
pages={414-420 vol.2},
abstract={A key consideration in building differentiated network services is the feasibility of maintaining stable and consistent service level agreements across multiple networks where allocations are made only on the edges. To investigate this, we consider a game theoretic model of capacity provisioning in a differentiated services Internet. The players are one raw-capacity seller per network, one broker per service per network, and users, to play the roles of wholesellers, retailers and end users respectively in a two-tier wholeseller/retailer market. Based on this model, we are able to construct an explicit necessary and sufficient condition for the stability of the game, which determines the sustainability of a given set of SLA configurations among peering ISP. The analytical results are validated with simulations of user and broker dynamics, using distributed progressive second price auctions as the spot market mechanism in a scenario with three interconnected networks, and two services.},
keywords={Internet;quality of service;game theory;differentiated Internet services;service level agreements;game theoretic model;capacity provisioning;wholesellers;retailers;end users;stability;sustainability;peering ISP;distributed progressive second price auctions;spot market mechanism;interconnected networks;Web and internet services;Telecommunication traffic;Traffic control;Pricing;Stability;Analytical models;Quality of service;Bandwidth;Communication system traffic control;Resource management},
doi={10.1109/INFCOM.2000.832214},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832215,
author={T. Nandagopal and V. Venkitaraman and R. Sivakumar and V. Bharghavan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Delay differentiation and adaptation in core stateless networks},
year={2000},
volume={2},
number={},
pages={421-430 vol.2},
abstract={We present a core-stateless quality of service architecture for achieving delay differentiation between flows. There are two key components in our approach: (1) per-class per-hop relative average delay-the average queueing delay perceived by the packets in a delay class at a link is inversely proportional to the delay weight of the class; (2) per-flow end-to-end delay class adaptation-the delay class of a flow is dynamically adjusted based on its perceived end-to-end delay in order to maintain the desired end-to-end average delay requirement of the flow. We show through simulations and analysis that these two components can, in concert, support end-to-end delay differentiation between flows using only simple mechanisms at the core routers in the network.},
keywords={quality of service;Internet;telecommunication traffic;delays;queueing theory;packet switching;telecommunication network routing;delay differentiation;delay adaptation;core stateless networks;quality of service architecture;per-class relative average delay;per-hop relative average delay;average queueing delay;packets;per-flow delay class adaptation;end-to-end delay class adaptation;simulations;core routers;Intelligent networks;Quality of service;Diffserv networks;Delay effects;Web and internet services;Contracts;Laboratories;Analytical models;Current measurement;Intserv networks},
doi={10.1109/INFCOM.2000.832215},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832216,
author={W. A. Aiello and Y. Mansour and S. Rajagopolan and A. Rosen},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Competitive queue policies for differentiated services},
year={2000},
volume={2},
number={},
pages={431-440 vol.2},
abstract={We consider the setting of a network providing differentiated services. As is often the case in differentiated services, we assume the packets are tagged as either being high- or low-priority packets. Outgoing links in the network are serviced by a single FIFO queue. Our model gives a benefit of /spl alpha//spl ges/1 to each high-priority packet and a benefit of 1 to each low-priority packet. A queue policy controls which of the arriving packets are dropped and which enter the queue. Once a packet enters the queue it is eventually sent. The aim of a queue policy is to maximize the sum of the benefits of all the packets it delivers. We analyze and compare different queue policies for this problem using the competitive analysis approach, where the benefit of the online policy is compared to the benefit of an optimal offline policy. We derive both upper and lower bounds for the policies we consider, and in most cases our bounds are tight. We believe that competitive analysis gives important insight into the performance of these simple queuing policies.},
keywords={queueing theory;quality of service;packet switching;telecommunication control;optimisation;competitive queue policies;differentiated services;packet tagging;priority;FIFO queue;queue policy control;maximization;competitive analysis;online policy;optimal offline policy;performance;Telecommunication traffic;Contracts;Quality of service;Bandwidth;Traffic control;Queueing analysis;Web and internet services;Jitter},
doi={10.1109/INFCOM.2000.832216},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832217,
author={Yang Guo and Weibo Gong and D. Towsley},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Time-stepped hybrid simulation (TSHS) for large scale networks},
year={2000},
volume={2},
number={},
pages={441-450 vol.2},
abstract={Data communication networks have been experiencing tremendous growth in size, complexity, and heterogeneity over the last decade. This trend poses a significant challenge to the design of scalable performance evaluation methodologies. In this paper we propose time-stepped hybrid simulation (TSHS) to deal with the scalability issue faced by traditional packet-level discrete event simulation methods. TSHS is a framework that offers the user the flexibility to choose the simulation time scale so as to trade off the computational cost of the simulation with its fidelity. Simulation speedup is achieved by evaluating the system at coarser time-scales. The potential loss of simulation accuracy when fine-time-scale behavior is evaluated at a coarser time-scale is studied both analytically and experimentally.},
keywords={discrete event simulation;data communication;hybrid simulation;telecommunication networks;time-stepped hybrid simulation;large-scale networks;data communication networks;scalable performance evaluation;packet-level methods;discrete event simulation;speedup;Large-scale systems;Computational modeling;Discrete event simulation;Smoothing methods;Communication networks;Computational efficiency;Delay;Scalability;Analytical models;Performance analysis},
doi={10.1109/INFCOM.2000.832217},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832218,
author={T. Wong and R. Katz and S. McCanne},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An evaluation of preference clustering in large-scale multicast applications},
year={2000},
volume={2},
number={},
pages={451-460 vol.2},
abstract={The efficiency of using multicast in multi-party applications is constrained by preference heterogeneity, where receivers range in their preferences for application data. We examine an approach in which approximately similar sources and receivers are clustered into multicast groups. The goal is to maximize preference overlap within each group while satisfying the constraint of limited network resources. This allows an application to control the number of multicast groups it uses and thus the number of connections it maintains. We present a clustering framework with a two-phase algorithm: a bootstrapping phase that groups new sources and receivers together, and an adaptation phase that re-groups them in reaction to changes. The framework is generic in that an application can customize the algorithm according to its requirements and data characteristics. We conducted detail simulation experiments to study various issues and tradeoffs in applying clustering to different preference patterns and application classes. We found that clustering successfully exploits preference similarity and utilizes network resources more efficiently than when it is not used. Also, application-level hints can be incorporated in our algorithm, which are instrumental in the creation of an effective grouping of sources and receivers. Our algorithm handles changes dynamically, and also limits multicast "join" and "leave" disruption to the application.},
keywords={multicast communication;constraint theory;optimisation;preference clustering;large-scale multicast applications;multi-party applications;multicast groups;preference overlap maximization;constraint satisfaction;network resources;two-phase algorithm;bootstrapping phase;simulation;preference similarity;Large-scale systems;Clustering algorithms;Application software;Multicast algorithms;Unicast;Contracts;Instruments;Heuristic algorithms;Spine;IP networks},
doi={10.1109/INFCOM.2000.832218},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832219,
author={R. Gopalakrishnan and J. Griffioen and G. Hjalmtysson and C. J. Sreenan and Su Wen},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A simple loss differentiation approach to layered multicast},
year={2000},
volume={2},
number={},
pages={461-469 vol.2},
abstract={Layered multicast is a promising technique for broadcasting adaptive-quality TV video to heterogeneous receivers. While several-layered multicast approaches have been proposed, prior work has identified several problems including significant and persistent instability in video quality, arbitrary unfairness with other sessions, low access link utilization due to conservative bandwidth allocation, and problems with receiver synchronization. In this paper we propose a new layered multicast scheme, where we exploit a simple, coarse-grained, two-tier loss differentiation architecture to achieve stable and fair bandwidth allocation for viewers. Despite the simplicity of our loss differentiation model, we show that it achieves most of the benefits of complex and costly priority dropping schemes. In addition, our protocol is receiver-driven and thus retains the incentives to limit bandwidth usage that are not present in existing priority dropping schemes.},
keywords={digital video broadcasting;bandwidth allocation;multicast communication;protocols;telecommunication congestion control;layered multicast;TV video broadcasting;adaptive-quality TV;heterogeneous receivers;coarse-grained loss differentiation;two-tier loss differentiation;stable bandwidth allocation;fair bandwidth allocation;protocol;priority dropping;TV broadcasting;Streaming media;Bandwidth;Multimedia communication;TV receivers;Satellite broadcasting;Channel allocation;IP networks;Internet telephony;Telecommunication traffic},
doi={10.1109/INFCOM.2000.832219},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832220,
author={B. N. Levine and J. Crowcroft and C. Diot and J. J. Garcia-Luna-Aceves and J. F. Kurose},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Consideration of receiver interest for IP multicast delivery},
year={2000},
volume={2},
number={},
pages={470-479 vol.2},
abstract={Large-scale applications are characterized by a large number of dynamic and often interactive group members. The nature of these applications is such that participants are not interested in all the content transmitted. We examine three currently available techniques to scope delivery of content to interested receivers in IP multicast: filtering, where data is filtered by middleware before being passed to the application; addressing, where data is routed only to those receivers that express their interest; and hybrid approaches. We propose a framework that models large-scale application behavior. We use this framework to evaluate the performance of these applications and related protocols when the network is capable of filtering or addressing. Our results show that the current Internet architecture does not efficiently support large-scale applications because it can not efficiently manage multiple multicast groups. We show that network-level addressing is preferred to filtering and hybrid approaches given that groups are easy to create and manage. We highlight areas of research in the multicast architecture to bring about this change.},
keywords={multicast communication;protocols;Internet;data communication;telecommunication network routing;client-server systems;performance evaluation;computer network management;IP multicast delivery;large-scale applications;dynamic interactive group members;content delivery scope;data filtering;middleware;addressing;data routing;hybrid approaches;performance evaluation;protocols;Internet architecture;multiple multicast group management;network-level addressing;multicast architecture;Large-scale systems;Multicast protocols;Information filtering;Information filters;Internet;Unicast;Computer science;Educational institutions;Application software;Middleware},
doi={10.1109/INFCOM.2000.832220},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832221,
author={Bin Wang and J. C. Hou},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={QoS-based multicast routing for distributing layered video to heterogeneous receivers in rate-based networks},
year={2000},
volume={2},
number={},
pages={480-489 vol.2},
abstract={We design an effective multicast routing algorithm for distributing layered multicast video to heterogeneous receivers in networks with rate-based link schedulers. The multicast tree constructed by the algorithm fulfils the QoS requirements imposed by heterogeneous receivers both in terms of bandwidth and delay, and at the same time, consumes as little network resource as possible. For the purpose of scalability, the proposed multicast routing algorithm is decentralized and can adapt to network and membership change. To facilitate construction of such a multicast tree in a distributed manner we equip each node with an auxiliary routing table, and propose procedures for updating/maintaining the auxiliary routing table. Simulation results indicate that the multicast tree constructed by the proposed algorithm is more resource efficient than those constructed by other existing algorithms, especially when there exist multiple alternative paths to multicast receivers in the network.},
keywords={quality of service;visual communication;multicast communication;simulation;telecommunication network routing;scheduling;trees (mathematics);network topology;QoS;layered video;heterogeneous receivers;rate-based networks;multicast routing algorithm;link schedulers;multicast tree;scalability;auxiliary routing table;simulation;multicast receivers;Routing;Multicast algorithms;Bandwidth;Algorithm design and analysis;Scheduling algorithm;Quality of service;Intelligent networks;Delay effects;Scalability;Spine},
doi={10.1109/INFCOM.2000.832221},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832222,
author={T. G. Griffin and G. Wilfong},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A safe path vector protocol},
year={2000},
volume={2},
number={},
pages={490-499 vol.2},
abstract={An IP routing protocol is safe if it is guaranteed to converge in the absence of network topology changes. BGP, currently the only interdomain routing protocol employed on the Internet, is not safe in this sense. It may seem that the source of BGP's potential divergence is inherent in the requirements for any interdomain routing protocol-policy-based metrics must be allowed to override distance-based metrics, and each autonomous system must be allowed to independently define its routing policies with little or no global coordination. In this paper we present a simple path vector protocol (SPVP) that captures the underlying semantics of BGP by abstracting away all nonessential details. We then add a dynamically computed attribute to SPVP routing messages, called the route history. Protocol oscillations caused by policy conflicts produce routes whose histories contain cycles. These cycles identify the policy conflicts and the autonomous systems involved. SPVP is made safe by automatically suppressing routes whose histories contain cycles. We discuss how this safe SPVP can be used in the design of a safe BGP.},
keywords={network topology;telecommunication network routing;Internet;protocols;route history;IP routing protocol;network topology changes;convergence;Internet;interdomain routing protocol;simple path vector protocol;protocol oscillations;policy conflicts;SPVP;safe BGP;Routing protocols;Internet;History;Network topology;Network interfaces;Distributed algorithms;Distributed computing},
doi={10.1109/INFCOM.2000.832222},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832223,
author={E. Ekici and I. F. Akyildiz and M. D. Bender},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Datagram routing algorithm for LEO satellite networks},
year={2000},
volume={2},
number={},
pages={500-508 vol.2},
abstract={Satellite networks provide global coverage and support a wide range of services. Low-Earth-orbit (LEO) satellites provide short round-trip delays and are becoming increasingly important. One of the challenges in LEO satellite networks is the development of specialized and efficient routing algorithms. In this work, a datagram routing algorithm for LEO satellite networks is introduced. The algorithm generates minimum propagation delay paths. The performance of the algorithm is evaluated through simulations and finally robustness issues are discussed.},
keywords={data communication;telecommunication network routing;satellite communication;delays;minimisation;datagram routing algorithm;LEO satellite networks;low-Earth-orbit satellites;round-trip delays;minimisation;propagation delay paths;performance evaluation;simulations;robustness;Routing;Low earth orbit satellites;Internet;Switches;Bandwidth;Telecommunication traffic;Network topology;Laboratories;Computer networks;Delay},
doi={10.1109/INFCOM.2000.832223},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832224,
author={R. Slosiar and D. Latin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A polynomial-time algorithm for the establishment of primary and alternate paths in ATM networks},
year={2000},
volume={2},
number={},
pages={509-518 vol.2},
abstract={The increasing proportion of data traffic being carried in public networks is necessitating tractable and scalable algorithms in the design of ATM networks. In particular, the design of routing tables for ATM networks operated under the interim inter-switch signalling protocol (IISP) requires a significant amount of manual work in order to design and implement the underlying static routing tables that enable end-to-end connectivity as the network grows. This paper presents a scalable algorithm that generates IISP routing table entries such that no loops are created and so that connectivity is maintained between all origin/destination nodes under single-link failures. The algorithm generates shortest (i.e., lowest-cost) primary and alternate paths for any single-link failure scenario, while also demonstrating that at least one such solution can be found for any network graph devoid of bridges. Note that re-routing for single-link failures is considered adequate when sufficient protection is provided at the lower network layers. The algorithm has been fully implemented in a practical software tool, with execution time being a polynomial function of the network complexity.},
keywords={asynchronous transfer mode;computational complexity;telecommunication network routing;data communication;telecommunication traffic;telecommunication signalling;protocols;graph theory;network topology;polynomial-time algorithm;primary paths;alternate paths;ATM networks;data traffic;public networks;scalable algorithms;routing tables;inter-switch signalling protocol;IISP;end-to-end connectivity;single-link failures;network graph;software tool;network complexity;Polynomials;Intelligent networks;Asynchronous transfer mode;Protection;Circuits;Signal design;Routing protocols;Software algorithms;Software tools;Laboratories},
doi={10.1109/INFCOM.2000.832224},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832225,
author={B. Fortz and M. Thorup},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Internet traffic engineering by optimizing OSPF weights},
year={2000},
volume={2},
number={},
pages={519-528 vol.2},
abstract={Open shortest path first (OSPF) is the most commonly used intra-domain Internet routing protocol. Traffic flow is routed along shortest paths, splitting flow at nodes where several outgoing links are on shortest paths to the destination. The weights of the links, and thereby the shortest path routes, can be changed by the network operator. The weights could be set proportional to their physical distances, but often the main goal is to avoid congestion, i.e., overloading of links, and the standard heuristic recommended by Cisco is to make the weight of a link inversely proportional to its capacity. Our starting point was a proposed AT&T WorldNet backbone with demands projected from previous measurements. The desire was to optimize the weight setting based on the projected demands. We showed that optimizing the weight settings for a given set of demands is NP-hard, so we resorted to a local search heuristic. Surprisingly it turned out that for the proposed AT&T WorldNet backbone, we found weight settings that performed within a few percent from that of the optimal general routing where the flow for each demand is optimally distributed over all paths between source and destination. This contrasts the common belief that OSPF routing leads to congestion and it shows that for the network and demand matrix studied we cannot get a substantially better load balancing by switching to the proposed more flexible multi-protocol label switching (MPLS) technologies. Our techniques were also tested on synthetic internetworks, based on a model of Zegura et al., (1996), for which we did not always get quite as close to the optimal general routing.},
keywords={Internet;telecommunication traffic;telecommunication network routing;protocols;telecommunication congestion control;channel capacity;computational complexity;search problems;optimisation;Internet traffic engineering;OSPF;open shortest path first protocol;intra-domain Internet routing protocol;traffic flow;link weights;congestion;link capacity;AT&T WorldNet backbone;NP-hardness;local search heuristic;optimal general routing;demand matrix;load balancing;synthetic internetworks;Telecommunication traffic;Web and internet services;Spine;Multiprotocol label switching;Throughput;Traffic control;Laboratories;Routing protocols;Load management;Testing},
doi={10.1109/INFCOM.2000.832225},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832226,
author={S. Iyer and A. Awadallah and N. McKeown},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Analysis of a packet switch with memories running slower than the line-rate},
year={2000},
volume={2},
number={},
pages={529-537 vol.2},
abstract={Our work is motivated by the desire to build a very high speed packet switch with extremely high line-rates. In this paper, we consider building a packet switch from multiple, lower speed packet switches operating independently and in parallel. In particular, we consider a (perhaps obvious) parallel packet switch (PPS) architecture in which arriving traffic is demultiplexed over k identical, lower speed packet-switches, switched to the correct output port, then recombined (multiplexed) before departing from the system. Essentially, the packet switch performs packet-by-packet load-balancing, or "inverse-multiplexing" over multiple independent packet switches. Each lower-speed packet switch, operates at a fraction of the line-rate, R; for example, if each packet switch operates at rate R/k no memory buffers are required to operate at the full line-rate of the system. Ideally, a PPS would share the benefits of an output-queued switch; i.e. the delay of individual packets could be precisely controlled, allowing the provision of guaranteed qualities of service. In this paper, we ask the question: Is it possible for a PPS to precisely emulate the behavior of an output-queued packet-switch with the same capacity and with the same number of ports? The main result of this paper is that it is theoretically possible for a PPS to emulate a FCFS (first come first served) output-queued packet-switch if each layer operates at a rate of approximately 2R/k. This simple result is analogous to Clos theorem for a three-stage circuit switch to be strictly non-blocking. We further show that the PPS can emulate any QoS queueing discipline if each layer operates at a rate of approximately 3R/k.},
keywords={packet switching;parallel architectures;telecommunication traffic;multiplexing;quality of service;queueing theory;high line-rates;very high speed packet switch;parallel packet switch;multiple lower speed packet switches;PPS architecture;arriving traffic;output port;packet-by-packet load-balancing;inverse-multiplexing;multiple independent packet switches;guaranteed qualities of service;full line-rate;output-queued packet-switch;QoS queueing discipline;Clos theorem;Packet switching;Wavelength division multiplexing;Optical packet switching;Optical buffering;Optical switches;Read-write memory;Laboratories;Buildings;Delay;Quality of service},
doi={10.1109/INFCOM.2000.832226},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832227,
author={R. Bhagwan and B. Lin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Fast and scalable priority queue architecture for high-speed network switches},
year={2000},
volume={2},
number={},
pages={538-547 vol.2},
abstract={In this paper, we present a fast and scalable pipelined priority queue architecture for use in high-performance switches with support for fine grained quality of service (QoS) guarantees. Priority queues are used to implement highest-priority-first scheduling policies. Our hardware architecture is based on a new data structure called a pipelined heap, or P-heap for short. This data structure enables the pipelining of the enqueue and dequeue operations, thereby allowing these operations to execute in essentially constant time. In addition to being very fast, the architecture also scales very well to a large number of priority levels and to large queue sizes. We give a detailed description of this new data structure, the associated algorithms and the corresponding hardware implementation. We have implemented this new architecture using a 0.35 micron CMOS technology. Our current implementation can support 10 Gb/s connections with over 4 billion priority levels.},
keywords={quality of service;queueing theory;pipeline processing;scheduling;data structures;packet switching;electronic switching systems;CMOS digital integrated circuits;fast scalable priority queue architecture;high-speed network switches;scalable pipelined priority queue architecture;high-performance switches;quality of service;fine grained QoS guarantees;priority queues;highest-priority-first scheduling policies;data structure;pipelined heap;P-heap;enqueue operation;dequeue operation;CMOS technology;packet switched integrated service networks;0.35 micron;10 Gbit/s;High-speed networks;Quality of service;Hardware;Data structures;Switches;Communication switching;Sorting;Calendars;Wireless communication;Pipeline processing},
doi={10.1109/INFCOM.2000.832227},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832228,
author={D. N. Serpanos and P. I. Antoniadis},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={FIRM: a class of distributed scheduling algorithms for high-speed ATM switches with multiple input queues},
year={2000},
volume={2},
number={},
pages={548-555 vol.2},
abstract={Advanced input queuing is an attractive, promising architecture for high-speed ATM switches, because it combines the low cost of input queuing with the high performance of output queuing. The need for scalable schedulers for advanced input queuing switch architectures has led to the development of efficient distributed scheduling algorithms. We introduce a new distributed scheduling algorithm, FIRM, which provides improved performance characteristics over alternative distributed algorithms. FIRM achieves saturation throughput 1 with lower delay than the most efficient alternative (up to 50% at high load). Furthermore, it provides improved fairness (it approximates FCFS) and tighter service guarantee than others. FIRM provides a basis for a class of distributed scheduling algorithms, many of which provide even more improved performance characteristics.},
keywords={distributed algorithms;scheduling;asynchronous transfer mode;queueing theory;FIRM;distributed scheduling algorithms;high-speed ATM switches;multiple input queues;advanced input queuing;output queuing;scalable schedulers;efficient distributed scheduling algorithms;saturation throughput;service guarantee;Scheduling algorithm;Asynchronous transfer mode;Switches;Communication switching;Scalability;Costs;Throughput;Processor scheduling;Computer science;Electronic mail},
doi={10.1109/INFCOM.2000.832228},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832229,
author={J. G. Dai and B. Prabhakar},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={The throughput of data switches with and without speedup},
year={2000},
volume={2},
number={},
pages={556-564 vol.2},
abstract={In this paper we use fluid model techniques to establish two results concerning the throughput of data switches. For an input-queued switch (with no speedup) we show that a maximum weight algorithm for connecting inputs and outputs delivers a throughput of 100%, and for combined input- and output-queued switches that run at a speedup of 2 we show that any maximal matching algorithm delivers a throughput of 100%. The only assumptions on the input traffic are that it satisfies the strong law of large numbers and that it does not oversubscribe any input or any output.},
keywords={data communication;queueing theory;telecommunication traffic;packet switching;data switches;fluid model techniques;input-queued switch;maximum weight algorithm;combined input/output-queued switches;maximal matching algorithm;input traffic;packet switches;Throughput;Switches;Packet switching;Fabrics;Traffic control;Scheduling algorithm;Computer industry;Data engineering;Systems engineering and theory;Mathematics},
doi={10.1109/INFCOM.2000.832229},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832230,
author={Sung-Ju Lee and W. Su and J. Hsu and M. Gerla and R. Bagrodia},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A performance comparison study of ad hoc wireless multicast protocols},
year={2000},
volume={2},
number={},
pages={565-574 vol.2},
abstract={In this paper we investigate the performance of multicast routing protocols in wireless mobile ad hoc networks. An ad hoc network is composed of mobile nodes without the presence of a wired support infrastructure. In this environment, routing/multicasting protocols are faced with the challenge of producing multihop routes under host mobility and bandwidth constraints. In recent years, a number of new multicast protocols of different styles have been proposed for ad hoc networks. However, systematic performance evaluations and comparative analysis of these protocols in a common realistic environment has not yet been performed. In this study, we simulate a set of representative wireless ad hoc multicast protocols and evaluate them in various network scenarios. The relative strengths, weaknesses, and applicability of each multicast protocol to diverse situations are studied and discussed.},
keywords={mobile radio;multicast communication;protocols;telecommunication network routing;ad hoc wireless multicast protocols;multicast routing protocols;mobile nodes;wired support infrastructure;routing/multicasting protocols;host mobility;bandwidth constraints;Multicast protocols;Ad hoc networks;Routing protocols;Performance analysis;Network topology;Analytical models;Access protocols;Laboratories;Computer science;Wireless application protocol},
doi={10.1109/INFCOM.2000.832230},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832231,
author={A. Bar-Noy and B. Patt-Shamir and I. Ziper},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Broadcast disks with polynomial cost functions},
year={2000},
volume={2},
number={},
pages={575-584 vol.2},
abstract={In broadcast disk systems, information is broadcast in a shared medium. When a client needs an item from the disk, it waits until that item is broadcast. The fundamental algorithmic problem for such systems is to determine the broadcast schedule based on the demand probability of items, and the cost incurred to the system by clients waiting. The goal is to minimize the mean access cost of a random client. Typically, it was assumed that the access cost is proportional to the waiting time. In this paper, we ask what are the best broadcast schedules for access costs which are arbitrary polynomials in the waiting time. These may serve as reasonable representations of reality in many cases, where the "patience" of a client is not necessarily proportional to its waiting time. We present an asymptotically optimal algorithm for a fluid model, where the bandwidth may be divided to allow for fractional concurrent broadcasting. This algorithm, besides being justified in its own right, also serves as a lower bound against which we test known discrete algorithms. We show that the Greedy algorithm has the best performance in most cases. Then we show that the performance of other algorithms deteriorate exponentially with the degree of the cost polynomial and approach the fractional solution for sub-linear cost. Finally, we study the quality of approximating the greedy schedule by a finite schedule.},
keywords={polynomials;broadcasting;scheduling;probability;optimisation;approximation theory;broadcast disk systems;polynomial cost functions;broadcast schedule;demand probability;mean access cost;waiting time;arbitrary polynomials;asymptotically optimal algorithm;fluid model;fractional concurrent broadcasting;known discrete algorithms;Greedy algorithm;cost polynomial;sub-linear cost;greedy schedule;finite schedule;Broadcasting;Polynomials;Cost function;File servers;Scheduling algorithm;Bandwidth;Testing;Greedy algorithms;Helium;Teletext},
doi={10.1109/INFCOM.2000.832231},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832232,
author={J. E. Wieselthier and G. D. Nguyen and A. Ephremides},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On the construction of energy-efficient broadcast and multicast trees in wireless networks},
year={2000},
volume={2},
number={},
pages={585-594 vol.2},
abstract={The wireless networking environment presents formidable challenges to the study of broadcasting and multicasting problems. After addressing the characteristics of wireless networks that distinguish them from wired networks, we introduce and evaluate algorithms for tree construction in infrastructureless, all-wireless applications. The performance metric used to evaluate broadcast and multicast trees is energy-efficiency. We develop the broadcast incremental power algorithm, and adapt it to multicast operation as well. This algorithm exploits the broadcast nature of the wireless communication environment, and addresses the need for energy-efficient operation. We demonstrate that our algorithm provides better performance than algorithms that have been developed for the link-based, wired environment.},
keywords={multicast communication;radio networks;radio broadcasting;trees (mathematics);energy-efficient broadcast;multicast trees;wireless networks;tree construction;infrastructureless all-wireless applications;energy-efficiency performance metric;broadcast incremental power algorithm;multicast operation;Energy efficiency;Broadcasting;Intelligent networks;Wireless networks;Multicast algorithms;Signal processing algorithms;Wireless communication;Interference;Broadcast technology;Information technology},
doi={10.1109/INFCOM.2000.832232},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832233,
author={R. Garces and J. J. Garcia-Luna-Aceves},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Collision avoidance and resolution multiple access for multichannel wireless networks},
year={2000},
volume={2},
number={},
pages={595-602 vol.2},
abstract={We introduce and analyze CARMA-MC (for collision avoidance and resolution multiple access for multiple channels), a new stable channel access protocol for multihop wireless networks with multiple channels. CARMA-MC relies on the assignment of a unique channel and a unique identifier to each node to support correct deterministic collision resolution in the presence of hidden terminals. CARMA-MC dynamically divides the channel of each node into cycles of variable length; each cycle consists of one or more receiving periods and a transmission period. During the receiving period, stations with one or more packets to send compete for the right to acquire the floor of a particular receiver's channel using a deterministic tree-splitting algorithm. Each receiving period consists of collision resolution steps. A single round of collision resolution (i.e., a success, and idle or a collision of control packets) is allowed in each contention step. The receiving period is initiated by the receiver and takes place in the channel assigned to the receiver station. The channel utilization and packet delays are studied analytically and by simulation.},
keywords={telecommunication channels;radio networks;multi-access systems;access protocols;packet switching;trees (mathematics);collision avoidance and resolution multiple access;CARMA-MC;multichannel wireless networks;multiple channels;stable channel access protocol;multihop wireless networks;unique identifier;unique channel;deterministic collision resolution;hidden terminals;deterministic tree-splitting algorithm;collision resolution steps;control packets;contention step;receiving period;receiver station;channel utilization;packet delays;Collision avoidance;Wireless networks;Interference;Road accidents;Throughput;Media Access Protocol;Spread spectrum communication;Base stations;Delay;Analytical models},
doi={10.1109/INFCOM.2000.832233},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832234,
author={M. Andrews},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Probabilistic end-to-end delay bounds for earliest deadline first scheduling},
year={2000},
volume={2},
number={},
pages={603-612 vol.2},
abstract={We analyze the earliest-deadline-first (EDF) scheduling discipline within the framework of statistical multiplexing. We derive techniques for bounding the probability of delay violations when the session injections are independent. This enables us to determine whether a given set of sessions can all meet their delay bounds with the required violation probability. These techniques can be used by a connection admission control (CAC) scheme to decide whether to admit a new session. Our analysis applies to both the single node problem and the network problem in which the sessions have multiple hops. We also give extensive numerical results to illustrate how our bounds may be calculated and to compare the results with estimates that have been derived for generalized processor sharing (GPS). In addition we show that by altering the deadlines for EDF we can match the desired violation probabilities more closely.},
keywords={probability;scheduling;multiplexing;telecommunication congestion control;quality of service;probabilistic end-to-end delay bounds;earliest deadline first scheduling;EDF scheduling discipline;statistical multiplexing;delay violations;session injections;connection admission control;CAC scheme;single node problem;network problem;violation probabilities;generalized processor sharing;quality of service;Delay;Global Positioning System;Network servers;Probability;Processor scheduling;Radio access networks;Admission control;Petroleum;Stochastic processes},
doi={10.1109/INFCOM.2000.832234},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832235,
author={D. Raz and Y. Shavitt},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Optimal partition of QoS requirements with discrete cost functions},
year={2000},
volume={2},
number={},
pages={613-622 vol.2},
abstract={The future Internet is expected to support applications with quality of service (QoS) requirements. To this end several mechanisms have been suggested in the IETF to support signaling, the most promising among them is DiffServ. An important problem in this framework is how to partition the QoS requirements of an application along a selected path. The problem which is in general NP complete, was solved for continuous convex cost functions by Lorenz and Orda (1999). This work concentrates on discrete cost functions, and presents efficient exact and approximated solutions for various conditions of the problem. We also show that the more complex problem of QoS sensitive routing with discrete cost functions is hard, but has a fully polynomial approximation scheme.},
keywords={quality of service;optimisation;Internet;least squares approximations;telecommunication network routing;polynomials;telecommunication signalling;QoS requirements;discrete cost functions;future Internet;quality of service;IETF;signaling;DiffServ;NP complete problem;continuous convex cost functions;approximated solutions;QoS sensitive routing;fully polynomial approximation scheme;Cost function;Quality of service;Routing;Multicast algorithms;Partitioning algorithms;Delay;Polynomials;Unicast;Approximation algorithms;Web and internet services},
doi={10.1109/INFCOM.2000.832235},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832236,
author={V. Elek and G. Karlsson and R. Ronngren},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Admission control based on end-to-end measurements},
year={2000},
volume={2},
number={},
pages={623-630 vol.2},
abstract={This paper proposes a controlled load service that provides a network state with bounded and well known worst-case behavior. The service is primarily developed for real time applications. The full system for achieving quality of service to the application consists of an admission control combined with forward-error correction. The admission control is used to limit the packet-loss probability to a known value; the error-control coding (i.e., FEC) is then used to raise the quality above the level enforced by the admission control. The basic idea for the admission control is that a host must probe the path to the receiver before sending actual data. It accepts the session if the probe is received with no or at most a moderate amount of loss. The performance evaluation shows clearly that the proposed scheme avoids network congestion and high packet losses even over short time scales.},
keywords={telecommunication congestion control;quality of service;forward error correction;packet switching;telecommunication services;Internet;admission control;end-to-end measurements;controlled load service;network state;worst-case behavior;real time applications;forward-error correction;packet-loss probability;error-control coding;FEC;performance evaluation;Admission control;Probes;Error correction;Delay;Quality of service;Web and internet services;Forward error correction;Intserv networks;Context-aware services;Context},
doi={10.1109/INFCOM.2000.832236},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832237,
author={V. Sivaraman and F. Chiussi},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Providing end-to-end statistical delay guarantees with earliest deadline first scheduling and per-hop traffic shaping},
year={2000},
volume={2},
number={},
pages={631-640 vol.2},
abstract={This paper develops a framework for statistically guaranteeing end-to-end delay bounds to leaky-bucket-constrained flows transporting real-time traffic in a network of switches using earliest deadline first (EDF) packet scheduling and per-hop traffic shaping. We first analyze the delay-bound violation probabilities at an isolated EDF scheduler fed by fluid source processes generating extremal dual-leaky-bucket-regulated traffic. We compute a close upper bound by applying the Benes approach to an equivalent hypothetical system derived from the real one. We then extend the analysis to the end-to-end scenario in the presence of traffic re-shaping at each node in the network. We compare the analytical results with simulations, and show that the match is very close. We also investigate the advantages of smoothing the traffic at the ingress to the network, and propose a simple choice of smoothing parameters, which perform very well. Using realistic traffic parameters, we compare the schedulable region of our statistical framework with that of the corresponding deterministic framework, and demonstrate that the statistical framework allows tremendous improvements in network utilization, even for very low delay-violation probabilities. The framework developed in this paper is therefore highly useful in practical packet networks to provide quality of service to real-time applications in the form of statistical, rather than deterministic, end-to-end delay bounds.},
keywords={statistical analysis;scheduling;telecommunication traffic;queueing theory;packet switching;probability;quality of service;end-to-end statistical delay guarantees;earliest deadline first scheduling;per-hop traffic shaping;leaky-bucket-constrained flows;real-time traffic;packet scheduling;delay-bound violation probabilities;fluid source processes;dual-leaky-bucket-regulated traffic;Benes approach;smoothing parameters;schedulable region;quality of service;Delay;Telecommunication traffic;Traffic control;Probability;Smoothing methods;Packet switching;Switches;Scheduling algorithm;Processor scheduling;Upper bound},
doi={10.1109/INFCOM.2000.832237},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832238,
author={N. Miller and P. Steenkiste},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Collecting network status information for network-aware applications},
year={2000},
volume={2},
number={},
pages={641-650 vol.2},
abstract={Network-aware applications, i.e., applications that adapt to network conditions in an application-specific way, need both static and dynamic information about the network to be able to adapt intelligently to network conditions. The CMU Remos interface gives applications access to a wide range of information in a network-independent fashion. Remos uses a logical topology to capture the network information that is relevant to applications in a concise way. However, collecting this information efficiently is challenging for several reasons: networks use diverse technologies and can be very large (Internet); applications need diverse information; and network managers might have concerns about leaking confidential information. In this paper we present an architecture for a hierarchical collector of network information. The decentralized architecture relies on data collectors that collect information on individual subnets; data collectors can collect information in manner that is appropriate for that subnet and can control the distribution of the information. For application queries that involve multiple subnets, we use a set of master collectors to partition requests and distribute subrequests to individual data collectors and to combine the results. Collectors cache recent network information to improve efficiency and responsiveness. This paper presents and justifies the collector architecture, describes a prototype implementation, and presents preliminary measurements characterizing its operation.},
keywords={Internet;data acquisition;cache storage;network status information;network-aware applications;CMU Remos interface;logical topology;Internet;hierarchical collector;decentralized architecture;data collectors;subnets;caching;Application software;Intelligent networks;Streaming media;Distributed computing;Bandwidth;Feedback;Delay estimation;Computer science;Electronic mail;Network topology},
doi={10.1109/INFCOM.2000.832238},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832239,
author={K. Li and S. Jamin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A measurement-based admission-controlled Web server},
year={2000},
volume={2},
number={},
pages={651-659 vol.2},
abstract={Current HTTP servers process requests using a first-come first-serve queuing policy. What this implies is that the WWW server must process each request as it arrives. The result is that the more requests a client makes, the more replies the server will generate in response. Unfortunately, the bandwidth of the network and the processing capabilities of the server are often limited resulting in an aggressive client, or sets of clients, consuming the majority of the server's resources, limiting other clients' ability to use their fair allocation. While the traditional behavior of a Web server works efficiently for a Web site that is non-discriminating towards all clients, guaranteeing service for preferred clients from the server itself is not yet possible. This paper describes the algorithm we have designed and implemented on the Apache HTTP server, which has been shown to be effective in allocating configurable fixed percentages of bandwidth across numerous simultaneous clients, independent of the aggressiveness of the clients' requests.},
keywords={transport protocols;client-server systems;queueing theory;information resources;telecommunication congestion control;quality of service;bandwidth allocation;network servers;measurement-based Web server;admission-controlled Web server;HTTP servers;queuing policy;client server system;WWW;service guarantee;Apache HTTP server;bandwidth allocation;Web server;Network servers;Bandwidth;Kelvin;Resource management;Hardware;Web services;Communication system traffic control;Traffic control;Optimal control},
doi={10.1109/INFCOM.2000.832239},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832240,
author={J. Kangasharju and K. W. Ross},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A replicated architecture for the Domain Name System},
year={2000},
volume={2},
number={},
pages={660-669 vol.2},
abstract={We propose a new design for the Domain Name System (DNS) that takes advantage of recent advances in disk storage and multicast distribution technology. In essence, our design consists of geographically distributed servers, called replicated servers, each of which has a complete and up-to-date copy of the entire DNS database. To keep the replicated servers up-to-date, they distribute new resource records over a satellite channel or over terrestrial multicast. The design allows Web sites to dynamically wander and replicate themselves without having to change their URL. The design can also significantly improve the Web surfing experience since it significantly reduces the DNS lookup delay.},
keywords={information resources;replicated databases;network servers;multicast communication;disc storage;replicated architecture;Domain Name System;DNS;disk storage;multicast distribution technology;geographically distributed servers;replicated servers;DNS database;Web sites;Web surfing;lookup delay;Domain Name System;Web server;Network servers;Satellite broadcasting;Telecommunication traffic;Uniform resource locators;Delay;Distributed databases;Space technology;Web page design},
doi={10.1109/INFCOM.2000.832240},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832241,
author={B. S. Michel and K. Nikoloudakis and P. Reiher and Lixia Zhang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={URL forwarding and compression in adaptive Web caching},
year={2000},
volume={2},
number={},
pages={670-678 vol.2},
abstract={Web caching is generally acknowledged as an important service for alleviating focused overloads when certain WWW servers' contents suddenly become popular. Cooperative caching systems are more effective than independent caches due to the larger collective backing store that cooperation creates. One such system currently being developed at UCLA, adaptive Web caching (AWC), uses an application-level forwarding table to locate the nearest copy of a requested URL's contents. This paper describes one specific design in AWC, a simple URL table compression algorithm allowing efficient content information-sharing among neighboring caches. The compression algorithm is based on a hierarchical URL decomposition to aggregate URL sharing common prefixes and an incremental hashing function to minimize collisions between prefixes. The algorithm's collision rate is derived analytically and verified by five sets of Web trace data. The results demonstrate that the collision rate is bounded and has little impact on page fetching latency. Finally, this compression method is compared to the summary cache method.},
keywords={cache storage;information resources;data compression;telecommunication congestion control;minimisation;URL forwarding;URL compression;adaptive Web caching;overloads;WWW;cooperative caching systems;UCLA;application-level forwarding table;content information sharing;incremental hashing function;collision minimization;Web trace data;page fetching latency;Uniform resource locators;Web server;Algorithm design and analysis;Compression algorithms;Internet;Topology;Routing protocols;Cooperative caching;Aggregates;Delay},
doi={10.1109/INFCOM.2000.832241},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832242,
author={Y. Serbest and Sangkyu Park and Aimin Sang and San-qi Li},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A simple adaptive SVC caching scheme for voice trunking over ATM (VTOA) applications},
year={2000},
volume={2},
number={},
pages={679-687 vol.2},
abstract={In voice trunking over ATM (VTOA) technology, the tandem is replaced by three components: trunk inter-working function (T-IWF), control and signaling inter-working function (CS-IWF), and ATM network. This new architecture calls for re-examination of the signaling channel delay issues, which are well-studied and well-specified for TDM networks. In VTOA, the ATM network together with the inter-working functions act as a virtual tandem switching system, which is called "ATM-based distributed virtual tandem switching system". The aim is that the performance of the ATM-based trunking network should be at least as good as the TDM-based network. The cross-office delay budget must be shared among the inter-working functions and the ATM network. Hence, the time for the ATM network to establish a switched virtual connection (SVC) is stringent. In this paper, we propose a simple adaptive SVC caching scheme to offload the high processing capacity burden on ATM switches. After a SVC is established in the usual way for a call, it is not torn down after the conversation is over. Instead, it is kept alive for variable duration (i.e., delayed release) with the expectation that there would be another call request for the same terminating end office during that time. The caching duration is adaptively changed with call arrival rate and call setup delay in the ATM network in order to stay within the delay budget specified by the requirements. The adaptability and the convergence of the algorithm are also shown by extensive simulations related to practical scenarios.},
keywords={cache storage;voice communication;asynchronous transfer mode;telecommunication signalling;telecommunication traffic;convergence;telecommunication congestion control;adaptive SVC caching scheme;voice trunking over ATM;VTOA;trunk inter-working function;T-IWF;control and signaling inter-working function;CS-IWF;ATM network;signaling channel delay;TDM networks;virtual tandem switching system;performance;cross-office delay budget;switched virtual connection;call arrival rate;call setup delay;simulation;convergence;Static VAr compensators;Asynchronous transfer mode;Time division multiplexing;Switching systems;Delay;Application software;Switches;Centralized control;Protocols;Computer networks},
doi={10.1109/INFCOM.2000.832242},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832243,
author={H. Levy and T. Mendelson and G. Goren},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Optimal use of virtual paths for connection setup reduction: the single link problem},
year={2000},
volume={2},
number={},
pages={688-696 vol.2},
abstract={One of the major problems faced by large networks is the enormous amount of processing required for setting up and tearing down the large number of connections maintained by the network. ATM aims at solving these problems via the virtual path (VP) mechanism which is used to group together the virtual connections (VC). When a need for setting up a VC arises the request and its resource allocation are processed by the VP authority and not by the network, thus reducing the processing cost significantly. An important question in the design of these networks is the amount of network resources to be allocated to and held by the VP authorities; too high an allocation will result in resource waste, while too low an allocation will result in heavy connection set-up and tear-down processing load. In this paper we deal with this problem, aiming at deriving simple operational rules to determine the amount of bandwidth resources to be held by the various VP authorities. We formulate the resource allocation problem by accounting both for bandwidth utilization and for connection processing constraints. For a single link network we realize that the pure problem is too complex and thus formulate an approximate model and derive the optimal allocation for it. The optimal rule is expressed as a closed-form square root allocation. Extensive numerical examination shows that the algorithms proposed yield very efficient allocations. The single link model is then generalized to a general network model and an algorithm based on the single link allocation is proposed; that analysis is however beyond the scope of this paper.},
keywords={asynchronous transfer mode;optimisation;bandwidth allocation;approximation theory;optimal use;virtual paths;connection setup reduction;ATM;VP;VC;virtual connections;resource allocation;VP authority;connection tear-down;bandwidth utilization;connection processing;single link network;approximate model;optimal rule;closed-form square root allocation;Bandwidth;Resource management;Telecommunications;Virtual colonoscopy;OFDM;Computer science;Physics;Gallium nitride;Face;Scalability},
doi={10.1109/INFCOM.2000.832243},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832244,
author={H. J. Wang and A. D. Joseph and R. H. Katz},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A signaling system using lightweight call sessions},
year={2000},
volume={2},
number={},
pages={697-706 vol.2},
abstract={Because of the emergence of heterogeneous access devices and diverse wired and wireless networks, and a substantial lack of support for integrating these networks, we are building a communication network and a service infrastructure that provides integrated telephony and data services across these networks. We generalize the basic call service to support communication between two or more call parties using any number of devices through any media. Call setup has already been addressed by protocols such as the session initiation protocol (SIP), so we focus on a missing component: scalable and fault-tolerant call session maintenance and control after call setup. In this paper, we present a new signaling protocol that offers scalability, high availability, robustness, and flexibility in creating new call processing services. The protocol is compatible with existing call setup protocols, but provides lightweight call session management using a completely decentralized, soft-state group control protocol. We show that this approach simplifies the implementation of the basic call service, including multi-device calling and service handoff between diverse access networks. The design of our protocol follows the principle of separation of control (signaling information) from data. The signaling protocol has been implemented in ICEBERG, an IP-based core network testbed with access to heterogeneous networks.},
keywords={telephony;integrated voice/data communication;fault tolerance;decentralised control;telecommunication control;telecommunication signalling;access protocols;telecommunication network management;subscriber loops;communication network;service infrastructure;integrated telephony;data services;fault-tolerant call session maintenance;call session control;signaling protocol;scalability;availability;call processing services;call setup protocols;lightweight call session management;decentralized control;soft-state group control;multi-device calling;service handoff;access networks;ICEBERG;IP-based core network testbed;heterogeneous networks;Communication system signaling;Access protocols;Wireless networks;Communication networks;Telephony;Fault tolerance;Communication system control;Signal processing;Scalability;Availability},
doi={10.1109/INFCOM.2000.832244},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832245,
author={A. Srinivasan and K. G. Ramakrishnan and K. Kumaran and M. Aravamudan and S. Naqvi},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Optimal design of signaling networks for Internet telephony},
year={2000},
volume={2},
number={},
pages={707-716 vol.2},
abstract={We present an approach for efficient design of a signaling network for a network of software switches supporting Internet telephony. While one may take an integer programming approach to solve this problem, it quickly becomes intractable even for modest-sized networks. Instead, our topology design uses random graphs that we show to be nearly optimal in cost, highly connected, and computationally efficient even for large networks. We then formulate a quadratic assignment problem (QAP) to map the abstract topology into the physical network to achieve optimal load balancing for given demand forecasts, which we solve using randomized heuristics. Numerical results on several example networks illustrate the performance and computational efficiency of our method. A graphical design tool has been developed based on our algorithms.},
keywords={Internet telephony;network topology;optimisation;telecommunication signalling;randomised algorithms;graph theory;bandwidth allocation;optimal design;signaling networks;Internet telephony;topology design;random graphs;quadratic assignment problem;optimal load balancing;demand forecasts;randomized heuristics;performance;computational efficiency;graphical design tool;Signal design;Internet telephony;Network topology;Switches;Linear programming;Cost function;Computer networks;Load management;Load forecasting;Demand forecasting},
doi={10.1109/INFCOM.2000.832245},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832246,
author={B. Kurceren and J. W. Modestino},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A joint source-channel coding approach to network transport on digital video},
year={2000},
volume={2},
number={},
pages={717-726 vol.2},
abstract={The use of forward error-control (FEC) coding, possibly in conjunction with passive-error recovery techniques, has emerged as a promising approach for real-time video transport over ATM networks for cell loss recovery and/or bit error correction, such as might be required for wireless links. Although FEC provides cell-loss recovery, through its erasure correcting capabilities, it also introduces transmission overhead which can possibly cause additional cell losses. A joint source-channel coding methodology is described to maximize the number of video sources multiplexed at a given quality of service (QoS), measured in terms of overall reproduced video quality. The transport channel is modeled as a block interference channel (BIC) and the multiplexer as a single server, deterministic service, finite buffer supporting N users. Based upon an information-theoretic characterization of the BIC and large deviation bounds on the buffer overflow probability, we describe a methodology that provides theoretically achievable upper limits on the number of sources multiplexed at a given level of performance. Performance of a specific coding technique using an MPEG-2 source encoder and interlaced non-binary Reed-Solomon (RS) channel codes is illustrated and shown to approach the information-theoretic predictions with increasing levels of complexity.},
keywords={combined source-channel coding;visual communication;forward error correction;asynchronous transfer mode;error statistics;quality of service;radio links;queueing theory;buffer storage;telecommunication congestion control;probability;Reed-Solomon codes;interleaved codes;video coding;joint source-channel coding;network transport;digital video;forward error-control coding;FEC;passive-error recovery;ATM networks;cell loss recovery;bit error correction;wireless links;quality of service;QoS;video quality;block interference channel;single server;finite buffer;deterministic service;multiplexer;information-theoretic characterization;deviation bounds;buffer overflow probability;performance;MPEG-2 source encoder;interlaced channel codes;non-binary channel codes;Reed-Solomon channel codes;RS channel codes;complexity;Forward error correction;Quality of service;Error correction;Asynchronous transfer mode;Error correction codes;Propagation losses;Interference channels;Multiplexing;Buffer overflow;Reed-Solomon codes},
doi={10.1109/INFCOM.2000.832246},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832247,
author={Yu-Chee Tseng and Chi-Ming Hsieh and Ming-Hour Yang and Wen-Hwa Liao and Jang-Ping Sheu},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Data broadcasting and seamless channel transition for highly-demanded videos},
year={2000},
volume={2},
number={},
pages={727-736 vol.2},
abstract={One way to broadcast a popular video is to let multiple users share fewer channels. The stress on channel demand can be alleviated without sacrificing viewers' waiting time. One such scheme that interests us is the fast broadcasting (FB) scheme (Juhn et al., 1997, 1998), which can broadcast a popular video using k channels without keeping newcoming viewers waiting for more than O(D/2/sup k/) time, where D is the length of the video. In this paper, we propose two enhancements to the FB scheme. First, since the level of demand on a video may change by time, we show how to dynamically change the number of channels assigned to the video and seamlessly perform this transition. Clients currently viewing this video will not experience any disruption during the transition. Second, given a set of channels and a set of popular videos, we propose a scheme to assign these channels to the videos such that the average viewers' waiting time is minimal. From the system manager's point of view, these enhancements will make the FB scheme more attractive.},
keywords={video on demand;video servers;minimisation;channel allocation;telecommunication network management;broadcasting;data broadcasting;seamless channel transition;highly-demanded videos;FB scheme;dynamic channel assignment;viewer waiting time;minimization;system manager;Multimedia communication;Bandwidth;Stress;TV broadcasting;Broadcast technology;Satellite broadcasting;Video recording;Computer science;Iron;Cable TV},
doi={10.1109/INFCOM.2000.832247},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832248,
author={D. Saparilla and K. W. Ross},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Optimal streaming of layered video},
year={2000},
volume={2},
number={},
pages={737-746 vol.2},
abstract={This paper presents a model and theory for streaming layered video. We model the bandwidth available to the streaming application as a stochastic process whose statistical characteristics are unknown a priori. The random bandwidth models short-term variations due to congestion control (such as TCP-friendly conformance). We suppose that the video has been encoded into a base and an enhancement layer, and that to decode the enhancement layer the base layer has to be available to the client. We make the natural assumption that the client has abundant local storage and attempts to prefetch as much of the video as possible during playback. At any instant of time, starvation or partial starvation can occur at the client in either of the two layers. During periods of starvation, the client applies video error concealment to hide the loss. We study the dynamic allocation of the available bandwidth to the two layers in order to minimize the impact pact of client starvation. For the case of an infinitely-long video, we find that the optimal policy takes on a surprisingly simple and static form. For finite-length videos, the optimal policy is a simple static policy when the enhancement layer is deemed at least as important as the base layer. When the base layer is more important, we design a threshold policy heuristic which switches between two static policies. We provide numerical results that compare the performance of no-prefetching, static and threshold policies.},
keywords={visual communication;multimedia communication;video coding;stochastic processes;telecommunication congestion control;decoding;error correction codes;channel allocation;channel coding;minimisation;optimal streaming;layered video;available bandwidth;stochastic process;statistical characteristics;short-term variations;congestion control;video encoding;decoding;enhancement layer;base layer;video error concealment;dynamic allocation;minimization;client starvation;optimal policy;threshold policy heuristic;performance;no-prefetching policies;static policies;Streaming media;Bandwidth;Internet;Prefetching;Telecommunication traffic;Video on demand;Video sharing;Systems engineering and theory;Stochastic processes;Decoding},
doi={10.1109/INFCOM.2000.832248},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832249,
author={Kang-Won Lee and R. Puri and Tae-eun Kim and K. Ramchandran and V. Bharghavan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An integrated source coding and congestion control framework for video streaming in the Internet},
year={2000},
volume={2},
number={},
pages={747-756 vol.2},
abstract={We describe a framework for video transmission over the Internet that features the coordinated operation of an application-layer video source coding algorithm and a transport-layer rate control mechanism. The proposed video coding scheme operates on a progressively encoded video stream and provides graceful resilience to network packet drops. The robustness is enabled through a generalized multiple description (MD) coding strategy, architectured as an adaptive array of packet-erasure correction codes. The video coding algorithm is matched to an efficient and reactive rate control mechanism that minimizes the fluctuation of rate and uses the profile of past losses to adjust the rate in a TCP-friendly manner. While the two constituent algorithms identified above are interesting in their own right, a key feature of this work is the integration of these algorithms in a simple framework that seeks to maximize the expected delivered video quality at the receiver through coordinated adaptation of the two components. We present simple simulation results to illustrate the utility of our approach.},
keywords={Internet;source coding;video coding;telecommunication congestion control;minimisation;adaptive codes;variable rate codes;error correction codes;integrated framework;source coding;congestion control;video streaming;Internet;video transmission;video coding;rate control mechanism;graceful resilience;network packet drops;generalized multiple description coding;adaptive code array;packet-erasure correction codes;minimization;video quality;simulation;Source coding;Streaming media;Internet;Video coding;Fluctuations;Transcoding;Forward error correction;Computer science;Resilience;Adaptive arrays},
doi={10.1109/INFCOM.2000.832249},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832250,
author={Yuguang Fang and I. Chlamtac and Hong-Bing Fei},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An active mobility database failure recovery scheme and performance analysis for PCS networks},
year={2000},
volume={2},
number={},
pages={757-764 vol.2},
abstract={In wireless mobile networks, particularly in PCS networks, new calls to a portable may be lost due to the incorrect location information in the mobility database, which leads to a database failure. Such database failure can be recovered either through the portable's registration initiation, the deregistration when it crosses the location area boundary or the active location update. In this paper, we analyze the active location update scheme under several different mobile traffic distributions for failure restoration. We present analytical results for cost analysis. We find that under certain conditions there exists an optimal choice of location update period to minimize the total cost which represents the tradeoff between the location update and call loss. Our results provide a general framework for evaluating active database failure recovery schemes in wireless networks.},
keywords={database management systems;personal communication networks;mobile radio;telecommunication traffic;minimisation;PCS networks;failure recovery scheme;mobility database;performance analysis;wireless mobile networks;active location update;mobile traffic distributions;cost analysis;optimal choice;cost minimization;call loss;Databases;Performance analysis;Personal communication networks;Wireless networks;Failure analysis;Cost function;Mobile computing;Computer networks;Telecommunication traffic;Authentication},
doi={10.1109/INFCOM.2000.832250},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832251,
author={Y. Bejerano and I. Cidon},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An anchor chain scheme for IP mobility management},
year={2000},
volume={2},
number={},
pages={765-774 vol.2},
abstract={This work presents a simple mobility scheme for IP-based networks, termed the "anchor chain" scheme. The scheme combines pointer forwarding and caching methods. Every mobile host (MH) is associated with a chain of anchors that connects it to its home agent. Each anchor defines the location of the MH at a certain degree of accuracy. The accuracy is increased along the chain until the attachment point of the MH is reached. We develop distributed procedures for updating the anchor chain (binding operation) with MH movements and for delivering messages to a MH (delivery operation). In terms of worst-case performance, the total cost of the binding operations is O(MovelogMove), where Move is the total geographic distance that the MH has traveled since its activation. The total length of the MH's pointer path is linear with the distance between the MH and its home network, and the delivery cost is near-optimal. In addition, the anchor chain of a MH is determined dynamically with no need for preliminary definitions of static anchors or regions. Our simulation results show that the anchor chain scheme also yields lower average overheads for both the binding and the delivery operations than other methods that are described in the literature, including the current home approach. We believe that the proposed scheme is scalable, fairly easy to implement and therefore attractive for supporting MH.},
keywords={personal communication networks;protocols;telecommunication network management;cache storage;optimisation;mobile radio;anchor chain scheme;IP mobility management;pointer forwarding;caching;mobile host;location;distributed procedures;binding operation;delivery operation;worst-case performance;near-optimal cost;simulation;PCS;Mobile radio mobility management;Home automation;Databases;Protocols;Routing;Cost function;TCPIP;Network servers;Sun},
doi={10.1109/INFCOM.2000.832251},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832252,
author={P. Bahl and V. N. Padmanabhan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={RADAR: an in-building RF-based user location and tracking system},
year={2000},
volume={2},
number={},
pages={775-784 vol.2},
abstract={The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.},
keywords={mobile computing;wireless LAN;radio tracking;radiowave propagation;signal processing;RADAR;in-building tracking system;RF-based tracking system;user location;mobile computing devices;local-area wireless networks;location-aware systems;signal strength processing;multiple base stations;overlapping coverage;signal propagation modeling;Radar tracking;Radio frequency;Wireless networks;Mobile computing;Computer networks;Wireless LAN;Global Positioning System;Radar signal processing;Signal processing;Base stations},
doi={10.1109/INFCOM.2000.832252},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832253,
author={Zuji Mao and C. Douligeris},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={High throughput database structures for location management in PCS networks},
year={2000},
volume={2},
number={},
pages={785-794 vol.2},
abstract={This paper introduces a distributed hierarchical database architecture for location management in global personal communications system (PCS) networks with the location-independent numbering plan. The proposed structure consists of a number of database subsystems, each of which is a three-level tree structure and is connected to the others only through its root. Due to the localized nature of calling and mobility patterns, this scheme effectively reduces the database loads and signaling traffic incurred by the location update and call delivery procedures. Moreover, based on the flat numbering plan, two memory-resident access structures-the memory-resident direct file and the T-tree are proposed for the location databases to further improve the database throughput. Analytical models and numerical examples are presented to evaluate the response time and the storage capacity required for each location database. Results show that our method can produce a high-throughput database system, which is crucial for the deployment of high-capacity PCS systems in the future. In addition, modifications to the data structure, the insert algorithm, and the delete algorithm for the T-tree are proposed to enhance the performance of the T-tree.},
keywords={distributed databases;personal communication networks;telecommunication traffic;tree data structures;telecommunication signalling;telecommunication computing;high-throughput database structures;location management;PCS networks;distributed hierarchical database architecture;global personal communications system;location-independent numbering plan;three-level tree structure;mobility patterns;calling patterns;signaling traffic;flat numbering plan;memory-resident direct file;T-tree;database throughput;response time;storage capacity;data structure;insert algorithm;delete algorithm;performance;Throughput;Personal communication networks;Distributed databases;Tree data structures;Telecommunication traffic;Traffic control;Analytical models;Delay;Database systems;Data structures},
doi={10.1109/INFCOM.2000.832253},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832254,
author={Y. Chawathe and S. McCanne and E. A. Brewer},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={RMX: reliable multicast for heterogeneous networks},
year={2000},
volume={2},
number={},
pages={795-804 vol.2},
abstract={Although IP multicast is an effective network primitive for best-effort, large-scale, multi-point communication, many multicast applications such as shared whiteboards, multi-player games and software distribution require reliable data delivery. Building services like reliable sequenced delivery on top of IP multicast has proven to be a hard problem. The enormous extent of network and end-system heterogeneity in multipoint communication exacerbates the design of scalable end-to-end reliable multicast protocols. In this paper, we propose a radical departure from the traditional end-to-end model for reliable multicast and instead propose a hybrid approach that leverages the successes of unicast reliability protocols such as TCP while retaining the efficiency of IP multicast for multi-point data delivery. Our approach splits a large heterogeneous reliable multicast session into a number of multicast data groups of co-located homogeneous participants. A collection of application-aware agents-reliable multicast proxies (RMX)-organizes these data groups into a spanning tree using an overlay network of TCP connections. Sources transmit data to their local group, and the RMX in that group forwards the data towards the rest of the data groups. RMX use detailed knowledge of application semantics to adapt to the effects of heterogeneity in the environment. To demonstrate the efficacy of our architecture, we have built a prototype implementation that can be customized for different kinds of applications.},
keywords={transport protocols;multicast communication;telecommunication network reliability;tree data structures;Internet;RMX;heterogeneous networks;shared whiteboards;multi-player games;software distribution;reliable multicast protocols;hybrid approach;TCP;IP multicast;multi-point data delivery;multicast data groups;co-located homogeneous participants;application-aware agents;reliable multicast proxies;spanning tree;overlay network;application semantics;Telecommunication network reliability;Multicast protocols;Computer network reliability;Unicast;TCPIP;Application software;Web and internet services;Bandwidth;Computer science;Large-scale systems},
doi={10.1109/INFCOM.2000.832254},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832255,
author={I. Rhee and S. R. Joshi and M. Lee and S. Muthukrishnan and V. Ozdemir},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Layered multicast recovery},
year={2000},
volume={2},
number={},
pages={805-813 vol.2},
abstract={We study the problem of localizing repair packets when packets are lost during multicasts. When repair packets are multicast, a highly lossy receiver may swamp the entire multicast "group" with duplicate repair packets thereby wasting bandwidth; thus, the protocols need repair locality. We present a multicast layering scheme where the sender proactively distributes FEC repair packets among multiple multicast groups. Each receiver can selectively tune in to a subset of these multicast groups to obtain packets close in number to what it needs. We develop an efficient algorithm that dynamically determines the optimal distribution of FEC repair packets to a given (small constant) number of multicast groups. The running time of this algorithm is independent of the number of receivers in the multicast session, and is hence highly scalable. However, the optimal algorithm requires the knowledge of the FEC repair requirements of all the receivers in the multicast group, and hence is subject to the implosion problem. To handle the implosion problem, we develop an heuristic algorithm that achieves repair locality very similar to that of the optimal algorithm, but does not require as much global knowledge. Our multicast layering scheme can be integrated into known reliable multicast protocols to make them more scalable. For concreteness, we focus on: (i) singly scoped SRM, (ii) hierarchically scoped SRM, and (iii) a tree-based reliable multicasting protocol RMTP, and present combined protocols incorporating our solutions into each of them. Simulation experiments show that our solutions can substantially enhance the scalability of these reliable multicast protocols.},
keywords={protocols;multicast communication;forward error correction;optimisation;tree data structures;telecommunication network reliability;layered multicast recovery;repair packet localization;FEC;multiple multicast groups;optimal distribution;scalable algorithm;optimal algorithm;implosion problem;heuristic algorithm;reliable multicast protocols;singly scoped SRM;hierarchically scoped SRM;tree-based reliable multicasting protocol;RMTP;simulation;scalability;Multicast protocols;Multicast algorithms;Heuristic algorithms;Computer science;Bandwidth;Scalability;Large-scale systems;Engineering profession;Casting},
doi={10.1109/INFCOM.2000.832255},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832256,
author={K. Guo and I. Rhee},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Message stability detection for reliable multicast},
year={2000},
volume={2},
number={},
pages={814-823 vol.2},
abstract={Many scalable reliable multicast protocols use the local repair scheme where certain receivers retransmit packets by other receivers. Such schemes need a mechanism, called message stability, to ensure reliable delivery to all members of a multicast group and to delete those packets received by all members from the buffers of the local repairers. We propose a new protocol for message stability based on random gossiping. The protocol offers scalabilty and fault-tolerance by limiting each of its message transmissions only to a constant number of randomly chosen group members, hence eliminating message implosion and single point failure through the diffusion of responsibility. Both statistical analysis and simulation study indicate that our gossip-style message stability protocol can be highly effective for large-scale reliable multicast.},
keywords={protocols;telecommunication network reliability;multicast communication;statistical analysis;fault tolerance;simulation;message stability detection;scalable multicast protocols;reliable multicast protocols;multicast group;random gossiping;fault-tolerance;statistical analysis;simulation;Multicast protocols;Buffer storage;Network topology;Computer science;Scalability;Fault tolerance;Analytical models;Stability analysis;Large-scale systems;Least squares approximation},
doi={10.1109/INFCOM.2000.832256},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832257,
author={K. C. Almeroth},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A long-term analysis of growth and usage patterns in the Multicast Backbone (MBone)},
year={2000},
volume={2},
number={},
pages={824-833 vol.2},
abstract={The Multicast Backbone (MBone), the Internet's multicast research infrastructure, has existed since the early 1990s. Since its inception, there have been few formal studies investigating the "state of multicast", i.e., the success of multicast deployment. Our work attempts to understand: (1) how the MBone is used, (2) how multicast deployment has progressed, and (3) what barriers exist for the continued deployment of multicast. Future research and deployment efforts would benefit significantly with answers to these macro-scale questions. Our work is based on data sets collected over a 4.5 year period. These data sets include join/leave statistics for many of the MBone sessions advertised through the MBone's session directory tool. Using this data, we examine characteristics about the number and frequency of multicast groups and about the users participating in these groups. In addition, we attempt to qualify the accuracy of our results by examining other sources of multicast traffic statistics. Among our conclusions, we find that the use and deployment of multicast has continued to grow, but at a relatively slow rate. Furthermore, most of the activity in the MBone occurs among a relatively small group of core users. Finally, in an attempt to understand why these conditions exist, we offer several possible reasons why multicast deployment has not been more rapid.},
keywords={Internet;protocols;telecommunication traffic;statistical analysis;growth patterns;usage patterns;Multicast Backbone;MBone;Internet;join/leave statistics;session directory tool;traffic statistics;Pattern analysis;Spine;Statistics;Internet;Computer science;Frequency;Multicast communication;Routing;Transport protocols;Streaming media},
doi={10.1109/INFCOM.2000.832257},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832258,
author={V. Duvvuri and P. Shenoy and R. Tewari},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Adaptive leases: a strong consistency mechanism for the World Wide Web},
year={2000},
volume={2},
number={},
pages={834-843 vol.2},
abstract={In this paper, we argue that weak cache consistency mechanisms supported by existing Web proxy caches must be augmented by strong consistency mechanisms to support the growing diversity in application requirements. Existing strong consistency mechanisms are not appealing for Web environments due to their large state space or control message overhead. We focus on the lease approach that balances these tradeoffs and present analytical models and policies for determining the optimal lease duration. We present extensions to HTTP to incorporate leases and then implement our techniques in the Squid proxy cache and the Apache Web server. Our experimental evaluation of the leases approach shows that: (i) our techniques impose modest overheads even for long leases (a lease duration of 1 hour requires state to be maintained for 1030 leases and imposes a per object overhead of a control message every 33 minutes); (ii) leases yield a 138-425% improvement over existing strong consistency mechanisms; and (iii) the implementation overhead of leases is comparable to existing weak consistency mechanisms.},
keywords={information resources;cache storage;optimisation;transport protocols;telecommunication control;telecommunication traffic;adaptive leases;World-Wide Web;cache consistency;Web proxy caches;strong consistency mechanisms;optimal lease duration;HTTP;Squid proxy cache;Apache Web server;object overhead;control message;Web sites;Web server;Network servers;Internet;Delay;Humans;Computer science;State-space methods;Analytical models;Protocols},
doi={10.1109/INFCOM.2000.832258},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832259,
author={J. Challenger and A. Iyengar and K. Witting and C. Ferstat and P. Reed},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A publishing system for efficiently creating dynamic Web content},
year={2000},
volume={2},
number={},
pages={844-853 vol.2},
abstract={This paper presents a publishing system for efficiently creating dynamic Web content. Complex Web pages are constructed from simpler fragments. Fragments may recursively embed other fragments. Relationships between Web pages and fragments are represented by object dependence graphs. We present algorithms for efficiently detecting and updating Web pages affected after one or more fragments change. We also present algorithms for publishing sets of Web pages consistently; different algorithms are used depending upon the consistency requirements. Our publishing system provides an easy method for Web site designers to specify and modify inclusion relationships among Web pages and fragments. Users can update content on multiple Web pages by modifying a template. The system then automatically updates an Web pages affected by the change. Our system accommodates both content that must be proof-read before publication and is typically from humans as well as content that has to be published immediately and is typically from automated feeds. Our system is deployed at several popular Web sites including the 2000 Olympic Games Web site. We discuss some of our experiences with real deployments of our system as well as its performance.},
keywords={electronic publishing;information resources;graphs;software performance evaluation;publishing system;dynamic Web content;object dependence graphs;Web site designers;inclusion relationships;template modification;automatic updates;proof-read content;automated feeds;Web sites;performance;Publishing;Web pages;Change detection algorithms;Humans;Feeds;Stock markets;Hardware;File systems;Markup languages},
doi={10.1109/INFCOM.2000.832259},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832260,
author={E. Cohen and H. Kaplan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Prefetching the means for document transfer: a new approach for reducing Web latency},
year={2000},
volume={2},
number={},
pages={854-863 vol.2},
abstract={User-perceived latency is recognized as the central performance problem in the Web. We systematically measure factors contributing to this latency, across several locations. Our study reveals that DNS query times, TCP connection establishment, and start-of-session delays at HTTP servers, more so than transmission time, are major causes of long waits. Wait due to these factors also afflicts high-bandwidth users and has detrimental effect on perceived performance. We propose simple techniques that address these factors: (i) pre-resolving host-names (pre-performing DNS lookup); (ii) pre-connecting (prefetching TCP connections prior to issuance of HTTP request); and (iii) pre-warming (sending a "dummy" HTTP HEAD request to Web servers). Trace-based simulations demonstrate a potential to reduce perceived latency dramatically. Our techniques surpass document prefetching in performance improvement per bandwidth used and can be used with non-prefetchable URL. Deployment of these techniques at Web browsers or proxies does not require protocol modifications or the cooperation of other entities. Applicable servers can be identified, for example, by analyzing hyperlinks. Bandwidth overhead is minimal, and so is processing overhead at the user's browser. We propose scalable deployment solutions to control the potential overhead to proxies and particularly to Web servers.},
keywords={information resources;document handling;performance evaluation;delays;online front-ends;network servers;hypermedia;transport protocols;prefetching;document transfer;Web latency;performance;DNS query times;TCP connection establishment;start-of-session delays;HTTP servers;high-bandwidth users;pre-resolving;pre-connecting;pre-warming;trace-based simulations;non-prefetchable URL;Web browsers;proxy servers;hyperlinks;scalable deployment;Web servers;Prefetching;Web server;Bandwidth;Transport protocols;TCPIP;Internet;Delay effects;Uniform resource locators;Time factors;Proposals},
doi={10.1109/INFCOM.2000.832260},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832261,
author={P. Rodriguez and A. Kirpal and E. W. Biersack},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Parallel-access for mirror sites in the Internet},
year={2000},
volume={2},
number={},
pages={864-873 vol.2},
abstract={Popular documents are frequently mirrored on multiple sites in an effort to share the load and reduce clients' retrieval latencies. However, choosing the best mirror site is a non-trivial task and a bad choice may give poor performance. We propose a scheme in which clients access multiple mirror sites in parallel to speedup document downloads while eliminating the problem of server selection. In our scheme, clients connect to mirror sites using unicast TCP connections and dynamically request different pieces of a document from different sites. The amount of data retrieved from a particular site varies depending on the network path/server conditions. Dynamic parallel-access can be easily implemented in the current Internet and does not require any modifications at the mirror sites. Using dynamic parallel-access, all clients experience dramatic speedups in downloading documents, and the load is shared among servers without the need for a server selection mechanism. Even in a situation where clients are connected through modem lines, dynamic parallel-access offers transmission rates at least as high as the fastest server.},
keywords={information retrieval;Internet;client-server systems;delays;performance evaluation;transport protocols;cache storage;mirror sites;Internet;retrieval latencies;performance;unicast TCP connections;dynamic parallel access;client server system;document downloading;Mirrors;Internet;Network servers;Web server;Delay;Unicast;Information retrieval;Modems;Bandwidth;Load management},
doi={10.1109/INFCOM.2000.832261},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832262,
author={Y. Afek and A. Bremler-Barr},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Trainet: a new label switching scheme},
year={2000},
volume={2},
number={},
pages={874-883 vol.2},
abstract={Trainet, a new scheme to extend MPLS (multi-protocol label switching) is presented. The scheme works much like the subway system in a large metropolitan area. Each (unidirectional) subway line corresponds to a labeled path, and a route in the network is defined by either a pair <label, count-value>, where count specifies how many hops a packet still has to take in the specified train, or a route may be defined by a sequence of such pairs. A sequence of such pairs specifies that the packet has to take a number of hops in one train-line, and then continue for a certain number of hops on another train-line and so forth. While slightly increasing the number of labels in a header and adding a counter to each label, the scheme reduces the total number of different labels necessary in the network, and in each switch. Thus, for a given number of labels it may support a larger number of flows. Moreover, our scheme considerably simplifies the path set-up cost while still providing all the features of MPLS: switching, supporting QoS, explicit routing, and traffic engineering.},
keywords={telecommunication switching;protocols;quality of service;telecommunication traffic;telecommunication network routing;Trainet;MPLS;multi-protocol label switching;pair sequence;path set-up cost;QoS;explicit routing;traffic engineering;Routing;Multiprotocol label switching;Switches;Packet switching;Protocols;Costs;Computer science;Urban areas;Counting circuits;Research and development},
doi={10.1109/INFCOM.2000.832262},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832263,
author={M. Kodialam and T. V. Lakshman},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Minimum interference routing with applications to MPLS traffic engineering},
year={2000},
volume={2},
number={},
pages={884-893 vol.2},
abstract={This paper presents a new algorithm for dynamic routing of bandwidth-guaranteed tunnels when tunnel routing requests arrive one-by-one and there is no a priori knowledge regarding future requests. This problem is motivated by service provider needs for fast deployment of bandwidth-guaranteed services and the consequent need in backbone networks for fast provisioning of bandwidth-guaranteed paths. Offline routing algorithms cannot be used since they require a priori knowledge of all tunnel requests that are to be routed. Instead, on-line algorithms that handle requests arriving one-by-one and that satisfy as many potential future demands as possible are needed. The newly developed algorithm is an on-line algorithm and is based on the idea that a newly routed tunnel must follow a route that does not "interfere too much" with a route that may be critical to satisfy a future demand. We show that this problem is NP-hard. We then develop a path selection heuristic that is based on the idea of deferred loading of certain "critical" links. These critical links are identified by the algorithm as links that, if heavily loaded, would make it impossible to satisfy future demands between certain ingress-egress pairs. Like min-hop routing, the presented algorithm uses link-state information and some auxiliary capacity information for path selection. Unlike previous algorithms, the proposed algorithm exploits any available knowledge of the network ingress-egress points of potential future demands even though the demands themselves are unknown.},
keywords={telecommunication network routing;minimisation;protocols;telecommunication switching;telecommunication traffic;quality of service;minimum interference routing;MPLS;traffic engineering;dynamic routing;bandwidth-guaranteed tunnels;bandwidth-guaranteed services;bandwidth-guaranteed paths;on-line algorithms;NP-hardness;path selection heuristic;deferred loading;critical links;link-state information;auxiliary capacity information;network ingress-egress points;potential future demands;Interference;Routing;Multiprotocol label switching;Bandwidth;Uninterruptible power systems;Telecommunication traffic;Traffic control;Delay effects;Quality of service},
doi={10.1109/INFCOM.2000.832263},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832264,
author={H. Saito and Y. Miyao and M. Yoshida},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Traffic engineering using multiple multipoint-to-point LSPs},
year={2000},
volume={2},
number={},
pages={894-901 vol.2},
abstract={Traffic engineering aims to optimize the utilization of existing network resources for load balance and failure recovery, and these are to be accomplished in a scalable fashion. This paper proposes a traffic engineering scheme using multiple multipoint-to-point (m-t-p) label switched paths (LSP) which can reduce the number of LSP and required labels in links. The scheme consists of m-t-p LSP creation and flow assignment. Routes are first selected, and m-t-p LSP are designed to include them. The m-t-p LSP design problem is formulated as a 0-1 integer programming problem. The flow assignment problem is formulated as a mixed integer programming problem in which maximum link load, i.e., maximum congestion, is minimized. Numerical comparisons with the conventional point-to-point LSP approach show that the m-t-p LSP approach can reduce the number of required LSP and labels. Moreover, numerical comparisons with conventional shortest path fast-based flow assignment show that our flow assignment scheme can reduce maximum link load.},
keywords={telecommunication traffic;telecommunication switching;telecommunication network routing;minimisation;integer programming;Internet;telecommunication congestion control;traffic engineering;multiple multipoint-to-point LSP;optimization;network resource utilization;load balance;failure recovery;label switched paths;flow assignment;routes;integer programming;maximum link load;congestion minimization;link load;Internet;Multiprotocol label switching;Communication system traffic control;Telecommunication traffic;Quality of service;Load management;Linear programming;Maintenance engineering;Tree graphs;Laboratories;National electric code},
doi={10.1109/INFCOM.2000.832264},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832265,
author={M. Kodialam and T. V. Lakshman},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Dynamic routing of bandwidth guaranteed tunnels with restoration},
year={2000},
volume={2},
number={},
pages={902-911 vol.2},
abstract={This paper presents new algorithms for dynamic routing of restorable bandwidth-guaranteed paths. A straightforward solution for the restoration problem is to find two disjoint paths. However, this results in excessive resource usage for backup paths and does not satisfy the implicit service provider requirement of optimizing network resource utilization so as to increase the number of potential future demands that can be routed. We give an integer programming formulation for this problem which is new. Complete path routing knowledge is a reasonable assumption for a centralized routing algorithm. However, it requires maintenance of non-aggregated or per-path information which is not often desirable particularly when distributed routing is preferred. We show that a partial information scenario which uses only aggregated and not per-path information provides sufficient information for a suitably developed algorithm to be able to perform almost as well as the complete information scenario. In this partial information scenario the routing algorithm only knows what fraction of each link's bandwidth, is currently used by active paths, and is currently used by backup paths. Obtaining this information is feasible using proposed traffic engineering extensions to routing protocols. We formulate the dynamic restorable bandwidth routing problem in this partial information scenario and develop efficient routing algorithms. We compare there routing performance of this algorithm to a bound obtained using complete information. Our partial information-based algorithm performs very well and its performance in terms of the number of rejected requests is very close to the full information bound.},
keywords={telecommunication network routing;integer programming;telecommunication traffic;protocols;quality of service;dynamic routing;bandwidth-guaranteed tunnels;restoration;bandwidth-guaranteed paths;optimization;network resource utilization;integer programming;path routing;centralized routing;distributed routing;active paths;backup paths;traffic engineering;routing protocols;performance;QoS;Routing;Bandwidth;Multiprotocol label switching;Spine;Uninterruptible power systems;Aggregates;Telecommunication traffic;Paper technology;Heuristic algorithms;Optical fiber networks},
doi={10.1109/INFCOM.2000.832265},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832266,
author={S. Borst and O. Boxma and P. Jelenkovic},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Asymptotic behavior of generalized processor sharing with long-tailed traffic sources},
year={2000},
volume={2},
number={},
pages={912-921 vol.2},
abstract={We analyze the asymptotic behavior of long-tailed traffic sources under the generalized processor sharing (GPS) discipline. GPS-based scheduling algorithms, such as weighted fair queueing, have emerged as an important mechanism for achieving differentiated quality-of-service in integrated-services networks. Under certain conditions, we prove that in an asymptotic sense an individual source with long-tailed traffic characteristics is effectively served at a constant rate, which may be interpreted as the maximum feasible average rate for that source to be stable. Thus, asymptotically, the source is only affected by the traffic characteristics of the other sources through their average rate. In particular, the source is essentially immune from excessive activity of sources with 'heavier'-tailed traffic characteristics. This suggests that GPS-based scheduling algorithms provide an effective mechanism for extracting high multiplexing gains, while protecting individual connections.},
keywords={telecommunication traffic;scheduling;multiplexing;queueing theory;quality of service;asymptotic behavior;generalized processor sharing;long-tailed traffic sources;scheduling algorithms;weighted fair queueing;quality of service;integrated-services networks;multiplexing gains;Traffic control;Global Positioning System;Scheduling algorithm;Queueing analysis;Tail;Telecommunication traffic;Communication system traffic control;Mathematics;Data mining;Protection},
doi={10.1109/INFCOM.2000.832266},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832267,
author={Zhiruo Cao and Zheng Wang and E. Zegura},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Rainbow fair queueing: fair bandwidth sharing without per-flow state},
year={2000},
volume={2},
number={},
pages={922-931 vol.2},
abstract={Fair bandwidth sharing at routers has several advantages, including protection of well-behaved flows and possible simplification of end-to-end congestion control mechanisms. Traditional mechanisms to achieve fair sharing (e.g., weighted fair queueing, flow random early discard) require per-flow state to determine which packets to drop under congestion, and therefore are complex to implement at the interior of a high-speed network. In recent work, Stoica et al., (1998), have proposed core-stateless fair queueing (CSFQ), a scheme to approximate fair bandwidth sharing without per-flow state in the interior routers. In this paper, we also achieve approximate fair sharing without per-flow state, however our mechanism differs from CSFQ. Specifically, we divide each flow into a set of layers, based on rate. The packets in a flow are marked at an edge router with a layer label (or "color"). A core router maintains a color threshold and drops layers whose color exceeds the threshold. Using simulations, we show that the performance of our rainbow fair queueing (RFQ) scheme is comparable to CSFQ when the application data does not contain any preferential structure. RFQ outperforms CSFQ in goodput when the application takes advantage of the coloring to encode preferences.},
keywords={queueing theory;telecommunication traffic;telecommunication congestion control;telecommunication network routing;quality of service;rainbow fair queueing;fair bandwidth sharing;well-behaved flows;end-to-end congestion control;weighted fair queueing;flow random early discard;high-speed network;edge router;layer label;core router;color threshold;simulations;performance;goodput;differentiated services;Bandwidth;Protection;High-speed networks;Educational institutions;Spine;Round robin;Labeling;Hardware},
doi={10.1109/INFCOM.2000.832267},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832268,
author={K. Kumaran and G. E. Margrave and D. Mitra and K. R. Stanley},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Novel techniques for the design and control of generalized processor sharing schedulers for multiple QoS classes},
year={2000},
volume={2},
number={},
pages={932-941 vol.2},
abstract={Generalized processor sharing (GPS) is a scheduling discipline which provides minimum service guarantees as well as fair resource sharing. The performance of GPS is governed by the scheduling weights associated with individual connections. We address the design of the GPS weights, along with the related connection admission control (CAC). Our main goal is to achieve statistical multiplexing gains in the presence of multiple traffic and quality-of-service (QoS) classes of connections that share a common trunk. We present novel techniques to compute and adapt the weights. We also characterize the capacity region of the system, and propose a natural CAC procedure. Numerical results on 2-class and 3-class examples demonstrate the effectiveness of our methods.},
keywords={telecommunication control;scheduling;quality of service;queueing theory;telecommunication congestion control;multiplexing;telecommunication traffic;generalized processor sharing;control;schedulers;multiple QoS classes;minimum service guarantees;fair resource sharing;performance;connection admission control;CAC;statistical multiplexing gains;multiple traffic;quality of service;weight adaptation;capacity region;Process control;Processor scheduling;Global Positioning System;Quality of service;Resource management;Traffic control;Switches;Delay;Explosives;Bandwidth},
doi={10.1109/INFCOM.2000.832268},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832269,
author={Rong Pan and B. Prabhakar and K. Psounis},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={CHOKe - a stateless active queue management scheme for approximating fair bandwidth allocation},
year={2000},
volume={2},
number={},
pages={942-951 vol.2},
abstract={We investigate the problem of providing a fair bandwidth allocation to each of n flows that share the outgoing link of a congested router. The buffer at the outgoing link is a simple FIFO, shared by packets belonging to the n flows. We devise a simple packet dropping scheme, called CHOKe, that discriminates against the flows which submit more packets per second than is allowed by their fair share. By doing this, the scheme aims to approximate the fair queueing policy. Since it is stateless and easy to implement, CHOKe controls unresponsive or misbehaving flows with a minimum overhead.},
keywords={bandwidth allocation;scheduling;queueing theory;telecommunication congestion control;telecommunication network routing;telecommunication network management;buffer storage;CHOKe;stateless active queue management;fair bandwidth allocation;approximation;congested router;FIFO buffer;packet dropping scheme;fair queueing policy;flow control;Inductors;Channel allocation;Scheduling algorithm;Bandwidth;Partitioning algorithms;Quality of service;Costs;State estimation;Engineering management;Web and internet services},
doi={10.1109/INFCOM.2000.832269},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832270,
author={Chuanhai Liu and J. Nonnenmacher},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Broadcast audience estimation},
year={2000},
volume={2},
number={},
pages={952-960 vol.2},
abstract={We investigate the estimation of the size of a broadcast audience. We give the maximum likelihood (ML) estimators for different scenarios. Using a Poisson approximation we obtain upper and lower bounds for the audience size. The ML estimators has closed-form expressions, so do the bounds. We treat the problem of a malfunctioning feedback flow control, where the sender is overwhelmed by feedback messages. The ML estimate of the audience size is obtained using the expectation-maximization (EM) algorithm, even under such conditions as censored values due to feedback implosion. Quantifying the influence of feedback implosion on the loss of information for the audience estimation, we further investigate the choice of the parameters in order to optimize estimation results.},
keywords={Internet;broadcasting;maximum likelihood estimation;feedback;Poisson distribution;telecommunication congestion control;optimisation;broadcast audience estimation;maximum likelihood estimators;Poisson approximation;upper bounds;lower bounds;closed-form expressions;malfunctioning feedback flow control;expectation-maximization algorithm;EM algorithm;censored values;feedback implosion;optimization;Internet;Feedback;Satellite broadcasting;Maximum likelihood estimation;Radio broadcasting;TV broadcasting;Unicast;Convergence;Closed-form solution;Statistics;Multicast algorithms},
doi={10.1109/INFCOM.2000.832270},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832271,
author={S. Chandra and C. S. Ellis and A. Vahdat},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Differentiated multimedia Web services using quality aware transcoding},
year={2000},
volume={2},
number={},
pages={961-969 vol.2},
abstract={The ability of a Web service to provide low-latency access to its contents is constrained by available network bandwidth. It is important for the service to manage available bandwidth wisely. While providing differentiated quality of service (QoS) is typically enforced through network mechanisms, in this paper we introduce a robust mechanism for managing network resources at the application level. We use transcoding to allow Web servers to customize the size of objects constituting a Web page, and hence the bandwidth consumed by that page, by dynamically varying the size of multimedia objects on a per-client basis. We leverage earlier work on characterizing quality versus size tradeoffs in transcoding JPEG images to dynamically determine the quality and size of the object to transmit. We evaluate the performance benefits of incorporating this information in a series of bandwidth management policies. We develop metrics to measure the performance of our system. We use realistic workloads and access scenarios to drive our system. The principal contribution of this work is the demonstration that it is possible to use informed transcoding techniques to provide differentiated service and to dynamically allocate available bandwidth among different client classes, while delivering a high degree of information content (quality factor) for all clients.},
keywords={quality of service;multimedia communication;information resources;bandwidth allocation;computer network management;performance evaluation;client-server systems;differentiated services;multimedia services;quality-aware transcoding;Web service;low-latency access;available bandwidth management;quality of service;QoS;robust mechanism;Web page;object size customization;performance evaluation;dynamic bandwidth allocation;client server system;information content;quality factor;Web services;Bandwidth;Transcoding;Quality of service;Robustness;Quality management;Resource management;Web server;Web pages;Q factor},
doi={10.1109/INFCOM.2000.832271},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832272,
author={P. Y. Wang and Y. Yemini and D. Florissi and J. Zinky and P. Florissi},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Experimental QoS performances of multimedia applications},
year={2000},
volume={2},
number={},
pages={970-979 vol.2},
abstract={Several QoS provisioning mechanisms such as differentiated services (Diffserv) and integrated services (Intserv) have been recently devised and applied to bring quality of service (QoS) to the Internet. This paper studies end-end QoS performances of two QoS-demanding applications using different transport protocols. Both applications are tested in a real network environment, with end-end QoS provisioning by Intserv. They use QoSockets, a new extension of QoS specification and management to the Berkeley sockets. Their performance in terms of throughput, delay, jitter, and loss are measured under a number of test cases combining several factors: (1) single or multiple flows, with or without resource reservations; (2) normal, heavy, or overloaded scenarios; (3) uni- or bi-directional streams; and (4) TCP or UDP protocols. The experimental results show that the performance of two applications with the Intserv resource reservations are significantly improved, but not always guaranteed. It is also shown that UDP applications are able to get the requested QoS while TCP applications may not because of the nature of its bi-directional traffic flow. The paper provides detailed interpretation of the results and provides generic conclusions on application QoS.},
keywords={multimedia communication;quality of service;transport protocols;Internet;software performance evaluation;computer network management;telecommunication traffic;multimedia applications;QoS;performance;provisioning mechanisms;differentiated services;Diffserv;integrated services;Intserv;quality of service;Internet;transport protocols;QoSockets;specification;management;Berkeley sockets;throughput;delay;jitter;loss;resource reservations;uni-directional streams;bi-directional streams;UDP;protocols;TCP;traffic flow;Quality of service;Testing;Bidirectional control;Diffserv networks;Intserv networks;Web and internet services;Transport protocols;Sockets;Performance evaluation;Throughput},
doi={10.1109/INFCOM.2000.832272},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832273,
author={R. Rejaie and Haobo Yu and M. Handley and D. Estrin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Multimedia proxy caching mechanism for quality adaptive streaming applications in the Internet},
year={2000},
volume={2},
number={},
pages={980-989 vol.2},
abstract={The Internet has witnessed a rapid growth in deployment of Web-based streaming applications during recent years. In these applications, the server should be able to perform end-to-end congestion control and quality adaptation to match the delivered stream quality to the average available bandwidth. Thus the delivered quality is limited by the bottleneck bandwidth on the path to the client. This paper proposes a proxy caching mechanism for layered-encoded multimedia streams in the Internet to maximize the delivered quality of popular streams to interested clients. The main challenge is to replay a quality-variable cached stream while performing quality adaptation effectively in response to the variations in available bandwidth. We present a prefetching mechanism to support higher quality cached streams during subsequent playbacks and improve the quality of the cached stream with its popularity. We exploit inherent properties of multimedia streams to extend the semantics of popularity and capture both level of interest among clients and usefulness of a layer in the cache. We devise a fine-grain replacement algorithm suited for layered-encoded streams. Our simulation results show that the interaction between the replacement algorithm and prefetching mechanism causes the state of the cache to converge to an efficient state such that the quality of a cached stream is proportional to its popularity, and the variations in quality of a cached stream are inversely proportional to its popularity. This implies that after serving several requests for a stream, the proxy can effectively hide low bandwidth paths to the original server from interested clients.},
keywords={multimedia communication;cache storage;quality of service;Internet;telecommunication congestion control;multimedia proxy caching mechanism;quality adaptive streaming applications;Internet;Web-based streaming applications;end-to-end congestion control;quality adaptation;average available bandwidth;delivered quality;bottleneck bandwidth;layered-encoded multimedia streams;quality-variable cached stream;prefetching mechanism;fine-grain replacement algorithm;layered-encoded streams;replacement algorithm;Streaming media;Internet;Bandwidth;Web server;Network servers;Prefetching;Intersymbol interference;Explosives;Pipelines;Mirrors},
doi={10.1109/INFCOM.2000.832273},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832274,
author={A. Sridharan and K. N. Sivarajan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Blocking in all-optical networks},
year={2000},
volume={2},
number={},
pages={990-999 vol.2},
abstract={We present a new analytical technique, based on the inclusion-exclusion principle from combinatorial mathematics, for the analysis of all-optical networks with no wavelength conversion and random wavelength assignment. We use this technique to propose two models of low complexity for analysing networks with arbitrary topologies and traffic patterns. The first model improves the current technique by Birman (1996) in that the complexity of calculation is independent of hop-length and scales only with the capacity of the link as against that of Birman's method which grows exponentially with hop-length. We then propose a new heuristic to account for wavelength correlation and show that the second model is accurate even for sparse networks. Our technique can also be extended to analyse fixed alternate and least loaded routing.},
keywords={optical fibre networks;combinatorial mathematics;network topology;telecommunication traffic;telecommunication network routing;correlation methods;all-optical networks;inclusion-exclusion principle;combinatorial mathematics;random wavelength assignment;arbitrary topologies;traffic patterns;hop-length;link capacity;wavelength correlation;sparse networks;fixed alternate routing;least loaded routing;blocking;Intelligent networks;All-optical networks;Wavelength routing;Optical wavelength conversion;Wavelength assignment;Traffic control;Switching circuits;Analytical models;Telecommunication traffic;Wavelength division multiplexing},
doi={10.1109/INFCOM.2000.832274},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832275,
author={T. Cinkler and D. Marx and C. P. Larsen and D. Fogaras},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Heuristic algorithms for joint configuration of the optical and electrical layer in multi-hop wavelength routing networks},
year={2000},
volume={2},
number={},
pages={1000-1009 vol.2},
abstract={An efficient and general graph-theoretic model (the wavelength-graph (WG)) has been proposed which enables solution of the static routing and wavelength assignment (RWA) problems in multihop wavelength routing (WR) wavelength division multiplexing (WDM) networks simultaneously, and-as a unique feature-it optimises the optical layer jointly with the electrical one. Based on the proposed WG model the problem has been formulated as an integer linear program (ILP), solved by stochastic algorithms improved by simple heuristics. The topology of the physical layer, the type of each node (e.g., OADM, OXC or EXC), the number of available wavelengths per link and the capacity of each wavelength-channel are assumed given with the aggregated traffic demand of each node-pair. The output of the optimisation is the system of wavelength paths, light paths and semi-light paths. The objective of the optimisation is to reduce resource usage at upper (electrical) layers, subject to the constrained amount of capacity of each wavelength and a limited number of wavelengths. Although the problem to be solved is NP-hard, all methods proposed give a result in a very short time.},
keywords={telecommunication network routing;optical fibre networks;graph theory;wavelength division multiplexing;linear programming;integer programming;stochastic processes;network topology;channel capacity;computational complexity;heuristic algorithms;optical layer;electrical layer;multi-hop wavelength routing networks;general graph-theoretic model;wavelength-graph;routing and wavelength assignment;multihop wavelength routing;wavelength division multiplexing;integer linear program;stochastic algorithms;wavelengths per link;wavelength-channel capacity;aggregated traffic demand;wavelength paths;light paths;semi-light paths;resource usage;NP-hard problem;Heuristic algorithms;Wavelength routing;Wavelength division multiplexing;Wavelength assignment;Spread spectrum communication;WDM networks;Optical fiber networks;Stochastic processes;Network topology;Physical layer},
doi={10.1109/INFCOM.2000.832275},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832276,
author={A. Narula-Tam and E. Modiano},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Dynamic load balancing for WDM-based packet networks},
year={2000},
volume={2},
number={},
pages={1010-1019 vol.2},
abstract={We develop load balancing algorithms for WDM-based packet networks in which the average traffic between nodes is dynamically changing. In WDM-based packet networks, routers are connected to each other using wavelengths (lightpaths) to form a logical network topology. This logical topology may be reconfigured by rearranging the lightpaths connecting the routers. The goal of our load balancing algorithms is to minimize network delay by reconfiguring the logical topology. Since delay becomes unbounded as the load approaches the link capacity, delay is usually dominated by the most heavily loaded link. Therefore, our algorithms attempt to minimize the maximum link load. Even when traffic is static, deriving the optimal logical topology for a given traffic pattern is known to be NP-complete. Previous work on reconfiguration proposed heuristic algorithms to determine the "best" logical topology for the given traffic pattern and migrated to that topology using a series of reconfiguration steps. However, when traffic patterns are changing rapidly, reconfiguring the full network with every change in the traffic may be extremely disruptive. In this paper, we develop iterative reconfiguration algorithms for load balancing that track rapid changes in the traffic pattern. At each reconfiguration step, our algorithms make only a small change to the network topology, hence, minimizing the disruption to the network. We study the performance of our algorithms under several dynamic traffic scenarios and show that our algorithms perform near optimally.},
keywords={network topology;wavelength division multiplexing;packet switching;telecommunication traffic;telecommunication network routing;iterative methods;optical fibre networks;dynamic load balancing;WDM-based packet networks;routers;logical network topology;link capacity;delay;maximum link load;optimal logical topology;NP-complete problem;iterative reconfiguration algorithms;Load management;Telecommunication traffic;Network topology;Optical transmitters;Traffic control;Iterative algorithms;Wavelength division multiplexing;Optical network units;Add-drop multiplexers;Circuit topology},
doi={10.1109/INFCOM.2000.832276},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832277,
author={Liwu Liu and Xiangyang Li and Peng-Jun Wan and O. Frieder},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Wavelength assignment in WDM rings to minimize SONET ADMs},
year={2000},
volume={2},
number={},
pages={1020-1025 vol.2},
abstract={We study wavelength assignment for lightpaths over WDM rings to minimize the SONET ADMs (add/drop multiplexers) used. This problem has attracted much attention recently. However, its computational complexity remains unknown, and the only known heuristic (Gerstel et al., 1998) which does not allow the splitting of lightpaths is problematic in terms of both the algorithm itself and its performance analysis. We first prove the NP-completeness of this problem, followed by a nontrivial randomized (3+e)/(1+e)-approximation scheme. We then present a tighter lower bound on the minimum number of ADMs required. After that, we show the incorrectness of the known heuristic and then modify it to make it correct. We also propose three additional heuristics. Their performances are compared through extensive simulation studies.},
keywords={wavelength division multiplexing;SONET;optical fibre networks;computational complexity;approximation theory;multiplexing equipment;optical communication equipment;wavelength assignment;WDM rings;SONET ADMs;lightpaths;computational complexity;NP-complete problem;nontrivial randomized approximation scheme;heuristics;add/drop multiplexers;Wavelength assignment;Wavelength division multiplexing;SONET;Add-drop multiplexers;WDM networks;Optical fiber networks;Computer science;Performance analysis;Clocks;Optical add-drop multiplexers},
doi={10.1109/INFCOM.2000.832277},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832278,
author={V. J. Ribeiro and R. H. Riedi and M. S. Crouse and R. G. Baraniuk},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Multiscale queuing analysis of long-range-dependent network traffic},
year={2000},
volume={2},
number={},
pages={1026-1035 vol.2},
abstract={Many studies have indicated the importance of capturing scaling properties when modeling traffic loads; however, the influence of long-range dependence (LRD) and marginal statistics still remains on an unsure footing. In this paper, we study these two issues by introducing a multiscale traffic model and a novel multiscale approach to queuing analysis. The multifractal wavelet model (MWM) is a multiplicative, wavelet-based model that captures the positivity, LRD, and "spikiness" of non-Gaussian traffic. Using a binary tree, the model synthesizes an N-point data set with only O(N) computations. Leveraging the tree structure of the model, we derive a multiscale queuing analysis that provides a simple closed form approximation to the tail queue probability, valid for any given buffer size. The analysis is applicable not only to the MWM but to tree-based models in general, including fractional Gaussian noise. Simulated queuing experiments demonstrate the accuracy of the MWM for matching real data traces and the precision of our theoretical queuing formula. Thus, the MWM is useful not only for fast synthesis of data for simulation purposes but also for applications requiring accurate queuing formulas such as call admission control. Our results clearly indicate that the marginal distribution of traffic at different time-resolutions affects queuing and that a Gaussian assumption can lead to over-optimistic predictions of tail queue probability even when taking LRD into account.},
keywords={queueing theory;telecommunication traffic;fractals;wavelet transforms;tree data structures;probability;buffer storage;telecommunication congestion control;multiscale queuing analysis;long-range-dependent network traffic;scaling properties;marginal statistics;multiscale traffic model;multifractal wavelet model;multiplicative wavelet-based model;non-Gaussian traffic;binary tree;N-point data set;tree structure;closed form approximation;tail queue probability;buffer size;fractional Gaussian noise;call admission control;Queueing analysis;Telecommunication traffic;Traffic control;Load modeling;Statistics;Fractals;Binary trees;Tree data structures;Tail;Gaussian noise},
doi={10.1109/INFCOM.2000.832278},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832279,
author={Heejune Ahn and Jae-Kyoon Kim and Song Chong and Bara Kim and Bong Dae Choi},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A video traffic model based on the shifting-level process: the effects of SRD and LRD on queueing behavior},
year={2000},
volume={2},
number={},
pages={1036-1045 vol.2},
abstract={Recently, a number of empirical studies have demonstrated the existence of long-range dependence (LRD) or self-similarity in VBR video traffic. Since previous LRD models cannot capture all short- and long-term correlation and rate-distribution while still retaining mathematical tractability, there exist many doubts on the importance of SRD, LED, and rate-distribution on traffic engineering. In this paper, we present a video traffic model based on the shifting-level (SL) process with an accurate parameter matching algorithm for video traffic. The SL process captures all those key statistics of an empirical video trace. Also, we devised a queueing analysis method of SL/D/1/K, where the system size at every embedded point is quantized into a fixed set of values, thus the name quantization reduction method. This method is different from previous LRD queueing results in that it provides queueing results over all range not just an asymptotic solution. Further, this method provides not only the approximation but also the bounds of the approximation for the system states and thus guarantees the accuracy of the analysis. We found that for most available traces their ACF can be accurately modeled by a compound correlation (SLCC): an exponential function in short range and a hyperbolic function in long range. Comparing the queueing performances with C-DAR(1), the SLCC, and real video traces identify the effects of SRD and LRD in VBR video traffic on queueing performance.},
keywords={telecommunication traffic;queueing theory;fractals;visual communication;quantisation (signal);correlation methods;video traffic model;shifting-level process;queueing behavior;long-range dependence;self-similarity;VBR video traffic;rate-distribution;traffic engineering;parameter matching algorithm;SL/D/1/K queueing;quantization reduction method;system states;compound correlation;exponential function;hyperbolic function;Traffic control;Communication system traffic control;Telecommunication traffic;Statistics;Queueing analysis;Autocorrelation;Layout;Mathematics;Quantization;Intserv networks},
doi={10.1109/INFCOM.2000.832279},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832280,
author={JiaFu He and K. Sohraby},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On the queueing analysis of dispersed periodic messages},
year={2000},
volume={2},
number={},
pages={1046-1054 vol.2},
abstract={Constant bit rate (CBR) traffic is expected to be an important source of traffic in high-speed networks. Such sources may have stringent delay and loss requirements and in many cases, they should be delivered exactly as they were generated. A simple delay priority scheme will bound the cell delay and jitter for CBR flows, so that in the network switches, CBR traffic will only compete with other CBR traffic in the networks. In this paper, we will consider a slotted queue at a typical (intermediate) node in such an environment. The cell arrival process of each source is characterized by a dispersed periodic arrival process (DPAP), the cells of which are assumed to arrive periodically and distribute randomly within the period. We provide an exact analysis of buffer fill and delay distribution using Ballot Theorems. Another generalized source model, the dispersed batch periodic arrival process (DBPAP) is also investigated. A DBPAP source is assumed to have a number of batches of cell arrivals and the batches position randomly in the period. This work shows that the traditional Markovian approximation models may grossly overestimate the buffer fill and delay, unless the number of sources is very large.},
keywords={queueing theory;telecommunication traffic;jitter;buffer storage;probability;asynchronous transfer mode;queueing analysis;dispersed periodic messages;constant bit rate traffic;CBR traffic;high-speed networks;cell delay;jitter;slotted queue;intermediate node;cell arrival process;dispersed periodic arrival process;buffer fill distribution;buffer delay distribution;Ballot Theorems;generalized source model;dispersed batch periodic arrival process;Markovian approximation models;ATM networks;Queueing analysis;Traffic control;Telecommunication traffic;Asynchronous transfer mode;Jitter;Quality of service;Cities and towns;Bit rate;Delay;Videoconference},
doi={10.1109/INFCOM.2000.832280},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832281,
author={D. Manjunath and B. Sikdar},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Variable length packet switches: delay analysis of crossbar switches under Poisson and self similar traffic},
year={2000},
volume={2},
number={},
pages={1055-1064 vol.2},
abstract={We consider crossbar switches for switching variable length packets. Analysis of such switches is important in the context of IP switches where the packet interarrival times and packet lengths are drawn from continuous distributions. Assuming a single stage M/spl times/N switch we obtain a very general throughput delay model for Poisson packet arrivals and exponential service times. We then analyze an M/spl times/N switch for self similar packet arrivals and exponential packet lengths. An MMPP (Markov modulated Poisson process) based self similar arrival process model corresponding to the arrival rate, the autocorrelation, the Hurst parameter and the time scales over which burstiness exists in the input process is first obtained using results from Andersen and Nielsen (1998). We then use queuing theory available for MMPP/G/1 queues to model the switch performance for self similar packet arrivals. The results from the analytical model are compared against those from a simulation model that is driven by traces that are statistically similar to the Bellcore traces. We also analyse the effect of link multiplicities (speedup) to the output and asymmetries in the input traffic.},
keywords={queueing theory;packet switching;fractals;telecommunication traffic;Markov processes;correlation methods;variable length packet switches;delay analysis;crossbar switches;Poisson traffic;self similar traffic;IP switches;packet interarrival times;packet lengths;continuous distributions;throughput delay model;Poisson packet arrivals;exponential service times;MMPP-based self similar arrival process model;autocorrelation;Hurst parameter;queuing theory;MMPP/G/1 queues;Bellcore traces;input traffic;Markov modulated Poisson process;Packet switching;Switches;Delay;Throughput;Queueing analysis;Traffic control;Analytical models;Space technology;Routing;Uninterruptible power systems},
doi={10.1109/INFCOM.2000.832281},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832168,
author={S. R. Das and C. E. Perkins and E. M. Royer},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Performance comparison of two on-demand routing protocols for ad hoc networks},
year={2000},
volume={1},
number={},
pages={3-12 vol.1},
abstract={Ad hoc networks are characterized by multi-hop wireless connectivity, frequently changing network topology and the need for efficient dynamic routing protocols. We compare the performance of two prominent on-demand routing protocols for mobile ad hoc networks - dynamic source routing (DSR) and ad hoc on-demand distance vector routing (AODV). A detailed simulation model with MAC and physical layer models is used to study inter-layer interactions and their performance implications. We demonstrate that even though DSR and AODV share a similar on-demand behavior the differences in the protocol mechanics can lead to significant performance differentials. The performance differentials are analyzed using varying network load, mobility and network size. Based on the observations, we make recommendations about how the performance of either protocol can be improved.},
keywords={telecommunication network routing;network topology;access protocols;telecommunication traffic;performance evaluation;mobile radio;mobile computing;performance;on-demand routing protocols;ad hoc networks;multi-hop wireless connectivity;network topology;dynamic routing protocols;dynamic source routing;ad hoc on-demand distance vector routing;simulation;MAC models;physical layer models;inter-layer interactions;network load;Routing protocols;Ad hoc networks;Computer science;Tin;Network topology;Portable computers;Personal digital assistants;Mobile ad hoc networks;IP networks},
doi={10.1109/INFCOM.2000.832168},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832169,
author={Young-Bae Ko and V. Shankarkumar and N. H. Vaidya},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Medium access control protocols using directional antennas in ad hoc networks},
year={2000},
volume={1},
number={},
pages={13-21 vol.1},
abstract={Using directional antennas can be beneficial for wireless ad hoc networks consisting of a collection of wireless hosts. To best utilize directional antennas, a suitable medium access control (MAC) protocol must be designed. Current MAC protocols, such as the IEEE 802.11 standard, do not benefit when using directional antennas, because these protocols have been designed for omnidirectional antennas. In this paper, we attempt to design new MAC protocols suitable for ad hoc networks based on directional antennas.},
keywords={directive antennas;access protocols;packet radio networks;medium access control protocols;directional antennas;wireless ad hoc networks;MAC protocol;Media Access Protocol;Access protocols;Directional antennas;Intelligent networks;Ad hoc networks;Directive antennas;Packet radio networks;Adaptive arrays;Multiaccess communication;Broadband antennas},
doi={10.1109/INFCOM.2000.832169},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832170,
author={Jae-Hwan Chang and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Energy conserving routing in wireless ad-hoc networks},
year={2000},
volume={1},
number={},
pages={22-31 vol.1},
abstract={An ad-hoc network of wireless static nodes is considered as it arises in a rapidly deployed, sensor-based, monitoring system. Information is generated in certain nodes and needs to reach a set of designated gateway nodes. Each node may adjust its power within a certain range that determines the set of possible one hop away neighbors. Traffic forwarding through multiple hops is employed when the intended destination is not within immediate reach. The nodes have limited initial amounts of energy that is consumed at different rates depending on the power level and the intended receiver. We propose algorithms to select the routes and the corresponding power levels such that the time until the batteries of the nodes drain-out is maximized. The algorithms are local and amenable to distributed implementation. When there is a single power level, the problem is reduced to a maximum flow problem with node capacities and the algorithms converge to the optimal solution. When there are multiple power levels then the achievable lifetime is close to the optimal (that is computed by linear programming) most of the time. It turns out that in order to maximize the lifetime, the traffic should be routed such that the energy consumption is balanced among the nodes in proportion to their energy reserves, instead of routing to minimize the absolute consumed power.},
keywords={telecommunication network routing;monitoring;telecommunication traffic;secondary cells;linear programming;packet radio networks;energy-conserving routing;wireless ad-hoc networks;sensor-based monitoring system;gateway nodes;traffic forwarding;multiple hops;power level;battery node drain-out maximization;maximum flow problem;linear programming;Routing;Intelligent networks;Ad hoc networks;Wireless sensor networks;Educational institutions;Spine;Sensor systems;Relays;Energy states;Laboratories},
doi={10.1109/INFCOM.2000.832170},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832171,
author={A. D. Amis and R. Prakash and T. H. P. Vuong and D. T. Huynh},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Max-min d-cluster formation in wireless ad hoc networks},
year={2000},
volume={1},
number={},
pages={32-41 vol.1},
abstract={An ad hoc network may be logically represented as a set of clusters. The clusterheads form a d-hop dominating set. Each node is at most d hops from a clusterhead. Clusterheads form a virtual backbone and may be used to route packets for nodes in their cluster. Previous heuristics restricted themselves to 1-hop clusters. We show that the minimum d-hop dominating set problem is NP-complete. Then we present a heuristic to form d-clusters in a wireless ad hoc network. Nodes are assumed to have a non-deterministic mobility pattern. Clusters are formed by diffusing node identities along the wireless links. When the heuristic terminates, a node either becomes a clusterhead, or is at most d wireless hops away from its clusterhead. The value of d is a parameter of the heuristic. The heuristic can be run either at regular intervals, or whenever the network configuration changes. One of the features of the heuristic is that it tends to re-elect existing clusterheads even when the network configuration changes. This helps to reduce the communication overheads during transition from old clusterheads to new clusterheads. Also, there is a tendency to evenly distribute the mobile nodes among the clusterheads, and evently distribute the responsibility of acting as clusterheads among all nodes. Thus, the heuristic is fair and stable. Simulation experiments demonstrate that the proposed heuristic is better than the two earlier heuristics, namely the LCA and degree-based solutions.},
keywords={packet radio networks;telecommunication network routing;minimax techniques;mobile radio;max-min d-cluster formation;wireless ad hoc networks;virtual backbone;packet routing;minimum d-hop dominating set problem;NP-completeness;non-deterministic mobility pattern;wireless links;mobile nodes;heuristic;fairness;Intelligent networks;Ad hoc networks;Routing;Ambient intelligence;Packet radio networks;Spine;Bones;Concurrent computing;Multiaccess communication;Spread spectrum communication},
doi={10.1109/INFCOM.2000.832171},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832172,
author={Tianji Jiang and M. Ammar and E. W. Zegura},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On the use of destination set grouping to improve inter-receiver fairness for multicast ABR sessions},
year={2000},
volume={1},
number={},
pages={42-51 vol.1},
abstract={Multicast applications can involve a large number of receivers with heterogeneous data reception capabilities. In a traditional single-rate multicast session, the transmission rate at the source is chosen to match the lowest capacity path to a receiver in the session. This can cause an under-utilization of higher capacity paths to other receivers. We have previously defined an inter-receiver fairness measure in order to quantify the effect of this underutilization. We also developed protocols that use this measure to guide the choice of the source rate for a single-rate session. In this paper we design and develop a multi-rate protocol in the context of an ATM ABR service to achieve better inter-receiver fairness for a multicast session. The multi-rate protocol we investigate is based on the use of destination set grouping (DSG) where the set of receivers in a multicast session is partitioned into disjoint subgroups. The transmitter carries a separate conversation with each subgroup. Based on a number of grouping heuristics, the DSG protocol attempts to find the partitioning of the receivers that maximizes the inter-receiver fairness of the session. The DSG protocol can result in a session receiving a higher bandwidth allocation when it is split into multiple connections. We address this issue by proposing a mechanism in which the connections split from a single multicast session are treated as a single aggregated-allocation connection (AAC). A set of examples demonstrate the effectiveness of the DSG scheme incorporating the AAC technique on improving inter-receiver fairness for multicast ABR sessions.},
keywords={protocols;multicast communication;bandwidth allocation;data communication;asynchronous transfer mode;receivers;optimisation;destination set grouping;inter-receiver fairness;multicast ABR sessions;heterogeneous data reception;capacity;multi-rate protocol;ATM;disjoint subgroups;grouping heuristics;maximization;bandwidth allocation;aggregated-allocation connection;Protocols;Asynchronous transfer mode;Virtual colonoscopy;Unicast;Bandwidth;Educational institutions;Wide area networks;Circuits;Bit rate;Random access memory},
doi={10.1109/INFCOM.2000.832172},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832173,
author={S. Sarkar and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Distributed algorithms for computation of fair rates in multirate multicast trees},
year={2000},
volume={1},
number={},
pages={52-61 vol.1},
abstract={We study fairness in arbitrary networks with multicast capabilities. Multicast traffic in Internet and ATM provides a motivation for studying these networks. A study of fairness in multicast networks poses several interesting problems, e.g., the issue of inter-session fairness in addition to that of inter-session fairness in unicast networks. We develop a mathematical framework to model the fair allocation of bandwidth in multirate multicast networks with minimum and maximum rate constraints. We present distributed algorithms for computation of maxmin fair rates allocated to various source-destination pairs.},
keywords={distributed algorithms;telecommunication traffic;Internet;asynchronous transfer mode;queueing theory;minimax techniques;bandwidth allocation;multicast communication;trees (mathematics);network topology;distributed algorithms;fair rates;multirate multicast trees;traffic;Internet;ATM;inter-session fairness;bandwidth allocation;maxmin fair rates;source-destination pairs;Distributed algorithms;Distributed computing;Computer networks;Multicast protocols;Video sharing;Intelligent networks;Educational institutions;IP networks;Mathematical model;Multicast algorithms},
doi={10.1109/INFCOM.2000.832173},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832174,
author={Aiguo Fei and M. Gerla},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Receiver-initiated multicasting with multiple QoS constraints},
year={2000},
volume={1},
number={},
pages={62-70 vol.1},
abstract={To support QoS for multicast with dynamic and distributed member joining, in this paper we present a receiver-initiated multicast protocol with multiple QoS constraints (RIMQoS). Assuming link-state information and QoS unicast routing protocol are available, a receiver computes a path to join the multicast tree rooted at the source. It then sends join request along the path to join the group. Our protocol specifies under what conditions the new member can be accepted into the group without affecting the QoS of other members and how to adjust the existing tree if necessary. It attempts to minimize the cost of the tree by letting a node join the tree via a low-cost path and may later switch to a higher-cost but more QoS stringent path when necessary. The proposed scheme allows fully distributed operation and supports multiple QoS metrics and requirements. It greatly reduces the number of messages and simplifies message processing to join members compared with some other approaches. Simulation results show that it is very efficient in finding low-cost solutions.},
keywords={multicast communication;telecommunication network routing;quality of service;protocols;trees (mathematics);minimisation;constraint theory;receiver-initiated multicasting;multiple QoS constraints;distributed member joining;multicast protocol;RIMQoS;multicast tree;cost minimization;Multicast algorithms;Costs;Multicast protocols;Routing protocols;Computer networks;Unicast;Cellular neural networks;NASA},
doi={10.1109/INFCOM.2000.832174},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832175,
author={M. Grossglauser and J. -. Bolot},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On service models for multicast transmission in heterogeneous environments},
year={2000},
volume={1},
number={},
pages={71-80 vol.1},
abstract={We examine in this paper the tradeoff between application complexity, network complexity, and network efficiency. We argue that the design of the current Internet reflects a tradeoff between lower network complexity (no state in the network, no signalling) and higher application complexity (rate and error control mechanisms to obtain an adaptive application) assuming a unicast service model. For such a service model, a design methodology that leans heavily towards application complexity has proven very successful. However, we also argue that this tradeoff changes radically for a multicast/multilayer service model. These insights motivate a new service model which slightly departs from the best-effort model, and which trades off a slightly higher network complexity for much lower application complexity and higher network efficiency. We describe this service model and the associated network protocols. The protocol complexity is only marginally higher than that of a simple multicast routing protocol with receiver-initiated join/leave capabilities. The dependencies between multilayer flows are established and maintained as soft state; therefore, no explicit session signalling to establish and tear down the flow dependence state is necessary.},
keywords={protocols;Internet;telecommunication traffic;multicast communication;quality of service;multicast transmission;heterogeneous environments;application complexity;network complexity;network efficiency;Internet;multilayer service model;network protocols;protocol complexity;multilayer flows;Nonhomogeneous media;Multicast protocols;Routing protocols;Signal design;IP networks;Web and internet services;Error correction;Programmable control;Adaptive control;Unicast},
doi={10.1109/INFCOM.2000.832175},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832176,
author={C. R. Kalmanek and W. T. Marshall and P. P. Mishra and D. M. Nortz and K. K. Ramakrishnan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={DOSA: an architecture for providing a robust IP telephony service},
year={2000},
volume={1},
number={},
pages={81-90 vol.1},
abstract={An increasing number of communication services are moving to an IP-based infrastructure. Packet telephony is probably the first important real-time service that must be supported well over an IP network. The use of IP presents a tremendous opportunity for service providers to exploit endpoint intelligence to offer creative new services going far beyond the current telephony service model. However, to support telephony, signaling protocols are needed that allow the service provider to offer network-layer service differentiation and, at the same time, to control access to both the enhanced network-layer quality of service as well as other services. This paper describes the distributed open signaling architecture (DOSA), which incorporates protocols that meet these needs. A key contribution of our work is a recognition of the need for coordination between call signaling, which controls access to telephony-specific services, and resource management, which controls access to network-layer resources.},
keywords={Internet telephony;quality of service;packet switching;protocols;telecommunication signalling;intelligent networks;telecommunication control;telecommunication network management;DOSA;IP telephony service;communication services;packet telephony;endpoint intelligence;signaling protocols;network-layer service differentiation;access control;network-layer quality of service;distributed open signaling architecture;call signaling;resource management;Robustness;Telephony;Resource management;IP networks;Quality of service;Streaming media;Access protocols;Silicon;Intelligent networks;Delay},
doi={10.1109/INFCOM.2000.832176},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832177,
author={B. Pagurek and Jingrong Tang and T. White and R. Glitho},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Management of advanced services in H.323 Internet protocol telephony},
year={2000},
volume={1},
number={},
pages={91-100 vol.1},
abstract={The intelligent network (IN) represents the world-wide accepted basis for uniform provisioning of advanced telecommunication services. On the other hand IP-based communication is fast becoming a viable alternative for voice communications. Mobile agents offer unique opportunities for structuring and implementing open distributed service architectures, facilitated by the dynamic downloading and movement of service code to specific network nodes. In this paper, a new service architecture for IP telephony, based on the ITU-T standard H.323, is proposed. The implementation uses mobile agents and Jini as enabling technologies and existing architectural concepts taken from IN. This IP service architecture enables telecommunication services deployed through mobile service agents on a per-user basis, which results in several advantages when compared to centralized service architectures. The paper demonstrates that the flexible extensible architecture can accommodate not only existing services but is flexible enough to accommodate a wide variety of future services. In addition we show how the architecture addresses the full management life cycle of advanced services, from open third party creation, to subscription and utilization, and ultimately to maintenance and withdrawal.},
keywords={telecommunication network management;Internet telephony;protocols;intelligent networks;telecommunication standards;voice communication;software agents;service management;H.323;Internet protocol telephony;intelligent network;IN;advanced telecommunication services;IP-based communication;voice communications;mobile agents;open distributed service architectures;ITU-T standard H.323;Jini;Web and internet services;Protocols;Internet telephony;Systems engineering and theory;Mobile communication;Mobile agents;Subscriptions;Bandwidth;Switching circuits;Intelligent networks},
doi={10.1109/INFCOM.2000.832177},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832178,
author={A. Mena and J. Heidemann},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An empirical study of real audio traffic},
year={2000},
volume={1},
number={},
pages={101-110 vol.1},
abstract={The delivery of multimedia content is a facet of Internet traffic that is rapidly growing in importance. The new generation of World Wide Web sites rely heavily on extensive multimedia content such as graphics, sound, music and video to attract and retain visitors. While there have been extensive studies on the growth and effects of hyper text transfer protocol (HTTP) traffic used on the Web, little or no work has been performed in analyzing streaming multimedia traffic. We present the results of a brief study to examine the traffic emanating from a popular Internet audio service using the RealAudio program. We found protocol distributions that show a bias towards non-TCP friendly protocols. In addition, we observed consistencies in audio traffic packet sizes and data rate patterns may be useful as a tool for identifying audio data flows. Our results show that audio flows exhibit significant consistency in data rates and are considerably more persistent than HTTP connections.},
keywords={telecommunication traffic;multimedia communication;Internet;packet switching;transport protocols;real audio traffic;multimedia content delivery;Internet traffic;World Wide Web sites;extensive multimedia content;multimedia traffic streaming;Internet audio service;RealAudio program;protocol distributions;non-TCP friendly protocols;audio traffic packet sizes;data rate patterns;audio data flows;Protocols;Streaming media;Web sites;Traffic control;Art;Feeds;Digital audio players;DSL;Internet;Bit rate},
doi={10.1109/INFCOM.2000.832178},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832179,
author={C. Perkins and J. Crowcroft},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Effects of interleaving on RTP header compression},
year={2000},
volume={1},
number={},
pages={111-117 vol.1},
abstract={We discuss the use of interleaving as a bandwidth efficient means of protecting audio streams from the effects of packet loss on the Internet. The adverse effects of interleaving on IP/UDP/RTP header compression are noted and a number of schemes which remedy this problem are discussed.},
keywords={data compression;Internet;audio coding;packet switching;interleaved codes;transport protocols;RTP header compression;interleaving;audio streams;packet loss;Internet;IP/UDP/RTP header compression;voice-over-IP;real time transport protocol;user datagram protocol;Interleaved codes;Streaming media;Protection;Bandwidth;Internet;Payloads;Delay;Computer science;Educational institutions;Optical wavelength conversion},
doi={10.1109/INFCOM.2000.832179},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832180,
author={R. A. Guerin and A. Orda},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Networks with advance reservations: the routing perspective},
year={2000},
volume={1},
number={},
pages={118-127 vol.1},
abstract={This paper provides an initial look at how support for advance reservations affects the complexity of the path selection process in networks. Advance reservations are likely to become increasingly important as networks and distributed applications become functionally richer and there have been a number of previous works and investigations that explored various related aspects. However, the impact or advance reservations on path selection is a topic that has been left largely untouched. This paper investigates several service models for advance reservations, which range from the traditional basic model of reserving a given amount of bandwidth for some time in the future, to more sophisticated models aimed at increasing the flexibility of services available through advance reservations. The focus is primarily on the issue of computational complexity when supporting advance reservations, and in that context, we derive a number of algorithms and/or intractability results for the various models we consider.},
keywords={telecommunication network routing;telecommunication services;computational complexity;bandwidth allocation;advance reservations;path selection process;distributed applications;service models;bandwidth reservation;computational complexity;Routing;Protocols;Satellites;Bandwidth;Intserv networks;Timing;Resource management;Transponders;Telecommunication traffic;Circuits},
doi={10.1109/INFCOM.2000.832180},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832181,
author={A. Orda and A. Sprintson},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={QoS routing: the precomputation perspective},
year={2000},
volume={1},
number={},
pages={128-136 vol.1},
abstract={A major algorithmic challenge posed by QoS routing is the need to promptly identify a suitable path upon a connection request, while at the same time ensuring that the selected path is satisfactory, both in terms of the connection's QoS requirements, as well as in terms of the global utilization of network resources. In many practical cases, a precomputation scheme offers a suitable solution to the problem: a background process prepares a database, which enables identification of a suitable path upon each connection request, through a simple, fast, procedure. While much work has been done in terms of path selection algorithms, the precomputation perspective has received little attention. Simplistic adaptations or standard algorithms turn out to be inefficient. Accordingly, we consider the precomputation perspective, focusing on two major settings of QoS routing. The first is the (practically important) special case where the QoS constraint is of the "bottleneck" type, e.g., a bandwidth requirement, and network optimization is sought through hop minimization. For this setting, the standard Bellman-Ford algorithm offers a straightforward precomputation scheme. However, we show that by exploiting the typical hierarchical structure of large-scale networks, one can achieve a substantial improvement in terms of computational complexity. Then, we turn to consider the more general setting of "additive" QoS constraints (e.g., delay) and general link costs. As the routing problem becomes NP-hard, we focus on /spl epsiv/-optimal approximations, and derive a precomputation scheme that offers a major improvement over the standard approach.},
keywords={telecommunication network routing;quality of service;telecommunication computing;minimisation;computational complexity;approximation theory;broadband networks;QoS routing;precomputation perspective;connection request;QoS requirements;global utilization;network resources;precomputation scheme;background process;bottleneck QoS constraint;network optimization;hop minimization;standard Bellman-Ford algorithm;hierarchical structure;large-scale networks;computational complexity;additive QoS constraints;general link costs;NP-hard routing problem;/spl epsiv/-optimal approximations;broadband integrated services networks;Proposals;Bandwidth;Routing protocols;Delay;Jitter},
doi={10.1109/INFCOM.2000.832181},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832182,
author={F. Ergun and R. Sinha and L. Zhang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={QoS routing with performance-dependent costs},
year={2000},
volume={1},
number={},
pages={137-146 vol.1},
abstract={We study a network model in which each network link is associated with a set of delays and costs. These costs are a function of the delays and reflect the prices paid in return for delay guarantees. Such a cost structure can model a setting in which the service provider provides multiple service classes with a different price and delay guarantee for each class. We are given a source node s, a sink node t, and an end-to-end delay constraint D. Our aim is to choose an s-t path and determine a set of per link delay guarantees along this path so as to satisfy the constraint D while minimizing the total cost incurred. In the case where the s-t path is known, we aim to optimally partition the end-to-end delay constraint into link constraints along the path. We present approximation algorithms for both problems, since they are known to be NP-hard. Our algorithms guarantee to produce solutions that are within a factor 1+/spl epsiv/ of the optimal, where /spl epsiv/ is a parameter of our choice. The run times are polynomial in the input size and 1//spl epsiv/. We also provide a number of heuristics for the second problem and present simulation results. Previous work on related problems either focused on optimal solutions for special cost functions or on heuristics that have no performance guarantees. In contrast, we present provably good approximation algorithms and heuristics which apply to general cost functions.},
keywords={telecommunication network routing;quality of service;telecommunication services;tariffs;constraint theory;approximation theory;polynomials;QoS routing;performance-dependent costs;network model;network link;cost structure;costs;delay guarantees;service provider;multiple service classes;source node;sink node;end-to-end delay constraint;per link delay guarantees;approximation algorithms;NP-hard problem;polynomial run times;heuristics;general cost functions;Routing;Costs;Delay;Large Hadron Collider;Partitioning algorithms},
doi={10.1109/INFCOM.2000.832182},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832183,
author={Fang Hao and E. W. Zegura},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On scalable QoS routing: performance evaluation of topology aggregation},
year={2000},
volume={1},
number={},
pages={147-156 vol.1},
abstract={A number of important questions remain concerning the scalability of networks with quality of service guarantees. We consider one of these questions: can QoS routing protocols scale to large networks? To address this question, we evaluate the performance of techniques that can reduce the QoS routing protocol overhead. We specifically focus on topology aggregation, which can reduce overhead by orders of magnitude. We also investigate the interaction of topology aggregation with other important factors that contribute to performance, such as routing update frequency, routing algorithms, and network configuration. Our experiments are based on simulations of relatively large, structured networks. Among our observations, we find-contrary to intuition-that topology aggregation does not always have a negative impact on routing performance. Aggregation can reduce the routing information fluctuation, increase stability, and thus benefit routing performance. We also propose two new methods of aggregating routing information. Our hybrid aggregation method performs much better than conventional star aggregation and approaches unaggregated performance. Our weighted aggregation method, while intuitively appealing, offers mixed performance across topologies.},
keywords={quality of service;telecommunication network routing;network topology;protocols;scalable QoS routing;topology aggregation;performance evaluation;quality of service guarantees;QoS routing protocols;large networks;routing update frequency;routing algorithms;network configuration;structured networks;routing information fluctuation;stability;routing performance;Scalability;Network topology;Routing protocols;Frequency;Cellular neural networks;Bandwidth;Educational institutions;Telecommunication computing;Telecommunication network topology;Jitter},
doi={10.1109/INFCOM.2000.832183},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832184,
author={S. Borst and O. Boxma and P. Jelenkovic},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Coupled processors with regularly varying service times},
year={2000},
volume={1},
number={},
pages={157-164 vol.1},
abstract={Consider two M/G/1 queues that are coupled in the following way. Whenever both queues are non-empty, each server serves its own queue at unit speed. However, if server 2 has no work in its own queue, then it assists server 1, resulting in an increased service speed r/sub 1//sup *//spl ges/1 in the first queue. This kind of coupling is related to generalized processor sharing. We assume that the service request distributions at both queues are regularly varying at infinity of index -v/sub 1/ and -v/sub 2/, namely, they are heavy-tailed. Under this assumption, we present a detailed analysis of the tail behaviour of the workload distribution at each queue. If the guaranteed unit speed of server 1 is already sufficient to handle its offered traffic, then the workload distribution at the first queue is shown to be regularly varying at infinity of index 1-v/sub 1/. But if it is not sufficient, then the workload distribution at the first queue is shown to be regularly varying at infinity of index 1-min(v/sub 1/,v/sub 2/). In particular, traffic at server 1 is then no longer protected from worse-behaved (heavier-tailed) traffic at server 2.},
keywords={queueing theory;telecommunication traffic;probability;quality of service;coupled processors;regularly varying service times;M/G/1 queues;server queue;service request distributions;heavy-tailed distribution;tail behaviour;workload distribution;offered traffic;guaranteed unit speed;Global Positioning System;Queueing analysis;Traffic control;Random variables;Boundary value problems;Mathematics;H infinity control;Protection},
doi={10.1109/INFCOM.2000.832184},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832185,
author={Sung-Ho Choi and K. Sohraby and Bara Kim},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={General QBD processes with applications to overload control},
year={2000},
volume={1},
number={},
pages={165-172 vol.1},
abstract={In this paper we introduce a general class of level-dependent quasi-birth-and-death (QBD) processes and their stationary solution. We obtain the complete characterization of their fundamental matrices in terms of minimal non-negative solution of the number of matrix quadratic equations. Our results provides a mixed-geometric solution for the stationary solution of level-dependent chains. Applications in overload control in communication networks are also discussed.},
keywords={queueing theory;telecommunication congestion control;telecommunication traffic;matrix algebra;minimisation;general QBD processes;overload control;level-dependent quasi-birth-and-death processes;stationary solution;fundamental matrices;minimal non-negative solution;matrix quadratic equations;mixed-geometric solution;level-dependent chains;communication networks;Design for quality;Cities and towns;Communication system control;Telecommunication control;Computer science;Mathematics;Application software;Business communication;Load flow control;State-space methods},
doi={10.1109/INFCOM.2000.832185},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832186,
author={N. Likhanov and R. R. Mazumdar},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Cell loss asymptotics in buffers fed by heterogeneous long-tailed sources},
year={2000},
volume={1},
number={},
pages={173-180 vol.1},
abstract={In this paper we consider a generalization of the so-called M/G//spl infin/ model where M types of long-tailed sessions enter a buffer. The instantaneous rates of the sessions are functions of the occupancy of an M/G//spl infin/ system with long-tailed G distributions. In particular we assume that a session of type i transmits r/sub i/ cells per unit time and lasts for a random time r with long-tailed distribution given by P(/spl tau/>x)/spl sim//spl alpha//sub i/x(-(1+/spl beta//sub i/)) where /spl beta//sub i/>0. We derive the mean cell loss asymptotics for large buffer size as well as the complementary distribution of the buffer occupancy exceeding a high level. When specialized to the homogeneous case we show that recent results on large buffer asymptotics, which have been shown under more restrictive assumptions, hold more generally. In the heterogeneous case, we show that the asymptotics are not necessarily governed by the sources with the smallest /spl beta//sub i/ but also depend on the rates r/sub i/ and it is the ratio of /spl beta//sub i/ to r/sub i/ which is important. Finally it is a simple observation that light-tailed (exponential tails for example) sources have no influence on the asymptotics except that they contribute to reducing the capacity available to heavy-tailed sources by their mean load.},
keywords={queueing theory;telecommunication traffic;probability;buffer storage;channel capacity;cell loss asymptotics;heterogeneous long-tailed sources;M/G//spl infin/ model;long-tailed G distributions;buffer occupancy;capacity;mean load;Bismuth;Traffic control;Queueing analysis;Web and internet services;Gaussian processes},
doi={10.1109/INFCOM.2000.832186},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832187,
author={R. Jafari and K. Sohraby},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={General discrete-time queueing systems with correlated batch arrivals and departures},
year={2000},
volume={1},
number={},
pages={181-188 vol.1},
abstract={Discrete time queueing systems have gained attention recently due to their applications in the performance analysis of ATM and other systems. In this paper, we analyze generic discrete-time queueing models with general distribution for batch arrivals and departures. Our models allow correlation and distributions with arbitrary rational probability generating functions. Our solution methodology is significantly different, compared with the traditional methods. We provide a state-space representation of the model resulting in an exact simple matrix geometric solution of the system probability vector. Our approach is algorithmic, numerically robust and efficient. Applications in ATM systems and classical (discrete) G/G/1 queues with semi-Markovian arrival and departure processes are immediate and are discussed.},
keywords={queueing theory;asynchronous transfer mode;discrete time systems;correlation theory;matrix algebra;telecommunication traffic;probability;rational functions;Markov processes;numerical stability;state-space methods;correlated batch arrivals;batch departures;performance analysis;ATM;generic discrete-time queueing models;general distribution;rational probability generating functions;state-space representation;matrix geometric solution;system probability vector;numerical robustness;G/G/1 queues;semi-Markovian processes;Asynchronous transfer mode;Queueing analysis;Cities and towns;Performance analysis;Computer science;Application software;Solid modeling;Microwave integrated circuits;Robustness;Communication networks},
doi={10.1109/INFCOM.2000.832187},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832188,
author={K. Mitchell and K. Sohraby and A. Van de Liefvoort and J. Place},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Approximation models of wireless cellular networks using moment matching},
year={2000},
volume={1},
number={},
pages={189-197 vol.1},
abstract={In this paper we present an analytical model for microcellular and picocellular wireless networks for any arbitrary topology in a high-mobility environment. We introduce an approximation technique which uses a single-cell decomposition analysis which incorporates moment matching of hand-off processes into the cell. The approximation technique is novel in that it can provide close approximations for non-Poisson arrival traffic and it is easily parallelized. Performance measures such as new calls blocked and hand-off calls lost are presented for any general call arrival distribution in a non-homogeneous traffic environment. We produce some numerical examples for some simple topologies with varying mobility for several call arrival distributions and compare our results to those from simulation studies.},
keywords={microcellular radio;picocellular radio;network topology;queueing theory;telecommunication traffic;telecommunication congestion control;approximation theory;approximation models;moment matching;microcellular wireless networks;picocellular wireless networks;arbitrary topology;high-mobility environment;single-cell decomposition analysis;hand-off processes;non-Poisson arrival traffic;performance;call blocking;call arrival distribution;non-homogeneous traffic;Land mobile radio cellular systems;Traffic control;Cities and towns;Telecommunication traffic;Telecommunication computing;Performance evaluation;Loss measurement;Wireless networks;Power control;Personal communication networks},
doi={10.1109/INFCOM.2000.832188},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832189,
author={Y. Bejerano and I. Cidon and J. Naor},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Efficient handoff rerouting algorithms: a competitive on-line algorithmic approach},
year={2000},
volume={1},
number={},
pages={198-207 vol.1},
abstract={This paper considers the design of handoff rerouting algorithms for reducing the overall session cost in personal communication systems (PCS). Most modern communication systems that are used as an infrastructure for PCS networks are based on connection-based technologies. In these systems the session cost is composed of two components. The setup cost represents the cost associated with the handoff operations and the hold cost determines the expense related to the use of network resources held by the connection. Using an efficient handoff rerouting algorithm is important for the efficient management of PCS networks. This work introduces for the first time rerouting algorithms for general graphs which are cost-effective in terms of their worst-case analysis. The algorithms are analyzed using a competitive analysis approach and it is proved that the competitive ratio of the proposed algorithms is a small constant whose precise value depends on the ratio between the setup costs and the hold costs of the links. We also prove that the competitive ratio of the best online algorithm is at least 2, which means that the proposed algorithms are close in terms of worst-case behavior to the best possible rerouting algorithm. In addition, experimental results also show that the proposed algorithms indeed balance between the session setup cost and the hold cost, yielding overall lower cost when compared to other algorithms described in the literature.},
keywords={telecommunication network routing;personal communication networks;competitive algorithms;telecommunication network management;graph theory;handoff rerouting algorithms;competitive algorithm;on-line algorithm;personal communication systems;PCS;setup cost;session cost;hold cost;connection-based technologies;network management;general graphs;Costs;Personal communication networks;Virtual colonoscopy;Algorithm design and analysis;Delay;Sun;Computer science;Mobile radio mobility management;Telephony;ISDN},
doi={10.1109/INFCOM.2000.832189},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832190,
author={J. McNair and I. F. Akyildiz and M. D. Bender},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={An inter-system handoff technique for the IMT-2000 system},
year={2000},
volume={1},
number={},
pages={208-216 vol.1},
abstract={Next-generation wireless communication is based on a global system of fixed and wireless mobile services that are transportable across different network backbones, network service providers, and network geographical boundaries. One of the most important problems for global wireless service is handoff management. In this paper, a new handoff technique is introduced which supports mobility between dissimilar networks. First, the system architecture is described, based on the concept of a boundary cell region between networks. Then a new inter-system handoff protocol is presented that uses boundary cells that allow the mobile terminal to roam into a different network. The performance of the protocol is analyzed in terms of the additional inter-system handoff signaling time and the minimum boundary cell area threshold for a successful transition within the prescribed time constraints.},
keywords={telecommunication network management;cellular radio;protocols;telecommunication signalling;minimisation;IMT-2000 system;next-generation wireless communication;mobile services;handoff management;dissimilar networks;system architecture;boundary cell region;inter-system handoff protocol;mobile terminal roaming;performance;signaling time;minimum area threshold;Protocols;Next generation networking;Performance analysis;3G mobile communication;Telecommunication standards;Roaming;Telecommunication traffic;Quality of service;Personal communication networks;Signal processing},
doi={10.1109/INFCOM.2000.832190},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832191,
author={Sung-Ho Choi and K. Sohraby},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Analysis of a mobile cellular systems with hand-off priority and hysteresis control},
year={2000},
volume={1},
number={},
pages={217-224 vol.1},
abstract={In this paper, we introduce and analyze a new cut-off priority scheme which provides a better grade-of-service to hand-off traffic while maintaining high throughput for the originating calls. A hysteresis control is used for additional robustness. The system model is found to have a general level-dependent quasi-birth-and-death (QBD) structure. An efficient solution methodology is used taking full advantage of the problem structure. Our model extends, generalizes and unifies the existing models for cut-off priority schemes in wireless cellular networks.},
keywords={cellular radio;queueing theory;telecommunication control;telecommunication traffic;quality of service;mobile cellular systems;hand-off priority;hysteresis control;cut-off priority;grade of service;hand-off traffic;throughput;level-dependent QBD structure;quasi-birth-and-death structure;wireless cellular networks;Hysteresis;Control systems;Traffic control;Cities and towns;Design for quality;Communication system control;Telecommunication control;Computer science;Telecommunication traffic;Mobile communication},
doi={10.1109/INFCOM.2000.832191},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832192,
author={N. Blefari-Melazzi and M. Femminella and G. Reali},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Dynamic bandwidth allocation in a circuit-switched satellite network: provision of deterministic and statistical QoS guarantees},
year={2000},
volume={1},
number={},
pages={225-234 vol.1},
abstract={Current satellite systems operate according to circuit switching transfer modes. To improve flexibility and efficiency, several kinds of packet switching systems have been proposed. However, it appears that full packet switches are still considered complex and expensive, when implemented on board the satellites. For the time being, a compromise has been found in satellite networks with dynamic bandwidth allocation capabilities (DBAC). Such systems are based on classical circuit switches, but the DBAC payload allows the changing dynamically of the capacity of each connection, without the need for tearing-down and setting-up again the connection itself. In this paper we consider a DBAC satellite system and define algorithms to allocate the bandwidth so as to provide deterministic and statistical QoS guarantees. The traffic sources are regulated by standard dual leaky buckets (DLB). We define bandwidth-handling policies, design connection admission control rules and evaluate analytically the system performance. As expected, the numerical results show a significant increase of the overall utilisation factor of our system, when compared with a plain circuit-switching solution.},
keywords={bandwidth allocation;circuit switching;packet switching;telecommunication congestion control;telecommunication traffic;satellite communication;quality of service;channel capacity;queueing theory;circuit-switched satellite network;deterministic QoS guarantees;statistical QoS guarantees;packet switching;dynamic bandwidth allocation capabilities;DBAC payload;capacity;dynamic changes;traffic sources;dual leaky buckets;connection admission control;bandwidth-handling policies;performance evaluation;utilisation factor;Channel allocation;Satellites;Switching circuits;Packet switching;Switches;Payloads;Bandwidth;Admission control;Performance analysis;System performance},
doi={10.1109/INFCOM.2000.832192},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832193,
author={C. Frei and B. Faltings},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Abstraction and constraint satisfaction techniques for planning bandwidth allocation},
year={2000},
volume={1},
number={},
pages={235-244 vol.1},
abstract={Communication networks are expected to offer a wide range of services to an increasingly large number of users, with a diverse range of quality of service. This calls for efficient control and management of these networks. We address the problem of quality-of-service routing, more specifically the planning of bandwidth allocation to communication demands. Shortest-path routing is the traditional technique applied to this problem. However, this can lead to poor network utilization and even congestion. We show how an abstraction technique combined with systematic search algorithms and heuristics derived from artificial intelligence make it possible to solve this problem more efficiently and in much tighter networks, in terms of bandwidth usage.},
keywords={bandwidth allocation;telecommunication network planning;constraint theory;quality of service;telecommunication network routing;telecommunication network management;telecommunication congestion control;search problems;heuristic programming;constraint satisfaction;abstraction techniques;bandwidth allocation;planning;communication networks;quality of service;network control;network management;routing;congestion;systematic search algorithms;heuristics;artificial intelligence;bandwidth usage;Channel allocation;Routing;Quality of service;Bandwidth;Telecommunication traffic;Resource management;Path planning;Rain;Technology planning;Communication networks},
doi={10.1109/INFCOM.2000.832193},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832194,
author={N. T. Spring and M. Chesire and M. Berryman and V. Sahasranaman and T. Anderson and B. Bershad},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Receiver based management of low bandwidth access links},
year={2000},
volume={1},
number={},
pages={245-254 vol.1},
abstract={In this paper, we describe a receiver-based congestion control policy that leverages TCP flow control mechanisms to prioritize mixed traffic loads across access links. We manage queueing at the access link to: (1) improve the response time of interactive network applications; (2) reduce congestion-related packet losses; while (3) maintaining high throughput for bulk-transfer applications. Our policy controls queue length by manipulating receive socket buffer sizes. We have implemented this solution in a dynamically loadable Linux kernel module, and tested it over low-bandwidth links. Our approach yields a 7-fold improvement in packet latency over an unmodified system while maintaining 94% link utilization. In the common case, congestion-related packet losses at the access link can be eliminated. Finally, by prioritizing short flows, we show that our system reduces the time to download a complex Web page during a large background transfer by a factor of two.},
keywords={subscriber loops;telecommunication network management;telecommunication congestion control;telecommunication traffic;transport protocols;queueing theory;buffer storage;Unix;information resources;Internet;receiver-based management;low-bandwidth access links;congestion control policy;TCP flow control;mixed traffic load;response time;interactive network;throughput;bulk-transfer applications;queue length;receive socket buffer sizes;dynamically loadable Linux kernel module;packet latency;link utilization;short flow prioritizing;complex Web page;Bandwidth;Delay;Telecommunication traffic;Throughput;Size control;Sockets;Linux;Kernel;Testing;Web pages},
doi={10.1109/INFCOM.2000.832194},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832195,
author={R. Garg and H. Saran},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Fair bandwidth sharing among virtual networks: a capacity resizing approach},
year={2000},
volume={1},
number={},
pages={255-264 vol.1},
abstract={Virtual private networks (VPN) and link sharing are cost-effective ways of realizing corporate intranets. Corporate intranets will increasingly have to provide integrated services for voice and multimedia traffic. Although packet scheduling algorithms can be used to implement integrated services in link sharing and virtual private networks, their statistical multiplexing gains are limited. We propose a new scheme called stochastic fair sharing (SFS) to carry out fair link sharing and fair sharing among virtual leased links (VLL). In the link sharing environment, capacities allocated to different classes are adjusted dynamically as sessions arrive (or depart). The SFS admission control algorithm decides which sessions to accept and which to reject depending upon the current utilizations and provisioned capacities of the classes. SFS gives protection to classes with low session arrival rate against classes with high session arrival rates by ensuring them a low blocking probability. In the case of multi-hop VLL, capacity resizing requests are sent in the service providers's network which are admission-controlled using SFS. Our simulations indicate that using SFS, the equivalent capacity of virtual links converge to their max-min fair capacity, with a fairness index of 0.97 in extreme situations. The average signaling load of the protocol was found to be reasonable. The scheme is simple to implement, efficient, and robust. The potential applications of SFS are fair and efficient resource sharing in telecommunication networks, ATM networks, virtual private networks (VPN) and integrated services or differentiated services-based IP networks.},
keywords={bandwidth allocation;channel capacity;intranets;business communication;quality of service;voice communication;multimedia communication;telecommunication traffic;stochastic processes;queueing theory;telecommunication congestion control;probability;minimax techniques;telecommunication signalling;protocols;asynchronous transfer mode;fair bandwidth sharing;capacity resizing;virtual private networks;link sharing;corporate intranets;integrated services;voice traffic;multimedia traffic;stochastic fair sharing;virtual leased links;dynamic allocation;admission control algorithm;blocking probability;multi-hop VLL;max-min fair capacity;signaling load;protocol;telecommunication networks;ATM networks;VPN;differentiated services;IP networks;Bandwidth;Virtual private networks;Intserv networks;Scheduling algorithm;Telecommunication traffic;Stochastic processes;Admission control;Protection;Spread spectrum communication;Protocols},
doi={10.1109/INFCOM.2000.832195},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832196,
author={Y. Breitbart and M. Garofalakis and C. Martin and R. Rastogi and S. Seshadri and A. Silberschatz},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Topology discovery in heterogeneous IP networks},
year={2000},
volume={1},
number={},
pages={265-274 vol.1},
abstract={Knowledge of the up-to-date physical topology of an IP network is crucial to a number of critical network management tasks, including reactive and proactive resource management, event correlation, and root-cause analysis. Given the dynamic nature of today's IP networks, keeping track of topology information manually is a daunting (if not impossible) task. Thus, effective algorithms for automatically discovering physical network topology are necessary. Earlier work has typically concentrated on either: (a) discovering logical (i.e., layer-3) topology, which implies that the connectivity of all layer-2 elements (e.g., switches and bridges) is ignored; or (b) proprietary solutions targeting specific product families. In this paper, we present novel algorithms for discovering physical topology in heterogeneous (i.e., multi-vendor) IP networks. Our algorithms rely on standard SNMP MIB information that is widely supported by modern IP network elements and require no modifications to the operating system software running on elements or hosts. We have implemented the algorithms presented in this paper in the context of a topology discovery tool that has been tested on Lucent's own research network. The experimental results clearly validate our approach, demonstrating that our tool can consistently discover the accurate physical network topology in time that is roughly quadratic in the number of network elements.},
keywords={computer network management;network topology;protocols;heterogeneous IP networks;network management;reactive resource management;proactive resource management;event correlation;root-cause analysis;physical network topology;multi-vendor IP networks;SNMP MIB information;topology discovery tool;Network topology;IP networks;Resource management;Knowledge management;Switches;Bridges;Software algorithms;Software standards;Operating systems;Software systems},
doi={10.1109/INFCOM.2000.832196},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832197,
author={W. Theilmann and K. Rothermel},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Dynamic distance maps of the Internet},
year={2000},
volume={1},
number={},
pages={275-284 vol.1},
abstract={There is an increasing number of Internet applications that attempt to optimize their network communication by considering the network distance across which data is transferred. Such applications range from replication management to mobile agent applications. One major problem of these applications is to efficiently acquire distance information for large computer networks. This paper presents an approach to creating a global view on the Internet, a so-called network distance map, which realizes a hierarchical decomposition of the network into regions and which allows us to estimate the network distance between any two hosts. This view is not only a single snapshot but is dynamically adapted to the continuously changing network conditions. The main idea is to use a certain set of hosts for performing distance measurements and to use the so-gained information for estimating the distance between arbitrary hosts. A hierarchical clustering provides the notion of regions and allows us to coordinate the measurements in such a way that the resulting network load is minimized. An experimental evaluation on the basis of 119 globally distributed measurement servers shows that already a small number of measurement servers allows us to construct fairly accurate distance maps at low cost.},
keywords={Internet;computer network management;telecommunication traffic;minimisation;data communication;dynamic distance maps;Internet;network communication optimization;data transfer;replication management;mobile agent applications;large computer networks;global view;hierarchical decomposition;dynamic adaptation;hierarchical clustering;load minimization;measurement servers;Internet;Application software;IP networks;Network servers;Mobile communication;Mobile agents;Computer network management;Performance evaluation;Distance measurement;Coordinate measuring machines},
doi={10.1109/INFCOM.2000.832197},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832198,
author={M. Stemm and R. Katz and S. Seshan},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A network measurement architecture for adaptive applications},
year={2000},
volume={1},
number={},
pages={285-294 vol.1},
abstract={The quality of network connectivity between a pair of Internet hosts can vary greatly. Adaptive applications can cope with these differences in connectivity by choosing alternate representations of objects or streams or by downloading the objects from alternate locations. In order to effectively adapt, applications must discover the condition of the network before communicating with distant hosts. Unfortunately, the ability to predict or report the quality of connectivity is missing in today's suite of Internet services. To address this limitation, we have developed SPAND (shared passive network performance discovery), a system that facilitates the development of adaptive network applications. In each domain, applications make passive application specific measurements of the network and store them in a local centralized repository of network performance information. Other applications may retrieve this information from the repository and use the shared experiences of all hosts in a domain to predict future performance. In this way, applications can make informed decisions about adaptation choices as they communicate with distant hosts. In this paper, we describe and evaluate the SPAND architecture and implementation. We show how the architecture makes it easy to integrate new applications into our system and how the architecture has been used with specifics types of data transport. Finally, we describe LookingGlass, a WWW mirror site selection tool that uses SPAND. LookingGlass meets the conflicting goals of collecting passive network performance measurements and maintaining good client response times. In addition, LookingGlass's server selection algorithms based on application level measurements perform much better than techniques that rely on geographic location or route metrics.},
keywords={Internet;telecommunication computing;prediction theory;data communication;software tools;computerised monitoring;network servers;network measurement architecture;adaptive applications;network connectivity;Internet hosts;data transport;shared passive network performance discovery;passive application specific measurements;local centralized repository;SPAND architecture;SPAND implementation;LookingGlass;WWW mirror site selection tool;client response times;server selection algorithm;mirrored Web objects;Passive networks;IP networks;Web and internet services;Adaptive systems;Information retrieval;World Wide Web;Mirrors;Measurement;Delay;Network servers},
doi={10.1109/INFCOM.2000.832198},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832199,
author={S. Jamin and Cheng Jin and Yixin Jin and D. Raz and Y. Shavitt and Lixia Zhang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={On the placement of Internet instrumentation},
year={2000},
volume={1},
number={},
pages={295-304 vol.1},
abstract={The IDMaps project aims to provide a distance map of the Internet from which relative distances between hosts on the Internet can be gauged. Many distributed systems and applications can benefit from such a distance map service, for example, a common method to improve user-perceived performance of the Internet is to place data and server mirrors closer to clients. When a client tries to access a mirrored server, which mirror should it access? With IDMaps, the closest mirror can be determined based on distance estimates between the client and the mirrors. In this paper we investigate both graph theoretic methods and ad hoc heuristics for instrumenting the Internet to obtain distance maps. We evaluate the efficacy of the resulting distance maps by comparing the determinations of the closest replica using known topologies against those obtained using the distance maps.},
keywords={Internet;network servers;client-server systems;performance evaluation;graph theory;Internet instrumentation;IDMaps project;distance map;relative host distances;distributed systems;user-perceived performance;data mirrors;server mirrors;client server system;graph theoretic methods;ad hoc heuristics;closest replica;Internet;Instruments;Mirrors;Engineering profession;Topology;Network servers;Round robin;Laboratories;Sun;Costs},
doi={10.1109/INFCOM.2000.832199},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832200,
author={R. D. Doverspike and S. J. Phillips and J. R. Westbrook},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Transport network architectures in an IP world},
year={2000},
volume={1},
number={},
pages={305-314 vol.1},
abstract={We develop a telecommunications architecture based on IP routers and compare it empirically to the current TDM hierarchy. The study is based on two premises: first that data traffic will continue to grow much faster than voice traffic and will be mostly IP, and second, that IP routers and networks will soon achieve the scalability and dependability necessary to provide the service quality expected of telecommunications networks. The IP architecture exploits a number of mechanisms to improve network efficiency: mesh restoration requires less spare bandwidth than SONET rings; private line services are carried as virtual leased lines, enabling more fine-grained bandwidth offerings; a voice subnetwork uses OC-48 links rather than DS-1 trunk groups, so it requires less total bandwidth to achieve the same blocking probability; and the multiplying inefficiencies of layer-by-layer routing in the TDM hierarchy are avoided. We find that an all-IP architecture could offer much greater network efficiency and considerable capital savings. We examine how technology must evolve to support such an architecture.},
keywords={telecommunication traffic;data communication;telecommunication networks;protocols;telecommunication network routing;quality of service;probability;telecommunication congestion control;transport network architectures;telecommunications architecture;IP routers;TDM hierarchy;data traffic;service quality;telecommunications networks;mesh restoration;virtual leased lines;voice subnetwork;OC-48 links;blocking probability;Intelligent networks;Time division multiplexing;Telecommunication traffic;Bandwidth;Computer architecture;SONET;Routing;Costs;Design optimization;Demand forecasting},
doi={10.1109/INFCOM.2000.832200},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832201,
author={Jaeook Lee and Sun Kang},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Satellite over satellite (SOS) network: a novel architecture for satellite network},
year={2000},
volume={1},
number={},
pages={315-321 vol.1},
abstract={Satellite systems have been proposed recently for broadband data and multimedia services. And many of them need a great number of satellites to provide broadband services with limited frequencies, and each satellite may have a number of direct intersatellite links (ISL) that are mutually visible satellites. But, in case when long-distance-dependent (LDD) traffic dominate, performance in terms of the overall network decrease, because of traffic transfer via many ISL on the routing path. To solve these problems, we propose a new topological design and routing protocol for broadband satellite communication networks. The former is called the satellite-over-satellite (SOS) network which has a multiple layered satellite constellation, and the latter is called the hierarchical QoS routing protocol (HQRP) supporting a simple routing protocol for LDD multimedia traffic. We also introduce the characteristics of SOS and HQRP by simulations of performance evaluations.},
keywords={satellite links;broadband networks;data communication;multimedia communication;quality of service;telecommunication traffic;telecommunication network routing;network topology;protocols;network architecture;broadband data;multimedia services;intersatellite links;ISL;long-distance-dependent traffic;performance;traffic transfer;topological design;satellite communication;satellite-over-satellite network;hierarchical QoS routing protocol;HQRP;simulations;Low earth orbit satellites;Telecommunication traffic;Traffic control;Artificial satellites;Quality of service;Delay;Routing protocols;Frequency conversion;Sun;Data engineering},
doi={10.1109/INFCOM.2000.832201},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832202,
author={C. Albuquerque and B. J. Vickers and T. Suda},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Network Border Patrol},
year={2000},
volume={1},
number={},
pages={322-331 vol.1},
abstract={The end-to-end nature of Internet congestion control is an important factor in its scalability and robustness. However, end-to-end congestion control algorithms alone are incapable of preventing the congestion collapse and unfair bandwidth allocations created by applications which are unresponsive to network congestion. In this paper, we propose and investigate a new congestion avoidance mechanism called Network Border Patrol (NBP). NBP relies on the exchange of feedback between routers at the borders of a network in order to detect and restrict unresponsive traffic flows before they enter the network. The NBP mechanism is compliant with the Internet philosophy of pushing complexity toward the edges of the network whenever possible. Simulation results show that NBP effectively eliminates congestion collapse, and that, when combined with fair queueing, NBP achieves approximately max-min fair bandwidth allocations for competing network flows.},
keywords={Internet;bandwidth allocation;telecommunication congestion control;feedback;telecommunication traffic;telecommunication network routing;queueing theory;minimax techniques;protocols;Internet;congestion control;Network Border Patrol;router feedback;unresponsive traffic flows;fair queueing;max-min fair bandwidth allocations;competing network flows;Bandwidth;Scalability;Computer science;Protocols;Telecommunication traffic;Helium;Web and internet services;Control systems;Telegraphy;Steel},
doi={10.1109/INFCOM.2000.832202},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832203,
author={Zhiruo Cao and Zheng Wang and E. Zegura},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Performance of hashing-based schemes for Internet load balancing},
year={2000},
volume={1},
number={},
pages={332-341 vol.1},
abstract={Load balancing is a key technique for improving Internet performance. Effective use of load balancing requires good traffic distribution schemes. We study the performance of several hashing schemes for distributing traffic over multiple links while preserving the order of packets within a flow. Although hashing-based load balancing schemes have been proposed in the past, this is the first comprehensive study of their performance using real traffic traces. We evaluate five direct hashing methods and one table-based hashing method. We find that hashing using a 16-bit CRC over the five-tuple gives excellent load balancing performance. Further, load-adaptive table-based hashing using the exclusive OR of the source and destination IP addresses achieves comparable performance to the 16-bit CRC. Table-based hashing can also distribute traffic load according to unequal weights. We also report on four other schemes with poor to moderate performance.},
keywords={Internet;performance evaluation;telecommunication traffic;resource allocation;file organisation;performance;Internet;load balancing;traffic distribution;direct hashing;16-bit CRC;load-adaptive table-based hashing;IP addresses;Internet;Load management;Cyclic redundancy check;Wavelength division multiplexing;Spine;Throughput;Web server;Educational institutions;Radio access networks;Scalability},
doi={10.1109/INFCOM.2000.832203},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832204,
author={Aimin Sang and San-qi Li},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A predictability analysis of network traffic},
year={2000},
volume={1},
number={},
pages={342-351 vol.1},
abstract={This paper assesses the predictability of network traffic by considering two metrics: (1) how far into the future a traffic rate process can be predicted for a given error constraint; (2) what the minimum prediction error is over a specified prediction time interval. The assessment is based on two stationary traffic models: the auto-regressive moving average (ARMA) model and the Markov-modulated Poisson process (MMPP) model. Our study in this paper provides an upper bound for the optimal performance of online traffic prediction. The analysis reveals that the application of traffic prediction is limited by the quickly deteriorating prediction accuracy with increasing prediction interval. Furthermore, we show that different traffic properties play different roles in predictability. Traffic smoothing (low-pass filtering) and statistical multiplexing also improves predictability. In particular, experimental results suggest that traffic prediction works better for backbone network traffic, or when short-term traffic variations have been properly filtered out. Moreover, this paper illustrates the various factors affecting the effectiveness of traffic prediction in network control. These factors include the traffic characteristics, the traffic measurement intervals, the network control time-scale, and the utilization target of network resources. Considering all of the factors, we present guidelines for utilizing and evaluating traffic prediction in network control areas.},
keywords={telecommunication traffic;prediction theory;autoregressive moving average processes;telecommunication congestion control;Markov processes;Poisson distribution;optimisation;predictability analysis;network traffic;minimum prediction error;stationary traffic models;auto-regressive moving average model;ARMA model;Markov-modulated Poisson process;MMPP model;optimal performance;online traffic prediction;traffic smoothing;traffic characteristics;traffic measurement intervals;network control time-scale;utilization target;Telecommunication traffic;Communication system traffic control;Traffic control;Low pass filters;Upper bound;Accuracy;Smoothing methods;Filtering;Spine;Guidelines},
doi={10.1109/INFCOM.2000.832204},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832205,
author={A. Erramilli and O. Narayan and A. Neidhardt and I. Saniee},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Performance impacts of multi-scaling in wide area TCP/IP traffic},
year={2000},
volume={1},
number={},
pages={352-359 vol.1},
abstract={Recent measurement and simulation studies have revealed that wide area network traffic has complex statistical, possibly multifractal, characteristics on short timescales, and is self-similar on long timescales. In this paper, using measured TCP traces and queueing simulations, we show that the fine timescale features can affect performance substantially at low and intermediate utilizations, while the coarse timescale self-similarity is important at intermediate and high utilizations. We outline an analytical method for estimating performance for traffic that is self-similar on coarse timescales and multi-fractal on fine timescales, and show that the engineering problem of setting safe operating points for planning or admission control can be significantly affected by fine timescale fluctuations in network traffic.},
keywords={transport protocols;telecommunication network planning;wide area networks;fractals;queueing theory;performance evaluation;statistical analysis;telecommunication traffic recording;telecommunication congestion control;performance;multi-scaling;wide area traffic;TCP/IP;simulation;statistical characteristics;multifractal characteristics;self-similarity;measured TCP traces;queueing simulations;planning;admission control;TCPIP;Traffic control;Telecommunication traffic;Fractals;Communication system traffic control;Area measurement;Wide area networks;Performance analysis;Admission control;Fluctuations},
doi={10.1109/INFCOM.2000.832205},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832206,
author={R. Morris and Dong Lin},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={Variance of aggregated Web traffic},
year={2000},
volume={1},
number={},
pages={360-366 vol.1},
abstract={If data traffic were Poisson, increases in the amount of traffic aggregated on a network would rapidly decrease the relative size of bursts. The discovery of pervasive long-range dependence demonstrates that real network traffic is burstier than any possible Poisson model. We present evidence that, despite being non-Poisson, aggregating Web traffic causes it to smooth out as rapidly as Poisson traffic. That is, the relationship between changes in mean bandwidth and changes in variance is the same for Web traffic as it is for Poisson traffic. We derive our evidence from traces of real traffic in two ways: first, by observing how variance changes over the large range of mean bandwidths present in 24-hour traces; second, by observing the relationship of variance and mean bandwidth for individual users and combinations of users. Our conclusion, that variance changes linearly with mean bandwidth, should be useful (and encouraging) to anyone provisioning a network for a large aggregate load of Web traffic.},
keywords={telecommunication traffic;information resources;data communication;Internet;aggregated Web traffic;variance;data traffic;long-range dependence;bursty traffic;mean bandwidth;Telecommunication traffic;Bandwidth;Internet;Spine;Aggregates;Fluctuations;Filters;Laboratories;Computer science;Toxicology},
doi={10.1109/INFCOM.2000.832206},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{832207,
author={C. Casetti and M. Meo},
booktitle={Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)},
title={A new approach to model the stationary behavior of TCP connections},
year={2000},
volume={1},
number={},
pages={367-375 vol.1},
abstract={In this paper, we outline a methodology that can be applied to model the behavior of TCP flows. The proposed methodology stems from a Markovian model of a single TCP source, and eventually considers the superposition and interaction of several such sources using standard queueing analysis techniques. Our approach allows the evaluation of such performance indices as throughput, queueing delay and packet loss of TCP flows. The results obtained through our model are validated by means of simulation, under several topology and traffic settings.},
keywords={transport protocols;telecommunication traffic;Markov processes;queueing theory;delays;network topology;stationary behavior;TCP connections;TCP flows;Markovian model;queueing analysis;performance evaluation;throughput;queueing delay;packet loss;topology;traffic;simulation;Protocols;Stochastic processes;Topology;Robustness;Large Hadron Collider;Traffic control;Fluid dynamics;Throughput;Steady-state;Queueing analysis},
doi={10.1109/INFCOM.2000.832207},
ISSN={0743-166X},
month={March},}

