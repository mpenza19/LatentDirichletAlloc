@INPROCEEDINGS{916614,
author={S. G. Dykes and K. A. Robbins},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A viability analysis of cooperative proxy caching},
year={2001},
volume={3},
number={},
pages={1205-1214 vol.3},
abstract={Cooperating proxy caches are groups of HTTP proxy servers that share cached objects. This paper models the speedup in average user response time for proxy cooperation and derives expressions for the upper bound, a mesh organization, and a hierarchical organization. The expressions are parameterized using empirically determined hit rates and HTTP response times. Models account for overhead of different discovery mechanisms (ICP or metadata directory) and clarify the trade-off between discovery overhead and effectiveness. We find proxy cooperation to be only marginally viable when the sole criterion is average response time. By offering a choice of Web sites, however, proxy cooperation can potentially reduce the variability in response time, the number of pathologically long delays, and congestion near busy Web servers.},
keywords={hypermedia;cache storage;Internet;cooperative systems;meta data;telecommunication congestion control;viability analysis;cooperative proxy caching;HTTP proxy servers;cached objects;average user response time;upper bound;mesh organization;hierarchical organization;empirically determined hit rates;ICP;metadata directory;discovery mechanisms;proxy cooperation;Web sites;congestion;Web server;Network servers;Upper bound;Cache memory;Delay effects;Microprocessor chips;File servers;Hardware;Bandwidth;Costs},
doi={10.1109/INFCOM.2001.916614},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916615,
author={H. Zhu and T. Yang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Class-based cache management for dynamic Web content},
year={2001},
volume={3},
number={},
pages={1215-1224 vol.3},
abstract={Caching dynamic pages at a server site is beneficial in reducing server resource demands and it also helps dynamic page caching at proxy sites. Previous work has used fine-grain dependence graphs among individual dynamic pages and underlying data sets to enforce result consistency. This paper proposes a complementary solution for applications that require coarse-grain cache management. The key idea is to partition dynamic pages into classes based on URL patterns so that an application can specify page identification and data dependence, and invoke invalidation for a class of dynamic pages. To make this scheme time-efficient with small space requirement, lazy invalidation is used to minimize slow disk accesses when IDs of dynamic pages are stored in memory with a digest format. Selective precomputing is further proposed to refresh stale pages and smoothen load peaks. A data structure is developed for efficient URL class searching during lazy or eager invalidation. This paper also presents design and implementation of a caching system called Cachuma which integrates the above techniques, runs in tandem with standard Web servers, and allows Web sites to add dynamic page caching capability with minimal changes. The experimental results show that the proposed techniques are effective in supporting coarse-grain cache management and reducing server response times for tested applications.},
keywords={Internet;cache storage;file servers;data structures;client-server systems;class-based cache management;dynamic Web content;server site;server resource demands;dynamic page caching;proxy sites;coarse-grain cache management;dynamic pages;URL patterns;page identification;data dependence;lazy invalidation;slow disk accesses;digest format;precomputing;stale pages;load peaks;data structure;eager invalidation;Cachuma;server response times;Content management;Uniform resource locators;Intrusion detection;Network servers;Web server;Prefetching;Pattern matching;Computer science;Data structures;Web page design},
doi={10.1109/INFCOM.2001.916615},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916617,
author={M. Busari and C. Williamson},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On the sensitivity of Web proxy cache performance to workload characteristics},
year={2001},
volume={3},
number={},
pages={1225-1234 vol.3},
abstract={This paper describes the design and use of a synthetic Web proxy workload generator (ProWGen) to investigate the sensitivity of proxy cache replacement policies to selected Web workload characteristics. Trace-driven simulations with synthetic workloads from ProWGen show the relative sensitivity of three popular cache replacement algorithms-LRU, LFU-aging and GD-size-to Zipf slope, temporal locality, and correlation (if any) between file size and popularity, and the relative insensitivity of these algorithms to one-timers and heavy tail index. Performance differences between the three policies are also highlighted.},
keywords={Internet;cache storage;sensitivity analysis;telecommunication traffic;Web proxy cache performance;workload characteristics;synthetic Web proxy workload generator;ProWGen;proxy cache replacement policies;Web workload characteristics;trace-driven simulations;sensitivity;cache replacement algorithms;LRU;GD-size;Zipf slope;temporal locality;correlation;file size;popularity;one-timers;heavy tail index;Web server;Internet;Tail;Delay;Computer science;Character generation;Computational modeling;Spine;Scalability;Network servers},
doi={10.1109/INFCOM.2001.916617},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916618,
author={A. Myers and J. Chuang and U. Hengartner and Y. Xie and W. Zhuang and H. Zhang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A secure, publisher-centric Web caching infrastructure},
year={2001},
volume={3},
number={},
pages={1235-1243 vol.3},
abstract={The current Web caching infrastructure, though it has a number of performance benefits for clients and network providers, does not meet publishers' requirements. We argue that to satisfy these requirements, caches should be enhanced in both the data and control planes. In the data plane, caches will dynamically generate content for clients by running code provided by publishers. In the control plane, caches will return logs of client accesses to publishers. In this paper, we introduce Gemini, a system which has both of these capabilities, and discuss two of its key components: security and incremental deployment. Since Gemini caches are deeply involved in content preparation and logging, ensuring that they perform correctly is vital. Traditional end-to-end security mechanisms are not sufficient to protect clients and publishers, so we introduce a new security model which consists of two pieces: an authorization mechanism and a verification mechanism. The former allows a publisher to authorize a set of caches to run its code and serve its content, while the latter allows clients and publishers to probabilistically verify that authorized caches are operating correctly. Because it is unrealistic to assume that Gemini caches will be deployed everywhere simultaneously, we have designed the system to be incrementally deployable and to coexist with legacy clients, caches, and servers. Finally, we describe our implementation of Gemini and present preliminary performance results.},
keywords={Internet;authorisation;client-server systems;cache storage;publishing;telecommunication security;telecommunication control;secure publisher-centric Web caching infrastructure;data plane;code;control plane;client accesses;Gemini;incremental deployment;content preparation;logging;security mechanisms;authorization mechanism;verification mechanism;authorized caches;Network servers;Information management;Computer science;Data security;Protection;Authorization;Hardware;Operating systems;Costs;Internet},
doi={10.1109/INFCOM.2001.916618},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916619,
author={B. Liu and D. R. Figueiredo and Y. Guo and J. Kurose and D. Towsley},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A study of networks simulation efficiency: fluid simulation vs. packet-level simulation},
year={2001},
volume={3},
number={},
pages={1244-1253 vol.3},
abstract={Network performance evaluation through traditional packet-level simulation is becoming increasingly difficult as today's networks grow in scale along many dimensions. As a consequence, fluid simulation has been proposed to cope with the size and complexity of such systems. This study focuses on analyzing and comparing the relative efficiencies of fluid simulation and packet-level simulation for several network scenarios. We use the "simulation event" rate to measure the computational effort of the simulators and show that this measure is both adequate and accurate. For some scenarios, we derive analytical results for the simulation event rate and identify the major factors that contribute to the simulation event rate. Among these factors, the "ripple effect" is very important since it can significantly increase the fluid simulation event rate. For a tandem queueing system, we identify the boundary condition to establish regions where one simulation paradigm is more efficient than the other. Flow aggregation is considered as a technique to reduce the impact of the "ripple effect" in fluid simulation. We also show that WFQ scheduling discipline can limit the "ripple effect", making fluid simulation particularly well suited for WFQ models. Our results show that tradeoffs between parameters of a network model determines the most efficient simulation approach.},
keywords={packet switching;simulation;telecommunication traffic;scheduling;queueing theory;computer networks;networks simulation efficiency;fluid simulation;packet-level simulation;network performance evaluation;complexity;simulation event rate;computational effort;ripple effect;tandem queueing system;boundary condition;flow aggregation;WFQ scheduling discipline;network model;Computational modeling;Discrete event simulation;Telecommunication traffic;Traffic control;Power system modeling;Computer simulation;Analytical models;Computer networks;Computer science;Boundary conditions},
doi={10.1109/INFCOM.2001.916619},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916620,
author={M. Krunz},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On the limitations of the variance-time test for inference of long-range dependence},
year={2001},
volume={3},
number={},
pages={1254-1260 vol.3},
abstract={The objective of this paper is to demonstrate the limitations of the variance-time (VT) test as a statistical tool for inferring long-range dependence (LRD) in network traffic. Since the early Bellcore studies, LRD has been in the center of a continuous debate within the teletraffic community. The controversy is typically focused on the utility of LRD models to predict the performance at network buffers. Our work here is not meant to advocate one modeling approach over another, but to point out (experimentally and theoretically) to the caveats in using the VT test as a tool for detecting LRD. We do that by deriving simple analytical expressions for the slope of the aggregated variance in three autocorrelated traffic models: M/G//spl infin/ process (short-range dependent (SRD) but non-Markovian), the discrete autoregressive of order one model (SRD Markovian), and the fractional ARIMA process (LRD). Our main result is that the VT test often indicates, falsely, the existence of an LRD structure (i.e., H>0.5) in synthetically generated traces from the two SRD models. The bias in the VT test, however, diminishes monotonically with the length of the trace. We provide some guidelines on selecting the minimum trace length so that the bias is negligible.},
keywords={telecommunication traffic;statistical analysis;queueing theory;correlation methods;Markov processes;autoregressive moving average processes;variance-time test limitations;long-range dependence inference;statistical tool;teletraffic;LRD models;network buffers;performance prediction;aggregated variance slope;autocorrelated traffic models;M/G//spl infin/ process;short-range dependent process;nonMarkovian process;discrete autoregressive order one model;SRD Markovian model;fractional ARIMA process;LRD structure;synthetically generated traces;VT test bias;minimum trace length selection;Testing;Traffic control;Telecommunication traffic;Predictive models;Autocorrelation;Bandwidth;Computer networks;Analysis of variance;Performance analysis;Guidelines},
doi={10.1109/INFCOM.2001.916620},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916621,
author={M. Agapie and K. Sohraby},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Algorithmic solution to second-order fluid flow},
year={2001},
volume={3},
number={},
pages={1261-1270 vol.3},
abstract={We develop a numerically stable algorithm for the solution of a general fluid-flow model in steady-state. The fluid dynamics is modulated by a semi-Markov process, with phase-type distributions for the sojourn times. We use an algorithmic solution to examine the impact of variance in the case of homogeneous on-off sources, and differences between the infinite and finite buffer case. The need for the complete distribution of the buffer is demonstrated through analysis of two existing approximations, which perform unsatisfactorily. Our numerical results demonstrate the robustness of the numerical algorithm; we compute both the cumulative distribution functions (CDF) and the moments of the process, over a wide range of time-scales and system parameters.},
keywords={telecommunication congestion control;queueing theory;Markov processes;approximation theory;buffer storage;differential equations;numerical stability;algorithmic solution;second-order fluid flow;numerically stable algorithm;general fluid-flow model;fluid dynamics;modulation;semi-Markov process;phase-type distributions;sojourn times;variance;homogeneous on-off sources;finite buffer;infinite buffer;approximations;buffer distribution;numerical algorithm;CDF;process moments;time-scales;system parameters;cumulative distribution functions;queueing system;first-order differential equations;Fluid flow;Diffusion processes;Stochastic processes;Queueing analysis;Differential equations;Cities and towns;Buffer storage;Steady-state;Fluid dynamics;Phase modulation},
doi={10.1109/INFCOM.2001.916621},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916622,
author={G. Wu and E. K. P. Chong and R. Givan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Congestion control via online sampling},
year={2001},
volume={3},
number={},
pages={1271-1280 vol.3},
abstract={We consider the congestion control problem in a communication network with multiple traffic sources, each modeled as a fully-controllable stream of fluid traffic. The controlled traffic shares a common bottleneck node with high-priority cross traffic described by a Markov-modulated fluid (MMF). Each controlled source is assumed to have a unique round-trip delay. We wish to maximize a linear combination of the throughput, delay, traffic loss rate, and a fairness metric at the bottleneck node. We introduce an online sampling-based burst-level congestion control scheme capable of performing effectively under rapidly-varying cross traffic by making explicit use of the provided MMF model of that variation. The control problem is posed as a finite-horizon Markov decision process and is solved heuristically using a technique called hindsight optimization. We provide a detailed derivation of our congestion control algorithm based on this technique. The distinguishing feature of our scheme relative to conventional congestion control schemes is that we exploit a stochastic model of the cross traffic. Our empirical study shows that our control scheme significantly outperforms the conventional proportional-derivative (PD) controller, achieving higher utilization, lower delay, and lower loss under reasonable fairness. The performance advantage of our scheme over the PD scheme grows as the rate variance of cross traffic increases, underscoring the effectiveness of our control scheme under variable cross traffic.},
keywords={telecommunication congestion control;telecommunication networks;telecommunication traffic;Markov processes;delays;optimisation;asynchronous transfer mode;packet switching;online sampling;communication network;multiple traffic sources;fluid traffic;controlled traffic;bottleneck node;high-priority cross traffic;Markov-modulated fluid;controlled source;round-trip delay;throughput;traffic loss rate;fairness metric;burst-level congestion control;rapidly-varying cross traffic;MMF model;finite-horizon Markov decision process;hindsight optimization;congestion control algorithm;stochastic model;proportional-derivative controller;ATM network;Sampling methods;Traffic control;Communication system traffic control;Delay;PD control;Communication system control;Proportional control;Communication networks;Throughput;Stochastic processes},
doi={10.1109/INFCOM.2001.916622},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916623,
author={A. Kuzmanovic and E. W. Knightly},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Measuring service in multi-class networks},
year={2001},
volume={3},
number={},
pages={1281-1289 vol.3},
abstract={Quality of service mechanisms and differentiated service classes are increasingly available in networks and servers. While network clients can assess their service by measuring basic performance parameters such as packet loss and delay, such measurements do not expose the network's core QoS functionality. We develop a framework and methodology for enabling network clients to assess a system's multi-class mechanisms and parameters. Using hypothesis testing, maximum likelihood estimation, and empirical arrival and service rates measured across multiple time scales, we devise techniques for clients to (1) determine the most likely service discipline among EDF, WFQ, and SP, (2) estimate the server's parameters with high confidence, and (3) detect and parameterize non-work-conserving elements such as rate limiters. We describe the important role of time scales in such a framework and identify the conditions necessary for obtaining accurate and high confidence inferences.},
keywords={quality of service;maximum likelihood estimation;delays;packet switching;network servers;file servers;Internet;performance evaluation;queueing theory;service measurement;multi-class networks;quality of service mechanisms;QoS mechanisms;differentiated service classes;MLE;performance parameters;packet loss;packet delay;multi-class mechanisms;multi-class parameters;hypothesis testing;maximum likelihood estimation;empirical arrival rate;empirical service rate;multiple time scales;EDF;WFQ;SP;server parameter estimation;nonwork-conserving elements;rate limiters;high confidence inference;accurate inference;routers;Web server;Internet;queueing;Intelligent networks;Quality of service;Monitoring;Time measurement;Loss measurement;Testing;Maximum likelihood detection;Telecommunication traffic;Traffic control;Network servers},
doi={10.1109/INFCOM.2001.916623},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916624,
author={M. Karsten and J. Schmitt and R. Steinmetz},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Implementation and evaluation of the KOM RSVP engine},
year={2001},
volume={3},
number={},
pages={1290-1299 vol.3},
abstract={We describe implementation aspects and performance results of an innovative and publicly available RSVP implementation. Much debate exists about the applicability of RSVP as a signalling protocol in the Internet, particularly for a large number of unicast flows. While there has been a significant amount of work published on the theoretical concepts of RSVP signalling and conjectures about its presumed shortcomings, rather little attention has been paid to the implementation details of the core protocol engine. With our work, in spite of being still far from a final judgement, we try to shed light on this issue by presenting certain design details of a new implementation and a study about its performance. One particular result is given by the observation that a relatively cheap router based on PC hardware can sustain the signalling for more than 50,000 unicast flows.},
keywords={Internet;protocols;telecommunication signalling;performance evaluation;telecommunication network routing;microcomputer applications;C++ language;KOM RSVP engine;performance results;signalling protocol;Internet;unicast flows;protocol engine;performance;router;PC hardware;object-oriented design;C++;Protocols;Search engines;Unicast;Internet;Solids;Hardware;Proposals;Security;Algorithm design and analysis;Multicast algorithms},
doi={10.1109/INFCOM.2001.916624},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916625,
author={A. Elwalid and C. Jin and S. Low and I. Widjaja},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={MATE: MPLS adaptive traffic engineering},
year={2001},
volume={3},
number={},
pages={1300-1309 vol.3},
abstract={Destination-based forwarding in traditional IP routers has not been able to take full advantage of multiple paths that frequently exist in Internet service provider networks. As a result, the networks may not operate efficiently, especially when the traffic patterns are dynamic. This paper describes a multipath adaptive traffic engineering mechanism, called MATE, which is targeted for switched networks such as multiprotocol label switching (MPLS) networks. The main goal of MATE is to avoid network congestion by adaptively balancing the load among multiple paths based on measurement and analysis of path congestion. MATE adopts a minimalist approach in that intermediate nodes are not required to perform traffic engineering or measurements besides normal packet forwarding. Moreover MATE does not impose any particular scheduling, buffer management, or a priori traffic characterization on the nodes. This paper presents an analytical model, derives a class of MATE algorithms, and proves their convergence. Several practical design techniques to implement MATE are described. Simulation results are provided to illustrate the efficacy of MATE under various network scenarios.},
keywords={Internet;telecommunication traffic;packet switching;telecommunication congestion control;MPLS adaptive traffic engineering;MATE;destination-based forwarding;IP routers;Internet service provider networks;traffic patterns;multipath adaptive traffic engineering mechanism;multiprotocol label switching;network congestion;load balancing;minimalist approach;packet forwarding;convergence;design techniques;Multiprotocol label switching;Telecommunication traffic;Routing;Traffic control;Reliability engineering;IP networks;Web and internet services;Communications technology;Rivers;Performance evaluation},
doi={10.1109/INFCOM.2001.916625},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916626,
author={D. Loguinov and H. Radha},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On retransmission schemes for real-time streaming in the Internet},
year={2001},
volume={3},
number={},
pages={1310-1319 vol.3},
abstract={This paper presents a trace-driven simulation study of three classes of retransmission timeout (RTO) estimators in the context of low-bitrate real-time streaming over the Internet. We explore the viability of employing retransmission timeouts in NACK-based real-time streaming applications that support multiple retransmission attempts per lost packet. In such applications, real-time RTO estimation plays a major role (i.e., poor RTO estimation results in a larger number of duplicate packets and sometimes more frequent underflow events). Our study is based on trace data collected during a number of real-time streaming tests conducted between our dialup clients in all 50 states of the U.S. (including 653 major U.S. cities) and our backbone video server during a seven-month period. First, we define a generic performance measure for assessing the quality of hypothetical RTO estimators based on the samples of the round-trip delay (RTT) recorded in the trace data. Second, using this performance measure, we evaluate the class of TCP-like estimators, find the most optimal estimator given our performance measure, and establish power laws that describe the tradeoff between the optimal number of duplicate packets and the optimal timeout waiting time. Third, we introduce a new class of RTO estimators based on delay jitter and show that they perform significantly better than TCP-like estimators in NACK-based applications. Finally, we gain a major insight into the RTT process by establishing which tuning parameters of an RTO estimator make it optimal given our performance measure and our experimental data, and give our explanation of the observed phenomena.},
keywords={Internet;timing jitter;real-time systems;visual communication;packet switching;client-server systems;transport protocols;retransmission schemes;real-time streaming;Internet;trace-driven simulation study;retransmission timeout estimators;RTO estimators;NACK-based real-time streaming;video server;performance;round-trip delay;TCP-like estimators;packets;timeout waiting time;delay jitter;tuning parameters;RTO;Internet;Delay estimation;Power measurement;Time measurement;Context modeling;Streaming media;Testing;Cities and towns;Spine;Jitter},
doi={10.1109/INFCOM.2001.916626},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916627,
author={R. J. La and V. Anantharam},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Window-based congestion control with heterogeneous users},
year={2001},
volume={3},
number={},
pages={1320-1329 vol.3},
abstract={We investigate the fundamental problem of achieving the system optimal rates, which maximize the total user utility, in a distributed network environment using only the information available at the end hosts. This is done by decomposing the overall system problem into subproblems for the network and for the individual users and introducing an incentive-compatible pricing scheme. The users are to solve the problem of maximizing individual net utility, which is their utility less the amount they pay. This is done using a window based algorithm. We provide an algorithm for the network to adjust its prices and the users to adjust their window sizes such that at an equilibrium the system optimum is achieved. It is notable that our algorithm does not require any explicit feedback from the network and can be deployed over the Internet with modifications only at the end hosts. Our scheme is incentive compatible in that there is no benefit to the users to lie about their utilities.},
keywords={Internet;telecommunication congestion control;window-based congestion control;heterogeneous users;system optimal rates;total user utility;distributed network environment;subproblems;incentive-compatible pricing scheme;individual net utility;Internet;Pricing;IP networks;Bandwidth;Internet;Computer networks;Distributed computing;Feedback;Protocols;Quality of service;Volume measurement},
doi={10.1109/INFCOM.2001.916627},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916628,
author={S. Kunniyur and R. Srikant},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A time scale decomposition approach to adaptive ECN marking},
year={2001},
volume={3},
number={},
pages={1330-1339 vol.3},
abstract={Fair resource allocation in high-speed networks such as the Internet can be viewed as a constrained optimization program. Kelly and his co-workers have shown that an unconstrained penalty function formulation of this problem can be used to design congestion controllers that are stable. In this paper, we examine the question of providing feedback from the network such that the congestion controllers derived from the penalty function formulation lead to the solution of the original unconstrained problem. This can be viewed as the decentralized design of early congestion notification (ECN) marking rates at each node in the Internet to ensure global loss-free operation of a fluid model of the network. We then look at the stability of such a scheme using a time-scale decomposition of the system. This results in two separate systems which are stable individually and we show that under certain assumptions the entire system is semi-globally stable and converges to the equilibrium point exponentially fast.},
keywords={Internet;optimisation;telecommunication congestion control;distributed algorithms;time scale decomposition approach;adaptive ECN marking;fair resource allocation;high-speed networks;Internet;constrained optimization program;unconstrained penalty function formulation;congestion controllers;feedback;penalty function formulation;ECN marking rates;global loss-free operation;fluid model;early congestion notification;Adaptive algorithm;Resource management;IP networks;Optimal control;High-speed networks;Constraint optimization;Feedback;Stability;Explosives;Internet},
doi={10.1109/INFCOM.2001.916628},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916629,
author={B. Nandy and J. Ethridge and A. Lakas and A. Chapman},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Aggregate flow control: improving assurances for differentiated services network},
year={2001},
volume={3},
number={},
pages={1340-1349 vol.3},
abstract={The differentiated services architecture is a simple, but novel, approach for providing service differentiation in an IP network. However, there are various issues to be addressed before any sophisticated end-to-end services can be offered. This work proposes an aggregate flow control (AFC) technique with a Diffserv traffic conditioner to improve the bandwidth and delay assurance of differentiated services. A prototype has been developed to study the end-to-end behavior of customer aggregates. In particular, this new approach improves performance in the following manner: (1) fairness issues among aggregated customer traffic with different number of micro-flows in an aggregate, interaction of non-responsive traffic (UDP) and responsive traffic (TCP), and the effect of different packet sizes in aggregates; (2) improved transactions per second for short TCP flows; and (3) reduced inter-packet delay variation for streaming UDP traffic. Experiments are also performed in a topology with multiple congestion points to show an improved treatment of conformant aggregates, and the ability of AFC to handle multiple aggregates and differing target rates.},
keywords={Internet;telecommunication congestion control;packet switching;telecommunication traffic;network topology;transport protocols;aggregate flow control;differentiated services network;service differentiation;IP network;AFC technique;Diffserv traffic conditioner;bandwidth;delay assurance;end-to-end behavior;customer aggregates;performance;fairness issues;micro-flows;responsive traffic;packet sizes;inter-packet delay variation;streaming UDP traffic;topology;multiple congestion points;conformant aggregates;AFC;multiple aggregates;target rates;Aggregates;Diffserv networks;Traffic control;Communication system traffic control;Bandwidth;Throughput;Automatic frequency control;Telecommunication traffic;TCPIP;Sections},
doi={10.1109/INFCOM.2001.916629},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916630,
author={E. Altman and K. Avrachenkov and C. Barakat and R. Nunez-Queija},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={State-dependent M/G/1 type queueing analysis for congestion control in data networks},
year={2001},
volume={3},
number={},
pages={1350-1359 vol.3},
abstract={We study in this paper a TCP-like linear-increase multiplicative-decrease flow control mechanism. We consider congestion signals that arrive in batches according to a Poisson process. We focus on the case when the transmission rate cannot exceed a certain maximum value. We write the Kolmogorov equations and we use Laplace transforms to calculate the distribution of the transmission rate in the steady state as well as its moments. Our model is particularly useful to study the behavior of TCP, the congestion control mechanism in the Internet. By a simple transformation, the problem can be reformulated in terms of an equivalent M/G/1 queue, where the transmission rate in the original model corresponds to the workload in the 'dual' queue. The service times in the queueing model are not i.i.d., and they depend on the workload in the system.},
keywords={queueing theory;data communication;telecommunication networks;telecommunication congestion control;transport protocols;Internet;stochastic processes;Laplace transforms;state-dependent M/G/1 type queueing;congestion control;data networks;TCP;linear-increase multiplicative-decrease flow control;congestion signals;Kolmogorov equations;Laplace transforms;transmission rate distribution;steady state;moments;Internet;dual queue;service times;queueing model;system workload;batch Poisson process;Queueing analysis;Intelligent networks;Telecommunication congestion control;Laplace equations;Internet;Signal processing;Poisson equations;Telecommunication control;Protocols;Switches},
doi={10.1109/INFCOM.2001.916630},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916631,
author={M. Grossglauser and D. Tse},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Mobility increases the capacity of ad-hoc wireless networks},
year={2001},
volume={3},
number={},
pages={1360-1369 vol.3},
abstract={The capacity of ad-hoc wireless networks is constrained by the mutual interference of concurrent transmissions between nodes. We study a model of an ad-hoc network where n nodes communicate in random source-destination pairs. These nodes are assumed to be mobile. We examine the per-session throughput for applications with loose delay constraints, such that the topology changes over the time-scale of packet delivery. Under this assumption, the per-user throughput can increase dramatically when the nodes are mobile rather than fixed. This improvement can be achieved by exploiting node mobility as a type of multiuser diversity.},
keywords={land mobile radio;channel capacity;radiofrequency interference;delays;network topology;packet radio networks;diversity reception;ad-hoc wireless networks;network capacity;mutual interference;concurrent transmissions;network nodes;random source-destination;mobile nodes;per-session throughput;delay constraints;topology changes;packet delivery time-scale;node mobility;multiuser diversity;Wireless networks;Diversity reception;Throughput;Delay;Interference constraints;Ad hoc networks;Network topology;Fading;Cellular networks;Diversity methods},
doi={10.1109/INFCOM.2001.916631},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916632,
author={H. Luo and P. Medvedev and J. Cheng and S. Lu},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A self-coordinating approach to distributed fair queueing in ad hoc wireless networks},
year={2001},
volume={3},
number={},
pages={1370-1379 vol.3},
abstract={Distributed fair queueing in shared-medium ad hoc wireless networks is non-trivial because of the unique design challenges in such networks, such as location-dependent contention, distributed nature of ad hoc fair queueing, channel spatial reuse, and scalability in the presence of node mobility. In this paper, we seek to devise new distributed, localized, scalable and efficient solutions to this problem. We first analyze an ideal centralized fair queueing algorithm developed for ad hoc networks, and extract the desired global properties that the localized algorithms should possess. We then propose three localized fair queueing models, in which local schedulers self-coordinate their local interactions and collectively achieve the desired global properties. We further describe a novel implementation of the proposed models within the framework of the popular CSMA/CA paradigm and address several practical issues. Our simulations and analysis demonstrate the effectiveness of our proposed design.},
keywords={land mobile radio;queueing theory;carrier sense multiple access;distributed algorithms;digital simulation;packet radio networks;self-coordinating approach;distributed fair queueing;location-dependent contention;shared-medium ad hoc wireless networks;ad hoc fair queueing;channel spatial reuse;centralized fair queueing algorithm;node mobility;localized solution;scalable solution;efficient solution;global properties;localized algorithms;localized fair queueing models;local schedulers;CSMA/CA paradigm;simulations;packet-switched multihop wireless network;Intelligent networks;Wireless networks;Wireless sensor networks;Algorithm design and analysis;Queueing analysis;Ad hoc networks;Scheduling algorithm;Multiaccess communication;Analytical models;Delay},
doi={10.1109/INFCOM.2001.916632},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916633,
author={S. Meguerdichian and F. Koushanfar and M. Potkonjak and M. B. Srivastava},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Coverage problems in wireless ad-hoc sensor networks},
year={2001},
volume={3},
number={},
pages={1380-1387 vol.3},
abstract={Wireless ad-hoc sensor networks have recently emerged as a premier research topic. They have great long-term economic potential, ability to transform our lives, and pose many new system-building challenges. Sensor networks also pose a number of new conceptual and optimization problems. Some, such as location, deployment, and tracking, are fundamental issues, in that many applications rely on them for needed information. We address one of the fundamental problems, namely coverage. Coverage in general, answers the questions about quality of service (surveillance) that can be provided by a particular sensor network. We first define the coverage problem from several points of view including deterministic, statistical, worst and best case, and present examples in each domain. By combining the computational geometry and graph theoretic techniques, specifically the Voronoi diagram and graph search algorithms, we establish the main highlight of the paper-optimal polynomial time worst and average case algorithm for coverage calculation. We also present comprehensive experimental results and discuss future research directions related to coverage in sensor networks.},
keywords={radio networks;land mobile radio;quality of service;optimisation;radio tracking;computational geometry;graph theory;statistical analysis;search problems;mobile computing;microsensors;coverage problems;wireless ad-hoc sensor networks;optimization problems;location;deployment;tracking;quality of service;surveillance;deterministic coverage;statistical coverage;worst case coverage;computational geometry;graph theory;Voronoi diagram;graph search algorithms;optimal polynomial time worst case algorithm;optimal polynomial time average case algorithm;personal computing;microsensor;Wireless sensor networks;Intelligent networks;Fires;Costs;Quality of service;Wireless communication;Sensor systems;Wiring;Computer science;Surveillance},
doi={10.1109/INFCOM.2001.916633},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916634,
author={R. Wattenhofer and L. Li and P. Bahl and Y. -. Wang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Distributed topology control for power efficient operation in multihop wireless ad hoc networks},
year={2001},
volume={3},
number={},
pages={1388-1397 vol.3},
abstract={The topology of wireless multihop ad hoc networks can be controlled by varying the transmission power of each node. We propose a simple distributed algorithm where each node makes local decisions about its transmission power and these local decisions collectively guarantee global connectivity. Specifically, based on the directional information, a node grows it transmission power until it finds a neighbor node in every direction. The resulting network topology increases the network lifetime by reducing the transmission power and reduces traffic interference by having low node degrees. Moreover, we show that the routes in the multihop network are efficient in power consumption. We give an approximation scheme in which the power consumption of each route can be made arbitrarily close to the optimal by carefully choosing the parameters. Simulation results demonstrate significant performance improvements.},
keywords={radio networks;network topology;distributed algorithms;telecommunication traffic;approximation theory;telecommunication control;distributed control;power control;distributed topology control;power efficient operation;multihop wireless ad hoc networks;network topology;transmission power;network node;distributed algorithm;global connectivity;directional information;network lifetime;traffic interference;multihop network routes;power consumption;approximation scheme;simulation results;static ad hoc multihop network topology;power control;Network topology;Distributed control;Intelligent networks;Spread spectrum communication;Ad hoc networks;Wireless networks;Mobile ad hoc networks;Batteries;Distributed algorithms;Interference},
doi={10.1109/INFCOM.2001.916634},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916635,
author={E. Cohen and H. Kaplan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Refreshment policies for Web content caches},
year={2001},
volume={3},
number={},
pages={1398-1406 vol.3},
abstract={Web content caches are often placed between end-users and origin servers as a mean to reduce server load, network usage, and ultimately, user-perceived latency. Cached objects typically have associated expiration times, after which they are considered stale and must be validated with a remote server (origin or another cache) before they can be sent to a client. A considerable fraction of cache hits involve stale copies that turned out to be current. These validations of current objects have small message size, but nonetheless, often induce latency comparable to full-fledged cache misses. Thus, the functionality of caches as a latency-reducing mechanism highly depends not only on content availability but also on its freshness. We propose policies for caches to preactively validate selected objects as they become stale, and thus allow for more client requests to be processed locally. Our policies operate within the existing protocols and exploit natural properties of request patterns such as frequency and recency. We evaluated and compared different policies using trace-based simulations.},
keywords={Internet;cache storage;client-server systems;refreshment policies;Web content caches;expiration times;cache hits;stale copies;message size;latency;cache misses;functionality;latency-reducing mechanism;content availability;freshness;protocols;request patterns;frequency;recency;trace-based simulations;Network servers;Delay;Costs;Bandwidth;Cache storage;Web server;Prefetching;Protocols;Frequency;Web and internet services},
doi={10.1109/INFCOM.2001.916635},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916636,
author={K. Psounis and B. Prabhakar},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A randomized Web-cache replacement scheme},
year={2001},
volume={3},
number={},
pages={1407-1415 vol.3},
abstract={The problem of document replacement in Web caches has received much attention in the literature research, and it has been shown that the eviction rule "replace the least recently used document" performs poorly in Web caches. Instead, it has been shown that using a combination of several criteria, such as the recentness and frequency of use, the size, and the cost of fetching a document, leads to a sizeable improvement in hit rate and latency reduction. However, in order to implement these novel schemes, one needs to maintain complicated data structures. We propose randomized algorithms for approximating any existing Web-cache replacement scheme and thereby avoid the need for any data structures. At document-replacement times, the randomized algorithm samples N documents from the cache and replaces the least useful document from the sample, where usefulness is determined according to the criteria mentioned above. The next M<N least useful documents are retained for the succeeding iteration. When the next replacement is to be performed, the algorithm obtains N-M new samples from the cache, and replaces the least useful document from the N-M new samples and the M previously retained. Using theory and simulations, we analyze the algorithm and find that it matches the performance of existing document replacement schemes for values of N and M as low as 8 and 2 respectively. Rather surprisingly, we find that retaining a small number of samples from one iteration to the next leads to an exponential improvement in performance as compared to retaining no samples at all.},
keywords={randomised algorithms;cache storage;Internet;randomized Web-cache replacement scheme;recentness;frequency of use;size;cost;hit rate;latency reduction;data structures;randomized algorithm;document-replacement times;iteration;document replacement schemes;Data structures;Costs;Delay;Telecommunication traffic;Frequency;Analytical models;Performance analysis;Algorithm design and analysis;Helium;Web sites},
doi={10.1109/INFCOM.2001.916636},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916637,
author={H. Che and Z. Wang and Y. Tung},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Analysis and design of hierarchical Web caching systems},
year={2001},
volume={3},
number={},
pages={1416-1424 vol.3},
abstract={This paper aims at finding fundamental design principles for hierarchical Web caching. An analytical modeling technique is developed to characterize an uncooperative two-level hierarchical caching system where the least recently used (LRU) algorithm is locally run at each cache. With this modeling technique, we are able to identify a characteristic time for each cache, which plays a fundamental role in understanding the caching processes. In particular, a cache can be viewed roughly as a lowpass filter with its cutoff frequency equal to the inverse of the characteristic time. Documents with access frequencies lower than this cutoff frequency will have good chances to pass through the cache without cache hits. This viewpoint enables us to take any branch of the cache tree as a tandem of lowpass filters at different cutoff frequencies, which further results in the finding of two fundamental design principles. Finally, to demonstrate how to use the principles to guide the caching algorithm design, we propose a cooperative hierarchical Web caching architecture based on these principles. The simulation study shows that the proposed cooperative architecture results in 50% saving of the cache resource compared with the traditional uncooperative hierarchical caching architecture.},
keywords={Internet;cache storage;low-pass filters;cooperative systems;hierarchical Web caching systems;design principles;analytical modeling technique;uncooperative two-level hierarchical caching system;least recently used algorithm;LRU algorithm;characteristic time;caching processes;lowpass filter;cutoff frequency;access frequencies;cache tree;cutoff frequencies;cooperative hierarchical Web caching architecture;cooperative architecture;cache resource;Algorithm design and analysis;Cutoff frequency;Network servers;Filters;Delay;Internet;Educational institutions;Analytical models;Service oriented architecture;Web services},
doi={10.1109/INFCOM.2001.916637},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916638,
author={M. Aida and T. Abe},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Pseudo-address generation algorithm of packet destinations for Internet performance simulation},
year={2001},
volume={3},
number={},
pages={1425-1433 vol.3},
abstract={This paper investigates the stochastic property of the packet destinations and proposes an address generation algorithm which is applicable for describing various Internet access patterns. We assume that a stochastic process of Internet access satisfies the stationary condition and derive the fundamental structure of the address generation algorithm. The pseudo IP-address sequence generated from our algorithm gives dependable cache performance and reproduces the results obtained from trace-driven simulation. The proposed algorithm is applicable not only to the destination IP address but also to the destination URLs of packets, and is useful for simulation studies of Internet performance, Web caching, DNS, and so on.},
keywords={Internet;cache storage;packet switching;pseudo-address generation algorithm;packet destinations;Internet performance simulation;stochastic property;Internet access patterns;pseudo IP-address sequence;cache performance;trace-driven simulation;Web caching;DNS;Internet performance;Internet;Traffic control;Stochastic processes;Uniform resource locators;IP networks;Algorithm design and analysis;Web sites;Table lookup;High-speed networks;Throughput},
doi={10.1109/INFCOM.2001.916638},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916639,
author={P. Warkhede and S. Suri and G. Varghese},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Fast packet classification for two-dimensional conflict-free filters},
year={2001},
volume={3},
number={},
pages={1434-1443 vol.3},
abstract={Routers can use packet classification to support advanced functions. Routers with packet classification capability can forward packets based on multiple header fields, such as source address, protocol type, or application port numbers. The destination-based forwarding can be thought of as one-dimensional packet classification. While several efficient solutions are known for the one-dimensional IP lookup problem, the multi-dimensional packet classification has proved to be far more difficult. While an O(log w) time scheme is known for the IP lookup, Srinivisan et al. (1999) show a lower bound of /spl Omega/(/spl omega//sup k-1/) for k-dimensional filter lookup, where /spl omega/ is the number of bits in a header field. In particular, this lower bound precludes the possibility of a binary search like scheme even for 2-dimensional filters. In this paper, we examine this lower bound more closely, and discover that the lower bound depends crucially on conflicts in the filter database. We then show that for two-dimensional conflict-free filters, a binary search scheme does work! Our lookup scheme requires O(log/sup 2/ /spl omega/) hashes in the worst-case, and uses O(n log/sup 2/ /spl omega/) memory. Alternatively, our algorithm can be viewed as making O (log /spl omega/) calls to a prefix lookup scheme. It has been observed in practice that filter databases have very few conflicts, and these conflicts can be removed by adding additional filters (one per conflict). Thus, our scheme may also be quite practical. Our simulation and experimental results show that the proposed scheme also performs as good as or better than existing schemes.},
keywords={packet switching;pattern classification;telecommunication network routing;search problems;fast packet classification;two-dimensional conflict-free filters;multiple header fields;source address;protocol type;application port numbers;destination-based forwarding;one-dimensional packet classification;multi-dimensional packet classification;k-dimensional filter lookup;lower bound;filter database;binary search scheme;prefix lookup scheme;firewall data-sets;filtering rules;Filters;Virtual private networks;Filtering;Routing;Bandwidth;Databases;Packet switching;Computer science;Access control;Access protocols},
doi={10.1109/INFCOM.2001.916639},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916640,
author={F. Ergun and S. Mittra and S. C. Sahinalp and J. Sharp and R. K. Sinha},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A dynamic lookup scheme for bursty access patterns},
year={2001},
volume={3},
number={},
pages={1444-1453 vol.3},
abstract={The problem of fast address lookup is crucial to routing and thus has received considerable attention. Most of the work in this field has focused on improving the speed of individual accesses-independent from the underlying access pattern. Gupta et al. (2000) proposed an efficient data structure to exploit the bias in access pattern. This technique achieves faster lookups for more frequently accessed keys while bounding the worst case lookup time; in fact it is (near) optimal under constraints on worst case performance. However,it needs to be rebuilt periodically to reflect the changes in access patterns, which can be inefficient for bursty environments. In this paper we introduce a new dynamic data structure to exploit biases in the access pattern, which tend to change dynamically. Previous work shows that there are many circumstances under which access patterns change quickly. Our data structure, which we call the biased skip list (BSL), has a self-update mechanism which reflects the changes in the access patterns efficiently and immediately, without any need for rebuilding. It improves throughput while keeping the worst case access time bounded by that of the fastest (unbiased) schemes. We demonstrate the practicality of BSL by experiments on data with varying degrees of burstiness.},
keywords={telecommunication network routing;data structures;packet switching;table lookup;Internet;dynamic lookup scheme;bursty access pattern;fast address lookup;routing;performance;access patterns;dynamic data structure;biased skip list;BSL;self-update mechanism;throughput;burstiness;Data structures;Throughput;Internet;Frequency;Routing},
doi={10.1109/INFCOM.2001.916640},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916641,
author={A. Broder and M. Mitzenmacher},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Using multiple hash functions to improve IP lookups},
year={2001},
volume={3},
number={},
pages={1454-1463 vol.3},
abstract={High performance Internet routers require a mechanism for very efficient IP address lookups. Some techniques used to this end, such as binary search on levels, need to construct quickly a good hash table for the appropriate IP prefixes. We describe an approach for obtaining good hash tables based on using multiple hashes of each input key (which is an IP address). The methods we describe are fast, simple, scalable, parallelizable, and flexible. In particular, in instances where the goal is to have one hash bucket fit into a cache line, using multiple hashes proves extremely suitable. We provide a general analysis of this hashing technique and specifically discuss its application to binary search on levels.},
keywords={table lookup;transport protocols;cryptography;Internet;search problems;telecommunication network routing;multiple hash functions;binary search;high performance Internet routers;IP address lookups;input key;IP prefixes;hash tables;hash bucket;cache line;fast methods;scalable methods;parallelizable methods;IP routing;Routing;Internet;Application software;Hardware;Filtering;Algorithms;Testing;Databases;Computer science;Engineering profession},
doi={10.1109/INFCOM.2001.916641},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916642,
author={V. Srinivasan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A packet classification and filter management system},
year={2001},
volume={3},
number={},
pages={1464-1473 vol.3},
abstract={Packet classification and fast filter matching have been an important field of research. Several algorithms have been proposed for fast packet classification. We first present a new filter matching scheme called entry-pruned tuple search and discuss its advantages over previously presented algorithms. We then show how this algorithm blends very well with an earlier packet classification algorithm that uses markers and precomputation, to give a blended entry-pruned tuple search with markers and precomputation (EPTSMP). We present performance measurements using several real-life filter databases. For a large real-life database of 1777 filters, our preprocessing times were close to 9 seconds; a lookup takes about 20 memory accesses and the data structure takes about 500 K bytes of memory. Then, we present scenarios that will require various programs/modules to automatically generate and add filters to a filter processing engine. We then consider issues in enabling this. We need policies that govern what filters can be added by different modules. We present our filter policy management architecture. We then show how to support fast filter updates. We present an incremental update algorithm based on maintaining an event list that can be applied to many of the previously presented filter matching schemes which did not support incremental updates. We then describe the event list based incremental update algorithm as it applies to EPTSMP. To stress the generality of the approach, we also describe how our update technique can be used with the packet classification technique based on crossproducing. We conclude with an outline of a hardware implementation of EPTSMP that can handle OC192 rates with 40 byte minimum packet lengths.},
keywords={packet switching;telecommunication network routing;telecommunication network management;search problems;telecommunication security;security of data;filter management system;performance measurements;fast filter matching;EPTSMP;fast packet classification algorithm;markers;blended entry-pruned tuple search;real-life filter databases;large real-life database;preprocessing times;lookup;data structure;memory access;filter processing engine;filter policy management architecture;incremental update algorithm;event list;crossproducting;packet lengths;OC192 rates;MLPS edge routers;firwall databases;Matched filters;Databases;Multiprotocol label switching;Data security;Ear;Classification algorithms;Measurement;Data structures;Search engines;Stress},
doi={10.1109/INFCOM.2001.916642},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916643,
author={P. Thiran and J. -. Le Boudec and F. Worm},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Network calculus applied to optimal multimedia smoothing},
year={2001},
volume={3},
number={},
pages={1474-1483 vol.3},
abstract={We consider a scenario where multimedia data are sent over a network offering a guaranteed service. A smoothing device writes the stream into a transmitting device with limited input buffer; at the destination, the decoder waits for an initial playback delay and reads the stream from the receiver buffer. We assume that some limited look-ahead is possible at the source, and that the playback buffer size is limited. First, we consider the case where the stream is delivered from the source directly to the destination buffer. We obtain closed-form expressions of the minimal required values in the case of a CBR smoothing. Then we consider the case where the stream is first transmitted through a backbone network to an intermediate server, which relays the multimedia data to the final destination via an access network. We compute the requirements on playback delay, buffer sizes and amount of look-ahead.},
keywords={optimisation;multimedia communication;calculus;smoothing methods;buffer storage;decoding;delays;network servers;subscriber loops;video servers;network calculus;optimal multimedia smoothing;multimedia data;guaranteed service;smoothing device;transmitting device;input buffer;decoder;playback delay;receiver buffer;look-ahead;playback buffer size;destination buffer;closed-form expressions;CBR smoothing;backbone network;stream transmission;access network;buffer size;video server;Calculus;Smoothing methods;Streaming media;Delay;Network servers;Multimedia systems;Decoding;Spine;Telecommunication traffic;Displays},
doi={10.1109/INFCOM.2001.916643},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916644,
author={J. Kaur and H. M. Vin},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Core-stateless guaranteed rate scheduling algorithms},
year={2001},
volume={3},
number={},
pages={1484-1492 vol.3},
abstract={Many per-flow scheduling algorithms have been proposed to provide rate and delay guarantees to flows. It is often argued that the need for maintaining per-flow state and performing per-packet classification seriously limits the scalability of routers that employ such per-flow scheduling algorithms. Consequently, design of algorithms that can provide per-flow rate and delay guarantees without requiring per-flow functionality in the network core routers has become an active area of research. We propose a methodology to transform any guaranteed rate (GR) per-flow scheduling algorithm into a version that does not require per-flow state to be maintained in the core routers. We prove that a network of such core-stateless servers provides the same delay guarantee as a corresponding network of GR servers.},
keywords={delays;packet switching;telecommunication network routing;network servers;clocks;Internet;core-stateless guaranteed rate scheduling algorithms;per-flow scheduling algorithms;delay guarantee;per-flow state;per-packet classification;router scalability;algorithm design;per-flow rate guarantee;network core routers;core-stateless servers;guaranteed rate servers;Internet;DiffServ architecture;network architecture;jitter virtual clock algorithm;virtual clock servers;Scheduling algorithm;Scalability;Delay;Network servers;Aggregates;Laboratories;Web server;Web and internet services;Telecommunication traffic;Jitter},
doi={10.1109/INFCOM.2001.916644},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916645,
author={K. Zhu and Y. Zhuang and Y. Viniotis},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Achieving end-to-end delay bounds by EDF scheduling without traffic shaping},
year={2001},
volume={3},
number={},
pages={1493-1501 vol.3},
abstract={Earliest deadline first scheduling with per-node traffic shaping (RC-EDF) has the largest schedulable region among all practical policies known today and has been considered a good solution for providing end-to-end packet delay bounds. In order to harness the traffic burstiness inside a network to satisfy the schedulability condition of EDF, per-node traffic shaping has been believed to be necessary. However, shaping introduces artificial packet delays. We show that by deadline assignments at each node that are strict time-shifting of the source packet arrival times, the functionality of shaping can be implicitly realized; the resulting schedulable region of the new scheduling policy is as large as that of RC-EDF. We name the new policy deadline-curve based EDF (DC-EDF). Not only working in a natural work-conserving way, when the global schedulability condition fails DC-EDF will also work in a "best-effort" way to allow packets excessively delayed at previous nodes to catch up and meet the end-to-end delay bounds. Therefore, DC-EDF is likely to provide "tight" statistical delay bounds. We also prove that a known EDF policy without traffic shaping also has a schedulable region as large as that of RC-EDF.},
keywords={queueing theory;packet switching;delays;telecommunication traffic;EDF scheduling;traffic burstiness;earliest deadline first scheduling;per-node traffic shaping;schedulable region;end-to-end packet delay bounds;deadline assignments;source packet arrival times;RC-EDF;deadline-curve based EDF;DC-EDF;global schedulability condition;statistical delay bounds;QoS;packet networks;earliest deadline first;weighted fair queueing;Delay;Traffic control;Telecommunication traffic;Processor scheduling;Computer networks;Communication system traffic control;Quality of service;Scheduling algorithm;Ear;Protection},
doi={10.1109/INFCOM.2001.916645},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916646,
author={J. C. R. Bennett and K. Benson and A. Charny and W. F. Courtney and J. -. LeBoudec},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Delay jitter bounds and packet scale rate guarantee for expedited forwarding},
year={2001},
volume={3},
number={},
pages={1502-1509 vol.3},
abstract={We consider the definition of the expedited forwarding per-hop behaviour (EF PHB) as given in RFC 2598 (Jacobsen et al. 1999), and its impact on worst case end-to-end delay jitter. On one hand, the definition in RFC 2598 can be used to predict extremely low end-to-end delay jitter, independent of the network scale. On the other hand, we find that the worst case delay jitter can be made arbitrarily large, while each flow traverses at most a specified number of hops, if we allow networks to become arbitrarily large; this is in contradiction with the previous statement. We analyze where the contradiction originates, and find the explanation. It resides in the fact that the definition in RFC 2598 is not easily implementable in schedulers we know of, mainly because it is not formal enough, and also because it does not contain an error term. We propose a new definition for the EF PHB, called "packet scale rate guarantee", which preserves the spirit of RFC 2598, while allowing a number of reasonable implementations, and has very useful properties for per-node and end-to-end network engineering. We show that this definition implies the rate-latency service curve guarantee. Then we propose some proven bounds on delay jitter for networks implementing this new definition, both in cases without loss and with loss.},
keywords={timing jitter;packet switching;quality of service;delay jitter bounds;packet scale rate guarantee;expedited forwarding per-hop behaviour;EF PHB;end-to-end delay jitter;RFC 2598;rate-latency service curve guarantee;differentiated services;Delay;Jitter;Traffic control;Aggregates;Bandwidth;Diffserv networks;Wire;Context-aware services;Spine;Scalability},
doi={10.1109/INFCOM.2001.916646},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916647,
author={C. V. Hollot and V. Misra and D. Towsley and Wei-Bo Gong},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A control theoretic analysis of RED},
year={2001},
volume={3},
number={},
pages={1510-1519 vol.3},
abstract={We use a previously developed nonlinear dynamic model of TCP to analyze and design active queue management (AQM) control systems using random early detection (RED). First, we linearize the interconnection of TCP and a bottlenecked queue and discuss its feedback properties in terms of network parameters such as link capacity, load and round-trip time. Using this model, we next design an AQM control system using the RED scheme by relating its free parameters such as the low-pass filter break point and loss probability profile to the network parameters. We present guidelines for designing linearly stable systems subject to network parameters like propagation delay and load level. Robustness to variations in system loads is a prime objective. We present no simulations to support our analysis.},
keywords={random processes;signal detection;control theory;queueing theory;control systems;network parameters;feedback;transport protocols;telecommunication network management;delays;channel capacity;probability;RED;control theory;nonlinear dynamic model;network parameters;active queue management control systems;free parameters;bottlenecked queue;TCP interconnection;feedback properties;link capacity;round-trip time;AQM control system;random early detection;low-pass filter break point;loss probability profile;linearly stable systems;propagation delay;load level;system loads;Guidelines;Analytical models;Control system synthesis;Fluid dynamics;Linear systems;Robust stability;Differential equations;Queueing analysis;Nonlinear control systems;Feedback},
doi={10.1109/INFCOM.2001.916647},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916648,
author={Wu-Chang Feng and D. D. Kandlur and D. Saha and K. G. Shin},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Stochastic fair blue: a queue management algorithm for enforcing fairness},
year={2001},
volume={3},
number={},
pages={1520-1529 vol.3},
abstract={This paper describes and evaluates stochastic fair blue (SFB), a novel technique for enforcing fairness among a large number of rows. SFB scalably detects and rate-limits non-responsive flows through the use of a marking probability derived from the blue queue management algorithm and a Bloom (1970) filter. Using analysis and simulation, SFB is shown to effectively handle non-responsive flows using an extremely small amount of state information.},
keywords={queueing theory;telecommunication network management;transport protocols;telecommunication congestion control;probability;stochastic processes;stochastic fair blue;queue management algorithm;nonresponsive flow detection;non-responsive flow rate limitation;marking probability;Bloom filter;simulation;state information;Internet;TCP congestion control;Stochastic processes;Information filtering;Information filters;Protection;Information analysis;Analytical models;IP networks;Buffer overflow},
doi={10.1109/INFCOM.2001.916648},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916649,
author={S. Y. Cheung and C. S. Pencea},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Pipelined sections: a new buffer management discipline for scalable QoS provision},
year={2001},
volume={3},
number={},
pages={1530-1538 vol.3},
abstract={The techniques used to provide quality of service in packet switched networks are buffer management and packet scheduling. The first line of defense against abusive flows that transmit excessive number of packets is the buffer manager. When the number of packets of a flow exceeds a threshold, new arrivals from that flow will be rejected. This threshold must be set to a level that is sufficiently high to provide specific guarantees to the flow and it must also be minimal so that the buffer manager will detect abusive behavior at the earliest possible moment. A buffer management technique that provides the same guarantees using a lower threshold will be more discriminating because it recognizes flow violations earlier. We present the new pipelined sections buffer management technique that is highly scalable and can provide rate guarantees to leaky bucket constrained flows using very low buffer reservations.},
keywords={pipeline processing;buffer storage;quality of service;packet switching;queueing theory;telecommunication networks;buffer management;scalable QoS provision;pipelined sections;quality of service;packet switched networks;packet scheduling;abusive flows;threshold;flow violations recognition;rate guarantees;leaky bucket constrained flows;low buffer reservations;queueing;Quality of service;Scheduling algorithm;Switches;Packet switching;Quality management;Web and internet services;Bandwidth;Delay;Costs;Mathematics},
doi={10.1109/INFCOM.2001.916649},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916650,
author={G. Ascia and V. Catania and G. Ficili and D. Panno},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A fuzzy buffer management scheme for ATM and IP networks},
year={2001},
volume={3},
number={},
pages={1539-1547 vol.3},
abstract={We address the relevant issue of managing traffic flows with different priorities in packet switched networks, namely ATM and IP networks. We consider a reference model in which two traffic flows with different priorities are multiplexed within the buffer of a cell-based switch. The solution we propose, based on the fuzzy system theory, is able to guarantee the QoS requirements of high-priority traffic flow, allowing at the same time the exploitation of unused buffer resources to accommodate low-priority traffic flow in order to maximize the total throughput. The performance assessment of the fuzzy scheme demonstrates that our solution outperforms other popular mechanisms, based on conventional logic, such as threshold and push out mechanisms.},
keywords={asynchronous transfer mode;telecommunication network management;computer network management;transport protocols;buffer storage;fuzzy systems;telecommunication traffic;switched networks;quality of service;telecommunication congestion control;fuzzy control;Internet;fuzzy buffer management;ATM networks;IP networks;traffic flow management;traffic priorities;packet switched networks;reference model;cell-based switch;fuzzy system theory;QoS requirements guarantee;high-priority traffic flow;buffer resources;low-priority traffic flow;total throughput maximisation;performance assessment;threshold mechanism;push out mechanism;congestion control;fuzzy priority control;IP networks;Switches;Asynchronous transfer mode;Packet switching;Fuzzy logic;Communication system traffic control;Telecommunication traffic;Traffic control;Fuzzy control;Fuzzy systems},
doi={10.1109/INFCOM.2001.916650},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916651,
author={L. M. Feeney and M. Nilsson},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Investigating the energy consumption of a wireless network interface in an ad hoc networking environment},
year={2001},
volume={3},
number={},
pages={1548-1557 vol.3},
abstract={Energy-aware design and evaluation of network protocols requires knowledge of the energy consumption behavior of actual wireless interfaces. But little practical information is available about the energy consumption behavior of well-known wireless network interfaces and device specifications do not provide information in a form that is helpful to protocol developers. This paper describes a series of experiments which obtained detailed measurements of the energy consumption of an IEEE 802.11 wireless network interface operating in an ad hoc networking environment. The data is presented as a collection of linear equations for calculating the energy consumed in sending, receiving and discarding broadcast and point-to-point data packets of various sizes. Some implications for protocol design and evaluation in ad hoc networks are discussed.},
keywords={packet radio networks;data communication;network interfaces;power consumption;IEEE standards;telecommunication standards;land mobile radio;access protocols;energy consumption;wireless network interface;ad hoc networking environment;energy-aware design;energy-aware evaluation;network protocols;IEEE 802.11 wireless network interface;linear equations;broadcast data packets;point-to-point data packets;packet size;protocol design;protocol evaluation;packet discarding;packet reception;packet transmission;mobile wireless hosts;MAC protocol;Energy consumption;Wireless networks;Intelligent networks;Costs;Wireless application protocol;Ad hoc networks;Broadcasting;Network interfaces;Energy measurement;Equations},
doi={10.1109/INFCOM.2001.916651},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916652,
author={Shiann-Tsong Sheu and Tzu-Fang Sheu},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={DBASE: a distributed bandwidth allocation/sharing/extension protocol for multimedia over IEEE 802.11 ad hoc wireless LAN},
year={2001},
volume={3},
number={},
pages={1558-1567 vol.3},
abstract={In ad hoc networks, carrier sense multiple access (CSMA) is one of the most pervasive medium access control (MAC) schemes for asynchronous data traffic. However, CSMA could not guarantee the quality of real-time traffic. In this paper, we will propose a distributed bandwidth allocation/sharing/extension (DBASE) protocol to support multimedia traffics with the characteristics of variable bit rate (VBR) and constant bit rate (CBR) over ad hoc WLAN. Overall quality of service (QoS) will be guaranteed in DBASE. Such a bandwidth allocation procedure is based on a contention process that only occurs before the first successful access and a reservation process after the successful contention. If any real-time station leaves, the reserved bandwidth will be released by DBASE immediately. The designed DBASE protocol will not only allocate sufficient bandwidth for real-time stations but also permit them to extend bandwidth requirements on demand if there is any excess bandwidth left. Moreover, the proposed DBASE is still compliant with the IEEE 802.11 standard. In this paper, the system capacity of DBASE is analyzed and the performance of DBASE is evaluated by simulations. Simulations show that the DBASE is able to provide high channel utilization, low access delay and small delay variation for real-time services.},
keywords={IEEE standards;telecommunication networks;wireless LAN;land mobile radio;access protocols;multimedia communication;bandwidth allocation;data communication;quality of service;telecommunication traffic;distributed processing;delays;real-time systems;quality of service;QoS;multimedia;IEEE 802.11 ad hoc wireless LAN;carrier sense multiple access;asynchronous data traffic;medium access control;MAC protocol;real-time traffic;distributed bandwidth allocation/sharing/extension;DBASE protocol;variable bit rate;VBR;constant bit rate;CBR;ad hoc WLAN;contention process;reservation process;real-time station;IEEE 802.11 standard;system capacity;simulations;high channel utilization;low access delay;delay variation;real-time services;Channel allocation;Bandwidth;Communication system traffic control;Multiaccess communication;Access protocols;Bit rate;Quality of service;Delay;Ad hoc networks;Media Access Protocol},
doi={10.1109/INFCOM.2001.916652},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916653,
author={T. Hara},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Effective replica allocation in ad hoc networks for improving data accessibility},
year={2001},
volume={3},
number={},
pages={1568-1576 vol.3},
abstract={The advances in computer and wireless communication technologies have led to an increasing interest in ad hoc networks which are temporarily constructed by only mobile hosts. In ad hoc networks, since mobile hosts move freely, disconnections occur frequently, and this causes frequent network division. Consequently, data accessibility in ad hoc networks is lower than that in the conventional fixed networks. We propose three replica allocation methods to improve data accessibility by replicating data items on mobile hosts. In these three methods, we take into account the access frequency from mobile hosts to each data item and the status of the network connection. We also show the results of simulation experiments regarding the performance evaluation of our proposed methods.},
keywords={land mobile radio;mobile computing;data communication;network topology;radio networks;effective replica allocation;ad hoc networks;data accessibility;wireless communication technology;computer communication technology;mobile hosts;network division;access frequency;network connection status;performance evaluation;mobile computing;network topology;relocation period;static access frequency;dynamic access frequency and neighborhood;dynamic connectivity based grouping;Intelligent networks;Ad hoc networks;Mobile computing;Computer networks;Communications technology;Portable computers;Wireless communication;Frequency;Computational modeling;Radio communication},
doi={10.1109/INFCOM.2001.916653},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916654,
author={T. Salonidis and P. Bhagwat and L. Tassiulas and R. LaMaire},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Distributed topology construction of Bluetooth personal area networks},
year={2001},
volume={3},
number={},
pages={1577-1586 vol.3},
abstract={Wireless ad hoc networks have been a growing area of research. While there has been considerable research on the topic of routing in such networks, the topic of topology creation has not received due attention. This is because almost all ad hoc networks to date have been built on top of a single channel, broadcast based wireless media, such as 802.11 or IR LANs. For such networks the distance relationship between the nodes implicitly (and uniquely) determines the topology of the ad hoc network. Bluetooth is a promising new wireless technology, which enables portable devices to form short-range wireless ad hoc networks and is based on a frequency hopping physical layer. This fact implies that hosts are not able to communicate unless they have previously discovered each other by synchronizing their frequency hopping patterns. Thus, even if all nodes are within direct communication range of each other, only those nodes which are synchronized with the transmitter can hear the transmission. To support any-to-any communication, nodes must be synchronized so that the pairs of nodes (which can communicate with each other) together form a connected graph. Using Bluetooth as an example, this paper first provides deeper insights into the issue to link establishment in frequency hopping wireless systems. It then introduces the Bluetooth topology construction protocol (BTCP), an asynchronous distributed protocol for constructing scatternets which starts with nodes that have no knowledge of their surroundings and terminates with the formation of a connected network satisfying all connectivity constraints posed by the Bluetooth technology. To the best of our knowledge, the work presented in this paper is the first attempt at building Bluetooth scatternets using distributed logic and is quite "practical" in the sense that it can be implemented using the communication primitives offered by the Bluetooth 1.0 specifications.},
keywords={personal communication networks;wireless LAN;distributed processing;network topology;frequency hop communication;packet radio networks;radio links;access protocols;Bluetooth personal area networks;distributed topology construction;wireless ad hoc networks;short-range wireless ad hoc networks;frequency hopping physical layer;frequency hopping patterns;connected graph;link establishment;frequency hopping wireless systems;Bluetooth topology construction protocol;asynchronous distributed protocol;scatternets;connected network;connectivity constraints;Bluetooth technology;distributed logic;communication primitives;Bluetooth 1.0 specifications;IEEE 802.11 LAN;IR LAN;packet forwarding;MAC protocol;Bluetooth;Network topology;Spread spectrum communication;Frequency synchronization;Mobile ad hoc networks;Ad hoc networks;Protocols;Personal area networks;Routing;Broadcasting},
doi={10.1109/INFCOM.2001.916654},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916655,
author={Lili Qiu and V. N. Padmanabhan and G. M. Voelker},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On the placement of Web server replicas},
year={2001},
volume={3},
number={},
pages={1587-1596 vol.3},
abstract={There has been an increasing deployment of content distribution networks (CDNs) that offer hosting services to Web content providers. CDNs deploy a set of servers distributed throughout the Internet and replicate provider content across these servers for better performance and availability than centralized provider servers. Existing work on CDNs has primarily focused on techniques for efficiently redirecting user requests to appropriate CDN servers to reduce request latency and balance load. However, little attention has been given to the development of placement strategies for Web server replicas to further improve CDN performance. We explore the problem of Web server replica placement in detail. We develop several placement algorithms that use workload information, such as client latency and request rates, to make informed placement decisions. We then evaluate the placement algorithms using both synthetic and real network topologies, as well as Web server traces, and show that the placement of Web replicas is crucial to CDN performance. We also address a number of practical issues when using these algorithms, such as their sensitivity to imperfect knowledge about client workload and network topology, the stability of the input data, and methods for obtaining the input.},
keywords={file servers;Internet;replica techniques;performance evaluation;network topology;stability;graph theory;placement algorithms;content distribution networks;Web content providers;hosting services;Internet;availability;request latency reduction;load balancing;workload information;Web server replica placement;client latency;request rates;real network topology;synthetic network topology;Web server traces;CDN performance;network topology;client workload;input data stability;World Wide Web;graph theory;Web server;Delay;Network servers;Network topology;Internet;Telecommunication traffic;Bandwidth;Cost function;Availability;Stability},
doi={10.1109/INFCOM.2001.916655},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916656,
author={M. Rabinovich and Hua Wang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={DHTTP: an efficient and cache-friendly transfer protocol for Web traffic},
year={2001},
volume={3},
number={},
pages={1597-1606 vol.3},
abstract={Today's Web interactions are frequently short, with an increasing number of responses carrying only control information and no data. While HTTP uses client-initiated TCP for all Web interactions, TCP is not always well-suited for short interactions. Furthermore, client-initiated TCP handicaps the deployment of interception caches in the network because of the possibility of disrupted connections when some client packets bypass the cache on their way to the server. We propose a new transfer protocol for Web traffic, called dual-transport HTTP (DHTTP), which splits the traffic between UDP and TCP channels. When choosing the TCP channel, it is the server who opens the connection back to the client. Among important aspects of DHTTP are adapting to bottleneck shifts between a server and the network and coping with the unreliable nature of UDP. The comparative performance study of DHTTP and HTTP using trace-driven simulation as well as testing real HTTP and DHTTP servers showed a significant performance advantage of DHTTP when the bottleneck is at the server and comparable performance when the bottleneck is in the network. By using server-initiated TCP, DHTTP also eliminates the possibility of disrupted TCP connections in the presence of interception caches thereby allowing unrestricted caching within backbones.},
keywords={transport protocols;hypermedia;telecommunication traffic;file servers;performance evaluation;cache storage;Internet;cache-friendly transfer protocol;efficient transfer protocol;Web traffic;DHTTP;control information;client-initiated TCP;Web interactions;short interactions;interception caches;disrupted connections;client packets;server;dual-transport HTTP;TCP channel;UDP channel;performance;trace-driven simulation;backbones;unrestricted caching;LAN;Internet;Protocols;Network servers;Web server;Pipeline processing;Telecommunication traffic;Modems;Delay;Throughput;Testing;Spine},
doi={10.1109/INFCOM.2001.916656},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916657,
author={G. P. Chandranmenon and G. Varghese},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Reducing Web latency using reference point caching},
year={2001},
volume={3},
number={},
pages={1607-1616 vol.3},
abstract={To reduce Web access latencies, we propose a new paradigm for caching at the reference point of a document. If a document X is referred to from a document Y, information is cached at Y to reduce the latency of client accesses to X. We focus on two specific instances of this paradigm: caching IP addresses to avoid DNS lookups at clients, and caching information about documents to avoid setting up new connections. Avoiding DNS lookup saves over 4 seconds 10-12% of the time and avoiding connection setup saves 240 ms on the average. These ideas enable new services such as search engines that return IP addresses to speed up search sessions, and caching at regional information servers that goes beyond the capabilities of today's proxy caching.},
keywords={file servers;Internet;delays;cache storage;transport protocols;search engines;Web latency reduction;reference point caching;paradigm;search engines;client accesses;IP address caching;regional information servers;proxy caching;Bandwidth;Modems;Character generation;Telecommunication traffic;Internet;Search engines;Access protocols;Delay effects;Network servers;Web server},
doi={10.1109/INFCOM.2001.916657},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916658,
author={Xiaoyun Zhu and Jie Yu and J. Doyle},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Heavy tails, generalized coding, and optimal Web layout},
year={2001},
volume={3},
number={},
pages={1617-1626 vol.3},
abstract={This paper considers Web layout design in the spirit of source coding for data compression and rate distortion theory, with the aim of minimizing the average size of files downloaded during Web browsing sessions. The novel aspect here is that the object of design is layout rather than codeword selection, and is subject to navigability constraints. This produces statistics for file transfers that are heavy tailed, completely unlike standard Shannon theory, and provides a natural and plausible explanation for the origin of observed power laws in Web traffic. We introduce a series of theoretical and simulation models for optimal Web layout design with varying levels of analytic tractability and realism with respect to modeling of structure, hyperlinks, and user behavior. All models produce power laws which are striking both for their consistency with each other and with observed data, and their robustness to modeling assumptions. These results suggest that heavy tails are a permanent and ubiquitous feature of Internet traffic, and not an artifice of current applications or user behavior. They also suggest new ways of thinking about protocol design that combines insights from information and control theory with traditional networking.},
keywords={information resources;Internet;telecommunication traffic;optimisation;statistical analysis;data compression;rate distortion theory;digital simulation;control theory;protocols;source coding;document image processing;file organisation;generalized coding;analytic tractability;heavy tails;source coding;data compression;rate distortion theory;average file size minimisation;Web browsing;navigability constraints;file transfer statistics;power laws;Web traffic;simulation models;optimal Web layout design;hyperlinks;user behavior;structure modeling;Internet traffic;protocol design;control theory;information theory;statistical analysis;self-similarity;Tail;Traffic control;Source coding;Data compression;Rate distortion theory;Statistics;Analytical models;Robustness;Internet;Communication system traffic control},
doi={10.1109/INFCOM.2001.916658},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916659,
author={Jangwon Lee and G. de Veciana},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Resource and topology discovery for IP multicast using a fan-out decrement mechanism},
year={2001},
volume={3},
number={},
pages={1627-1635 vol.3},
abstract={As the use of IP multicast sessions becomes widespread, the potential benefits derived from currently unavailable topological information on multicast distribution trees may become increasingly critical. We propose a framework for discovering the topology of shared multicast trees based on a novel fan-out decrement mechanism analogous to time-to-live (TTL) decrementing in IP. We propose an algorithm for topology discovery based on the matrix of path/fan-out distances among a set of E session members-the algorithm's computational complexity is O(|E|/sup 2/). We exhibit sufficient conditions for topology discovery based on a reduced distance matrix, and propose a practical protocol to acquire this information requiring the exchange of 2|E| multicast messages of size O(|E|). Finally, we show how the same approach permits nodes to discover the multicast distribution tree associated with members within their fan-out/TTL scoped neighborhoods. This permits one to reduce the computational costs while making the communication costs proportional to the size of neighborhoods.},
keywords={transport protocols;multicast communication;network topology;computational complexity;trees (mathematics);packet switching;topology discovery;resource discovery;IP multicast;fan-out decrement mechanism;topological information;multicast distribution trees;shared multicast trees;algorithm;path/fan-out distances matrix;computational complexity;sufficient conditions;reduced distance matrix;practical protocol;multicast message size;network nodes;multicast distribution tree;fan-out/TTL;computational costs reduction;communication costs;neighborhood size;time-to-live decrementing;multicast packet;Multicast protocols;Network topology;Multicast algorithms;Costs;Internet;Computational complexity;Sufficient conditions;Computational efficiency;Circuit topology;Application software},
doi={10.1109/INFCOM.2001.916659},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916660,
author={N. G. Duffield and J. Horowitz and F. Lo Prestis},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Adaptive multicast topology inference},
year={2001},
volume={3},
number={},
pages={1636-1645 vol.3},
abstract={The use of end-to-end multicast traffic measurements has been recently proposed as a means to infer network internal characteristics as packet link loss rate and delay. We propose an algorithm that infers the multicast tree topology based on these end-to-end measurements. It is different from previous approaches which make only partial use of the available information, this algorithm adaptively combines different performance measures to reconstruct the topology. We establish its consistency and evaluate its accuracy through simulation. We show that in general it requires many fewer probes to correctly identify the topology than other methods.},
keywords={adaptive systems;multicast communication;network topology;telecommunication traffic;delays;packet switching;telecommunication links;trees (mathematics);telecommunication networks;statistical analysis;adaptive multicast topology inference;end-to-end multicast traffic measurements;network internal characteristics;packet link loss rate;packet delay;algorithm;multicast tree topology;performance measures;topology reconstruction;simulation;accuracy;network topology;statistical properties;Multicast algorithms;Network topology;Delay estimation;Multicast protocols;Telecommunication traffic;Current measurement;Statistics;Computer science;Loss measurement;Probes},
doi={10.1109/INFCOM.2001.916660},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916661,
author={Y. Shavitt and Xiaodong Sun and A. Wool and B. Yener},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Computing the unmeasured: an algebraic approach to Internet mapping},
year={2001},
volume={3},
number={},
pages={1646-1654 vol.3},
abstract={Distance estimation is important to many Internet applications, most notably for a WWW client that needs to select a server among several potential candidates. Current approaches to distance (i.e., time delay) estimation in the Internet are based on placing Tracer stations in key locations and conducting measurements between them. The Tracers construct an approximated map of the Internet after processing the information obtained from these measurements. This work presents a novel algorithm, based on algebraic tools, that computes additional distances, which are not explicitly measured. As such, the algorithm extracts more information from the same amount of measurement data. Our algorithm has several practical imparts. First, it can reduce the number of Tracers and measurements without sacrificing information. Second, our algorithm is able to compute distance estimates between locations where Tracers cannot be placed. This is especially important when unidirectional measurements are conducted, since such measurements require specialized equipment which cannot be placed everywhere. To evaluate the algorithm's performance, we tested it both on randomly generated topologies and on real Internet measurements. Our results show that the algorithm computes up to 50-200% additional distances beyond the basic Tracer-to-Tracer measurements.},
keywords={Internet;distance measurement;delay estimation;performance evaluation;computational complexity;network topology;algebra;algebraic approach;Internet mapping;distance estimation;Internet applications;WWW;server;time delay estimation;Tracer stations;approximated map;algebraic tools;measurement data;algorithm;unidirectional measurements;performance;randomly generated topologies;Internet measurements;Tracer-to-Tracer measurements;computational complexity;Internet;World Wide Web;Web server;Delay effects;Delay estimation;Current measurement;Time measurement;Data mining;Testing;Topology},
doi={10.1109/INFCOM.2001.916661},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916662,
author={L. Doherty and K. S. J. pister and L. El Ghaoui},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Convex position estimation in wireless sensor networks},
year={2001},
volume={3},
number={},
pages={1655-1663 vol.3},
abstract={A method for estimating unknown node positions in a sensor network based exclusively on connectivity-induced constraints is described. Known peer-to-peer communication in the network is modeled as a set of geometric constraints on the node positions. The global solution of a feasibility problem for these constraints yields estimates for the unknown positions of the nodes in the network. Providing that the constraints are tight enough, simulation illustrates that this estimate becomes close to the actual node positions. Additionally, a method for placing rectangular bounds around the possible positions for all unknown nodes in the network is given. The area of the bounding rectangles decreases as additional or tighter constraints are included in the problem. Specific models are suggested and simulated for isotropic and directional communication, representative of broadcast-based and optical transmission respectively, though the methods presented are not limited to these simple cases.},
keywords={radio networks;optical communication;optical links;graph theory;parameter estimation;sensors;broadcasting;wireless sensor networks;convex position estimation;node position estimation;connectivity-induced constraints;peer-to-peer communication;geometric constraints;global solution;feasibility problem;simulation;rectangular bounds;bounding rectangle area;isotropic communication;directional communication;broadcast-based transmission;optical transmission;Smart Dust project;graph;Intelligent networks;Wireless sensor networks;Linear matrix inequalities;Radio frequency;Sensor systems;Energy consumption;Global Positioning System;Solids;Electrical capacitance tomography;Ad hoc networks},
doi={10.1109/INFCOM.2001.916662},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916663,
author={M. Ajmone Marsan and A. Bianco and P. Giaccone and E. Leonardi and F. Neri},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On the throughput of input-queued cell-based switches with multicast traffic},
year={2001},
volume={3},
number={},
pages={1664-1672 vol.3},
abstract={In this paper we discuss the throughput achievable in input-queued cell-based switches loaded with multicast traffic. The switch architecture is assumed to comprise a synchronous broadcast switching fabric, where fixed-size data units, called cells, can be transferred in one slot from one Input to any set of outputs. The switch scheduler must select the time slots for transfers of non-conflicting cells, i.e., cells neither coming from the same input nor directed to the same output. Contrary to the case of unicast traffic, for which input-queued switches were proved to yield the same throughput as output queued switches, we show by simulation experiments and analytical modeling that throughput limitations exist in input-queued switches loaded with multicast traffic.},
keywords={packet switching;telecommunication traffic;multicast communication;queueing theory;telecommunication network routing;throughput;input-queued cell-based switches;multicast traffic;switch architecture;synchronous broadcast switching fabric;fixed-size data units;switch scheduler;time slots;nonconflicting cells transfer;simulation experiments;analytical modeling;IP routers;packet switch;Throughput;Switches;Traffic control;Telecommunication traffic;IP networks;Fabrics;Communication switching;Multicast protocols;Unicast;Analytical models},
doi={10.1109/INFCOM.2001.916663},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916664,
author={M. Andrews and L. Zhang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Achieving stability in networks of input-queued switches},
year={2001},
volume={3},
number={},
pages={1673-1679 vol.3},
abstract={Recent research has generated many interesting results on scheduling input-queued switches. However, most of this work focuses on a single switch in isolation. In this paper we study the problem of scheduling a network of input-queued switches. We consider the longest-queue-first and longest-port-first protocols that are stable for a single switch and show that they can be unstable even for a fixed traffic pattern in a simple network of eight input-queued switches. Moreover, this result holds regardless of how the traffic sharing the same port-pair is scheduled at each switch. On the positive side we present a protocol, longest-in-network, that is stable in networks of input-queued switches. This result holds even if the traffic pattern is allowed to change over time.},
keywords={packet switching;scheduling;protocols;telecommunication traffic;queueing theory;input-queued switches;stability;network scheduling;fixed traffic pattern;longest-queue-first protocol;longest-port-first protocol;longest-in-network protocol;Stability;Intelligent networks;Switches;Protocols;Packet switching;Telecommunication traffic;Traffic control;Scheduling algorithm},
doi={10.1109/INFCOM.2001.916664},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916665,
author={S. Iyer and N. McKeown},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Making parallel packet switches practical},
year={2001},
volume={3},
number={},
pages={1680-1687 vol.3},
abstract={A parallel packet switch (PPS) is a switch in which the memories run slower than the line rate. Arriving packets are spread (or load-balanced) packet-by-packet over multiple slower-speed packet switches. It is already known that with a speedup of S/spl ges/2, a PPS can theoretically mimic a FCFS output-queued (OQ) switch. However, the theory relies on a centralized packet scheduling algorithm that is essentially impractical because of high communication complexity. In this paper, we attempt to make a high performance PPS practical by introducing two results. First, we show that small co-ordination buffers can eliminate the need for a centralized packet scheduling algorithm, allowing a full distributed implementation with low computational and communication complexity. Second, we show that without speedup, the resulting PPS can mimic an FCFS OQ switch within a delay bound.},
keywords={packet switching;queueing theory;communication complexity;computational complexity;parallel architectures;parallel packet switches;arriving packets;multiple slower-speed packet switches;FCFS output-queued switch;centralized packet scheduling algorithm;communication complexity;co-ordination buffers;distributed implementation;delay bound;computational complexity;load balancing;Packet switching;Switches;Communication switching;Random access memory;Scheduling algorithm;Bandwidth;Complexity theory;Information retrieval;Concurrent computing;Laboratories},
doi={10.1109/INFCOM.2001.916665},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916666,
author={Yihan Li and S. Panwar and H. J. Chao},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On the performance of a dual round-robin switch},
year={2001},
volume={3},
number={},
pages={1688-1697 vol.3},
abstract={The dual round-robin matching (DRRM) switch has a scalable, low complexity architecture which allows for an aggregate bandwidth exceeding 1 Tb/s using current CMOS technology. In this paper we prove that the DRRM switch can achieve 100% throughput under i.i.d. and uniform traffic. The DRRM is the first practical matching scheme for which this property has been proved. The performance of the DRRM switch is then studied and compared with the iSLIP switch. The delay performance under uniform traffic and the hot-spot throughput of DRRM is better than that of iSLIP, while the throughput of iSLIP under some nonuniform traffic scenarios is slightly higher than that of DRRM. Since throughput drops below 100%, under nonuniform traffic, we also examine some variations of the DRRM matching scheme for nonuniform traffic.},
keywords={packet switching;telecommunication traffic;queueing theory;scheduling;dual round-robin switch;dual round-robin matching switch;DRRM matching scheme;scalable architecture;low complexity architecture;aggregate bandwidth;CMOS technology;DRRM switch;throughput performance;uniform traffic;i.i.d. traffic;iSLIP switch;delay performance;hot-spot throughput;nonuniform traffic;virtual output queueing switch;Switches;Throughput;Traffic control;Chaos;Iterative algorithms;CMOS technology;Delay;Fabrics;Telecommunication switching;Aggregates},
doi={10.1109/INFCOM.2001.916666},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916667,
author={H. -. Schwefel},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Behavior of TCP-like elastic traffic at a buffered bottleneck router},
year={2001},
volume={3},
number={},
pages={1698-1705 vol.3},
abstract={A major challenge in traffic modeling and performance analysis for the transmission control protocol (TCP) stems from the fact that the incoming traffic is not independent of the congestion level in the network. This paper investigates a queueing model where the traffic essentially shows ON/OFF characteristics, i.e. the number of active TCP connections of finite (probabilistic) duration varies as described by a stochastic process. The essential behavior of TCP-like flow-control mechanisms is captured in the analytic model by the feature that the packet-rate of active connections can be throttled in order to avoid that the overall packet-stream exceeds the output-bandwidth of the bottleneck router. By appropriate adjustment of the connection duration, the number of packets in the connections remains unaffected. However, since TCP reacts to existing congestion, the throttling mechanism is only activated when the buffer-occupancy at the bottleneck router exceeds a certain threshold. The impact of such a flow-control mechanism on the characteristics of the incoming traffic as well as on the performance behavior at the bottleneck router is discussed and illustrated by numerical results of the analytic model. In particular, the use of (truncated) power-tail distributions for the ON periods leads to conclusions about the behavior of long-range dependent traffic under the influence of TCP's flow-control mechanism.},
keywords={transport protocols;telecommunication congestion control;telecommunication traffic;telecommunication network routing;stochastic processes;Markov processes;queueing theory;TCP-like elastic traffic;buffered bottleneck router;traffic modeling;performance analysis;transmission control protocol;queueing model;ON/OFF characteristics;stochastic process;flow-control mechanisms;congestion level;analytic model;packet-rate;active connections;connection duration;throttling mechanism;buffer-occupancy;numerical results;power-tail distributions;long-range dependence;Markov modulated Poisson processes;Traffic control;Communication system traffic control;Telecommunication traffic;Performance analysis;Protocols;Throughput;Stochastic processes;Capacity planning;Performance loss;Computer networks},
doi={10.1109/INFCOM.2001.916667},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916668,
author={M. Garetto and R. Lo Cigno and M. Meo and M. Ajmone Marsan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A detailed and accurate closed queueing network model of many interacting TCP flows},
year={2001},
volume={3},
number={},
pages={1706-1715 vol.3},
abstract={This paper presents a new analytical model for the estimation of the performance of TCP connections. The model is based on the description of the behavior of TCP-Tahoe in terms of a closed queueing network, whose solution can be obtained with very low cost, even when the number of TCP connections that interact over the underlying IP network is huge. The protocol model can be very accurate, deriving directly from the finite state machine description of the protocol. The assessment of the accuracy of the analytical model is based on comparisons against detailed simulation experiments developed with the ns-2 package. Numerical results indicate that the proposed closed queueing network model provides extremely accurate performance estimates, not only for average values, but even for distributions, in the case of the classical single-bottleneck configuration, as well as in more complex networking setups.},
keywords={transport protocols;Internet;packet switching;queueing theory;network topology;digital simulation;interacting TCP flows;accurate closed queueing network model;analytical model;performance estimation;TCP-Tahoe;protocol model;finite state machine;simulation experiments;ns-2 package;distributions;single-bottleneck configuration;Internet transport layer protocol;packet networks;network topology;Analytical models;TCPIP;Protocols;IP networks;Delay estimation;Resource management;Costs;Automata;Packaging machines;Queueing analysis},
doi={10.1109/INFCOM.2001.916668},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916669,
author={Y. R. Yang and Nin Sik Kim and S. S. Lam},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Transient behaviors of TCP-friendly congestion control protocols},
year={2001},
volume={3},
number={},
pages={1716-1725 vol.3},
abstract={We investigate the fairness, smoothness, responsiveness, and aggressiveness of TCP and three representative TCP-friendly congestion control protocols: GAIMD, TFRC, and TEAR. The properties are evaluated both analytically and via simulation by studying protocol responses to three network environment changes. The first environment change is the inherent fluctuations in a stationary network environment. Under this scenario, we consider three types of sending rate variations: smoothness, short-term fairness, and long-term fairness. For a stationary environment, we observe that smoothness and fairness are positively correlated. We derive an analytical expression for the sending rate coefficient of variation for each of the four protocols. These analytical results match well with experimental results. The other two environment changes we study are a step increase of network congestion and a step increase of available bandwidth. Protocol responses to these changes reflect their responsiveness and aggressiveness, respectively.},
keywords={Internet;transport protocols;telecommunication congestion control;correlation methods;transients;TCP-friendly congestion control protocols;transient behavior;smoothness;responsiveness;aggressiveness;GAIMD;TFRC;TEAR;simulation;protocol response;network environment changes;stationary network environment;Internet;short-term fairness;long-term fairness;correlation;sending rate coefficient of variation;network congestion;available bandwidth;Protocols;Delay;Bandwidth;Control systems;IP networks;Streaming media;Analytical models;Fluctuations;Unicast;Internet},
doi={10.1109/INFCOM.2001.916669},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916670,
author={C. V. Hollot and V. Misra and D. Towsley and Wei-Bo Gong},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On designing improved controllers for AQM routers supporting TCP flows},
year={2001},
volume={3},
number={},
pages={1726-1734 vol.3},
abstract={In this paper we study a previously developed linearized model of TCP and active queue management (AQM). We use classical control system techniques to develop controllers well suited for the application. The controllers are shown to have better theoretical properties than the well known RED controller. We present guidelines for designing stable controllers subject to network parameters like load level propagation delay etc. We also present simple implementation techniques which require a minimal change to RED implementations. The performance of the controllers are verified and compared with RED using ns simulations. The second of our designs, the proportional integral (PI) controller is shown to outperform RED significantly.},
keywords={queueing theory;controllers;telecommunication control;telecommunication network management;transport protocols;telecommunication network routing;improved controllers;AQM routers;TCP flows;linearized model;classical control system techniques;stable controller;load level propagation delay;implementation techniques;proportional integral controller;PI controller;active queue management;Control systems;Guidelines;Pi control;Proportional control;Stability;Steady-state;Optimal control;Propagation delay;Performance analysis;Analytical models},
doi={10.1109/INFCOM.2001.916670},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916671,
author={C. R. Lin},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On-demand QoS routing in multihop mobile networks},
year={2001},
volume={3},
number={},
pages={1735-1744 vol.3},
abstract={The emergence of nomadic applications have generated a lot of interest in next generation wireless network infrastructures which provide differentiated service classes. So it is important to study how the quality of service (QoS) should be guaranteed. To accomplish this, we develop an admission control scheme which can guarantee bandwidth for real-time applications in multihop mobile networks. In our scheme, a host need not discover and maintain any information of the network resources status on the routes to another host until a connection request is generated for the communication between the two hosts, unless the former host is offering its services as an intermediate forwarding station to maintain connectivity between two other hosts. This bandwidth guarantee feature is important for a mobile network to interconnect wired networks with QoS support. Our connection admission control scheme can also work in a standalone mobile ad hoc network for real-time applications. This control scheme contains end-to-end bandwidth calculation and bandwidth allocation. Under such a scheme, the source is informed of the bandwidth and QoS available to any destination in the mobile network. This knowledge enables the establishment of QoS connections within the mobile network and the efficient support of real time applications. In the case of an ATM interconnection, the bandwidth information can be used to carry out intelligent handoff between ATM gateways and/or to extend the ATM virtual circuit service to the mobile network with possible renegotiation of QoS parameters at the gateway. We examine via simulation the system performance in various QoS traffic flows and mobility environments. The "on-demand" feature enhances the performance in the mobile environment because the source can keep more connectivity with enough bandwidth to a receiver in the path-finding duration.},
keywords={quality of service;telecommunication network routing;asynchronous transfer mode;packet radio networks;cellular radio;telecommunication congestion control;bandwidth allocation;on-demand QoS routing;multihop mobile networks;nomadic applications;next generation wireless network infrastructures;differentiated service classes;quality of service;packet loss;admission control scheme;real-time applications;bandwidth guarantee feature;connection admission control scheme;standalone mobile ad hoc network;end-to-end bandwidth calculation;bandwidth allocation;intelligent handoff;ATM gateways;ATM virtual circuit service;traffic flows;performance;protocol;on-demand feature;Routing;Spread spectrum communication;Quality of service;Bandwidth;Admission control;Integrated circuit interconnections;Next generation networking;Wireless networks;Mobile communication;Mobile ad hoc networks},
doi={10.1109/INFCOM.2001.916671},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916672,
author={Shengming Jiang and Dajiang He and Jianqiang Rao},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A prediction-based link availability estimation for mobile ad hoc networks},
year={2001},
volume={3},
number={},
pages={1745-1752 vol.3},
abstract={One critical issue for routing in mobile ad hoc networks (MANET) is how to select a reliable path that can last longer since mobility may cause radio links to break frequently. To answer this question, a criterion that can judge path reliability is needed. The reliability of a path depends on the availability of the links constituting the path. However, how to measure link availability to answer the above question has not been addressed adequately in the literature. In this paper, a prediction-based link availability estimation is introduced and verified through computer simulations. This estimation algorithm can be used to develop a metric for path selection in terms of path reliability, which can improve the network performance as shown by simulation results.},
keywords={telecommunication network routing;telecommunication network reliability;land mobile radio;estimation theory;prediction-based link availability estimation;mobile ad hoc networks;routing;MANET;reliable path;radio links;link availability;estimation algorithm;path selection;network performance;Mobile ad hoc networks;Routing;Availability;Stability;Computer network reliability;Quality of service;Time measurement;Radio link;Current measurement;Helium},
doi={10.1109/INFCOM.2001.916672},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916673,
author={R. V. Boppana and S. P. Konduru},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={An adaptive distance vector routing algorithm for mobile, ad hoc networks},
year={2001},
volume={3},
number={},
pages={1753-1762 vol.3},
abstract={We present a new routing algorithm called adaptive distance vector (ADV) for mobile, ad hoc networks (MANETs). ADV is a distance vector routing algorithm that exhibits some on-demand characteristics by varying the frequency and the size of the routing updates in response to the network load and mobility conditions. Using simulations we show that ADV outperforms AODV and DSR especially in high mobility cases by giving significantly higher (50% or more) peak throughputs and lower packet delays. Furthermore, ADV uses fewer routing and control overhead packets than that of AODV and DSR, especially at moderate to high loads. Our results indicate the benefits of combining both proactive and on-demand routing techniques in designing suitable routing protocols for MANETs.},
keywords={land mobile radio;radio networks;telecommunication network routing;packet radio networks;protocols;adaptive distance vector routing algorithm;mobile ad hoc networks;MANET;on-demand characteristics;routing updates frequency;routing updates size;network load;network mobility conditions;simulations;peak throughputs;packet delays;control overhead packets;routing overhead packets;proactive routing;on-demand routing;routing protocols design;Ad hoc networks;Routing protocols;Frequency;Throughput;Delay;Mobile ad hoc networks;Algorithm design and analysis;Computer science;Portable computers;Wireless communication},
doi={10.1109/INFCOM.2001.916673},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916674,
author={P. Sinha and R. Sivakumar and V. Bharghavan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Enhancing ad hoc routing with dynamic virtual infrastructures},
year={2001},
volume={3},
number={},
pages={1763-1772 vol.3},
abstract={Several routing algorithms for mobile ad hoc networks (MANETs) have been proposed previously. With the exception of a few, these protocols (i) involve all nodes in the route management process, (ii) rely on the use of broadcast relays for route computation, and (iii) are primarily reactive in nature. Related work has shown that the capacity utilization in ad hoc networks decreases significantly when broadcast relays or "broadcast storms" are performed frequently. This effect is compounded when all nodes in the network take part in the route computation. We propose and study an approach based on overlaying a virtual infrastructure adaptation of the core, proposed by Sivakumar, Sinha and Bharghavan (see IEEE Journal on Selected Areas in Communications, vol.17, no.8, p.1454-65, 1999) on an ad hoc network and operating routing protocols over the infrastructure. The core enables routing protocols to use only a subset of nodes in the network for route management and avoid the use of broadcast relays. Using the ns-2 simulator we evaluate the performance of two ad hoc routing protocols, dynamic source routing (DSR) and ad hoc on demand distance vector (AODV), when they are operated over the core and compare their performance against those of their basic versions.},
keywords={telecommunication network routing;land mobile radio;protocols;radio broadcasting;digital simulation;ad hoc routing;dynamic virtual infrastructures;routing algorithms;mobile ad hoc networks;MANET;route management;network nodes;broadcast relays;route computation;capacity utilization;broadcast storms;routing protocols;ns-2 simulator;performance evaluation;DSR;AODV;dynamic source routing;ad hoc on demand distance vector;Broadcasting;Routing protocols;Ad hoc networks;Relays;Wireless networks;Network topology;Mobile ad hoc networks;Computer networks;Computer network management;Spread spectrum communication},
doi={10.1109/INFCOM.2001.916674},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916675,
author={I. Cidon and S. Kutten and R. Soffer},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Optimal allocation of electronic content},
year={2001},
volume={3},
number={},
pages={1773-1780 vol.3},
abstract={The delivery of large files to single users, such as application programs for some versions of the envisioned network computer, or movies, is expected by many to be one of the main requirements of communication networks. This requires expensive high bandwidth capacity as well as fast and high storage servers. This motivates multimedia providers to optimize the delivery distances, as well as the electronic content allocation. A hierarchical architecture for providing the multimedia content was introduced by Nussbaumer, Patel, Schaffa, and Sternbenz (1994). They also introduced the trade-off between bandwidth and storage requirements for the placement of the content servers on the hierarchy tree. They found the best level of the hierarchy for the server location to minimize the total of the costs of communication and storage. Their algorithm is centralized. We solve the more general ease where servers can be located at different levels of the hierarchy. Our algorithm is distributed, and each node requires a limited memory capacity and computational power. Results for related approaches to caching design are of higher complexity. Results for related classic operations research problems are for centralized algorithms, mostly linear programming, that are not easy to convert into distributed algorithms. Instead, we observe that the use of dynamic programming is more natural for distributed implementations. For the specific problem at hand, we also managed to find a natural function (a generalization of the problem) that simplifies the combination operation used in dynamic programming. We also show how to map such contemporary problems to the area of classical plant location problems in operations research.},
keywords={dynamic programming;computer networks;multimedia communication;network servers;cache storage;operations research;distributed algorithms;video servers;video on demand;optimal allocation;application programs;network computer;movies;communication networks;high bandwidth capacity;high storage servers;fast servers;multimedia providers;delivery distance optimization;electronic content allocation;hierarchical architecture;content servers;hierarchy tree;server location;centralized algorithm;distributed algorithm;network node;caching design;operations research;linear programming;dynamic programming;combination operation;plant location problems;VOD servers;Bandwidth;Operations research;Dynamic programming;Application software;Computer networks;Motion pictures;Communication networks;Network servers;Computer architecture;Costs},
doi={10.1109/INFCOM.2001.916675},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916676,
author={Mon-Yen Luo and Chu-Sing Yang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Constructing zero-loss Web services},
year={2001},
volume={3},
number={},
pages={1781-1790 vol.3},
abstract={Modern Web services must support large and rapidly growing user populations, and remain available 24 hours per day, 7 day per week. Server-cluster is the most promising approach to address this challenge. We further augment the server-cluster schemes with a novel mechanism that enables a Web request to be smoothly migrated and recovered on another working node in the presence of server failure or overload. The new mechanism provides a powerful solution to fault tolerance and dynamic load-distribution for Web services. The administrator can explicitly specify some services to be guaranteed for fault-tolerance or higher performance support. We present the details of our design, implementation, and performance data. The performance results show that the proposed mechanism is efficient and with low associated overhead.},
keywords={information resources;Internet;file servers;fault tolerant computing;computer network reliability;performance evaluation;zero-loss Web services;server-cluster schemes;server failure;server overload;fault tolerance;dynamic load-distribution;performance data;overhead;Web services},
doi={10.1109/INFCOM.2001.916676},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916677,
author={J. Kangasharju and F. Hartanto and M. Reisslein and K. W. Ross},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Distributing layered encoded video through caches},
year={2001},
volume={3},
number={},
pages={1791-1800 vol.3},
abstract={The efficient distribution of stored information has become a major concern in the Internet which has increasingly become a vehicle for the transport of stored video. Because of the highly heterogeneous access to the Internet, researchers and engineers have argued for layered encoded video. We investigate delivering layered encoded video using caches. Based on a stochastic knapsack model we develop a model for the layered video caching problem. We propose heuristics to determine which videos and which layers in the videos should be cached. We evaluate the performance of our heuristics through extensive numerical experiments. We also consider two intuitive extensions to the initial problem.},
keywords={visual communication;video coding;Internet;cache storage;knapsack problems;layered encoded video distribution;caches;stored information distribution;Internet;heterogeneous access;stochastic knapsack model;heuristics;performance evaluation;Internet;Video sharing;Network servers;Stochastic processes;Automotive engineering;Vehicles;Modems;Power cables;Bandwidth;Web server},
doi={10.1109/INFCOM.2001.916677},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916678,
author={A. Shaikh and R. Tewari and M. Agrawal},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On the effectiveness of DNS-based server selection},
year={2001},
volume={3},
number={},
pages={1801-1810 vol.3},
abstract={The rapid growth of the Internet in users and content has fueled extensive efforts to improve the user's overall Internet experience. A growing number of providers deliver content from multiple servers or proxies to reduce response time by moving content closer to end users. An increasingly popular mechanism to direct clients to the closest point of service is DNS-based redirection, due to its transparency and generality. This paper draws attention to two of the main issues in using DNS: (1) the negative effects of reducing or eliminating the cache lifetimes of DNS information, and (2) the implicit assumption that client nameservers are indicative of actual client location and performance. We quantify the impact of reducing DNS TTL values on Web access latency and show that it can increase name resolution latency by two orders of magnitude. Using HTTP and DNS server logs, as well as a large number of dial-up ISP clients, we measure client-nameserver proximity and show that a significant fraction are distant, more than 8 hops apart. Finally, we suggest protocol modifications to improve the accuracy of DNS-based redirection schemes.},
keywords={Internet;file servers;performance evaluation;naming services;transport protocols;DNS-based server selection;Internet;content providers;network servers;response time reduction;DNS-based redirection;cache lifetime reduction;DNS information;client nameservers;client location;performance;Web access latency;name resolution latency;HTTP;DNS server logs;dial-up ISP clients;client-nameserver proximity measurement;protocol modifications;domain name system;Web server;Web server;Network servers;Domain Name System;Application software;Transport protocols;Routing protocols;Web and internet services;Delay effects;USA Councils;Load management},
doi={10.1109/INFCOM.2001.916678},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916249,
author={O. Verscheure and P. Frossard and J. -. Le Boudec},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Joint smoothing and source rate selection for guaranteed service networks},
year={2001},
volume={2},
number={},
pages={613-620 vol.2},
abstract={We consider the transmission of variable bit rate (VBR) video over a network offering a guaranteed service such as ATM VBR or the guaranteed service of the IETF. The guaranteed service requires that the flow accepted by the network has to be conforming with a traffic envelope /spl sigma/. In this context, the output of the video encoder is constrained by the traffic envelope defined at the network entry point, the playback delay budget and the decoding buffer size. In previous works, the constraints are satisfied either by smoothing a fixed coder output, or by modifying the encoding parameters. In this paper we take a combined approach. This shows us to find a joint source rate selection/smoothing solution which minimizes the total average distortion while satisfying constraints on the traffic envelope, playback delay and decoding buffer size. Our solution is based on a Viterbi-like algorithm. Our approach is. Made possible by the representation of the optimally smoothed output as the time inverse of a shaper output. Experimental results exhibit significant improvements in terms of total average distortion compared to the smoothing of a fixed coder output, under equivalent traffic parameters and decoding constraints.},
keywords={video coding;visual communication;asynchronous transfer mode;telecommunication traffic;decoding;packet switching;delays;buffer storage;rate distortion theory;smoothing methods;total average distortion minimization;playback delay;guaranteed service networks;variable bit rate;VBR video transmission;ATM VBR;IETF;traffic envelope;video encoder output;playback delay budget;decoding buffer size;encoding parameters;joint source rate selection/smoothing;Viterbi-like algorithm;shaper output;traffic parameters;decoding constraints;video coding;rate control;rate distortion;Smoothing methods;Decoding;Telecommunication traffic;Delay;Bit rate;Streaming media;Encoding;Protocols;Quantization;Video coding},
doi={10.1109/INFCOM.2001.916249},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916250,
author={P. Halvorsen and T. Plagemann and V. Goebel},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Integrated error management for media-on-demand services},
year={2001},
volume={2},
number={},
pages={621-630 vol.2},
abstract={Data servers for multimedia applications like news-on-demand represent a severe bottleneck, because a potentially (very) high number of users concurrently retrieve data with high data rates. In the Intermediate Storage Node Concept (INSTANCE) project, we develop a new architecture for media-on-demand servers that maximizes the number of concurrent clients a single server can support. Traditional bottlenecks, like copy operations, multiple copies of the same data element in main memory, and checksum calculation in communication protocols are avoided by applying three orthogonal techniques: zero-copy-one-copy memory architecture, network level framing, and integrated error management. We describe the design, implementation, and evaluation of our integrated error management mechanism. Our results show that the reuse of parity information from a RAID system as forward error correction information in the transport protocol reduces the server workload and enables smooth playout at the client.},
keywords={video on demand;multimedia communication;forward error correction;memory architecture;multimedia servers;research initiatives;RAID;transport protocols;magnetic disc storage;integrated error management;media-on-demand services;data servers;multimedia applications;high data rates;data retrieval;Intermediate Storage Node Concept;INSTANCE project;media-on-demand servers;copy operations;checksum calculation;communication protocols;zero-copy-one-copy memory architecture;orthogonal techniques;network level framing;integrated error management mechanism;parity information reuse;forward error correction information;FEC information;transport protocol;server workload reduction;magnetic disk;error correction codes;Network servers;Information retrieval;Protocols;Web server;Electrical capacitance tomography;Informatics;Memory management;Memory architecture;Communication system operations and management;Forward error correction},
doi={10.1109/INFCOM.2001.916250},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916251,
author={D. Bansal and H. Balakrishnan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Binomial congestion control algorithms},
year={2001},
volume={2},
number={},
pages={631-640 vol.2},
abstract={This paper introduces and analyzes a class of nonlinear congestion control algorithms called binomial algorithms, motivated in part by the needs of streaming audio and video applications for which a drastic reduction in transmission rate upon each congestion indication (or loss) is problematic. Binomial algorithms generalize TCP-style additive-increase by increasing inversely proportional to a power k of the current window (for TCP, k=0); they generalize TCP-style multiplicative decrease by decreasing proportional to a power l of the current window (for TCP, l=1). We show that there are an infinite number of deployable TCP-compatible binomial algorithms, those which satisfy k+1=1, and that all binomial algorithms converge to fairness under a synchronized-feedback assumption provided k+l>0; k, l/spl ges/0. Our simulation results show that binomial algorithms interact well with TCP across a RED gateway. We focus on two particular algorithms, IIAD (k=1, l=0) and SQRT (k=l=0.5), showing that they are well-suited to applications that do not react well to large TCP-style window reductions.},
keywords={telecommunication congestion control;transport protocols;feedback;synchronisation;binomial congestion control algorithms;nonlinear congestion control algorithms;audio streaming application;video streaming application;transmission rate reduction;TCP-compatible binomial algorithms;algorithm convergence;fairness;synchronized-feedback;simulation results;RED gateway;Internet transport protocol;IIAD algorithm;SQRT algorithm;random early drop;Internet;Propagation losses;Streaming media;Transport protocols;Throughput;Algorithm design and analysis;Stability;Bandwidth;Delay;Laboratories},
doi={10.1109/INFCOM.2001.916251},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916252,
author={S. Mohamed and F. Cervantes-Perez and H. Afifi},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Integrating networks measurements and speech quality subjective scores for control purposes},
year={2001},
volume={2},
number={},
pages={641-649 vol.2},
abstract={Traditionally, QoS has been addressed by using network measurements (e.g., loss rates and delays), and little attention has been paid to the quality perceived by end-users of the applications running over the network. Here, we address the issue of integrating speech quality subjective scores and network parameters measurements, for designing control algorithms that would yield the best QoS that could be delivered under a given communications network situation. First, we build a neural network based automaton to measure speech quality in real time, at the style of a group of human subjects when participating in an MOS test. We consider the effects of changes in network parameters (e.g., packetization interval, packet loss rate and their pattern distribution) and encoding on speech signals transmitted over the network. Our database includes transmitted speech signals in different languages. Then, we outline a control mechanism which, based on the application performance within a session (i.e., MOS speech quality scores generated by the neural networks), dynamically adjusts parameters (codec and packetization interval). Finally, we analyze preliminary results to show two main benefits: first, a better use of bandwidth, and second, delivery of the best possible speech quality given the network current situation.},
keywords={telecommunication networks;speech coding;speech intelligibility;telecommunication control;quality of service;packet switching;delays;voice communication;feedforward neural nets;control algorithms design;speech quality subjective scores;QoS;delays;network parameters measurements;communications network;neural network based automaton;speech quality measurement;real-time measurement;MOS test;packetization interval;packet loss rate;speech coding;database;transmitted speech signals;languages;codec;bandwidth;three-layer feedforward neural network;TCP-friendly algorithm;Neural networks;Speech analysis;Loss measurement;Algorithm design and analysis;Automatic control;Communication system control;Communication networks;Automata;Particle measurements;Humans},
doi={10.1109/INFCOM.2001.916252},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916253,
author={P. Marbach},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Pricing differentiated services networks: bursty traffic},
year={2001},
volume={2},
number={},
pages={650-658 vol.2},
abstract={We study the role of pricing in differentiated services (Diff-Serv) networks. We model DiffServ as a priority service, where users are given the freedom to choose the priorities of their traffic, but are charged accordingly. Using a game theoretic framework, we study the case where users choose an allocation of priorities to packets in order to optimize their net benefit. For the case where users with bursty traffic access a single link, we show that there always exists an equilibrium for the corresponding noncooperative game. Furthermore we show that pricing can be used to provide relative QoS guarantees.},
keywords={Internet;telecommunication traffic;costing;tariffs;quality of service;game theory;differentiated services networks;bursty traffic;Diff-Serv networks;priority service;traffic priorities;game theory;equilibrium;noncooperative game;QoS guarantees;packet transmission;interactive Web traffic;Pricing;Diffserv networks;Telecommunication traffic;Traffic control;IP networks;Web and internet services;Delay;Costs;Game theory;Quality of service},
doi={10.1109/INFCOM.2001.916253},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916254,
author={Fang Hao and E. W. Zegura and M. H. Ammar},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Supporting server selection in differentiated service networks},
year={2001},
volume={2},
number={},
pages={659-668 vol.2},
abstract={As the Internet has grown in size and diversity of applications, two trends have emerged to provide good end-user perceived performance. First, servers are often replicated for better scalability of the service. Second, QoS approaches, such as the differentiated services framework, have been proposed as enhancement to the best-effort IP service. We are interested in the combination of these two trends; that is, replicated servers in QoS-based networks. We focus on the problem of selecting amongst replicated servers in the context of differentiated service networks. Our contributions are twofold. First, we design a QoS-based server-selection architecture. The architecture is scalable in the sense that server selection and resource reservation are done in an aggregated fashion and operate in the background, rather than being driven by individual client demand. At the same time, the architecture offers a fast response time to client requests for server selection. Second, we explore the design space implied by the architecture and evaluate various design options including signalling protocols, server selection/sorting algorithms and resource reservation granularity.},
keywords={Internet;transport protocols;telecommunication signalling;quality of service;performance evaluation;network servers;server selection;differentiated service networks;Internet;end-user perceived performance;replicated servers;service scalability;best-effort IP service;QoS-based server-selection architecture;QoS-based networks;scalable architecture;fast response time;design space;signalling protocols;server selection/sorting algorithms;resource reservation granularity;performance evaluation;Network servers;Diffserv networks;Web server;Space exploration;Signal design;Algorithm design and analysis;Internet;Scalability;Context-aware services;Delay},
doi={10.1109/INFCOM.2001.916254},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916255,
author={Shengquan Wang and Dong Xuan and Riccardo Bettati and Wei Zhao},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Providing absolute differentiated services for real-time applications in static-priority scheduling networks},
year={2001},
volume={2},
number={},
pages={669-678 vol.2},
abstract={We propose and analyze a methodology for providing absolute differentiated services for real-time applications in networks that use static-priority schedulers. We extend previous work on worst-case delay analysis and develop a method that can be used to derive delay bounds without specific information on flow population. With this new method, we are able to successfully employ a utilization-based admission control approach for flow admission. This approach does not require explicit delay computation at admission time and hence is scalable to large systems. We assume the underlying network to use static-priority schedulers. We design and analyze several priority assignment algorithms, and investigate their ability to achieve higher utilization bounds. Traditionally, schedulers in differentiated services networks assign priorities on a class-by-class basis, with the same priority for each class on each router. We show that relaxing this requirement, that is, allowing different routers to assign different priorities to classes, achieves significantly higher utilization bounds.},
keywords={Internet;telecommunication congestion control;delays;telecommunication network routing;quality of service;telecommunication traffic;performance evaluation;absolute differentiated services;real-time applications;static-priority scheduling networks;worst-case delay analysis;delay bounds;utilization-based admission control;flow admission;static-priority schedulers;priority assignment algorithms;utilization bounds;differentiated services networks;router;Internet;heuristic algorithms;QoS architecture;performance evaluation;traffic model;Admission control;Job shop scheduling;Diffserv networks;Delay effects;Processor scheduling;Algorithm design and analysis;Bandwidth;Application software;System testing;Intelligent networks},
doi={10.1109/INFCOM.2001.916255},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916256,
author={Huican Zhu and Hong Tang and Tao Yang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Demand-driven service differentiation in cluster-based network servers},
year={2001},
volume={2},
number={},
pages={679-688 vol.2},
abstract={Service differentiation that provides prioritized service qualities to multiple classes of client requests can effectively utilize available server resources. This paper studies how demand-driven service differentiation in terms of end-user performance can be supported in cluster-based network servers. Our objective is to deliver better services to high priority request classes without over-sacrificing low priority classes. To achieve this objective, we propose a dynamic scheduling scheme, called DDSD that adapts to fluctuating request resource demands by periodically repartitioning servers. This scheme also employs priority-based admission control to drop excessive user requests and achieve soft performance guarantees. For each scheduling period, our scheme monitors the system status and uses a queuing model to approximate server behaviors and guide resource allocation. Our experiments show that the proposed technique achieves demand-driven service differentiation while maximizing resource utilization and that it can substantially outperform static server partitioning.},
keywords={Internet;network servers;quality of service;resource allocation;performance evaluation;telecommunication congestion control;demand-driven service differentiation;cluster-based network servers;prioritized service quality;server resources;end-user performance;high priority request classes;low priority classes;dynamic scheduling;DDSD;periodic server repartitioning;priority-based admission control;soft performance guarantees;scheduling period;system status monitoring;queuing model;server behavior;resource allocation;resource utilization;static server partitioning;Web site;Internet;Web server;Intelligent networks;Network servers;Resource management;Bandwidth;Admission control;Web server;Computer science;Dynamic scheduling;Computer network management;Quality management},
doi={10.1109/INFCOM.2001.916256},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916257,
author={L. Georgiadis and P. Georgatsos and K. Floros and S. Sartzetakis},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Lexicographically optimal balanced networks},
year={2001},
volume={2},
number={},
pages={689-698 vol.2},
abstract={We consider the problem of allocating bandwidth between two endpoints of a backbone network so that no parts of the network are unnecessarily loaded. We formulate the problem as lexicographic optimization, and develop algorithms for its solution. The solution consists of (a) identifying a cut in the network where the optimal load can be determined on all the links of the cut, and (b) considering the same problem in each of the subnetworks to which the cut is dividing the original network.},
keywords={telecommunication networks;optimisation;bandwidth allocation;computational complexity;lexicographically optimal balanced networks;bandwidth allocation;backbone network;algorithms;network cut identification;optimal load;subnetworks;computationally efficient algorithm;Bandwidth;Spine;Channel allocation;Admission control;Cost function;Electronic mail;Virtual private networks;Context;Capacity planning;Routing},
doi={10.1109/INFCOM.2001.916257},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916258,
author={Yu Liu and D. Tipper and P. Siripongwutikorn},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Approximating optimal spare capacity allocation by successive survivable routing},
year={2001},
volume={2},
number={},
pages={699-708 vol.2},
abstract={Spare capacity allocation (SCA) is an important part of a fault tolerant network design. In the spare capacity allocation problem one seeks to determine where to place spare capacity in the network and how much spare capacity must be allocated to guarantee seamless communications services survivable to a set of failure scenarios (e.g., any single link failure). Formulated as a multi-commodity flow integer programming problem, SCA is known to be NP-hard. We provide a two-pronged attack to approximate the optimal SCA solution: unravel the SCA structure and find an effective algorithm. First, a literature review on the SCA problem and its algorithms is provided. Second, a integer programming model for SCA is provided. Third, a simulated annealing algorithm using the above INP model is introduced. Next, the structure of SCA is modeled by a matrix method. The per-flow based backup path information are aggregated into a square matrix, called the spare provision matrix (SPM). The size of the SPM is the number of links. Using the SPM as the state information, a new adaptive algorithm is then developed to approximate the optimal SCA solution termed successive survivable routing (SSR). SSR routes link-disjoint backup paths for each traffic flow one at a time. Each flow keeps updating its backup path according to the current network state as long as the backup path is not carrying any traffic. In this way, SSR can be implemented by shortest path algorithms using advertised state information with complexity of O( Link/sup 2/). The analysis also shows that SSR is using a necessary condition of the optimal solution. The numerical results show that SSR has near optimal spare capacity allocation with substantial advantages in computation speed.},
keywords={telecommunication network reliability;telecommunication network routing;simulated annealing;computational complexity;integer programming;telecommunication traffic;approximation theory;channel capacity;network topology;matrix algebra;optimal spare capacity allocation;successive survivable routing;fault tolerant network design;seamless communications services;single link failure;multi-commodity flow integer programming;NP-hard problem;optimal SCA solution approximation;algorithms;integer programming model;simulated annealing algorithm;INP model;matrix method;per-flow based backup path information;square matrix;spare provision matrix;state information;adaptive algorithm;link-disjoint backup paths;traffic flow;network state;shortest path algorithms;complexity;necessary condition;optimal solution;computation speed;network topology;Routing;Linear programming;Scanning probe microscopy;Bandwidth;Telecommunication traffic;Fault tolerance;Simulated annealing;Indium phosphide;Approximation algorithms;Circuits},
doi={10.1109/INFCOM.2001.916258},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916259,
author={G. Fayolle and A. de La Fortelle and J. Lasgouttes and L. Massoulie and J. Roberts},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Best-effort networks: modeling and performance analysis via large networks asymptotics},
year={2001},
volume={2},
number={},
pages={709-716 vol.2},
abstract={We introduce a class of Markov models, termed best-effort networks, designed to capture performance indices such as mean transfer times in data networks with best-effort service. We introduce the so-called min bandwidth sharing policy as a conservative approximation to the classical max-min policy. We establish necessary and sufficient ergodicity conditions for best-effort networks under the min policy. We then resort to the mean field technique of statistical physics to analyze network performance deriving fixed point equations for the stationary distribution of large symmetrical best-effort networks. A specific instance of such networks is the star-shaped network which constitutes a plausible model of a network with an overprovisioned backbone. Numerical and analytical study of the equations allows us to state a number of qualitative conclusions on the impact of traffic parameters (link loads) and topology parameters (route lengths) on mean document transfer time.},
keywords={telecommunication traffic;telecommunication network routing;Markov processes;statistical analysis;minimisation;data communication;network topology;bandwidth allocation;best-effort networks;network modeling;large networks asymptotics;Markov models;performance indices;data networks;best-effort service;min bandwidth sharing policy;conservative approximation;max-min policy;sufficient ergodicity condition;necessary ergodicity condition;mean field technique;statistical physics;network performance analysis;fixed point equations;stationary distribution;star-shaped network;overprovisioned backbone;traffic parameters;link loads;topology parameters;route lengths;mean document transfer time;bandwidth allocation;Performance analysis;Traffic control;Bandwidth;Internet;Equations;Channel allocation;Research and development;Delay;Physics;Spine},
doi={10.1109/INFCOM.2001.916259},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916260,
author={J. Ros and W. K. Tsai},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A theory of convergence order of maxmin rate allocation and an optimal protocol},
year={2001},
volume={2},
number={},
pages={717-726 vol.2},
abstract={The problem of allocating maxmin rates with minimum rate constraints for connection-oriented networks is considered. This paper proves that the convergence of maxmin rate allocation satisfies a partial ordering in the bottleneck links. This partial ordering leads to a tighter lower bound for the convergence time for any maxmin protocol. An optimally fast maxmin rate allocation protocol called the distributed constraint precedence graph (CPG) protocol is designed based on this ordering theory. The new protocol employs bi-directional minimization and does not induce transient oscillations. The distributed CPG protocol is compared against ERICA, showing far superior performance.},
keywords={minimax techniques;convergence of numerical methods;protocols;telecommunication links;graph theory;quality of service;telecommunication traffic;distributed algorithms;convergence order;optimal protocol;minimum rate constraints;connection-oriented networks;partial ordering;bottleneck links;lower bound;convergence time;maxmin protocol;optimally fast maxmin rate allocation protocol;distributed CPG protocol;bi-directional minimization;ERICA;performance;ATM networks;best-effort traffic;QoS;distributed algorithm;Convergence;Protocols;Switches;Feedback;Asynchronous transfer mode;Virtual colonoscopy;Bidirectional control;Scalability;Constraint optimization;Delay},
doi={10.1109/INFCOM.2001.916260},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916261,
author={J. L. Sobrinho},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Algebra and algorithms for QoS path computation and hop-by-hop routing in the Internet},
year={2001},
volume={2},
number={},
pages={727-735 vol.2},
abstract={Prompted by the advent of QoS routing in the Internet, we investigate the properties that path weight functions must have so that hop-by-hop routing is possible and optimal paths can be computed with a generalized Dijsktra's (1959) algorithm. For this purpose we define an algebra of weights which contains a binary operation, for the composition of link weights into path weights, and an order relation. Isotonicity is the key property of the algebra. It states that the order relation between the weights of any two paths is preserved if both of them are either prefixed or appended by a common, third, path. We show that isotonicity is both necessary and sufficient for a generalized Dijkstra's algorithm to yield optimal paths. Likewise, isotonicity is also both necessary and sufficient for hop-by-hop routing. However, without strict isotonicity, hop by-hop routing based on optimal paths may produce routing loops. They are prevented if every node computes what we call lexicographic-optimal paths. These paths can be computed with an enhanced Dijkstra's algorithm that has the same complexity as the standard one. Our findings are extended to multipath routing as well. As special cases of the general approach, we conclude that shortest-widest paths can neither be computed with a generalized Dijkstra's algorithm nor can packets be routed hop-by-hop over those paths. In addition, loop free hop by hop routing over widest and widest-shortest paths requires that each node computes lexicographic-optimal paths, in general.},
keywords={Internet;telecommunication network routing;computational complexity;optimisation;protocols;directed graphs;quality of service;QoS path computation;weights algebra;hop-by-hop routing;Internet;QoS routing;path weight functions;optimal paths;generalized Dijsktra's algorithm;binary operation;link weights;path weights;order relation;isotonicity;lexicographic-optimal paths;enhanced Dijkstra's algorithm;algorithm complexity;multipath routing;packet routing;loop free hop by hop routing;widest-shortest path;widest path;link state protocols;connected directed graph;Algebra;Internet;Delay;Circuits;Throughput;Bandwidth;Telecommunication computing;Routing protocols;Quality of service},
doi={10.1109/INFCOM.2001.916261},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916262,
author={H. Tangmunarunkit and R. Govindan and S. Shenker and D. Estrin},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={The impact of routing policy on Internet paths},
year={2001},
volume={2},
number={},
pages={736-742 vol.2},
abstract={The impact of routing policy on Internet paths is poorly understood. In theory, the policy can inflate shortest-router-hop paths. To our knowledge, the extent of this inflation has not been previously examined. Using a simplified model of the routing policy in the Internet, we obtain approximate indications of the impact of policy routing on Internet paths. Our findings suggest that the routing policy does impact the length of Internet paths significantly. For instance, in our model of the routing policy, some 20% of Internet paths are inflated by more than five router-level hops.},
keywords={Internet;telecommunication network routing;protocols;Internet paths;routing policy;shortest-router-hop paths;routing protocols;delay;throughput;autonomous systems;administrative domains;AS path approximation;Internet;Delay;Routing protocols;Stability;Throughput},
doi={10.1109/INFCOM.2001.916262},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916263,
author={Gang Liu and K. G. Ramakrishnan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A*Prune: an algorithm for finding K shortest paths subject to multiple constraints},
year={2001},
volume={2},
number={},
pages={743-749 vol.2},
abstract={We present a new algorithm, A*Prune, to list (in order of increasing length) the first K multiple-constrained-shortest-path (KMCSP) between a given pair of nodes in a digraph in which each are is associated with multiple quality of-service (QoS) metrics. The algorithm constructs paths starting at the source and going towards the destination. But, at each iteration, the algorithm gets rid of all paths that are guaranteed to violate the constraints, thereby keeping only those partial paths that have the potential to be turned into feasible paths, from which the optimal paths are drawn. The choice of which path to be extended first and which path can be pruned depend upon a projected path cost function, which is obtained by adding the cost already incurred to get to an intermediate node to an admissible cost to go the remaining distance to the destination. The Dijkstra's shortest path algorithm is a good choice to give a good admissible cost. Experimental results show that A*Prune is comparable to the current best known /spl epsiv/-approximate algorithms for most of randomly generated graphs, BA*Prune, which combines the A*Prune with any known polynomial time /spl epsiv/-approximate algorithms to give either optimal or /spl epsiv/-approximate solutions to the KMCSP problem, is also presented.},
keywords={telecommunication network routing;graph theory;polynomial approximation;quality of service;search problems;optimisation;A*Prune algorithm;digraph nodes;multiple constraints;multiple-constrained-shortest-path;quality of-service;QoS metrics;optimal paths;projected path cost function;admissible cost;Dijkstra's shortest path algorithm;randomly generated graphs;BA*Prune;polynomial time /spl epsiv/-approximate algorithms;optimal solutions;/spl epsiv/-approximate solutions;QoS sensitive routing;Quality of service;Routing;Cost function;Bandwidth;Jitter;Polynomials;Diffserv networks;Added delay},
doi={10.1109/INFCOM.2001.916263},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916265,
author={Hong-Hsu Yen and F. Y. -. Lin},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Near-optimal delay constrained routing in virtual circuit networks},
year={2001},
volume={2},
number={},
pages={750-756 vol.2},
abstract={An essential issue in designing, operating and managing a modern network is to assure end-to-end quality-of-service (QoS) from users' perspective, and in the meantime to optimize a certain "average" performance objective from the system's perspective. We consider the problem of minimizing the average cross-network packet delay in virtual circuit networks subject to an end-to-end delay constraint for each origin-destination user pair. The problem is formulated as a multicommodity network flow problem with integer routing decision variables, where additional end-to-end delay constraints are considered. The difficulties of this problem result from the integrality nature and particularly the nonconvexity associated with the end-to-end delay constraints. The basic approach to the algorithm development is Lagrangean relaxation in conjunction with number of optimization-based heuristics. In the computational experiments, it is shown that the proposed algorithm calculates solutions which are within 1% and 3% of optimal solutions under lightly and heavily loaded conditions, respectively, in minutes of CPU time for networks with up to 26 nodes.},
keywords={telecommunication network routing;quality of service;delays;packet switching;optimisation;near-optimal delay constrained routing;virtual circuit networks;network management;network design;network operation;quality-of-service;QoS;performance optimization;average cross-network packet delay;end-to-end delay constraint;multicommodity network flow problem;integer routing decision variables;end-to-end delay constraints;Lagrangean relaxation;algorithm;optimization-based heuristics;computational experiments;optimal solutions;CPU time;Routing;Intelligent networks;Circuits;Quality of service;Lagrangian functions;Added delay;Computer network management;Asynchronous transfer mode;Information management;Quality management},
doi={10.1109/INFCOM.2001.916265},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916266,
author={I. Koutsopoulos and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Channel state-adaptive techniques for throughput enhancement in wireless broadband networks},
year={2001},
volume={2},
number={},
pages={757-766 vol.2},
abstract={Wireless broadband access is becoming increasingly popular in the telecommunications market due to the projected demand for flexible and easily deployable high, speed connections. In order to adhere to the volatility of the wireless medium, the adoption of sophisticated adaptation techniques is required. We investigate the problem of enhancing channel throughput by performing resource assignment and reuse with adaptation of physical layer parameters. We propose an algorithm to allocate channels to users with different rate requirements, while appropriately adjusting the modulation level and transmission power, based on instantaneous channel quality. Our algorithm constructs the cochannel set of users in a sequential manner, by utilizing a criterion which is based on the induced and received amounts of interference for a user and the contribution in throughput increase. Although illustrated in the context of TDMA/TDD, the proposed technique can be applied in systems which support different multiple access and signaling schemes with orthogonal channels (e.g. OFDMA, CDMA). Our results indicate a considerable increase in throughput per utilized channel under such adaptive techniques.},
keywords={radio access networks;broadband networks;adaptive systems;radiofrequency interference;time division multiple access;multiuser channels;cellular radio;adaptive modulation;telecommunication control;power control;channel state-adaptive techniques;channel throughput enhancement;wireless broadband networks;wireless broadband access;telecommunications market;resource assignment;resource reuse;physical layer parameters;channel allocation;modulation level;transmission power;instantaneous channel quality;interference;TDMA/TDD;orthogonal channels;power control;wireless cellular network;adaptive modulation;modulation control;Throughput;Intelligent networks;Broadband communication;Multiaccess communication;Signal to noise ratio;Educational institutions;Physical layer;Interference;Power control;Web and internet services},
doi={10.1109/INFCOM.2001.916266},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916267,
author={Z. Naor and H. Levy},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A centralized dynamic access probability protocol for next generation wireless networks},
year={2001},
volume={2},
number={},
pages={767-775 vol.2},
abstract={A multiple access protocol that is particularly suitable for cellular Internet access and satellite-based networks with on-board processing is developed. The basic idea is that when a user wishes to send a message, it transmits with a probability p/sub access/ that depends on the load on the channel. Under conditions of low load, the probability p/sub access/ approaches 1, while at high load p/sub access/ is relatively low. This media access control protocol guarantees high channel utilization at high load, as well as low delay at low load periods. Using the statistical usage of the shared channel, the load is estimated with certain uncertainty. Our analysis shows that using the statistical usage of the shared channel, the optimal access probability can be well estimated for a broad class of load distribution patterns. In addition, we propose to use a central station to broadcast the value of p/sub access/ in networks with poor collision detection capability, or long feedback delay. The proposed method is particularly suitable for shared channels with poor collision detection capability, under conditions of bursty traffic and a large number of users. Examples for such channels are the reservation channel in satellite-based networks with on-board processing, and the control channel in cellular networks. Hence, the proposed method can be used for cellular Internet access and for accessing public satellite-based networks. The broadcast mechanism that already exists in such networks can be used to inform the users the dynamic access probability.},
keywords={access protocols;probability;Internet;feedback;telecommunication traffic;delays;radio access networks;satellite communication;cellular radio;statistical analysis;telecommunication channels;multi-access systems;centralized dynamic access probability protocol;next generation wireless networks;multiple access protocol;cellular Internet access networks;satellite-based networks;on-board processing;media access control protocol;channel load;high channel utilization;statistical usage;shared channel;optimal access probability;load distribution patterns;central station;collision detection;feedback delay;bursty traffic;reservation channel;control channel;broadcast mechanism;Access protocols;Cellular networks;IP networks;Probability;Media Access Protocol;Road accidents;Delay;Uncertainty;Pattern analysis;Broadcasting},
doi={10.1109/INFCOM.2001.916267},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916268,
author={Xin Liu and E. K. P. Chong and N. B. Shroff},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Transmission scheduling for efficient wireless utilization},
year={2001},
volume={2},
number={},
pages={776-785 vol.2},
abstract={We present an "opportunistic" transmission scheduling policy that exploits time-varying channel conditions and maximizes the system performance stochastically under a certain resource allocation fairness constraint. We establish the optimality of the scheduling scheme and also describe a practical scheduling procedure to implement our scheme. Through simulation results, we show that the scheme also works well for nonstationary scenarios and results in performance improvements of 20-150% compared with a scheduling scheme that does not take into account channel conditions. Furthermore, we note that in wireless networks, an important role of resource allocation is to balance the system performance and fairness among "good" and "bad" users. We propose three heuristic time-fraction assignment schemes, which approach the problem from different viewpoints.},
keywords={radio networks;broadband networks;voice communication;data communication;time-varying channels;cellular radio;optimisation;transmission scheduling;efficient wireless utilization;time-varying channel conditions;system performance;resource allocation fairness constraint;optimal scheduling;simulation results;nonstationary scenarios;wireless networks;resource allocation;heuristic time-fraction assignment;wideband data communications;voice communications;time-slotted system;opportunistic scheduling policy;time-slotted cellular system;Throughput;Resource management;Processor scheduling;Time-varying channels;Wireless networks;System performance;Frequency;Shadow mapping;Signal to noise ratio;Base stations},
doi={10.1109/INFCOM.2001.916268},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916269,
author={S. Deb and M. Kapoor and A. Sarkar},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Error avoidance in wireless networks using link state history},
year={2001},
volume={2},
number={},
pages={786-795 vol.2},
abstract={We address the problem of time varying connectivity, as would arise in a wireless communication system with channels occasionally becoming more error prone. Such channels have the property that they can only be used during intervals of variable duration as the devices' connectivities with a centralized controller change unpredictably with time. We propose a link state history based scheme in which the centralized controller, (a master for a master slave kind of system) tries to identify at each scheduling instant, the devices seeing bad connectivity. We demonstrate the advantage of the scheme on top of a master driven frequency hopping system derived from the Bluetooth specification. We also analyze the scheme using Markov chains. Numerical results from analysis show the performance of the scheme. We show that, with the right tuning of parameters, we can achieve high accuracy in identifying the good and the bad periods of the channels. Simulation results are also shown indicating improvement in throughput and goodput.},
keywords={radio links;microcellular radio;Markov processes;frequency hop communication;packet radio networks;time-varying channels;multiuser channels;time division multiple access;data communication;error avoidance;wireless networks;link state history;time varying connectivity;wireless communication system;centralized controller;master driven frequency hopping system;Bluetooth specification;Markov chains;simulation results;throughput;goodput;indoor wireless data networks;microcellular centralized architecture;TDMA;packet size;Wireless networks;History;Centralized control;Communication system control;Master-slave;Time varying systems;Wireless communication;Control systems;Frequency;Bluetooth},
doi={10.1109/INFCOM.2001.916269},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916270,
author={E. Altman and C. Barakat and V. M. Ramos},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Queueing analysis of simple FEC schemes for IP telephony},
year={2001},
volume={2},
number={},
pages={796-804 vol.2},
abstract={In interactive voice applications, FEC schemes are necessary for the recovery from packet losses. These schemes need to be simple with a light coding and decoding overhead in order to not impact the interactivity. The objective of this paper is to study a well known simple FEC scheme, in which for every packet n, some redundant information is added in some subsequent packet n+/spl phi/. If packet n is lost, it will be reconstructed in case packet n+/spl phi/ is well received. The quality of the reconstructed copy of packet n will depend on the amount of information on packet n we add to packet n+/spl phi/. We propose a detailed queueing analysis based on a ballot theorem and obtain simple expressions for the audio quality as a function of the amount of redundancy and its relative position to the original information. The analysis shows that this FEC scheme does not scale well and that the quality will deteriorate for any amount of FEC and for any offset /spl phi/.},
keywords={Internet telephony;queueing theory;forward error correction;redundancy;queueing analysis;FEC schemes;IP telephony;interactive voice applications;packet losses recovery;ballot theorem;audio quality;redundancy;Queueing analysis;Telephony;Forward error correction;Delay;Jitter;Decoding;Web and internet services;Automatic repeat request;Redundancy;Information analysis},
doi={10.1109/INFCOM.2001.916270},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916271,
author={F. Poppe and D. de Vleeschauwer and G. H. Petit},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Choosing the UMTS air interface parameters, the voice packet size and the dejittering delay for a voice-over-IP call between a UMTS and a PSTN party},
year={2001},
volume={2},
number={},
pages={805-814 vol.2},
abstract={We develop a methodology to set the VoIP application parameters (voice packet size and dejittering delay) and the UMTS air interface parameters in such a way that the quality of VoIP calls involving a UMTS party is ensured. We use analytical techniques to determine the delay and packet loss contributions of the various transmission stages crossed by the voice packet flow, and the E-model to predict the perceived quality. Our numerical results show that provided the parameters of the VoIP application and the UMTS air interface are chosen properly, UMTS access and the stringent delay and packet loss requirements of VoIP are reconcilable.},
keywords={land mobile radio;network interfaces;voice communication;packet radio networks;Internet telephony;delays;jitter;UMTS air interface parameters;voice packet size;dejittering delay;voice-over-IP call;delay;PSTN;VoIP;packet loss;voice packet flow;E-model;perceived quality;UMTS access;3G mobile communication;Delay;Propagation losses;Spine;Radio access networks;Postal services;Wireless networks;IP networks;Mouth;Ear},
doi={10.1109/INFCOM.2001.916271},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916272,
author={Wen-Tsai Liao and Jeng-Chun Chen and Ming-Syan Chen},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Adaptive recovery techniques for real-time audio streams},
year={2001},
volume={2},
number={},
pages={815-823 vol.2},
abstract={There are a number of packet-loss recovery techniques proposed for streaming audio applications. However, there are few works that are able to exploit the tradeoff between the recovery quality and the computational complexity. We develop a recovery method, called DSPWR (Double Sided Pitch Waveform Replication) which is able to tolerate a much higher packet loss rate. In essence, DSPWR is composed of several procedures devised to improve the quality of the reconstructed speech. It is noted that a more sophisticated recovery scheme that can tolerate a higher degree of packet loss in general requires a larger computational cost. In view of this, we evaluate the quality of the reconstructed speech under different packet loss rates for various receiver-based recovery methods, and compare the computational complexity among these methods. Under the acceptable speech quality whose MOS (Mean Opinion Score) is above 3.5, we develop an adaptive mechanism that can select the recovery method with the minimal complexity in accordance with different packet loss rates encountered. To conduct real experiments in the networks, we implement these recovery methods and evaluate the performance of DSPWR devised and the adaptive recovery techniques empirically. As validated by our experimental results, the adaptive mechanism is able to strike a compromise between the computational overhead and the quality of the speech desired.},
keywords={adaptive signal processing;speech processing;speech intelligibility;packet switching;computational complexity;audio signal processing;signal reconstruction;adaptive recovery techniques;real-time audio streams;packet-loss recovery;streaming audio applications;recovery quality;computational complexity;double sided pitch waveform replication;packet loss rate;DSPWR;reconstructed speech quality;computational cost;packet loss rates;receiver-based recovery methods;speech quality;mean opinion score;adaptive mechanism;performance evaluation;computational overhead;Streaming media;Delay;Computational complexity;Computational efficiency;Asia;Speech analysis;Computer aided instruction;Internet telephony;Redundancy;Costs},
doi={10.1109/INFCOM.2001.916272},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916273,
author={M. J. Karam and F. A. Tobagi},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Analysis of the delay and jitter of voice traffic over the Internet},
year={2001},
volume={2},
number={},
pages={824-833 vol.2},
abstract={In the future, voice communication is expected to migrate from the public switched telephone network (PSTN) to the Internet. Because of the particular characteristics (low volume and burstiness) and stringent delay and loss requirements of voice traffic, it is important to separate voice traffic from other traffic in the network by providing it with a separate queue. In this study, we conduct a thorough assessment of voice delay in this context. We conclude that priority queuing is the most appropriate scheduling scheme for the handling of voice traffic, while preemption of non-voice packets is strongly recommended for sub-10 Mbit/s links. We also find that per-connection custom packetization is in most cases futile, i.e. one packet size allows a good compromise between an adequate end-to-end delay and an efficient bandwidth utilization for voice traffic.},
keywords={Internet telephony;jitter;telecommunication traffic;voice communication;delays;queueing theory;packet switching;voice traffic;Internet;jitter analysis;delay analysis;voice communication;public switched telephone network;PSTN;loss requirements;delay requirements;priority queuing;voice delay;scheduling scheme;per-connection custom packetization;packet size;end-to-end delay;efficient bandwidth utilization;Speech analysis;Delay;Jitter;Traffic control;Telecommunication traffic;Communication system traffic control;IP networks;Communication switching;Internet telephony;Switches},
doi={10.1109/INFCOM.2001.916273},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916274,
author={T. Korkmaz and M. Krunz},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Multi-constrained optimal path selection},
year={2001},
volume={2},
number={},
pages={834-843 vol.2},
abstract={Providing quality-of-service (QoS) guarantees in packet networks gives rise to several challenging issues. One of them is how to determine a feasible path that satisfies a set of constraints while maintaining high utilization of network resources. The latter objective implies the need to impose an additional optimality requirement on the feasibility problem. This can be done through a primary cost function (e.g., administrative weight, hop count) according to which the selected feasible path is optimal. In general, multi-constrained path selection, with or without optimization, is an NP-complete problem that cannot be exactly solved in polynomial-time. Heuristics and approximation algorithms with polynomial and pseudo-polynomial-time complexities are often used to deal with this problem. However, existing solutions suffer either from excessive computational complexities that cannot be used for online network operation or from low performance. Moreover, they only deal with special cases of the problem (e.g., two constraints without optimization, one constraint with optimization, etc.). For the feasibility problem under multiple constraints, some researchers have proposed a nonlinear cost function whose minimization provides a continuous spectrum of solutions ranging from a generalized linear approximation (GLA) to an asymptotically exact solution. We propose an efficient heuristic algorithm for the most general form of the problem. We first formalize the theoretical properties of the above nonlinear cost function. We then introduce our heuristic algorithm (H MCOP), which attempts to minimize both the nonlinear cost function (for the feasibility part) and the primary cost function (for the optimality part). We prove that H MCOP guarantees at least the performance of GLA and often improves upon it. H MCOP has the same order of complexity as Dijkstra's algorithm. Using extensive simulations on random graphs with correlated and uncorrelated link weights, we show that under the same level of computational complexity, H MCOP outperforms its (less general) contenders in its success rate in finding feasible paths and in the cost of such paths.},
keywords={quality of service;optimisation;computational complexity;polynomial approximation;nonlinear functions;telecommunication network routing;correlation methods;multi-constrained optimal path selection;quality-of-service guarantees;QoS guarantees;packet networks;network resources;administrative weight;hop count;optimization;NP-complete problem;heuristics;approximation algorithms;pseudo-polynomial-time complexity;polynomial-time complexity;online network operation;nonlinear cost function minimization;generalized linear approximation;asymptotically exact solution;efficient heuristic algorithm;primary cost function;H MCOP;Dijkstra's algorithm;random graphs;simulations;correlated link weights;uncorrelated link weights;computational complexity;success rate;Internet;scalable routing;Cost function;Heuristic algorithms;Polynomials;Computational complexity;Constraint optimization;Quality of service;NP-complete problem;Approximation algorithms;Linear approximation;Computational modeling},
doi={10.1109/INFCOM.2001.916274},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916275,
author={Xin Yuan and Xingming Liu},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Heuristic algorithms for multi-constrained quality of service routing},
year={2001},
volume={2},
number={},
pages={844-853 vol.2},
abstract={Multi-constrained quality of service (QoS) routing finds a route in the network that satisfies multiple independent quality of service constraints. This problem is NP-hard and a number of heuristic algorithms have been proposed to solve the problem. This paper studies two heuristics, the limited granularity heuristic and the limited path heuristic, for solving general k-constrained problems. Analytical and simulation studies are conducted to compare the time/space requirements of the heuristics and the effectiveness of the heuristics in finding the paths that satisfy the QoS constraints. We prove analytically that for an N nodes and E edges network with k (a small constant) independent QoS constraints, the limited granularity heuristic must maintain a table of size O(|N|/sup k-1/) in each node to be effective, which results in a time complexity of O(|N|/sup k/|E|). We also prove that the limited path heuristic can achieve very high performance by maintaining O(|N|/sup 2/lg(|N|)) entries in each node, which indicates that the performance of the limited path heuristic is not sensitive to the number of constraints. We conclude that although both the limited granularity heuristic and the limited path heuristic can efficiently solve 2-constrained QoS routing problems, the limited path heuristic is superior to the limited granularity heuristic in solving k-constrained QoS routing problems when k>3. Our simulation study further confirms this conclusion.},
keywords={quality of service;telecommunication network routing;computational complexity;directed graphs;heuristic algorithms;multi-constrained quality of service routing;multi-constrained QoS routing;NP-hard problem;limited granularity heuristic;limited path heuristic;simulation studies;time/space requirements;time complexity;directed graph;Heuristic algorithms;Quality of service;Routing;Delay;Bandwidth;Performance analysis;Computer science;Analytical models;Aggregates;Costs},
doi={10.1109/INFCOM.2001.916275},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916276,
author={A. Goel and K. G. Ramakrishnan and D. Kataria and D. Logothetis},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Efficient computation of delay-sensitive routes from one source to all destinations},
year={2001},
volume={2},
number={},
pages={854-858 vol.2},
abstract={In this paper we describe an efficient algorithm for the constrained shortest path problem which is defined as follows. Given a directed graph with two weights on each link e, a cost l/sub e/, and a delay t/sub e/, find the cheapest path from a source to all destinations such that the delay of each path is no more than a given threshold. The constrained shortest path problem arises in quality-of-service-sensitive routing in data networks and is of particular importance in real time services. The problem formulation and the algorithmic framework presented are quite general; they apply to IP, ATM, and optical networks. Unlike previous algorithms, our algorithm generates paths from one source to all destinations. Our algorithm is strongly polynomial, and is asymptotically faster than earlier algorithms. We corroborate our analysis by a preliminary simulation study.},
keywords={quality of service;telecommunication network routing;delays;directed graphs;delay-sensitive routes;efficient algorithm;constrained shortest path problem;directed graph;cheapest path;quality-of-service-sensitive routing;data networks;real time services;optical networks;ATM networks;IP networks;polynomial algorithm;QoS;Delay;Routing;Optical fiber networks;Shortest path problem;Bandwidth;Maximum likelihood detection;Polynomials;Analytical models;Internet telephony;IP networks},
doi={10.1109/INFCOM.2001.916276},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916277,
author={A. Juttner and B. Szviatovski and I. Mecs and Z. Rajko},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Lagrange relaxation based method for the QoS routing problem},
year={2001},
volume={2},
number={},
pages={859-868 vol.2},
abstract={In this paper a practically efficient QoS routing method is presented, which provides a solution to the delay constrained least cost routing problem. The algorithm uses the concept of aggregated costs and provides an efficient method to find the optimal multiplier based on Lagrange relaxation. This method is proven to be polynomial and it is also efficient in practice. The benefit of this method is that it also gives a lower bound on the theoretical optimal solution along with the result. The difference between the lower bound and the cost of the found path is very small proving the good quality of the result. Moreover, by further relaxing the optimality of paths, an easy way is provided to control the trade-off between the running time of the algorithm and the quality of the found paths. We present a comprehensive numerical evaluation of the algorithm, by comparing it to a wide range of QoS routing algorithms proposed in the literature. It is shown that the performance of the proposed polynomial time algorithm is close to the optimal solution computed by an exponential algorithm.},
keywords={quality of service;telecommunication network routing;relaxation theory;optimisation;polynomials;Lagrange relaxation based method;QoS routing problem;delay constrained least cost routing problem;aggregated costs;optimal multiplier;lower bound;numerical evaluation;polynomial time algorithm;exponential algorithm;Lagrangian functions;Routing;Propagation delay;Costs;Polynomials;Quality of service;Resource management;Internet;Telecommunication traffic;Performance analysis},
doi={10.1109/INFCOM.2001.916277},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916278,
author={P. Henry and Hui Luo},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Off-the-record email system},
year={2001},
volume={2},
number={},
pages={869-877 vol.2},
abstract={In the flood of communications now carried via email, it frequently happens that users want to keep some casual or sensitive exchanges off the record, just as in ordinary telephone conversations. Within the system architectures commonly in use today, however, virtually all email transmissions leave a permanent record behind-a paper trail-that is extremely difficult to obliterate. Even after an email is "deleted" by both the sender and the recipient, a copy will likely remain in backup storage at one or more of the email servers that handled the message during its lifetime. Encryption does not solve the problem, because the message can be recovered if the decryption key is revealed, perhaps under court order, or for some other reason. To ensure email privacy, an off-the-record email system is proposed. In this system, the email stays in the sender's computer and is read by the recipient through a Web browser over a secure connection. The message content cannot be recovered from an encrypted copy even with the help of both parties' private keys. Further, the email has a limited lifetime. After it is deleted from the sender's computer, it cannot be recovered from any remaining backup records. The new system is completely compatible with current email implementations. Using existing tools, email users can conduct secure, off-the-record communications. Two practical implementations are given to demonstrate how to deploy off-the-record email both in an intranet as well as on the Internet.},
keywords={electronic mail;cryptography;telecommunication security;intranets;Internet;security of data;online front-ends;off-the-record email system;email servers;encryption;decryption key;court order;email privacy;Web browser;secure connection;message content;encrypted copy;private keys;secure off-the-record communications;intranet;Internet;Web server;Access protocols;Cryptography;Privacy;Electronic mail;Floods;Security;Internet telephony;Electrical capacitance tomography;Reflection},
doi={10.1109/INFCOM.2001.916278},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916279,
author={Dawn Xiaodong Song and A. Perrig},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Advanced and authenticated marking schemes for IP traceback},
year={2001},
volume={2},
number={},
pages={878-886 vol.2},
abstract={Defending against distributed denial-of-service attacks is one of the hardest security problems on the Internet today. One difficulty to thwart these attacks is to trace the source of the attacks because they often use incorrect, or spoofed IP source addresses to disguise the true origin. In this paper, we present two new schemes, the advanced marking scheme and the authenticated marking scheme, which allow the victim to trace-back the approximate origin of spoofed IP packets. Our techniques feature low network and router overhead, and support incremental deployment. In contrast to previous work, our techniques have significantly higher precision (lower false positive rate) and fewer computation overhead for the victim to reconstruct the attack paths under large scale distributed denial-of-service attacks. Furthermore the authenticated marking scheme provides efficient authentication of routers' markings such that even a compromised router cannot forge or tamper markings from other uncompromised routers.},
keywords={transport protocols;Internet;telecommunication security;message authentication;packet switching;telecommunication network routing;authenticated marking scheme;IP traceback;distributed denial-of-service attacks;security problems;Internet;spoofed IP source addresses;advanced marking scheme;spoofed IP packets;low network overhead;low router overhead;low false positive rate;computation overhead;attack paths reconstruction;router markings authentication;Computer crime;Internet;Distributed computing;Computer science;Computer security;Large-scale systems;Authentication;Usability;US Government agencies;Contracts},
doi={10.1109/INFCOM.2001.916279},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916280,
author={Yu-Chee Tseng and Hsiang-Kuang Pan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Secure and invisible data hiding in 2-color images},
year={2001},
volume={2},
number={},
pages={887-896 vol.2},
abstract={In an earlier paper, we propose a steganography scheme for hiding a piece of critical information in a host binary image. That scheme ensures that in each m/spl times/n image block of the host image, as many as [log/sub 2/(mn+1)] bits can be hidden in the block by changing at most 2 bits in the block. As a sequel of that work, in this paper we propose a revised scheme that can maintain higher quality of the host image by sacrificing some data hiding space. The new scheme can still offer a good data hiding ratio. It ensures that for any bit that is modified in the host image, the bit is adjacent to another bit which has a value equal to the former's new value. Thus, the hiding effect is quite invisible.},
keywords={image colour analysis;image coding;data encapsulation;security of data;2-color images;invisible data hiding;secure data hiding;steganography;host binary image;image block;data hiding ratio;digital media;image coding;Data encapsulation;Cryptography;Steganography;Information security;Computer science;Data security;Pixel;Image processing;Image coding;Terminology},
doi={10.1109/INFCOM.2001.916280},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916281,
author={H. M. Heys},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={An analysis of the statistical self-synchronization of stream ciphers},
year={2001},
volume={2},
number={},
pages={897-904 vol.2},
abstract={In this paper, we examine a recently proposed mode of operation for block ciphers which we refer to as statistical cipher feedback (SCFB) mode. SCFB mode configures the block cipher as a keystream generator for use in a stream cipher such that it has the property of statistical self-synchronization, thereby allowing the stream cipher to recover from slips in the communications channel. Statistical self-synchronization involves feeding back ciphertext to the input of the keystream generator similar to the conventional cipher feedback (CFB) mode of block ciphers, except that the feedback only occurs when a special pattern is recognized in the ciphertext. In the paper, we examine the efficiency, resynchronization, and error propagation characteristics of SCFB and compare these to the conventional modes of CFB, output feedback (OFB), and counter mode. In particular, we study these characteristics of SCFB as a function of the synchronization pattern size. We conclude that, although it can take significantly longer to resynchronize, SCFB mode can be used to provide self-synchronizing implementations for stream ciphers that are much more efficient than conventional CFB mode and that have error propagation characteristics similar to CFB mode.},
keywords={synchronisation;feedback;cryptography;stream ciphers;statistical self-synchronization;block ciphers;statistical cipher feedback mode;keystream generator;communications channel;error propagation characteristics;resynchronization characteristics;synchronization pattern size;encryption;Output feedback;Communication channels;Cryptography;Noise measurement;Pattern recognition;Counting circuits;Hardware;Transmitters;Security},
doi={10.1109/INFCOM.2001.916281},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916282,
author={C. Dovrolis and P. Ramanathan and D. Moore},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={What do packet dispersion techniques measure?},
year={2001},
volume={2},
number={},
pages={905-914 vol.2},
abstract={The packet pair technique estimates the capacity of a path (bottleneck bandwidth) from the dispersion (spacing) experienced by two back-to-back packets. We demonstrate that the dispersion of packet pairs in loaded paths follows a multimodal distribution, and discuss the queueing effects that cause the multiple modes. We show that the path capacity is often not the global mode, and so it cannot be estimated using standard statistical procedures. The effect of the size of the probing packets is also investigated, showing that the conventional wisdom of using maximum sized packet pairs is not optimal. We then study the dispersion of long packet trains. Increasing the length of the packet train reduces the measurement variance, but the estimates converge to a value, referred to as the asymptotic dispersion rate (ADR), that is lower than the capacity. We derive the effect of the cross traffic in the dispersion of long packet trains, showing that the ADR is not the available bandwidth in the path, as was assumed in previous work. Putting all the pieces together, we present a capacity estimation methodology that has been implemented in a tool called pathrate.},
keywords={telecommunication traffic;Internet;queueing theory;packet switching;packet dispersion techniques;packet pair technique;capacity;bottleneck bandwidth;back-to-back packets;loaded paths;multimodal distribution;queueing effects;multiple modes;path capacity;long packet trains;asymptotic dispersion rate;ADR;cross traffic;capacity estimation methodology;pathrate;Internet traffic;Dispersion;Bandwidth;Monitoring;Telecommunication traffic;Web and internet services;Throughput;Length measurement;Traffic control;Quality of service;Capacity planning},
doi={10.1109/INFCOM.2001.916282},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916283,
author={N. G. Duffield and F. Lo Presti and V. Paxson and D. Towsley},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Inferring link loss using striped unicast probes},
year={2001},
volume={2},
number={},
pages={915-923 vol.2},
abstract={In this paper we explore the use of end-to-end unicast traffic as measurement probes to infer link-level loss rates. We leverage on of earlier work that produced efficient estimates for link-level loss rates based on end-to-end multicast traffic measurements. We design experiments based on the notion of transmitting stripes of packets (with no delay between transmission of successive packets within a stripe) to two or more receivers. The purpose of these stripes is to ensure that the correlation in receiver observations matches as closely as possible what would have been observed if the stripe had been replaced by a notional multicast probe that followed the same paths to the receivers. Measurements provide good evidence that a packet pair to distinct receivers introduces considerable correlation which can be further increased by simply considering longer stripes. We then use simulation to explore how well these stripes translate into accurate link-level loss estimates. We observe good accuracy with packet pairs, with a typical error of about 1%, which significantly decreases as stripe length is increased to 4 packets.},
keywords={telecommunication traffic;Internet;packet switching;losses;link loss;striped unicast probes;end-to-end unicast traffic;link-level loss rates;receiver observations;packet pair;correlation;stripe length;Unicast;Probes;Loss measurement;Delay;Internet;Computer science;Telecommunication traffic;Size measurement;Statistics;Performance loss},
doi={10.1109/INFCOM.2001.916283},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916284,
author={Do Young Eun and N. B. Shroff},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A measurement-analytic framework for QoS estimation based on the dominant time scale},
year={2001},
volume={2},
number={},
pages={924-932 vol.2},
abstract={In this paper we describe a measurement-analytic framework for estimating the overflow probability, an important measure of quality of service (QoS), at a given multiplexing point in the network. A multiplexing point in the network could be a multiplexer or an output port of a switch where resources such as bandwidth and buffers are shared. Our approach impinges on using the notion of the dominant or critical time scale, which corresponds to the time-scale relevant for describing the queueing behavior based on particular network configurations. The dominant time-scale provides us with a measurement window for the statistics of the traffic, but is unfortunately itself defined in terms of the statistics of the traffic over all time. This in essence results in a chicken and an egg type of unresolved problem. For the dominant time scale to be useful for on-line measurements, we need to be able to break this chicken and egg type of cycle. In this paper, we present a stopping criterion to successfully break this cycle through online measurements and find a bound on the dominant time scale. Thus, the result has significant implications for network measurements. Our approach is quite different from other works in the literature that require off-line measurements of the entire trace of the traffic (since in our case, we need to measure only the statistics of the traffic up to a bound on the dominant time scale.) We also investigate the characteristics of this upper bound on the dominant time scale, and provide numerical results to illustrate the utility of our measurement analytic approach.},
keywords={quality of service;telecommunication traffic;queueing theory;statistical analysis;buffer storage;multiplexing;parameter estimation;measurement-analytic framework;QoS estimation;dominant time scale;overflow probability;quality of service;multiplexing point;output port;bandwidth;buffers;critical time scale;dominant time-scale;queueing behavior;network configurations;statistics;stopping criterion;bound;Time measurement;Telecommunication traffic;Traffic control;Quality of service;Switches;Statistics;Multiplexing;Bandwidth;Statistical analysis;Upper bound},
doi={10.1109/INFCOM.2001.916284},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916285,
author={Y. Breitbart and Chee-Yong Chan and M. Garofalakis and R. Rastogi and A. Silberschatz},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Efficiently monitoring bandwidth and latency in IP networks},
year={2001},
volume={2},
number={},
pages={933-942 vol.2},
abstract={Effective monitoring of network utilization and performance indicators is a key enabling technology for proactive and reactive resource management, flexible accounting, and intelligent planning in next-generation IP networks. In this paper, we address the challenging problem of efficiently monitoring bandwidth utilization and path latencies in an IP data network. Unlike earlier approaches, our measurement architecture assumes a single point-of-control in the network (corresponding to the network operations center) that is responsible for gathering bandwidth and latency information using widely-deployed management tools, like SNMP, RMON/NetFlow, and explicitly-routed IP probe packets. Our goal is to identify effective techniques for monitoring (a) bandwidth usage for a given set of links or packet flows, and (b) path latencies for a given set of paths, while minimizing the overhead imposed by the management tools on the underlying production network. We demonstrate that minimizing overheads under our measurement model gives rise to new combinatorial optimization problems, most of which prove to be NP-hard. We also propose novel approximation algorithms for these optimization problems and prove guaranteed upper bounds on their worst-case performance. Our simulation results validate our approach, demonstrating the effectiveness of our novel monitoring algorithms over a wide range of network topologies.},
keywords={Internet;computer network management;monitoring;network topology;data communication;combinatorial mathematics;minimisation;monitoring;network utilization;performance indicators;resource management;flexible accounting;intelligent planning;next-generation IP networks;bandwidth utilization;path latencies;IP data network;measurement architecture;SNMP;RMON/NetFlow;explicitly-routed IP probe packets;packet flows;overhead;production network;combinatorial optimization problems;NP-hard problem;approximation algorithms;optimization problems;worst-case performance;network topologies;Monitoring;Bandwidth;Delay;IP networks;Resource management;Intelligent networks;Technology planning;Next generation networking;Information management;Probes},
doi={10.1109/INFCOM.2001.916285},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916286,
author={Xin Wang and H. Schulzrinne},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Pricing network resources for adaptive applications in a differentiated services network},
year={2001},
volume={2},
number={},
pages={943-952 vol.2},
abstract={The differentiated services framework (DiffServ) has been proposed to provide multiple quality of service (QoS) classes over IP networks. A network supporting multiple classes of service also requires a differentiated pricing structure. We propose a pricing scheme in a DiffServ environment based on the cost of providing different levels of quality of service to different classes, and on long-term demand. Pricing of network services dynamically based on the level of service, usage, and congestion allows a more competitive price to be offered, allows the network to be used more efficiently, and provides a natural and equitable incentive for applications to adapt their service contract according to network conditions. We develop a DiffServ simulation framework to compare the performance of a network supporting congestion-sensitive pricing and adaptive service negotiation to that of a network with a static pricing policy. Adaptive users adapt to price changes by adjusting their sending rate or selecting a different service class. We also develop the demand behavior of adaptive users based on a perceptually reasonable user utility function. Simulation results show that a congestion-sensitive pricing policy coupled with user rate adaptation is able to control congestion and allow a service class to meet its performance assurances under large or bursty offered loads, even without explicit admission control. Users are able to maintain a stable expenditure. Allowing users to migrate between service classes in response to price increases further stabilizes the individual service prices. When admission control is enforced, congestion-sensitive pricing still provides an advantage in terms of a much lower connection blocking rate at high loads.},
keywords={quality of service;costing;Internet;telecommunication congestion control;network resources;pricing;adaptive applications;differentiated services network;DiffServ;quality of service;QoS;IP networks;long-term demand;usage;congestion;service contract;simulation framework;performance;adaptive service negotiation;sending rate;demand behavior;user utility function;user rate adaptation;large loads;bursty offered loads;admission control;connection blocking rate;Pricing;Adaptive systems;Intelligent networks;Diffserv networks;Quality of service;Costs;Contracts;Admission control;Resource management;IP networks},
doi={10.1109/INFCOM.2001.916286},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916287,
author={J. Altmann and K. Chu},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A proposal for a flexible service plan that is attractive to users and Internet service providers},
year={2001},
volume={2},
number={},
pages={953-958 vol.2},
abstract={The current Internet service provider market does not offer different types of service plans for Internet access. The predominant pricing plan is a flat-rated plan. Since the number of new Internet users is still growing very fast, there is no real competition in the Internet market. Consequently, there is no incentive for Internet service providers (ISPs) to focus on certain user groups by offering more attractive pricing plans in order to differentiate themselves. However, as soon as the number of new Internet users stagnates, ISPs have to specialize on certain market segments. Then, the question raises of what is an attractive service plan that is attractive for users, but allows ISPs to build a sustainable business. Based on empirical results of the INDEX project, we discuss a service plan for Internet access that might be appreciated by Internet users as well as by ISPs. This service plan combines the advantages of flat-rate pricing and usage-based pricing. Using this service plan, users will benefit by receiving a basic service, but are given the choice of higher quality whenever they demand. From the ISP perspective, it will help to focus on certain user groups and limit the peak load on their network.},
keywords={Internet;costing;tariffs;flexible service plan;ISP;Internet access;pricing plan;Internet service provider market;pricing plans;INDEX project;flat-rate pricing;usage-based pricing;peak network load;USA;Proposals;Web and internet services;Pricing;Bandwidth;Electronic mail;DSL;Computer science;Laboratories;Quality of service;Spine},
doi={10.1109/INFCOM.2001.916287},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916288,
author={A. Ganesh and K. Laevens and R. Steinberg},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Congestion pricing and user adaptation},
year={2001},
volume={2},
number={},
pages={959-965 vol.2},
abstract={The problem of sharing bandwidth in a communication network has been the focus of much research aimed at guaranteeing an appropriate quality of service to users. This is particularly challenging in an environment with a great diversity of users and applications, which makes it difficult, if not impossible, to tightly constrain user attributes and requirements. This motivates shifting the burden of rate allocation from the network to the end-systems. We propose a decentralized scheme for user adaptation and study its dynamics. The proposed scheme uses congestion prices as a mechanism for providing both feedback and incentives to end-systems.},
keywords={telecommunication congestion control;quality of service;costing;tariffs;Internet;packet switching;congestion pricing;user adaptation;bandwidth sharing;communication network;quality of service;QoS guarantee;rate allocation;decentralized user adaptation;congestion prices;end-system feedback;end-system incentives;Internet;system stability;slow-start;TCP;price feedback;packet switching;Pricing;Switches;Quality of service;Telecommunication traffic;Traffic control;Packet switching;Web and internet services;Bandwidth;Feedback;Proposals},
doi={10.1109/INFCOM.2001.916288},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916289,
author={K. Ravindran and A. Sabbir and D. Loguinov and G. S. Bloom},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Cost-optimal multicast trees for multi-source data flows in multimedia distribution},
year={2001},
volume={2},
number={},
pages={966-975 vol.2},
abstract={From a graph-theoretical perspective, the problem of constructing multicast distribution paths, modeled as 'Steiner trees', is NP-complete. So, many heuristics-based algorithms are available to generate near-optimal trees. Typically, an algorithm first assigns the edge costs for all links, and then examines various candidate paths for interconnecting a given set of nodes. This strategy does not work well for the evolving multimedia application configurations (such as audio-video and image distributions) where it is often necessary to construct multiple distribution paths, viz., one per media data stream. This is because the overlapping of multiple tree segments over a common link forces the link cost to change, based on the delay and bandwidth characteristics of data streams flowing over these segments. Accordingly, algorithms that hitherto have assumed non-varying link costs during various phases of a run now need to take into account the variability of link costs as candidate trees with different levels of path overlapping are examined in a given run. In other words, as an algorithm runs by examining various paths, the link costs change. The paper embarks on a study of heuristics-based algorithms to tackle this 'modified Steiner tree' problem. The algorithms allow more cost-efficient routing of data than feasible otherwise with a classical treatment of the 'Steiner tree' problem.},
keywords={multimedia systems;trees (mathematics);telecommunication network routing;computational complexity;multicast communication;optimisation;telecommunication links;delays;cost-optimal multicast trees;multi-source data flows;multimedia distribution;graph theory;multicast distribution paths;heuristics-based algorithms;near-optimal trees;edge costs;network nodes;audio-video distribution;image distribution;delay characteristics;bandwidth characteristics;data streams;nonvarying link costs;link costs variability;cost-efficient data routing;NP-complete problem;Intelligent networks;Vegetation mapping},
doi={10.1109/INFCOM.2001.916289},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916290,
author={S. Borst and P. Whiting},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Dynamic rate control algorithms for HDR throughput optimization},
year={2001},
volume={2},
number={},
pages={976-985 vol.2},
abstract={The relative delay tolerance of data applications, together with the bursty traffic characteristics, opens up the possibility for scheduling transmissions so as to optimize throughput. A particularly attractive approach, in fading environments, is to exploit the variations in the channel conditions, and transmit to the user with the currently 'best' channel. We show that the 'best' user may be identified as the maximum-rate user when the feasible rates are weighed with some appropriately determined coefficients. Interpreting the coefficients as shadow prices, or reward values, the optimal strategy may thus be viewed as a revenue-based policy. Calculating the optimal revenue vector directly is a formidable task, requiring detailed information on the channel statistics. Instead, we present adaptive algorithms for determining the optimal revenue vector on-line in an iterative fashion, without the need for explicit knowledge of the channel behavior. Starting from an arbitrary initial vector, the algorithms iteratively adjust the reward values to compensate for observed deviations from the target throughput ratios. The algorithms are validated through extensive numerical experiments. Besides verifying long-run convergence, we also examine the transient performance, in particular the rate of convergence to the optimal revenue vector. The results show that the target throughput ratios are tightly maintained, and that the algorithms are well able to track changes in the channel conditions or throughput targets.},
keywords={packet radio networks;delays;telecommunication congestion control;data communication;telecommunication traffic;fading channels;optimisation;adaptive systems;iterative methods;convergence of numerical methods;transient analysis;time-varying channels;dynamic rate control algorithms;HDR throughput optimization;delay tolerance;data applications;bursty traffic characteristics;transmission scheduling;throughput optimisation;fading environments;channel conditions;maximum-rate user;shadow prices;reward values;revenue-based policy;optimal revenue vector;channel statistics;adaptive algorithms;iterative method;wireless networks;numerical experiments;long-run convergence;transient performance;convergence rate;target throughput ratios;packet delay;high data rate;Heuristic algorithms;Throughput;Delay;Fading;Rayleigh channels;Base stations;Statistics;Iterative algorithms;Convergence;Adaptive algorithm},
doi={10.1109/INFCOM.2001.916290},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916291,
author={Pai-Hsiang Hsiao and A. Hwang and H. T. Kung and D. Vlah},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Load-balancing routing for wireless access networks},
year={2001},
volume={2},
number={},
pages={986-995 vol.2},
abstract={The widespread use of wireless devices presents new challenges for network operators, who need to provide service to ever larger numbers of mobile end users, while ensuring quality-of-service guarantees. We describe a new distributed routing algorithm that performs dynamic load-balancing for wireless access networks. The algorithm constructs a load-balanced backbone tree, which simplifies routing and avoids per-destination state for routing and per-flow state for QoS reservations. We evaluate the performance of the algorithm using several metrics including adaptation to mobility, degree of load-balance, bandwidth blocking rate, and convergence speed. We find that the algorithm achieves better network utilization by lowering bandwidth blocking rates than other methods.},
keywords={radio access networks;telecommunication network routing;quality of service;land mobile radio;convergence of numerical methods;distributed algorithms;trees (mathematics);load-balancing routing;wireless access networks;wireless devices;network operators;mobile end users;quality-of-service guarantees;distributed routing algorithm;dynamic load-balancing;load-balanced backbone tree;QoS reservations;performance evaluation;adaptation mobility;bandwidth blocking rate;convergence speed;network utilization;Routing;Wireless networks;Tree graphs;Joining processes;Bandwidth;Spine;Network topology;Bluetooth;Home appliances;Upper bound},
doi={10.1109/INFCOM.2001.916291},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916292,
author={C. F. Chiasserini and R. R. Rao},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Combining paging with dynamic power management},
year={2001},
volume={2},
number={},
pages={996-1004 vol.2},
abstract={In this paper we develop a novel approach to conserving energy in battery powered communication devices. There are two salient aspects to this approach. First, the battery powered devices move through multiple, progressively deeper, sleep states in a predictable manner. Nodes in deeper sleep states consume lower energy while asleep but incur a longer delay and higher energy cost to wake up. Second, the nodes are woken up on demand through a paging signal. To awaken nodes that are in deep sleep, the paging signal has to be decoded using very low power circuits such as those used in RF tags. To accommodate this need, in a manner that scales with with the number of nodes, the number of distinct paging signals has to be much less than the number of possible nodes. This is accomplished through a group based wake up scheme, that initially awakens the targeted node along with a number of other similarly disposed nodes that subsequently return to their original sleep state. Trade-offs among energy consumption, delay as well as overhead are presented; comparisons with other protocols show the potential for 16 to 50% improvement in energy consumption.},
keywords={quality of service;protocols;land mobile radio;power control;telecommunication control;paging communication;paging;dynamic power management;battery powered communication devices;sleep states;delay;energy cost;paging signal;very low power circuits;RF tags;wake up scheme;energy consumption;protocols;Energy management;Sleep;Batteries;Delay;Energy consumption;Costs;RF signals;Decoding;Circuits;Radio frequency},
doi={10.1109/INFCOM.2001.916292},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916293,
author={K. Mitchell and K. Sohraby},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={An analysis of the effects of mobility on bandwidth allocation strategies in multi-class cellular wireless networks},
year={2001},
volume={2},
number={},
pages={1005-1011 vol.2},
abstract={In this paper we present a multi-cell analytic model for multi-class cellular networks. We investigate the effects subscriber mobility has on bandwidth control strategies when the network supports multiple classes of subscribers having different bandwidth requirements. We introduce control strategies from non-mobile networks and examine them in a mobile environment. The expressions for call blocking using these control strategies have product form solutions. This allows us to develop a multi-cell, multi-class, model by generalizing on the Erlang fixed point approximation using generalized multi-rate, multi-class, Erlang loss formulas for each class of traffic. We produce expressions for originating calls lost, hand-off calls lost, forced-termination, and mean channel occupancy for each class of traffic in each cell for different control strategies. The multicell analytic model allows us to investigate the effects of asymmetric loads and mobility patterns in the network. The analytic results are supported by simulation.},
keywords={bandwidth allocation;telecommunication control;cellular radio;bandwidth allocation strategies;multi-class cellular wireless networks;subscriber mobility;bandwidth control strategies;nonmobile networks;call blocking;product form solutions;Erlang fixed point approximation;Erlang loss formulas;hand-off calls;forced-termination;mean channel occupancy;lost calls;asymmetric loads;mobility patterns;Channel allocation;Traffic control;Land mobile radio cellular systems;Bandwidth;Communication system traffic control;Cellular networks;Cities and towns;Pattern analysis;Quality of service;Intelligent networks},
doi={10.1109/INFCOM.2001.916293},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916294,
author={M. Dilman and D. Raz},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Efficient reactive monitoring},
year={2001},
volume={2},
number={},
pages={1012-1019 vol.2},
abstract={Networks are monitored in order to ensure that the system operates within desirable parameters. The increasing complexity of networks and services provided by them increases this need for monitoring. Monitoring consists of measuring properties of the network, and of inferring an aggregate predicate from these measurements. Conducting such monitoring introduces traffic overhead that may reduce the overall effective throughput. This paper studies ways to minimize the monitoring communication overhead in IP networks. We develop and analyze several monitoring algorithms that achieve significant reduction in the management overhead while maintaining the functionality. The main idea is to combine global polling with local event driven reporting. The amount of traffic saving depends on the statistical characterization of the monitored data. We indicate the specific statistical factors that affect the saving and show how to choose the right algorithm for the type of monitored data. In particular our results show that for Internet traffic our algorithms can save more than 90% of the monitoring traffic.},
keywords={telecommunication traffic;monitoring;Internet;computer network management;statistical analysis;efficient reactive monitoring;complexity;aggregate predicate;traffic overhead;throughput;IP networks;monitoring communication overhead;management overhead;functionality;global polling;local event driven reporting;statistical characterization;Internet traffic;Condition monitoring;Telecommunication traffic;Information management;Computerized monitoring;Aggregates;Throughput;IP networks;Internet;Maintenance;Payloads},
doi={10.1109/INFCOM.2001.916294},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916295,
author={G. Kar and A. Keller},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={An architecture for managing application services over global networks},
year={2001},
volume={2},
number={},
pages={1020-1027 vol.2},
abstract={This paper proposes a novel approach for providing end-to-end management of application services that have been deployed over large IP networks. A key feature of the proposed architecture is that it can be implemented as enhancements to existing, commercial network management platforms, thus allowing network service providers to offer new functionality by leveraging existing, deployed infrastructures.},
keywords={Internet;computer network management;application services;global networks;architecture;end-to-end management;IP networks;enhancement;network management platform;functionality;Content management;Environmental management;IP networks;Web and internet services;Switches;Virtual private networks;Costs;Customer service;Monitoring;Service oriented architecture},
doi={10.1109/INFCOM.2001.916295},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916296,
author={S. Banerjee and S. Khuller},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A clustering scheme for hierarchical control in multi-hop wireless networks},
year={2001},
volume={2},
number={},
pages={1028-1037 vol.2},
abstract={In this paper we present a clustering scheme to create a hierarchical control structure for multi-hop wireless networks. A cluster is defined as a subset of vertices, whose induced graph is connected. In addition, a cluster is required to obey certain constraints that are useful for management and scalability of the hierarchy. All these constraints cannot be met simultaneously for general graphs, but we show how such a clustering can be obtained for wireless network topologies. Finally, we present an efficient distributed implementation of our clustering algorithm for a set of wireless nodes to create the set of desired clusters.},
keywords={network topology;graph theory;land mobile radio;telecommunication control;telecommunication network management;clustering scheme;hierarchical control;multi-hop wireless networks;vertices;graph;management;scalability;wireless network topologies;Intelligent networks;Spread spectrum communication;Wireless networks;Wireless sensor networks;Switches;Scalability;Clustering algorithms;Intelligent sensors;Packet switching;Network topology},
doi={10.1109/INFCOM.2001.916296},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916297,
author={O. Gurewitz and M. Sidi},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Estimating one-way delays from cyclic-path delay measurements},
year={2001},
volume={2},
number={},
pages={1038-1044 vol.2},
abstract={In this paper we present a novel approach for the estimation of one-way delays from cyclic-path delay measurements that does not require any kind of synchronization among the nodes of the network. Furthermore, this approach takes into account the asymmetric nature of the network, and the fact that traffic flows are not necessarily the same in both directions. Our approach is based on cyclic-path delay measurements, each of which is extracted using a single (source) clock and therefore is accurate. The basic idea of the approach is to express the cyclic-path delays in terms of one-way delay variables. If there were enough independent cyclic-path delay measurements, then one could solve explicitly for the one-way delays. We show that the maximal number of independent measurements that can be taken is smaller hence a procedure for estimating the one-way delay is proposed.},
keywords={delay estimation;telecommunication traffic;one-way delays;cyclic-path delay measurement;asymmetric network;traffic flow;independent measurements;telecommunication networks;Delay estimation;Synchronization;Clocks;Global Positioning System;Electric variables measurement;Telecommunication traffic;Delay effects;Data analysis;Performance analysis;Quality of service},
doi={10.1109/INFCOM.2001.916297},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916298,
author={S. Alouf and P. Nain and D. Towsley},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Inferring network characteristics via moment-based estimators},
year={2001},
volume={2},
number={},
pages={1045-1054 vol.2},
abstract={In this work we develop simple inference models based on finite capacity single server queues for estimating the buffer size and the intensity of cross traffic at the bottleneck link of a path between two hosts. Several pairs of moment-based estimators are proposed to estimate these two quantities. The best scheme is then identified through simulation.},
keywords={telecommunication traffic;queueing theory;buffer storage;estimation theory;Internet;network characteristics;moment-based estimators;inference models;finite capacity single server queues;buffer size;cross traffic intensity;bottleneck link;Internet;Traffic control;Bandwidth;Quality of service;Diffserv networks;IP networks;Web and internet services;Joining processes;Computer science;Monitoring;Helium},
doi={10.1109/INFCOM.2001.916298},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916299,
author={M. J. Neely and E. Modiano},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Convexity and optimal load distributions in work conserving */*/1 queues},
year={2001},
volume={2},
number={},
pages={1055-1064 vol.2},
abstract={In this paper we develop fundamental convexity properties of unfinished work and packet waiting time in a work conserving */*/1 queue. The queue input consists of an uncontrollable background process and a rate-controllable input stream. We show that any moment of unfinished work is a convex function of the controllable input rate. The convexity properties are then extended to address the problem of optimal routing of arbitrary input streams over a collection of N queues in parallel with different (possibly time-varying) linespeeds (/spl mu//sub 1/(t),..., /spl mu//sub N/(t)). Our convexity results hold for stream-based routing (where individual packet streams must be routed to the same queue) as well as for packet-based routing where each packet is routed to a queue using some pre-determined splitting method, such as probabilistic splitting. Our analysis of these general systems is carried out by introducing a new function of the superposition of two input streams that we call the blocking function. Using this function facilitates analysis and provides much insight into the sample path dynamics of */*/1 queues.},
keywords={telecommunication network routing;queueing theory;telecommunication traffic;packet switching;convexity;optimal load distributions;work conserving */*/1 queues;unfinished work;packet waiting time;uncontrollable background process;rate-controllable input stream;convex function;optimal routing;input streams;stream-based routing;packet streams;packet-based routing;splitting method;probabilistic splitting;blocking function;sample path dynamics;Routing;Random processes;Optimal control;Global Positioning System;Streaming media},
doi={10.1109/INFCOM.2001.916299},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916300,
author={R. Jafari and I. Sohraby},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Combined M/G/1-G/M/1 type structured chains: a simple algorithmic solution and applications},
year={2001},
volume={2},
number={},
pages={1065-1074 vol.2},
abstract={We consider combined M/G/1-G/M/1 type Markov chains with block-structured transition. It is assumed that all the blocks are generated with rational generating matrices. We provide an algorithmic approach to find the stationary probability distribution based on well-known/concepts in linear system theory. These chains arise in the (correlated) G/G/1 queueing systems and known structured Markov chains such as canonical and non-canonical M/G/1 and G/M/1 types which frequently arising in teletraffic analysis of computer and communications networks are special cases. We provide a truncation-free algorithmic solution in a simple geometric form of the the stationary probability vector of the chain taking full advantage of the rational generating matrices.},
keywords={queueing theory;Markov processes;matrix algebra;probability;telecommunication traffic;system theory;correlation methods;combined M/G/1-G/M/1 type Markov chains;algorithmic applications;block-structured transition;rational generating matrices;stationary probability distribution;linear system theory;correlated G/G/1 queueing systems;structured Markov chains;canonical M/G/1 Markov chain;noncanonical M/G/1 Markov chain;canonical G/M/1 Markov chain;noncanonical G/M/1 Markov chain;teletraffic analysis;computer networks;communications networks;truncation-free algorithmic solution;stationary probability vector;Application software;Cities and towns;Stochastic processes;Computer science;Probability distribution;Linear systems;Queueing analysis;Computer networks;Communication networks;Solid modeling},
doi={10.1109/INFCOM.2001.916300},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916301,
author={JiaFu He and K. Sohraby},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A new analysis framework for discrete time queueing systems with general stochastic sources},
year={2001},
volume={2},
number={},
pages={1075-1084 vol.2},
abstract={This paper considers a general class of discrete time systems with batch arrivals and departures. Such models appear frequently in the teletraffic analysis of computer and communications networks. Our arrival models are assumed to be quite general. They could be independent and identically distributed (i.i.d) in successive slots, be periodic, be Markovian or described by the moving average time-series model, etc. Our solution framework is novel and unifying. It uses a combination of multi-dimensional generating functions and combinatorial analysis using extensions of classical ballot theorems. In general, we provide an explicit analytical expression as an infinite sum to obtain the system stationary probability distribution avoiding classical root finding methods, matrix analytical methodologies and finally spectral decomposition approaches. We provide a number of analytical and numerical examples including a simple multi-server model with i.i.d arrivals, an ATM multiplexer fed by a (random) number of periodic sources, and a new example considering the discrete moving average model for the arrival process where a simple closed-form expression for the stationary distribution of the system queue lengths is provided.},
keywords={discrete time systems;queueing theory;telecommunication traffic;moving average processes;Markov processes;time series;probability;asynchronous transfer mode;multiplexing equipment;packet switching;discrete time queueing systems;general stochastic sources;batch arrivals;batch departures;teletraffic analysis;communications networks;computer networks;general arrival models;independent identically distributed models;i.i.d models;periodic models;Markovian models;moving average time-series model;multidimensional generating functions;combinatorial analysis;ballot theorems;infinite sum;stationary probability distribution;multi-server model;i.i.d arrivals;ATM multiplexer;periodic sources;discrete moving average model;closed-form expression;system queue lengths;Queueing analysis;Stochastic systems;Performance analysis;Asynchronous transfer mode;Matrix decomposition;Cities and towns;Fluctuations;Random variables;Helium;Discrete time systems},
doi={10.1109/INFCOM.2001.916301},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916302,
author={F. Ajmone Marsan and A. Bianco and P. Giaccone and E. Leonardi and E. Neri},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Packet scheduling in input-queued cell-based switches},
year={2001},
volume={2},
number={},
pages={1085-1094 vol.2},
abstract={Input-queued switch architectures play a major role in the design of high performance switches and routers for packet networks. These architectures must be controlled by a scheduling algorithm, which solves contentions in the transfer of data units from inputs to outputs. Several scheduling algorithms were proposed in the literature for input-queued cell switches, operating on fixed-size data units. In this paper we consider the case of packet switches, i.e., devices operating on variable-size data units at their interfaces, but internally operating on cells, and we propose novel extensions of known scheduling algorithms. We prove that the maximum throughput achievable by input-queued packet switches is identical to that achievable with input- and output-queued cell switches. We show by simulation that, in the case of packet switches, input-queued architectures may provide performance advantages over output-queued architectures.},
keywords={queueing theory;packet switching;telecommunication network routing;delay estimation;packet scheduling;input-queued cell-based switches;input-queued switch architecture;high performance switch design;high performance router design;packet networks;scheduling algorithm;data units transfer;scheduling algorithms;variable-size data units;maximum throughput;input-queued cell switch;output-queued cell switch;simulation;output-queued architecture;packet delay estimation;Scheduling algorithm;Packet switching;Switches;Fabrics;Intelligent networks;Throughput;Delay;Buffer storage;Algorithm design and analysis;Contracts},
doi={10.1109/INFCOM.2001.916302},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916303,
author={E. Leonardi and M. Mellia and F. Neri and M. Ajmone Marsan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Bounds on average delays and queue size averages and variances in input-queued cell-based switches},
year={2001},
volume={2},
number={},
pages={1095-1103 vol.2},
abstract={We develop a general methodology, mainly based upon Lyapunov functions, to derive bounds on average delays, and on queue size averages and variances of complex systems of queues. We then apply this methodology to input-buffered, cell-based switch and router architectures. These architectures require a scheduling algorithm to select at each slot a subset of input-buffered cells which can be transferred towards output ports. Although the stability properties (i.e., the limit throughput) of input-buffered, cell-based switches was already studied for several classes of scheduling algorithms, no analytical results concerning cell delays or queue sizes are yet available in the technical literature. We concentrate on purely input-buffered switches that adopt a maximum weight matching scheduling algorithm, that was proved to be the scheduling algorithm providing the best performance. The derived bounds proved to be rather tight, when compared to simulation results.},
keywords={queueing theory;packet switching;delays;buffer storage;Lyapunov methods;average delays;queue size average;queue size variance;input-queued cell-based switches;Lyapunov functions;input-buffered cell-based switch architecture;input-buffered router architecture;scheduling algorithm;output ports;stability properties;limit throughput;cell delays;maximum weight matching scheduling algorithm;performance;tight bounds;simulation results;Delay;Switches;Scheduling algorithm;Fabrics;Algorithm design and analysis;Throughput;Buffer storage;Lyapunov method;Stability analysis;Queueing analysis},
doi={10.1109/INFCOM.2001.916303},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916304,
author={T. Bonald and A. Proutiere and J. W. Roberts},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Statistical performance guarantees for streaming flows using expedited forwarding},
year={2001},
volume={2},
number={},
pages={1104-1112 vol.2},
abstract={We suggest that satisfactory statistical performance guarantees for streaming flows can be fulfilled when their packets receive expedited forwarding in non-preemptive priority queues. This relies on the conjecture that jitter remains negligible in the network such that performance measures can be bounded by assuming flows constitute Poisson arrival processes of maximum transfer unit (MTU) sized packets. We provide analytical and simulation evidence in support of this conjecture and show how it leads to simple engineering rules for both constant and variable rate streaming traffic.},
keywords={statistical analysis;Internet;queueing theory;stochastic processes;packet switching;telecommunication traffic;jitter;delays;probability;asynchronous transfer mode;computer network management;expedited forwarding;statistical performance guarantees;nonpreemptive priority queues;jitter;performance measures;Poisson arrival processes;MTU sized packets;simulation;engineering rules;variable rate streaming traffic;constant rate streaming traffic;Internet;maximum transfer unit;packet loss probability;packet delay bounds;ATM;traffic management;Jitter;Delay;Traffic control;Streaming media;Telecommunication traffic;Probability;Quality of service;Internet telephony;Admission control;Communication system traffic control},
doi={10.1109/INFCOM.2001.916304},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916305,
author={V. Sivaraman and F. M. Chiussi and M. Gerla},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={End-to-end statistical delay service under GPS and EDF scheduling: a comparison study},
year={2001},
volume={2},
number={},
pages={1113-1122 vol.2},
abstract={Generalized processor sharing (GPS) has gained much popularity as a simple and effective scheduling mechanism for the provisioning of quality of service (QoS) in emerging high-speed networks. For supporting deterministic end-to-end delay guarantees, GPS is known to be sub-optimal in comparison to the earliest deadline first (EDF) scheduling discipline; nevertheless it is often prefered over EDF due to its simplicity. In this paper, using analytical frameworks developed in the literature, we reassess the merits of GPS as compared to EDF in the setting of statistical delay service. Our contributions are threefold. The statistical frameworks in the literature enable the aggregate losses (i.e., delay bound violations) at an EDF scheduler to be estimated-our first contribution, therefore, is to develop a mechanism that allows the aggregate losses to translate to per-flow guarantees. This is achieved by means of a simple packet discard scheme that drops packets fairly then delay violations are imminent at the EDF scheduler. The discard mechanism has a constant complexity and is feasible for implementation in current packet switches. The ability to derive the per-flow guarantees from the aggregate allows a direct comparison between EDF and GPS-our next contribution, therefore, is to show for various traffic mixes with given per-flow loss constraints that EDF offers consistently larger schedulable regions than GPS, both in the single-hop and multi-hop setting. As our final contribution, we argue that the use of GPS for statistical delay support is inherently problematic. We demonstrate that achieving the maximal schedulable regions under GPS could necessitate dynamic resynchronization of the GPS weights, an operation considered infeasible for practical implementation.},
keywords={quality of service;queueing theory;packet switching;statistical analysis;delays;processor scheduling;end-to-end statistical delay service;GPS scheduling;EDF scheduling;generalized processor sharing;scheduling mechanism;quality of service;QoS;emerging high-speed networks;deterministic end-to-end delay guarantees;earliest deadline first scheduling;statistical delay service;statistical frameworks;aggregate losses;delay bound violations;per-flow guarantees;packet discard scheme;delay violations;packet switches;traffic mixes;single-hop setting;multi-hop setting;Global Positioning System;Processor scheduling;Quality of service;Optimal scheduling;Aggregates;Delay estimation;Packet switching;Switches;Computer science;Drives},
doi={10.1109/INFCOM.2001.916305},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916306,
author={S. Sarkar and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Back pressure based multicast scheduling for fair bandwidth allocation},
year={2001},
volume={2},
number={},
pages={1123-1132 vol.2},
abstract={We study fair allocation of resources in multicast networks with multirate capabilities. In multirate transmission, the session source hierarchically encodes its signal and the receivers subscribe to the appropriate number of layers. The objective of the network is to distribute the layers fairly. This can be attained either by computing the fair rates first, and then using a scheduling policy to attain the fair rates, or by using a scheduling policy which allocates the fair rates without computing them explicitly. The first requires knowledge of system parameters like link bandwidth, which are not generally known to the link schedulers. The second approach is more realistic. We present a scheduling policy which allocates the fair rates without computing them beforehand. We have presented analytical and experimental results demonstrating the fairness of the resulting rate allocation. In addition to guaranteeing the fair rates, this policy confines the packet losses to enhancement layers, and protects the more important base layers, when there is shortage of bandwidth. Furthermore, this policy does not require any knowledge of traffic statistics, is computationally simple, and is essentially local information based.},
keywords={scheduling;packet switching;multicast communication;bandwidth allocation;Internet;telecommunication control;back pressure based multicast scheduling;fair bandwidth allocation;receivers;fairness;packet losses;enhancement layers;base layers;Channel allocation;Bandwidth;Processor scheduling;Resource management;Quality of service;Web and internet services;Educational institutions;Protection;Statistics;ISDN},
doi={10.1109/INFCOM.2001.916306},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916307,
author={A. Chaintreau and F. Baccelli and C. Diot},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Impact of network delay variations on multicast sessions with TCP-like congestion control},
year={2001},
volume={2},
number={},
pages={1133-1142 vol.2},
abstract={We study the impact of random noise (queueing delay) on the performance of a multicast session. With a simple analytical model, we analyze the throughput degradation within a multicast (one-to-many) tree under TCP-like congestion and flow control. We use the (max, plus) formalism together with methods based on stochastic comparison (association and convex ordering) and on the theory of extremes (Lai and Robbins' (1978) notion of maximal characteristics) to prove various properties of the throughput. We first prove that the throughput obtained from Golestani and Sabnani's (1999) deterministic model is systematically optimistic. In presence of light tailed random noise, we show that the throughput decreases like the inverse of the logarithm of the number of receivers. We find analytically an upper and a lower bound for the throughput degradation. Within these bounds, we characterize the degradation which is obtained for various tree topologies. In particular, we observe that a class of trees commonly found in IP multicast sessions (which we call umbrella trees) is significantly more sensitive to network noise than other topologies.},
keywords={random noise;network topology;delays;transport protocols;telecommunication congestion control;multicast communication;queueing theory;telecommunication traffic;Internet;network delay variations;multicast sessions;TCP-like congestion control;random noise;queueing delay;performance;throughput degradation;multicast tree;flow control;stochastic comparison;association;convex ordering;maximal characteristics;throughput;Golestani's deterministic model;tree topologies;IP multicast sessions;umbrella trees;(max, plus) formalism;Throughput;Degradation;Bandwidth;Sliding mode control;Network topology;Size control;Delay;Analytical models;Stochastic resonance;Force control},
doi={10.1109/INFCOM.2001.916307},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916308,
author={J. Byers and M. Luby and M. Mitzenmacher},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Fine-grained layered multicast},
year={2001},
volume={2},
number={},
pages={1143-1151 vol.2},
abstract={Traditional approaches to receiver-driven layered multicast have advocated the benefits of cumulative layering, which can enable coarse-grained congestion control that complies with TCP-friendliness equations over large time scales. In this paper, we quantify the costs and benefits of using non-cumulative layering and present a new, scalable multicast congestion control scheme which provides a fine-grained approximation to the behavior of TCP additive increase/multiplicative decrease (AIMD). In contrast to the conventional wisdom, we demonstrate that fine-grained rate adjustment can be achieved with only modest increases in the number of layers and aggregate bandwidth consumption, while using only a small constant number of control messages to perform either additive increase or multiplicative decrease.},
keywords={multicast communication;transport protocols;telecommunication congestion control;receivers;fine-grained layered multicast;receiver-driven layered multicast;noncumulative layering;scalable multicast congestion control scheme;fine-grained approximation;TCP additive increase/multiplicative decrease;AIMD;fine-grained rate adjustment;aggregate bandwidth consumption;control messages;additive increase;multiplicative decrease;Subscriptions;Encoding;Bandwidth;Computer science;Scheduling algorithm;Equations;Aggregates;Jacobian matrices;Frequency;Engineering profession},
doi={10.1109/INFCOM.2001.916308},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916309,
author={Xi Zhang and K. G. Shin},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Statistical analysis of feedback-synchronization signaling delay for multicast flow control},
year={2001},
volume={2},
number={},
pages={1152-1161 vol.2},
abstract={Feedback signaling plays a crucial role in flow control because the traffic source relies on the signaling information to make correct and timely flow-control decisions. Multicast flow-control signaling imposes two additional challenges: scalability and feedback synchronization. We developed a binary-tree deterministic model (Zhang and Shin 1999) and an independent-marking statistical model (Zhang and Shin 2000) to study the delay performance of various multicast feedback-synchronization signaling algorithms. In this paper, we consider the general case in which the congestion markings at different links are dependent. We develop a Markov chain model defined by the link-marking state on each path in a multicast tree. The Markov chain can not only characterize link-marking dependencies, but also yield a tractable analytical model. We also develop a Markov-chain dependency-degree model which can he used to quantify/evaluate all possible Markov-chain dependency degrees without knowing a priori the dependency degree information. Using the Markov-chain and dependency-degree models, we derive the general expressions for the probability distribution of each path bring the multicast-tree bottleneck. Also derived are the closed-form expressions for the first and second moments of multicast signaling delays. The proposed Markov chain is also shown to asymptotically reach an equilibrium, and its limiting state distributions converge to the link-marking marginal probabilities when the Markov chain is irreducible. By applying these two models, we analyze and contrast the feedback-delay scalability of two representative multicast signaling protocols: soft-synchronization protocol and hop-by-hop (HBH) signaling algorithms.},
keywords={multicast communication;Markov processes;statistical analysis;feedback;synchronisation;delays;telecommunication signalling;telecommunication congestion control;protocols;statistical analysis;feedback-synchronization signaling delay;multicast flow control;feedback signaling;signaling message;scalability;feedback synchronization;delay performances;binary-tree deterministic model;independent-marking statistical model;delay performance;Markov chain model;link-marking state;Markov-chain dependency-degree model;dependency-degree models;probability distribution;closed-form expressions;multicast signaling delays;feedback-delay scalability;multicast signaling protocols;soft-synchronization protocol;hop-by-hop signaling algorithms;Statistical analysis;Delay;Multicast protocols;Feedback;Scalability;Multicast algorithms;Traffic control;Analytical models;Genetic expression;Probability distribution},
doi={10.1109/INFCOM.2001.916309},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916310,
author={P. -. Wan and G. Calinescu and X. -. Li and O. Frieder},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Minimum-energy broadcast routing in static ad hoc wireless networks},
year={2001},
volume={2},
number={},
pages={1162-1171 vol.2},
abstract={Energy conservation is a critical issue in ad hoc wireless networks for node and network life, as the nodes are powered by batteries only. One major approach for energy conservation is to route a communication session along the routes which requires the lowest total energy consumption. This optimization problem is referred to as minimum-energy routing. While minimum-energy unicast routing can be solved in polynomial time by shortest-path algorithms, it remains open whether minimum-energy broadcast routing can be solved in polynomial time, despite the NP-hardness of its general graph version. Previously three greedy heuristics were proposed in Wieselthier et al. (2000): MST (minimum spanning tree), SPT (shortest-path tree), and BIP (broadcasting incremental power). They have been evaluated through simulations in Wieselthier et al.], but little is known about their analytical performance. The main contribution of this paper is the quantitative characterization of their performances in terms of approximation ratios. By exploring geometric structures of Euclidean MSTs, we have been able to prove that the approximation ratio of MST is between 6 and 12, and the approximation ratio of BIP is between /sup 13///sub 3/ and 12. On the other hand, the approximation ratio of SPT is shown to be at least /sup n///sub 2/, where n is the number of receiving nodes. To our best knowledge, these are the first analytical results for minimum-energy broadcasting.},
keywords={telecommunication network routing;optimisation;radio broadcasting;multicast communication;minimum-energy broadcast routing;static ad hoc wireless networks;energy conservation;optimization problem;minimum-energy routing;NP-hardness problem;quantitative characterization;performances;approximation ratios;geometric structures;approximation ratio;minimum spanning tree;MST;SPT;shortest-path tree;BIP;broadcasting incremental power;minimum-energy broadcasting;Broadcasting;Routing;Wireless networks;Energy conservation;Polynomials;Tree graphs;Batteries;Energy consumption;Unicast;Analytical models},
doi={10.1109/INFCOM.2001.916310},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916312,
author={S. Roy and J. J. Garcia-Luna-Aceves},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Using minimal source trees for on-demand routing in ad hoc networks},
year={2001},
volume={2},
number={},
pages={1172-1181 vol.2},
abstract={The on-demand routing protocols that have been proposed to date use either path information (e.g., DSR) or distance information (e.g., AODV). We present SOAR, an on-demand link-state protocol based on partial link-state information in which a wireless router communicates to its neighbors the link states of only those links in its source tree that belong to the paths it chooses to advertise for reaching destinations with which it has active flows, SOAR does not require periodic link-state advertisements when there are no link connectivity changes in the network. Simulation studies for several scenarios of node mobility and traffic flows reveal that SOAR performs more efficiently than DSR, which is one of the best performing on-demand routing approaches based on path information.},
keywords={protocols;telecommunication network routing;packet radio networks;network topology;land mobile radio;minimal source trees;ad hoc networks;on-demand routing protocols;SOAR;on-demand link-state protocol;partial link-state information;wireless router;node mobility;traffic flows;source-tree on-demand adaptive routing protocol;Intelligent networks;Ad hoc networks;Routing protocols;Wireless communication;Personal digital assistants;Network topology;Wireless application protocol;Telecommunication traffic;Traffic control;Wireless networks},
doi={10.1109/INFCOM.2001.916312},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916313,
author={T. Ozaki and Jaime Bae Kim and T. Suda},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Bandwidth-efficient multicast routing for multihop, ad-hoc wireless networks},
year={2001},
volume={2},
number={},
pages={1182-1191 vol.2},
abstract={In this paper, we propose and investigate a bandwidth-efficient multicast routing protocol for ad-hoc networks. The proposed protocol achieves low communication overhead, namely, it requires a small number of control packet transmissions for route setup and maintenance. The proposed protocol also achieves high multicast efficiency, namely, it delivers multicast packets to receivers with a small number of transmissions. In order to achieve low communication overhead and high multicast efficiency, the proposed protocol employs the following mechanisms: (1) on-demand invocation of the route setup and route recovery processes to avoid periodic transmissions of control packets, (2) a new route setup process that allows a newly joining node to find the nearest forwarding node to minimize the number of forwarding nodes, and (3) a route optimization process that detects and removes unnecessary forwarding nodes to eliminate redundant and inefficient routes. Our simulation results show that the proposed protocol achieves high multicast efficiency with low communication overhead compared with other existing multicast routing protocols, especially in the ease where the number of receivers in a multicast group is large.},
keywords={telecommunication network routing;protocols;multicast communication;land mobile radio;packet radio networks;minimisation;bandwidth-efficient multicast routing;multihop ad-hoc wireless networks;bandwidth-efficient multicast routing protocol;control packet transmissions;route setup;route maintenance;multicast efficiency;multicast packets;on-demand invocation;route recovery;forwarding node;route optimization process;redundant routes;inefficient routes;communication overhead;multicast group;Spread spectrum communication;Wireless networks;Multicast protocols;Routing protocols;Mobile computing;Mobile communication;Bandwidth;Computer science;Wire;Land mobile radio cellular systems},
doi={10.1109/INFCOM.2001.916313},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916314,
author={Lusheng Ji and M. S. Corson},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Differential destination multicast-a MANET multicast routing protocol for small groups},
year={2001},
volume={2},
number={},
pages={1192-1201 vol.2},
abstract={In this paper we propose a multicast routing protocol for mobile ad hoc networks (MANETs). The protocol-termed differential destination mmulticast (DDM)-differs from common approaches proposed for MANET multicast routing in two ways. Firstly, instead of distributing membership control throughout the network, DDM concentrates this authority at the data sources (i.e. senders) thereby giving sources knowledge of group membership. Secondly, differentially-encoded, variable-length destination headers are inserted in data packets which are used in combination with unicast routing tables to forward multicast packets towards multicast receivers. Instead of requiring that multicast forwarding state to be stored in all participating nodes, this approach also provides the option of stateless multicasting. Each node independently has the choice of caching forwarding state or having its upstream neighbor to insert this state into self-routed data packets, or some combination thereof. The protocol is best suited for use with small multicast groups operating in dynamic networks of any size.},
keywords={land mobile radio;protocols;multicast communication;packet radio networks;telecommunication network routing;differential destination multicast;MANET multicast routing protocol;small groups;mobile ad hoc networks;DDM;group membership;differentially-encoded variable-length destination headers;data packets;unicast routing tables;multicast packets;multicast forwarding state;stateless multicasting;self-routed data packets;dynamic networks;forwarding state;Multicast protocols;Mobile ad hoc networks;Routing protocols;Unicast;Information security;Educational institutions;Electronic mail;Distributed decision making;Bandwidth;Computer networks},
doi={10.1109/INFCOM.2001.916314},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916681,
author={Y. Bejerano and I. Cidon},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Efficient location management based on moving location areas},
year={2001},
volume={1},
number={},
pages={3-12 vol.1},
abstract={Personal communication systems (PCS) maintain a location management mechanism for tracking the location of their mobile users. The increasing population of mobile users leads to congestion problems in these systems, and motivates the development of more efficient management schemes. This work presents a new mobility management scheme that integrates the location area approach with the location prediction idea. It is based on results from traffic flow theory and it is first that uses the concept of moving location areas. Traffic flow theory suggests that people tend to reside in specific places for long periods of time. Occasionally, they move to new locations and try to minimize the travel time using highways as much as possible. The scheme uses two complementary sets of location areas that overlap each other. The first set contains small location areas and is designated for locating mobile users in a quasi-static state. The second set covers the highways and it is designated to track mobile users while they are traveling from place to place, where each highway is covered by a single location area. The dual set design enables tracking mobile users at a high degree of accuracy with low update cost while they are quasi-static state, and reduces the amount of update operations when they travel. For tracing mobile users on a highway, the scheme uses a system of moving location areas. A moving location area (MLA) is a small location area that defines the location of a group of mobile users, which are geographically concentrated and move in the same direction. The scheme guarantees low rate of update and search operations at each cell of the system and efficiently utilizes the radio spectrum and the network resources with low computational overhead. These advantages are also backed by simulation results.},
keywords={personal communication networks;cellular radio;telecommunication network management;efficient location management;moving location areas;personal communication systems;PCS;mobile users tracking;mobile users location;mobility management scheme;location prediction;traffic flow theory;quasi-static state;cellular radio;Personal communication networks;Mobile radio mobility management;Road transportation;Bandwidth;Costs;Computer networks;Computational modeling;GSM;Radio spectrum management;Design optimization},
doi={10.1109/INFCOM.2001.916681},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916682,
author={I. Demirkol and C. Ersoy and M. U. Caglayan and H. Delic},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Location area planning in cellular networks using simulated annealing},
year={2001},
volume={1},
number={},
pages={13-20 vol.1},
abstract={Location area (LA) planning plays an important role in cellular networks because of the trade-off caused by paging and registration signaling. The upper bound on the size of an LA is the service area of a mobile switching center (MSC). In that extreme case, the cost of paging is at its maximum, but no registration is needed. On the other hand, if each cell is an LA, the paging cost is minimal, but the registration cost is the largest. In general, the most important component of these costs is the load on the signaling resources. Between the extremes lie one or more partitions of the MSC service area that minimize the total cost of paging and registration. In this paper, we try to find an optimal method for determining the location areas. For that purpose, we use the available network information to formulate a realistic optimization problem. We propose an algorithm based on simulated annealing (SA) for the solution of the resulting problem. Then, we investigate the quality of the SA technique by comparing its results to greedy search and random generation methods.},
keywords={cellular radio;simulated annealing;telecommunication network planning;telecommunication signalling;location area planning;cellular radio networks;simulated annealing;paging;registration signaling;upper bound;optimal method;mobile switching center;MSC service area;optimization problem;greedy search method;random generation method;Intelligent networks;Land mobile radio cellular systems;Simulated annealing;Costs;Bandwidth;Paging strategies;Personal communication networks;Base stations;Databases;Communication system traffic control},
doi={10.1109/INFCOM.2001.916682},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916683,
author={Hsiao-Kuang Wu and Ming-Hui Jin and Jorng-Tzong Horng and Chen-Yi Ke},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Personal paging area design based on mobile's moving behaviors},
year={2001},
volume={1},
number={},
pages={21-30 vol.1},
abstract={We propose a new location tracking strategy called behavior-based strategy (BBS) based on each mobile's moving behavior. With the help of data mining technologies the moving behavior of each mobile could be mined from long-term collection of the mobile's moving logs. From the moving behavior of each mobile, we first estimate the time-varying probability of the mobile and then the optimal paging area of each time region is derived. To reduce unnecessary computation, we consider the location tracking and computational cost and then derive a cost model. A heuristics is proposed to minimize the cost model through finding the appropriate moving period checkpoints of each mobile. The experimental results show our strategy outperforms fixed paging area strategy currently used in the GSM system and time-based strategy for highly regular moving mobiles.},
keywords={personal communication networks;paging communication;radio direction-finding;data mining;probability;personal paging area design;mobile moving behavior;location tracking;behavior-based strategy;data mining technologies;mobile moving logs;time-varying probability;optimal paging area;time region;computational cost;cost model;heuristics;fixed paging area;GSM system;regular moving mobiles;PCN;personal communication network;Costs;Data mining;Computational efficiency;GSM},
doi={10.1109/INFCOM.2001.916683},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916684,
author={S. Jamin and Cheng Jin and A. R. Kurc and D. Raz and Y. Shavitt},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Constrained mirror placement on the Internet},
year={2001},
volume={1},
number={},
pages={31-40 vol.1},
abstract={Internet service providers and infrastructural companies often employ mirrors of popular content to decrease client download time and server load. Due to the immense scale of the Internet and decentralized administration of the networks, companies have a limited number of sites (relative to the size of the Internet) where they can place mirrors. Mirrors of popular content are usually replicated on every site to maximize reachability to clients. We study the performance improvements as the number of mirrors increases under different placement algorithms subject to the constraint that mirrors can be placed only at certain locations. Although there are extensive theoretical studies on center placement and, analytical and empirical studies on Web cache placement, we are not aware of any published literature on mirror placement especially in the case of constrained mirror placement. Our results show that increasing the number of mirror sites under the constraint is effective in reducing client download time and reducing server load only for a surprisingly small range of values regardless of the mirror placement algorithm.},
keywords={Internet;file servers;performance evaluation;constrained mirror placement;Internet;Internet service providers;ISP;download time reduction;server load reduction;decentralized network administration;performance;center placement;Web cache placement;mirror placement algorithm;Mirrors;Costs;Network servers;Web server;IP networks;Engineering profession;Telecommunication traffic;Web and internet services;Constraint theory;Laboratories},
doi={10.1109/INFCOM.2001.916684},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916685,
author={J. T. Moore and M. Hicks and S. Nettles},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Practical programmable packets},
year={2001},
volume={1},
number={},
pages={41-50 vol.1},
abstract={We present SNAP (safe and nimble active packets), a new scheme for programmable (or active) packets centered around a new low-level packet language. Unlike previous active packet approaches, SNAP is practical: namely, adding significant flexibility over IP without compromising safety and security or efficiency. In this paper we show how to compile from the well-known active picket language PLAN to SNAP, showing that SNAP retains PLAN's flexibility; give proof sketches of its novel approach to resource control; and present experimental data showing SNAP attains performance very close to that of a software IP router.},
keywords={packet switching;transport protocols;telecommunication security;Internet;program compilers;practical programmable packets;safe and nimble active packets;low-level packet language;SNAP;IP;safety;security;efficiency;active picket language;PLAN;resource control;performance;software IP router;Internet;complier;Safety;Data security;Resource management;Contracts;Protection;Information science;Software performance;Explosives;IP networks;Application software},
doi={10.1109/INFCOM.2001.916685},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916686,
author={D. Craig and Hwangnam Kim and R. Sivakumar and V. Bharghavan and C. Polychronopoulos},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={nanoProtean: scalable system software for a gigabit active router},
year={2001},
volume={1},
number={},
pages={51-59 vol.1},
abstract={We introduce nanoProtean, a new router operating system and execution environment that reduces system overhead, making it possible to process the packets produced by gigabit networks. The ovearhead decreases as the offered load per packet increases due to the following features in nanoProtean (i) a completely preemptable operating system, (ii) efficient management of the system's job queue, and (iii) system support for fine-grain sharing of processing time amongst packets. These features are a result of a novel integration of efficient thread scheduling for multiprocessors and interrupt handling. Experimental analysis used to test our systems scalability uses a technique to emulate processing requests generated in real-time at 802.3z (gigabit) line speeds and greater. Our results demonstrate 2 Gbps routing; with MAE-East tables on two processors, and system overheads decreasing from 3.6 /spl mu/s per packet to 1.64 /spl mu/s per packet on one processor. By reducing the system overhead, we also demonstrate that nanoProtean enables active networking in a router supporting gigabit connections.},
keywords={telecommunication computing;telecommunication network routing;packet switching;network operating systems;multiprocessing systems;processor scheduling;nanoProtean;scalable system software;gigabit active router;router operating system;router execution environment;system overhead reduction;packet processing;gigabit networks;offered load per packet;preemptable operating system;job queue management;processing time sharing;efficient thread scheduling;multiprocessors;interrupt handling;system scalability;real-time generated processing requests;802.3z line speeds;MAE-East tables;active networking;2 Gbit/s;System software;Operating systems;Yarn;Switches;Processor scheduling;Routing;Real time systems;Packet switching;Bandwidth;Hardware},
doi={10.1109/INFCOM.2001.916686},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916687,
author={Sumi Choi and J. Turner and T. Wolf},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Configuring sessions in programmable networks},
year={2001},
volume={1},
number={},
pages={60-66 vol.1},
abstract={The provision of advanced computational services within networks is rapidly becoming both feasible and economical. We present a general approach to the problem of configuring application sessions that require intermediate processing by showing how the session configuration problem can be transformed to a conventional shortest path problem for unicast sessions or to a conventional Steiner tree problem for multicast sessions. We show, through a series of examples, that the method can be applied to a wide variety of different situations.},
keywords={telecommunication network routing;multicast communication;telecommunication congestion control;trees (mathematics);programmable networks;computational services;application sessions configuration;intermediate processing;shortest path problem;unicast sessions;Steiner tree problem;multicast sessions;general purpose processing;network routers;network processor components;congestion control processing;Intelligent networks;Computer networks;Resource management;Routing;Video compression;Bandwidth;Computer science;Application software;Shortest path problem;Unicast},
doi={10.1109/INFCOM.2001.916687},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916688,
author={I. Pratt and K. Fraser},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Arsenic: a user-accessible gigabit Ethernet interface},
year={2001},
volume={1},
number={},
pages={67-76 vol.1},
abstract={Arsenic is a gigabit Ethernet NIC which exports an extended interface to the operating system and user applications. Unlike conventional adaptors, it implements some of the protection and multiplexing functions traditionally performed by the operating system. This enables applications to be given direct access to their own 'virtual interface', allowing them to send and receive packets without operating system interaction. Packet filters uploaded to the interface card by the operating system are used to demultiplex received packets to their destination application, and to validate packets before transmission. Transmit traffic shaping and scheduling mechanisms enable the bandwidth used by applications to be controlled. These features allow protocol processing to be moved into user-space shared libraries without sacrificing the security and resource management functionality that the operating system normally provides. The paper describes Arsenic's design and implementation, and outlines how it is integrated into the Linux 2.3 operating system. Performance measurements are presented that show Arsenic supports low latency, high bandwidth communication while offering greater CPU efficiency and better quality of service than conventional devices.},
keywords={local area networks;network interfaces;network operating systems;packet switching;Unix;quality of service;telecommunication traffic;software libraries;telecommunication control;performance evaluation;protocols;user-accessible gigabit Ethernet interface;Arsenic;gigabit Ethernet NIC;extended interface;user applications;protection functions;multiplexing functions;virtual interface;packet filters;interface card;received packets demultiplexing;packet transmission;packet validation;transmit traffic shaping;traffic scheduling;bandwidth control;protocol processing;user-space shared libraries;resource management;security;Linux 2.3 operating system;performance measurements;CPU efficiency;quality of service;low latency communication;high bandwidth communication;network interface cards;Ethernet networks;Operating systems;Bandwidth;Protection;Filters;Shape control;Protocols;Libraries;Communication system security;Resource management},
doi={10.1109/INFCOM.2001.916688},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916689,
author={Y. Ishibashi and S. Tasaka and H. Ogawa},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A comparison of media synchronization quality among reactive control schemes},
year={2001},
volume={1},
number={},
pages={77-84 vol.1},
abstract={This paper assesses the quality of media synchronization of recovery control schemes from asynchrony, which are referred to as reactive control schemes here, in terms of objective and subjective measures. We deal with four reactive control techniques: skipping, discarding, shortening and extension of output duration, and virtual time-contraction and time-expansion. We have carried out subjective and objective assessment of the media synchronization quality of nine schemes, which consist of combinations of the four techniques. The paper makes a comparison of media synchronization quality among the schemes. It also clarifies the relations between the two kinds of quality measures.},
keywords={video signal processing;synchronisation;telecommunication control;voice communication;multimedia communication;Internet;media synchronization quality;reactive control schemes;recovery control schemes;objective measures;subjective measures;skipping;discarding;output duration shortening;output duration extension;distributed multimedia applications;multimedia conferencing;distance learning;Internet;lip synchronization;video stream;Streaming media;Electric variables measurement;Computer aided instruction;Internet;Jitter;Timing;Lips;IP networks},
doi={10.1109/INFCOM.2001.916689},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916690,
author={S. Ramesh and Injong Rhee and K. Guo},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Multicast with cache (Mcache): an adaptive zero-delay video-on-demand service},
year={2001},
volume={1},
number={},
pages={85-94 vol.1},
abstract={This paper presents a closed-loop (demand-driven) approach towards VoD services, called multicast with caching (Mcache). Servers use multicast to reduce bandwidth usage by serving multiple requests using a single data stream. However, this requires clients to delay receiving the movie until the multicast starts. Using regional cache servers, Mcache removes initial playout delays at the clients, because the clients can receive the prefix of a requested clip from regional caches while waiting for the multicast to start. In addition, the multicast containing the later portion of the movie can wait until the prefix is played out. While this use of caches has been proposed before, the novelty of our scheme lies in that the requests coming after the multicast starts can still be batched together to be served by multicast patches without any playout delays. The use of patches has been proposed to be used either with unicast or with playout delays. Mcache effectively hires the idea of a multicast patch with caches to provide a truly adaptive VoD service whose bandwidth usage is up to par with the best known open-loop schemes under high request rates while using only minimal bandwidth under low request rates. In addition, efficient use of multicast and caches removes the need for a priori knowledge of client request rates and client disk storage requirements which some of the existing schemes assume. This makes Mcache ideal for the current heterogeneous Internet environments where those parameters are hard to predict.},
keywords={video servers;video on demand;multicast communication;Internet;adaptive systems;delays;closed loop systems;multicast with cache;adaptive zero-delay VoD service;video-on-demand service;closed-loop approach;Mcache;servers;bandwidth reduction;data stream;regional cache servers;playout delays;clip prefix reception;movie;multicast patches;unicast;high request rates;low request rates;client disk storage;heterogeneous Internet environments;Bandwidth;Network servers;Web server;Delay;Streaming media;Motion pictures;Internet;Computer science;Microelectronics;Unicast},
doi={10.1109/INFCOM.2001.916690},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916691,
author={J. Brassil and H. Schulzrinne},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Enhancing Internet streaming media with cueing protocols},
year={2001},
volume={1},
number={},
pages={95-103 vol.1},
abstract={We propose a new, media-independent protocol for including program timing, structure and identity information in Internet media streams. The protocol uses signaling messages called cues to indicate events whose timing is significant to receivers, such as the start or stop time of a media program. We describe the implementation and operation of a prototype Internet radio station which transmits program cues in audio broadcasts using the Real-Time Transport Protocol. A collection of simple yet powerful stream processing applications we implemented demonstrate how application creation is greatly eased when media streams are enriched with program cues.},
keywords={Internet;transport protocols;timing;telecommunication signalling;radio broadcasting;Internet streaming media;cueing protocols;media-independent protocol;program timing;structure information;identity information;signaling messages;receivers;start time;stop time;media program;prototype Internet radio station;program cues transmission;audio broadcasts;Real-Time Transport Protocol;stream processing applications;application creation;Internet;Streaming media;Radio broadcasting;TV broadcasting;Satellite broadcasting;Timing;Transport protocols;IP networks;Network servers;Broadcast technology},
doi={10.1109/INFCOM.2001.916691},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916692,
author={N. E. Baughman and B. N. Levine},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Cheat-proof playout for centralized and distributed online games},
year={2001},
volume={1},
number={},
pages={104-113 vol.1},
abstract={We explore exploits possible for cheating in real-time, multiplayer games for both client-server and distributed, serverless architectures. We offer the first formalization of cheating in online games and propose an initial set of strong solutions. We propose a protocol that has provable anti-cheating guarantees, but suffers a performance penalty. We then develop an extended version of this protocol, called asynchronous synchronization, which avoids the penalty, is serverless, offers provable anti-cheating guarantees, is robust in the face of packet loss, and provides for significantly increased communication performance. This technique is applicable to common game features as well as clustering and cell-based techniques for massively multiplayer games. Our performance claims are backed by analysis using a simulation based on real game traces.},
keywords={games of skill;game theory;protocols;online operation;client-server systems;synchronisation;packet switching;cheat-proof playout;distributed online games;centralized online games;real-time multiplayer games;client-server architecture;distributed serverless architecture;cheating;protocol;performance penalty;asynchronous synchronization;provable anti-cheating guarantees;packet loss;communication performance;cell-based techniques;clustering techniques;performance;real game traces;simulation;Protocols;Scalability;Performance analysis;Communication system control;Information security;Computer science;Computer architecture;Robustness;Performance loss;Analytical models},
doi={10.1109/INFCOM.2001.916692},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916693,
author={Jin Tang and G. Morabito and I. F. Akyildiz and M. Johnson},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={RCS: a rate control scheme for real-time traffic in networks with high bandwidth-delay products and high bit error rates},
year={2001},
volume={1},
number={},
pages={114-122 vol.1},
abstract={Currently there is no control for real-time traffic sources in IP networks. This is a serious problem because real-time traffic can not only congest the network but can also cause unfairness and starvation of TCP traffic. A new rate control scheme, RCS, is introduced for real-time traffic in networks with high bandwidth-delay products and high bit error rates. RCS is based on the concept of using dummy packets to probe the availability of network resources. Dummy packets are treated as low priority packets and consequently they do not affect the throughput of actual data traffic. Therefore, RCS requires all the routers in the connection path to support some priority policy. Simulation experiments show that in environments with high bandwidth-delay products and high bit error rates, RCS achieves good throughput performance without penalizing TCP connections.},
keywords={telecommunication traffic;telecommunication networks;telecommunication congestion control;error statistics;delays;transport protocols;packet switching;telecommunication network routing;RCS;rate control;IP networks;high bandwidth-delay products;high bit error rates;real-time traffic sources;unfairness;starvation;TCP traffic;dummy packets;network resources availability;low priority packets;data traffic;routers;priority policy;simulation experiments;throughput performance;BER;network congestion control;Communication system traffic control;Intelligent networks;Bit error rate;Protocols;Throughput;Delay;IP networks;Intserv networks;Bandwidth;Costs},
doi={10.1109/INFCOM.2001.916693},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916694,
author={K. Kar and S. Sarkar and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Optimization based rate control for multirate multicast sessions},
year={2001},
volume={1},
number={},
pages={123-132 vol.1},
abstract={Multirate multicasting, where the receivers of a multicast group can receive service at different rates, is an efficient mode of data delivery for many real-time applications. We address the problem of achieving rates that maximize the total receiver utility for multirate multicast sessions. This problem not only takes into account the heterogeneity in user requirements, but also provides a unified framework for diverse fairness objectives. We propose two algorithms and prove that they converge to the optimal rates for this problem. The algorithms are distributed and scalable, and do not require the network to know the receiver utilities. We discuss how these algorithms can be implemented in a real network, and also demonstrate their convergence through simulation experiments.},
keywords={multicast communication;telecommunication congestion control;optimisation;optimal control;data communication;receivers;distributed algorithms;group theory;trees (mathematics);optimization based rate control;multirate multicast sessions;multicast group;data delivery;real-time applications;receiver utility;fairness objectives;distributed algorithms;scalable algorithms;simulation experiments;congestion prices;multicast tree;Multicast algorithms;Communication system traffic control;Resource management;Educational institutions;Convergence;Teleconferencing;Multimedia communication;Broadcasting;Encoding;Internet},
doi={10.1109/INFCOM.2001.916694},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916695,
author={K. Kar and S. Sarkar and L. Tassiulas},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A simple rate control algorithm for max total user utility},
year={2001},
volume={1},
number={},
pages={133-141 vol.1},
abstract={We consider the rate control problem with the objective of maximizing the total user utility. It takes into account the possible differences in user requirements, and also provides a framework for achieving a wide range of fairness objectives. We propose a simple algorithm for achieving the optimal rates for this problem. The algorithm can be implemented in a distributed way and does not require the network to know the user utility functions. In our algorithm, the network communicates to the user the number of congested links on the user's path, and the user (end-host) adjusts its rate accordingly, taking into account its utility function and the network congestion feedback. We show through analysis and experimentation that our algorithm converges to the optimum rates.},
keywords={telecommunication congestion control;optimisation;distributed algorithms;convergence of numerical methods;protocols;packet switching;telecommunication links;feedback;max total user utility;rate control algorithm;fairness objectives;optimal rates;distributed algorithm;congested links;utility function;network congestion feedback;algorithm convergence;congestion control;ACK-based protocol;flow control;Communication system traffic control;Bandwidth;Feedback;Educational institutions;Algorithm design and analysis;Communication networks;IP networks;Web and internet services;Joining processes;Optimal control},
doi={10.1109/INFCOM.2001.916695},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916696,
author={Jian-Hao Hu and K. L. Yeung},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={FDA: a novel base station flow control scheme for TCP over heterogeneous networks},
year={2001},
volume={1},
number={},
pages={142-151 vol.1},
abstract={A novel proactive base station flow control algorithm, called forced duplicate acknowledgement (FDA), is proposed for extending TCP over wireless networks. FDA is implemented at the base station (BS) of a wireless network. It works in conjunction with existing TCP enhancement schemes such as Snoop or New Snoop. In FDA, if the average occupied buffer size at a BS exceeds a pre-defined threshold, an incipient congestion is detected. Then three forced duplicate ACKs, functioning as a congestion notification, will be generated by the BS and forwarded to a set of selected TCP senders. Upon receiving the forced duplicate ACKs, a sender reduces its transfer rate as a result of performing the fast retransmit procedure. To prevent multiple packet dropping due to buffer overflow at the BS, a quality guaranteed cache release policy is designed. The idea is to make room for the on-the-fly packets by releasing some cached but not-yet-acknowledged packets at the BS in advance. The performance of the proposed FDA is evaluated by simulations. We found that under various traffic and system configurations, FDA can not only fairly allocate the available wireless bandwidth among all TCP connections, but also achieves the highest throughput as compared to other schemes we have investigated.},
keywords={transport protocols;telecommunication congestion control;packet radio networks;telecommunication traffic;buffer storage;Internet;land mobile radio;TCP;heterogeneous networks;forced duplicate acknowledgement;proactive base station flow control algorithm;wireless networks;FDA;Snoop;New Snoop;occupied buffer size;congestion notification;congestion detection;forced duplicate ACK;transfer rate reduction;fast retransmit procedure;multiple packet dropping prevention;buffer overflow;quality guaranteed cache release policy;on-the-fly packets;performance evaluation;system configuration;traffic configuration;wireless bandwidth allocation;throughput;mobile hosts;wireless Internet access;Base stations;Bandwidth;Delay;Buffer overflow;Throughput;Force control;Protocols;Partial response channels;Computer simulation;Control systems},
doi={10.1109/INFCOM.2001.916696},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916697,
author={N. Geary and A. Antonopoulos and E. Drakopoulos and J. O'Reilly},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Analysis of optimisation issues in multi-period DWDM network planning},
year={2001},
volume={1},
number={},
pages={152-158 vol.1},
abstract={Techniques for the planning of multi-service telecommunications networks over a multi-period scenario are proposed, based on routing optimisation to reduce network cost by removing DWDM transmission systems. A model of a medium-size national network is optimised using the various techniques, and the results presented in terms of the total number of DWDM systems required and the amount of wavelength-hops (giving an indication toward the number of optical transponders required). Traffic is taken as a mix between unprotected and 1+1 SNCP optical path protected demands. Traffic growth is applied over the 5 year planning horizon to give a tenfold increase in total traffic volume for the final year. A greenfield situation is assumed, yet since deployment occurs over several years, a present value calculation is used to estimate total cost, assuming that transponders and systems are only installed when they are due to be 'lit'.},
keywords={wavelength division multiplexing;optical fibre networks;telecommunication network planning;telecommunication network routing;optimisation;telecommunication traffic;medium-size national network;optical transponders;DWDM network planning;multi-service telecommunications networks;multi-period scenario;routing optimisation;traffic growth;greenfield situation;present value calculation;total cost estimation;Intelligent networks;Wavelength division multiplexing;Synchronous digital hierarchy;Optical sensors;Telecommunication traffic;Protection;Optical fiber networks;Meeting planning;SONET;Routing},
doi={10.1109/INFCOM.2001.916697},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916698,
author={G. Maier and A. Pattavina},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Generalized space-equivalent analysis of optical cross-connect architectures},
year={2001},
volume={1},
number={},
pages={159-168 vol.1},
abstract={Optical cross-connects (OXCs) are gaining an increasing importance in high-capacity wavelength-division multiplexing networks. In this work we propose a theoretical approach for the analysis and design of these optical-switching systems. Our method is based on a space-switching equivalent representation which allows one to easily classify a general OXC architecture, identify its blocking properties and understand the trade-off between space and wavelength switching-domains. We explain this method and demonstrate its application to some of the best known OXC implementations presented so far in the literature.},
keywords={optical switches;wavelength division multiplexing;space division multiplexing;generalized space-equivalent analysis;optical cross-connect architectures;high-capacity WDM networks;wavelength-division multiplexing;optical-switching system design;optical-switching system analysis;space-switching equivalent representation;OXC architecture;blocking properties;wavelength switching-domain;space switching-domain;Optical wavelength conversion;Optical fiber networks;Wavelength division multiplexing;WDM networks;Costs;Optical design;Network topology;Space technology;Performance analysis;Optical fiber devices},
doi={10.1109/INFCOM.2001.916698},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916699,
author={Hwa-Chun Lin and Chun-Hsin Wang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A hybrid multicast scheduling algorithm for single-hop WDM networks},
year={2001},
volume={1},
number={},
pages={169-178 vol.1},
abstract={This paper shows that, for single-hop WDM networks, a multicast scheduling algorithm which always tries to partition a multicast transmission into multiple unicast or multicast transmissions may not always produce lower mean packet delay than a multicast scheduling algorithm which does not partition multicast transmissions. The performance of a multicast scheduling algorithm may depend on the traffic conditions and the availability of the channel resource in the network. A hybrid multicast scheduling algorithm that can produce good performance for wide ranges of the traffic conditions and the availability of the channel resource in the network is proposed. Depending on the average utilizations of the data channels and the receivers, the proposed hybrid multicast scheduling algorithm dynamically chooses to employ a multicast scheduling algorithm which always tries to partition multicast transmissions or a multicast scheduling algorithm which does not partition multicast transmissions. Extensive simulations are performed to study the performance of the proposed hybrid algorithm. Our simulation results show that the proposed hybrid algorithm produces lower mean packet delay for wide ranges of the load, the maximum multicast group size, the percentage of unicast traffic, and the number of data channels in the network compared with a multicast scheduling algorithm which always tries to partition multicast transmissions and a multicast scheduling which does not partition multicast transmissions.},
keywords={wavelength division multiplexing;optical fibre networks;multicast communication;packet switching;delays;telecommunication traffic;data communication;hybrid multicast scheduling algorithm;single-hop WDM networks;multicast transmission partitioning;multiple unicast transmissions;mean packet delay;traffic conditions;channel resource availability;data channels;receivers;multicast scheduling algorithm performance;simulation results;maximum multicast group size;Scheduling algorithm;WDM networks;Bandwidth;Optical coupling;Telecommunication traffic;Optical transmitters;Optical receivers;Unicast;Availability;Multicast algorithms},
doi={10.1109/INFCOM.2001.916699},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916700,
author={R. Srinivasan and A. K. Somani},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A generalized framework for analyzing time-space switched optical networks},
year={2001},
volume={1},
number={},
pages={179-188 vol.1},
abstract={Previous advances in photonic switching have paved the way for realizing all-optical time switched networks. The current technology of wavelength division multiplexing (WDM) offers bandwidth granularity that match peak electronic transmission speed by dividing the fiber bandwidth into multiple wavelengths. However, the bandwidth of a single wavelength is too large for certain traffic. Time division multiplexing (TDM) allows multiple traffic streams to share the bandwidth of a wavelength efficiently. While introducing wavelength converters and time slot interchangers improve the network blocking performance, it is often of interest to know the incremental benefits offered by every additional stage of switching. As all-optical networks in future are expected to employ heterogeneous switching architectures, it is necessary to have generalized network model that allows one to study these networks under a unified framework. In this paper, a network model, called the Trunk Switched Network (TSN), is proposed to facilitate modeling and analysis of such networks. An analytical model for evaluating the blocking performance of a class of TSN's has also been developed. Using the analytical model, it is shown that a significant performance improvement is obtained with a time-space switch with no wavelength conversion at each node in a multi-wavelength TDM switched network.},
keywords={wavelength division multiplexing;time division multiplexing;optical frequency conversion;telecommunication traffic;optical fibre networks;switching networks;generalized framework;time-space switched optical networks;photonic switching;all-optical time switched networks;wavelength division multiplexing;bandwidth granularity;WDM;fiber bandwidth;time division multiplexing;multiple traffic streams;bandwidth sharing;wavelength converters;time slot interchangers;network blocking performance;heterogeneous switching architecture;generalized network model;Trunk Switched Network;analytical model;time-space switch;multi-wavelength TDM switched network;Optical fiber networks;Optical wavelength conversion;Bandwidth;Wavelength division multiplexing;Telecommunication traffic;Time division multiplexing;Wavelength conversion;WDM networks;All-optical networks;Analytical models},
doi={10.1109/INFCOM.2001.916700},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916701,
author={A. Tzamaloukas and J. J. Garcia-Luna-Aceves},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A receiver-initiated collision-avoidance protocol for multi-channel networks},
year={2001},
volume={1},
number={},
pages={189-198 vol.1},
abstract={The medium-access control (MAC) protocols for wireless networks proposed or implemented to date based on collision-avoidance handshakes between sender and receiver either require carrier sensing or the assignment of unique codes to nodes to ensure that intended receivers hear data packets without interference from hidden sources. We present and analyze a new collision-avoidance MAC protocol that we call receiver-initiated channel-hopping with dual polling (RICH-DP). RICH-DP is the first MAC protocol based on a receiver-initiated collision-avoidance handshake that does not require carrier sensing or the assignment of unique codes to nodes In order to ensure collision-free reception of data at the intended receivers in the presence of hidden terminals. The throughput and delay characteristics of RICH-DP is studied analytically, and extensive simulations are presented to verify the analysis and to present a more accurate prediction of how RICH-DP would operate in realistic scenarios. RICH-DP is applicable to ad-hoc networks based on commercial off-the-shelf frequency hopping radios operating in the unlicensed frequency bands.},
keywords={access protocols;telecommunication channels;telecommunication networks;delays;frequency hop communication;radio receivers;packet radio networks;data communication;spread spectrum communication;multi-access systems;receiver-initiated collision-avoidance protocol;multi-channel networks;medium-access control protocols;MAC protocols;wireless networks;collision-avoidance handshakes;hidden terminals;data packets;collision-avoidance MAC protocol;receiver-initiated channel-hopping with dual polling;RICH-DP;receiver-initiated collision-avoidance handshake;delay characteristics;throughput;simulations;ad-hoc networks;commercial off-the-shelf FH radios;frequency hopping radios;unlicensed frequency bands;DS-SS radio;direct sequence spread-spectrum;Media Access Protocol;Frequency;Wireless application protocol;Wireless networks;Interference;Throughput;Delay;Analytical models;Predictive models;Ad hoc networks},
doi={10.1109/INFCOM.2001.916701},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916702,
author={S. Kandukuri and N. Bambos},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Multimodal dynamic multiple access (MDMA) in wireless packet networks},
year={2001},
volume={1},
number={},
pages={199-208 vol.1},
abstract={We investigate novel channel access schemes for packetized wireless networks, which can dynamically switch between distinct transmission modes in order to better match the channel state and deliver packets to the receiver with higher success probability (rate). We call them multimodal dynamic multiple access-MDMA schemes. Based on the observed channel impairment state (typically a combination of interference, fading, multipath, etc.) and the transmitter queue packet backlog at any time instant (slot), each user autonomously selects the best transmission mode to activate and power level to transmit at. First, a general formulation of the MDMA problem is introduced in several methodological steps of progressive complexity. It is based on dynamic programming and captures the basic tradeoffs. Analytical issues are not pursued in detail here, but instead several ubiquitous structural properties of MDMA schemes are identified and explored. Based on those, a novel suite of MDMA algorithms is designed and evaluated. On a simulated baseline scenario, MDMA is shown to achieve over 30% higher throughput than previously studied raw PCMA schemes and even higher performance gains over other standard benchmark ones. This indicates that MDMA schemes can release 'latent' network capacity which is suppressed by others, and should be further explored. This study is a first step towards designing full MDMA protocols for high-performance wireless packet networks.},
keywords={packet radio networks;multi-access systems;access protocols;multipath channels;fading channels;radiofrequency interference;radio transmitters;dynamic programming;queueing theory;telecommunication control;power control;multimodal dynamic multiple access;channel access schemes;transmission modes;channel state;success probability;channel impairment state;interference;fading;multipath;transmitter queue packet backlog;dynamic programming;structural properties;MDMA algorithms;PCMA;performance;network capacity;MDMA protocols;high-performance wireless packet networks;power control;adaptive modulation;adaptive coding;Switches;Wireless networks;Packet switching;Interference;Fading;Transmitters;Dynamic programming;Algorithm design and analysis;Throughput;Performance gain},
doi={10.1109/INFCOM.2001.916702},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916703,
author={I. Aad and C. Castelluccia},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Differentiation mechanisms for IEEE 802.11},
year={2001},
volume={1},
number={},
pages={209-218 vol.1},
abstract={The IETF is currently working on service differentiation in the Internet. However, in wireless environments where bandwidth is scarce and channel conditions are variable, IP differentiated services are sub-optimal without lower layers' support. We present three service differentiation schemes for IEEE 802.11. The first one is based on scaling the contention window according to the priority of each flow or user. The second one assigns different inter-frame spacings to different users. Finally, the last one uses different maximum frame lengths for different users. We simulate and analyze the performance of each scheme with TCP and UDP flows.},
keywords={IEEE standards;telecommunication standards;transport protocols;quality of service;access protocols;packet radio networks;differentiation mechanisms;IETF;wireless environments;bandwidth;channel conditions;IP differentiated services;contention window scaling;flow priority;inter-frame spacing;maximum frame length;TCP flow;UDP flow;performance analysis;performance simulation;IEEE 802.11 standard;medium access control;MAC sub-layer;transport control protocol;user datagram protocol;IEEE 802.11 protocol;QoS;CSMA/CD;Quality of service;Delay;Analytical models;Wireless communication;Mobile communication;Programmable logic arrays;HTML;Web and internet services;Bandwidth;Computational modeling},
doi={10.1109/INFCOM.2001.916703},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916704,
author={J. P. Monks and V. Bharghavan and W. -. W. Hwu},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A power controlled multiple access protocol for wireless packet networks},
year={2001},
volume={1},
number={},
pages={219-228 vol.1},
abstract={Multiple access-based collision avoidance MAC protocols have typically used fixed transmission power, and have not considered power control mechanisms based on the distance of the transmitter and receiver in order to improve spatial channel reuse. This work proposes PCMA, a power controlled multiple access wireless MAC protocol within the collision avoidance framework. PCMA generalizes the transmit-or-defer "on/off" collision avoidance model of current protocols to a more flexible "variable bounded power" collision suppression model. The algorithm is provisioned for ad hoc networks and does not require the presence of base stations to manage transmission power (i.e. it is decentralized). The advantage of implementing a power controlled protocol in an ad-hoc network is that source-destination pairs can be more tightly packed into the network allowing a greater number of simultaneous transmissions (spectral reuse). Our initial simulation results show that the PCMA can improve the throughput performance of the non-power controlled IEEE 802.11 by a factor of 2 with potential for additional scalability as source-destination pairs become more localized, thus providing a compelling reason for migrating to a new power controlled multiple access wireless MAC protocol standard.},
keywords={packet radio networks;access protocols;telecommunication control;power control;IEEE standards;telecommunication standards;power controlled multiple access protocol;wireless packet networks;collision avoidance MAC protocols;transmitter distance;receiver distance;spatial channel reuse;transmit-or-defer on/off collision avoidance;PCMA wireless MAC protocol;variable bounded power collision suppression model;algorithm;ad hoc networks;base stations;decentralized transmission power;spectral reuse;simulation results;throughput performance;nonpower controlled IEEE 802.11;MAC protocol standard;Access protocols;Collision avoidance;Media Access Protocol;Wireless application protocol;Ad hoc networks;Power control;Transmitters;Base stations;Energy management;Throughput},
doi={10.1109/INFCOM.2001.916704},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916705,
author={P. Radoslavov and C. Papadopoulos and R. Govindan and D. Estrin},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A comparison of application-level and router-assisted hierarchical schemes for reliable multicast},
year={2001},
volume={1},
number={},
pages={229-238 vol.1},
abstract={One possible approach to achieve scalability in reliable multicast is to use a hierarchy. A hierarchy can be established at the application level, or by using router assistance. Because the routers have more detailed knowledge about the underlying network topology, intuitively a hierarchy produced by router assistance is expected to improve performance. We test this assumption by comparing two schemes, one that uses an application-level hierarchy (ALH) and another that uses router-assisted hierarchy (RAH). Contrary to our expectations, we find that the qualitative performance of ALH is comparable to RAH when a good technique is used to build the hierarchy. We do not model the overhead of creating the hierarchy nor the cost of adding router-assistance to the network. Therefore, our conclusions inform rather than close the debate of which approach is better.},
keywords={multicast communication;telecommunication network routing;telecommunication network reliability;network topology;transport protocols;telecommunication traffic;recovery latency;exposure;reliable multicast transport protocol;scalability;network topology;application-level hierarchy;router-assisted hierarchy;qualitative performance;data traffic network overhead;control traffic network overhead;irregular multicast trees;RMTP;lightweight multicast services;Delay;Scalability;Network topology;Testing;Costs;Impedance;Building materials;Manuals;Tree data structures;Least squares approximation},
doi={10.1109/INFCOM.2001.916705},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916706,
author={Zhen Xiao and K. P. Birman},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A randomized error recovery algorithm for reliable multicast},
year={2001},
volume={1},
number={},
pages={239-248 vol.1},
abstract={An efficient error recovery algorithm is essential for a liable multicast in large groups. Tree-based protocols (RMTP, TMTP, LBRRM) group receivers into local regions and select a repair server for performing error recovery in each region. Hence a single server bears the entire responsibility of error recovery for a region. In addition, the deployment of repair servers requires topological information of the underlying multicast tree, which is generally not available at the transport layer. This paper presents RRMP, a randomized reliable multicast protocol which improves the robustness of tree-based protocols by diffusing the responsibility of error recovery among all members in a group. The protocol works well within the existing IP multicast framework and does not require additional support from routers. Both analysis and simulation results show that the performance penalty due to randomization is low and can be tuned according to application requirements.},
keywords={random processes;telecommunication network reliability;transport protocols;multicast communication;network topology;trees (mathematics);reliable multicast;randomized error recovery algorithm;efficient error recovery algorithm;tree-based protocols;RMTP;TMTP;LBRRM;receivers;repair server;local regions;topological information;multicast tree;randomized reliable multicast protocol;IP multicast framework;simulation results;performance penalty;round trip time measurements;Multicast algorithms;Multicast protocols;Computer errors;Application software;Collaborative software;Algorithm design and analysis;Error correction;Transport protocols;Computer science;Robustness},
doi={10.1109/INFCOM.2001.916706},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916707,
author={D. S. C. Kheong and Gang Feng},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Efficient setup for multicast connections using tree-caching},
year={2001},
volume={1},
number={},
pages={249-258 vol.1},
abstract={The problem of finding a minimum-cast multicast tree (Steiner tree) is known as NP-complete. Heuristic-based algorithms for this problem to achieve good performance are usually time-consuming. In this paper, we propose a new strategy called tree-caching for efficient setup of multicast connections in connection-oriented networks. In this scheme, the tree topologies that have been computed are cached in a database of the source nodes and can be used for setup of subsequent connection requests which have some common multicast members. This can reduce the connection establishment time by an efficient reuse of cached trees without having to rerun a multicast routing algorithm for the whole group. This gain is obtained by eliminating, whenever possible, the expensive tree computation algorithm that has to be performed in setting up a multicast connection. We first formulate the problem of tree-caching. We then propose a tree-caching algorithm to reduce the complexity of the tree computations when a new connection is to be established. Through simulations, we find that the proposed tree-caching strategy perform well and can significantly reduce the computation complexity for setting up multicast connections.},
keywords={multicast communication;telecommunication network routing;network topology;trees (mathematics);computational complexity;cache storage;efficient setup;multicast connections;tree-caching;minimum-cast multicast tree;Steiner tree;NP-complete problem;heuristic-based algorithms;connection-oriented networks;tree topologies;source nodes database;connection establishment time reduction;multicast routing algorithm;tree computation algorithm;tree-caching algorithm;computational complexity reduction;simulations;multicast communications;Multicast algorithms;Routing;Quality of service;Delay;Teleconferencing;Steiner trees;Minimization methods;Costs;Heuristic algorithms;Network topology},
doi={10.1109/INFCOM.2001.916707},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916708,
author={M. J. Donahoo and S. R. Ainapure},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Scalable multicast representative member selection},
year={2001},
volume={1},
number={},
pages={259-268 vol.1},
abstract={In multicast applications requiring receiver feedback, the primary impediment to receiver-set scalability stems from the feedback implosion problem. Some applications only need feedback from a single, representative receiver. For example, an adaptive video server may only need to know the video quality for the worst receiver. Soliciting a response from a receiver with the specific metric value is difficult because a receiver does not know the metric value at other receivers and, therefore, cannot assess if it should report its metric value. Previous work in feedback aggregation solicits a response from any single receiver, not a receiver with some particular metric characteristic. In addition, existing solutions exhibit high application specificity, allowing very little protocol control. We propose adaptation of two existing approaches to representative selection: backoff timers and probabilistic polls. Both adapted approaches are application independent protocols and allow control over the definition of implosion, probability of implosion, and target metric values. We explicitly consider the inherent tradeoff between implosion and delay.},
keywords={multicast communication;feedback;probability;timing;delays;transport protocols;receiver feedback;scalable multicast representative member selection;receiver-set scalability;feedback implosion problem;adaptive video server;video quality;feedback aggregation;protocol control;backoff timers;probabilistic polls;application independent protocols;implosion probability;IP multicast mechanisms;delay variation;delay minimization;Video compression;Scalability;Delay;Multicast protocols;Impedance;Streaming media;Aggregates;Feedback control;Network topology;Routing protocols},
doi={10.1109/INFCOM.2001.916708},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916709,
author={M. Van Uitert and S. Borst},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Generalised processor sharing networks fed by heavy-tailed traffic flows},
year={2001},
volume={1},
number={},
pages={269-278 vol.1},
abstract={We consider networks where traffic is served according to the generalised processor sharing (GPS) principle. GPS-based scheduling algorithms are considered important for providing differentiated quality of service in integrated-services networks. We are interested in the workload of a particular flow i at the bottleneck node on its path. Flow i is assumed to have long-tailed traffic characteristics. We distinguish between two traffic scenarios, (i) flow i generates instantaneous traffic bursts and (ii) flow i generates traffic according to an on/off process. In addition, we consider two configurations of feedforward networks. First we focus on the situation where other flows join the path of flow i. Then we extend the model by adding flows which may branch off at any node, with cross traffic as a special case. We prove that under certain conditions the tail behaviour of the workload distribution of flow i is equivalent to that in a two-node tandem network where flow i is served in isolation at constant rates. These rates only depend on the traffic characteristics of the other flows through their average rates. This means that the results do not rely on any specific assumptions regarding the traffic processes of the other flows. In particular, flow i is not affected by excessive activity of flows with 'heavier-tailed' traffic characteristics. This confirms that GPS has the potential to protect individual flows against extreme behaviour of other flows, while obtaining substantial multiplexing gains.},
keywords={queueing theory;telecommunication traffic;quality of service;processor scheduling;feedforward;generalised processor sharing networks;heavy-tailed traffic flows;GPS-based scheduling algorithms;differentiated quality of service;integrated-services networks;bottleneck node;long-tailed traffic characteristics;instantaneous traffic bursts;on/off process;feedforward networks;cross traffic;weighted fair queueing;QoS;Telecommunication traffic;Traffic control;Global Positioning System;Quality of service;Scheduling algorithm;Communication system traffic control;Mathematics;Feedforward systems;Probability distribution;Protection},
doi={10.1109/INFCOM.2001.916709},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916710,
author={B. Zwart and S. Borst and M. Mandjes},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Exact queueing asymptotics for multiple heavy-tailed on-off flows},
year={2001},
volume={1},
number={},
pages={279-288 vol.1},
abstract={We consider a fluid queue fed by multiple on-off flows with heavy-tailed (regularly varying) on-periods. Under fairly mild assumptions, we prove that the workload distribution is asymptotically equivalent to that in a reduced system. The reduced system consists of a dominant subset of the flows, with the original service rate subtracted by the mean rate of the other flows. We describe how a dominant set may be determined from a simple knapsack formulation. We exploit a powerful intuitive argument to obtain the exact asymptotics for the reduced system. Combined with the reduced-load equivalence, the results for the reduced system provide an asymptotic characterization of the buffer behavior.},
keywords={queueing theory;telecommunication traffic;knapsack problems;exact queueing asymptotics;heavy-tailed on-off flows;multiple on-off flows;workload distribution;knapsack formulation;reduced-load equivalence;buffer behavior;asymptotic characterization;fluid queue;Traffic control;Mathematics;Telecommunication traffic;Queueing analysis;Probability distribution;Time measurement;Layout;Performance analysis;Communication system traffic control;Size control},
doi={10.1109/INFCOM.2001.916710},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916711,
author={P. Jelenkovic and P. Momcilovic},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Capacity regions for network multiplexers with heavy-tailed fluid on-off sources},
year={2001},
volume={1},
number={},
pages={289-298 vol.1},
abstract={Consider a network multiplexer with a finite buffer fed by a superposition of independent heterogeneous on-off sources. An on-off source consists of a sequence of alternating independent activity and silence periods. During its activity period a source produces fluid with constant rate. For this system, under the assumption that the residual activity periods are intermediately regularly varying, we derive explicit and asymptotically exact formulas for approximating the stationary overflow probability and loss rate. The derived asymptotic formulas, in addition to their analytical tractability, exhibit excellent quantitative accuracy, which is illustrated by a number of simulation experiments. We demonstrate through examples how these results can be used for efficient computation of capacity regions for network switching elements. Furthermore, the results provide important insight into qualitative tradeoffs between the overflow probability, offered traffic load, available capacity, and buffer space. Overall, they provide a new set of tools for designing and provisioning of networks with heavy-tailed traffic streams.},
keywords={multiplexing;telecommunication traffic;queueing theory;probability;network multiplexer;heavy-tailed fluid on-off sources;independent heterogeneous on-off sources;independent activity periods;silence periods;residual activity periods;asymptotically exact formulas;stationary overflow probability;loss rate;simulation experiments;capacity regions;network switching elements;offered traffic load;available capacity;buffer space;heavy-tailed traffic streams;finite buffer fluid queue;Multiplexing;Telecommunication traffic;Traffic control;Tail;Quality of service;Streaming media;File servers;Computational modeling;Analytical models;Computer networks},
doi={10.1109/INFCOM.2001.916711},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916712,
author={C. Kotopoulos and N. Likhanov and R. R. Mazumdar},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Asymptotic analysis of GPS systems fed by heterogeneous long-tailed sources},
year={2001},
volume={1},
number={},
pages={299-308 vol.1},
abstract={In this paper we consider a multi-buffered system consisting of N buffers accessed by heterogeneous long-tailed sessions and served according to the generalized processor sharing (GPS) discipline with weights {/spl phi//sub i/}. We assume that sessions arrive according to a Poisson process. A session of type i transmits at rate r/sub i/ and has a duration whose distribution is longtailed of the form P(/spl tau//sub i/>t)/spl sim//spl alpha//sub i/t/sup -(1+/spl beta/i)/ where /spl alpha//sub i/, /spl beta//sub i/>0. We obtain the large buffer asymptotics under very general stability hypotheses. In particular we show that recent results on the GPS asymptotics obtained by Borst, Boxma and Jelenkovic (see IEEE INFOCOM, vol.2, p.912-21, 2000) can be recovered and there are important cases for which we obtain exact asymptotes for which the previous results do not apply. The methodology exploits the sample-path description of the workload evolution under GPS as well as the marked Poisson structure of the inputs.},
keywords={queueing theory;telecommunication traffic;asymptotic stability;processor scheduling;buffer storage;stochastic processes;asymptotic analysis;N-queue GPS system;heterogeneous long-tailed source;multi-buffered system;heterogeneous long-tailed sessions;generalized processor sharing;Poisson process;buffer asymptotics;general stability hypotheses;sample-path description;workload evolution;Global Positioning System;Telecommunication traffic;Buffer overflow;Probability distribution;Asymptotic stability;IP networks;Stochastic processes;Traffic control;Internet;Statistical analysis},
doi={10.1109/INFCOM.2001.916712},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916713,
author={R. K. Balan and B. P. Lee and K. R. R. Kumar and L. Jacob and W. K. G. Seah and A. L. Ananda},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={TCP HACK: TCP header checksum option to improve performance over lossy links},
year={2001},
volume={1},
number={},
pages={309-318 vol.1},
abstract={Wireless networks have become increasingly common and an increasing number of devices are communicating with each other over lossy links. Unfortunately, TCP performs poorly over lossy links as it is unable to differentiate the loss due to packet corruption from that due to congestion. We present an extension to TCP which enables TCP to distinguish packet corruption from congestion in lossy environments resulting in improved performance. We refer to this extension as the HeAder ChecKsum option (HACK). We implemented our algorithm in the Linux kernel and performed various tests to determine its effectiveness. Our results have shown that HACK performs substantially better than both SACK and NewReno in cases where burst corruptions are frequent. We also found that HACK can co-exist very nicely with SACK and performs even better with SACK enabled.},
keywords={transport protocols;radio networks;radio links;packet radio networks;telecommunication congestion control;Unix;TCP HACK;algorithm;lossy links performance;wireless networks;packet corruption;congestion;TCP header checksum option;Linux kernel;SACK;NewReno;burst corruption;mobile computing;client-server network;Computer hacking;Performance loss;TCPIP;Jacobian matrices;Wireless networks;Wireless application protocol;Bit error rate;IP networks;Computer networks;Linux},
doi={10.1109/INFCOM.2001.916713},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916714,
author={G. T. Wong and M. A. Hiltunen and R. D. Schlichting},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A configurable and extensible transport protocol},
year={2001},
volume={1},
number={},
pages={319-328 vol.1},
abstract={The ability to configure transport protocols from collections of smaller software modules allows the characteristics of the protocol to be customized for a specific application or network technology. This paper describes an approach to building such customized protocols using Cactus, a system in which micro-protocols implementing individual attributes of transport can be combined into a composite protocol that realizes the desired overall functionality. In contrast with similar systems, Cactus supports non-hierarchical module composition and event-driven execution, both of which increase flexibility and allow finer-grain modules implementing orthogonal properties. To illustrate this approach, the design and implementation of a configurable transport protocol called CTP is presented. CTP allows customization of a number of properties including reliable transmission, congestion detection and control, jitter control, and message ordering. This suite of micro-protocols has been implemented using Cactus/C 2.0 on Red Hat Linux 6.2, with initial experimental results indicating that the ability to target the guarantees more precisely to the needs of applications can in fact result in better performance.},
keywords={transport protocols;Unix;telecommunication congestion control;jitter;extensible transport protocol;configurable transport protocol;software modules;network technology;customized protocols;micro-protocols;composite protocol;nonhierarchical module composition;event-driven execution;orthogonal properties;CTP;reliable transmission;congestion detection;congestion control;message ordering;Cactus/C 2.0;Red Hat Linux 6.2;performance;Transport protocols;Linux;Prototypes;Computer science;Application software;Jitter;Wireless networks;Standards development;Bandwidth;Streaming media},
doi={10.1109/INFCOM.2001.916714},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916715,
author={L. Alvisi and T. C. Bressoud and A. El-Khashab and K. Marzullo and D. Zagorodnov},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Wrapping server-side TCP to mask connection failures},
year={2001},
volume={1},
number={},
pages={329-337 vol.1},
abstract={We present an implementation of a fault-tolerant TCP (FT-TCP) that allows a faulty server to keep its TCP connections open until it either recovers or it is failed over to a backup. The failure and recovery of the server process are completely transparent to client processes connected with it via TCP. FT-TCP does not affect the software running on a client, does not require to change the server's TCP implementation, and does not use a proxy.},
keywords={transport protocols;network servers;computer network reliability;fault tolerant computing;system recovery;connection failures masking;fault-tolerant TCP;FT-TCP;backup;server failure;server recovery;software;low overhead;throughput;latency;Wrapping;Application software;Checkpointing;Fault tolerance;Computer science;Bidirectional control;Design engineering;Control systems;Costs;Computer bugs},
doi={10.1109/INFCOM.2001.916715},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916716,
author={Kihong Park and Heejo Lee},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={On the effectiveness of probabilistic packet marking for IP traceback under denial of service attack},
year={2001},
volume={1},
number={},
pages={338-347 vol.1},
abstract={Effective mitigation of denial of service (DoS) attack is a pressing problem on the Internet. In many instances, DoS attacks can be prevented if the spoofed source IP address is traced back to its origin which allows assigning penalties to the offending party or isolating the compromised hosts and domains from the rest of the network. IP traceback mechanisms based on probabilistic packet marking (PPM) have been proposed for achieving traceback of DoS attacks. We show that probabilistic packet marking-of interest due to its efficiency and implementability vis-a-vis deterministic packet marking and logging or messaging based schemes-suffers under spoofing of the marking field in the IP header by the attacker which can impede traceback by the victim. We show that there is a trade-off between the ability of the victim to localize the attacker and the severity of the DoS attack, which is represented as a function of the marking probability, path length, and traffic volume. The optimal decision problem-the victim can choose the marking probability whereas the attacker can choose the spoofed marking value, source address, and attack volume-can be expressed as a constrained minimax optimization problem, where the victim chooses the marking probability such that the number of forgeable attack paths is minimized. We show that the attacker's ability to hide his location is curtailed by increasing the marking probability, however, the latter is upper-bounded due to sampling constraints. In typical IP internets, the attacker's address can be localized to within 2-5 equally likely sites which renders PPM effective against single source attacks. Under distributed DoS attacks, the uncertainty achievable by the attacker can be amplified, which diminishes the effectiveness of PPM.},
keywords={transport protocols;Internet;telecommunication security;security of data;probability;telecommunication traffic;optimisation;packet switching;minimax techniques;probabilistic packet marking;IP traceback;distributed denial of service attack;Internet;spoofed source IP address;deterministic packet marking;deterministic packet logging;messaging based schemes;spoofing;IP header;path length;traffic volume;optimal decision problem;spoofed marking value;source address;attack volume;constrained minimax optimization problem;forgeable attack paths;sampling constraints;IP internets;Computer crime;Impedance;Pressing;IP networks;Web and internet services;Web server;Quality of service;Computer networks;Intelligent networks;Minimax techniques},
doi={10.1109/INFCOM.2001.916716},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916717,
author={E. Modiano and A. Narula-Tam},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Survivable routing of logical topologies in WDM networks},
year={2001},
volume={1},
number={},
pages={348-357 vol.1},
abstract={Network restoration is often done at the electronic layer by rerouting traffic along a redundant path. With wavelength division multiplexing (WDM) as the underlying physical layer, it is possible that both the primary and backup paths traverse the same physical links and would fail simultaneously in the event of a link failure. It is therefore critical that lightpaths are routed in such a way that a single link failure would not disconnect the network. We call such a routing survivable and develop algorithms for survivable routing of a logical topology. We prove necessary and sufficient conditions for a routing to be survivable and use this condition to formulate the problem as an integer linear program. We use our new formulation to route various logical topologies over a number of different physical topologies and show that this new approach offers a much greater degree of protection than alternative routing schemes such as shortest path routing and a greedy routing algorithm.},
keywords={wavelength division multiplexing;optical fibre networks;telecommunication network routing;network topology;telecommunication traffic;integer programming;linear programming;telecommunication network reliability;logical topologies;WDM networks;survivable routing;network restoration;electronic layer;traffic rerouting;redundant path;wavelength division multiplexing;physical layer;primary paths;backup paths;physical links;link failure;lightpath routing;necessary conditions;sufficient conditions;integer linear program;physical topologies;shortest path routing;greedy routing algorithm;Network topology;Intelligent networks;WDM networks;Wavelength division multiplexing;Protection;Laboratories;Wavelength routing;Wavelength assignment;Joining processes;Internet},
doi={10.1109/INFCOM.2001.916717},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916718,
author={M. Kodialam and T. V. Lakshman},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Integrated dynamic IP and wavelength routing in IP over WDM networks},
year={2001},
volume={1},
number={},
pages={358-366 vol.1},
abstract={This paper develops an algorithm for integrated dynamic routing of bandwidth guaranteed paths in IP over WDM networks. By integrated routing, we mean routing taking into account the combined topology and resource usage information at the IP and optical layers. Typically, routing in IP over WDM networks has been separated into routing at the IP layer taking only IP layer information into account, and wavelength routing at the optical layer taking only optical network information into account. The motivation for integrated routing is the potential for better network usage, and this is a topic which has not been been studied extensively. We develop an integrated routing algorithm that determines (1) whether to route an arriving request over the existing topology or whether it is better to open new wavelength paths. Sometimes it is better to open new wavelength paths even if it feasible to route the current demand over the existing IP topology due to previously set-up wavelength paths. 2) For routing over the existing IP-level topology, compute "good" routes. (3) If new wavelength paths are to be set-up, determine the routers amongst which new wavelength paths are to be set-up and compute "good" routes for these new wavelength paths. The performance objective is the accomodation of as many requests as possible without requiring any a priori knowledge regarding future arrivals. The route computations account for the presence or absence of wavelength conversion capabilities at optical crossconnects. We show that the developed scheme performs very well in terms of performance metrics such as the number of rejected demands.},
keywords={telecommunication network routing;Internet;wavelength division multiplexing;network topology;optical fibre networks;WDM networks;integrated dynamic routing;bandwidth guaranteed paths;dynamic IP;topology;resource usage;network usage;performance;wavelength conversion capabilities;optical crossconnects;rejected demands;wavelength routing;Internet;Wavelength routing;Wavelength division multiplexing;Optical wavelength conversion;WDM networks;Network topology;Optical fiber networks;Heuristic algorithms;Bandwidth;Integrated optics;Optical computing},
doi={10.1109/INFCOM.2001.916718},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916719,
author={S. S. Lumetta and M. Medard},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Towards a deeper understanding of link restoration algorithms for mesh networks},
year={2001},
volume={1},
number={},
pages={367-375 vol.1},
abstract={We study the relationship between failure localization and the properties of link restoration algorithms, employing a quantitative measure of a network's ability to recover from two-link failures. This model allows us to consider issues of failure localization that cannot be addressed through models that assume only single failures. Based on the relationship between algorithmic properties and restoration failures, we construct a failure classification hierarchy that provides insight as to the relative value of advances in algorithm design. Finally, we apply this classification scheme to three networks from the literature and discuss the results in terms of their importance for link restoration algorithms. We find that the topological constraints on restoration paths required by algorithms that embed rings within mesh networks result in significant degradation of failure localization. The preselection of restoration paths (as opposed to selection at the time of failure) also has a negative impact, although it is not as significant as the topological effect. Algorithms that make use of the mesh topology and dynamically route around existing failures come close to an inherent limit imposed by the complexity of additional algorithmic advances.},
keywords={network topology;telecommunication network reliability;link restoration algorithms;mesh networks;failure localization;two-link failures;failure classification hierarchy;algorithm design;ring;restoration paths;topological effect;Mesh networks;Network topology;Algorithm design and analysis;Degradation;High-speed networks;Coordinate measuring machines;Fluid dynamics;Telecommunication network reliability;Protection},
doi={10.1109/INFCOM.2001.916719},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916720,
author={M. Kodialam and T. V. Lakshman},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Dynamic routing of locally restorable bandwidth guaranteed tunnels using aggregated link usage information},
year={2001},
volume={1},
number={},
pages={376-385 vol.1},
abstract={We consider a new QoS routing problem which requires the on-line routing of a bandwidth guaranteed path along with the setting up of bypass paths for every link or node traversed by the primary active path. The bypass paths are used for fast local restoration where upon a link or node failure, the first upstream node re-establishes path continuity (with bandwidth guarantees) by switching to the bypass path for the failed node or link, The routing objective is to minimize the bandwidth usage for each connection so as optimize use of network resources while protecting against single node or link failure. Bandwidth efficiency is achieved by exploiting the potential for inter-demand and intra-demand backup bandwidth sharing. We develop a new algorithm for this routing problem which only uses aggregated link usage information (total bandwidth consumed on each link by active paths, total bandwidth consumed on each link by backup paths, and the residual bandwidths) that is easily obtainable by proposed routing protocol extensions. We show that the algorithm performs well in terms of the number of rejected requests and the total bandwidth used, The main use of this algorithm is for MPLS network routing and for wavelength routing in optical networks with wavelength conversion.},
keywords={telecommunication network routing;protocols;telecommunication network reliability;quality of service;optical fibre networks;dynamic routing;locally restorable bandwidth guaranteed tunnels;aggregated link usage information;MPLS;multi protocol label switching;dynamic provisioning;bandwidth guaranteed paths;wavelength paths;backup paths;service provider requirement;resource utilization;sharing performance;traffic engineering extensions;routing protocols;shortest path computations;Bandwidth;Multiprotocol label switching;Telecommunication traffic;Heuristic algorithms;Switches;Routing protocols;Aggregates;Paper technology;Optical propagation;Wavelength routing},
doi={10.1109/INFCOM.2001.916720},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916721,
author={B. Prabhakar and E. Uysal Biyikoglu and A. El Gamal},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Energy-efficient transmission over a wireless link via lazy packet scheduling},
year={2001},
volume={1},
number={},
pages={386-394 vol.1},
abstract={The paper considers the problem of minimizing the energy used to transmit packets over a wireless link via lazy schedules that judiciously vary packet transmission times. The problem is motivated by the following key observation: in many channel coding schemes, the energy required to transmit a packet can be significantly reduced by lowering the transmission power and transmitting the packet over a longer period of time. However, information is often time-critical or delay-sensitive and transmission times cannot be made arbitrarily long. We therefore consider packet transmission schedules that minimize energy subject to a deadline or a delay constraint. Specifically, we obtain an optimal offline schedule for a node operating under a deadline constraint. An inspection of the form of this schedule naturally leads us to an online schedule which is shown, through simulations, to be energy-efficient. Finally, we relax the deadline constraint and provide an exact probabilistic analysis of our offline scheduling algorithm. We then devise a lazy online algorithm that varies transmission times according to backlog and show that it is more energy efficient than a deterministic schedule that guarantees stability for the same range of arrival rates.},
keywords={radio links;packet radio networks;channel coding;delays;data communication;optimisation;energy-efficient transmission;wireless link;lazy packet scheduling;energy minimization;packet transmission times;channel coding;transmission power;packet transmission schedules;wireless data network;delay constraint;optimal offline schedule;deadline constraint;online schedule;simulations;exact probabilistic analysis;offline scheduling algorithm;lazy online algorithm;deterministic schedule;stability guarantee;arrival rates;energy conservation;Energy efficiency;Scheduling algorithm;Wireless sensor networks;Batteries;Power control;Delay;Signal processing algorithms;Signal processing;Interference;Information systems},
doi={10.1109/INFCOM.2001.916721},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916722,
author={S. Ulukus and E. Biglieri and M. Z. Win},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Optimum modulation and multicode formats in CDMA systems with multiuser receivers},
year={2001},
volume={1},
number={},
pages={395-402 vol.1},
abstract={We study the problem of maximizing the total system throughput under a bit error rate constraint for all users in the uplink of a single-cell synchronous CDMA system. Users realize variable bit rates by using a combination of multicode transmission and adaptive QAM modulation. We assume random signature sequences for all users, and perform an asymptotic analysis. We parametrize each user's resource allocation scheme by two parameters, viz., the number of signatures the user transmits with and the number of signal points in the user's QAM constellation, and optimize the total throughput over this parameter space. We examine four different settings: single-user matched filter (SUMF) and minimum-mean-square error (MMSE) receiver at the base station, with and without maximum power constraints. For a single user system, we describe the jointly optimum number of multicodes and constellation sizes for these four different system models. When multiple users are present, we show that the total throughput is maximized when only one user transmits: with no maximum power constraints this user can be chosen arbitrarily, otherwise it should be the one with the largest SNR. This solution, although optimal in the sense of maximizing the total throughput, is unfair to all but one user: thus, we examine a scheduling mechanism that assigns equal time frames to all users, thus yielding maximum fairness, and discuss the resulting total throughput loss.},
keywords={code division multiple access;radio receivers;multiuser channels;radio links;adaptive modulation;codes;quadrature amplitude modulation;random processes;sequences;matched filters;least mean squares methods;filtering theory;noise;cellular radio;error statistics;optimum modulation format;optimum multicode format;multicode transmission;multiuser receivers;total system throughput;bit error rate constraint;BER constraint;uplink;single-cell synchronous CDMA system;adaptive QAM modulation;random signature sequences;asymptotic analysis;resource allocation;signal points;QAM constellation;parameter space;single-user matched filter;minimum-mean-square error;MMSE receiver;base station;maximum power constraints;single user system;constellation size;system models;total throughput;SNR;scheduling mechanism;maximum fairness;total throughput loss;cellular radio;Multiaccess communication;Throughput;Quadrature amplitude modulation;Bit error rate;Code division multiplexing;Bit rate;Performance analysis;Resource management;Constellation diagram;Matched filters},
doi={10.1109/INFCOM.2001.916722},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916723,
author={Chenxi Zhu and M. S. Corson},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A distributed channel probing scheme for wireless networks},
year={2001},
volume={1},
number={},
pages={403-411 vol.1},
abstract={This paper presents a distributed channel probing scheme for wireless networks. By transmitting a probing signal in a channel and measuring the signal-to-interference ratio (SIR), a wireless node can estimate channel admissibility and predict its required transmission power without fully powering up. The channel probing scheme can be used as part of a distributed channel allocation algorithm, and simulations have shown that it outperforms other schemes.},
keywords={radio networks;channel allocation;distributed algorithms;radiofrequency interference;telecommunication control;power control;time division multiple access;frequency division multiple access;multiuser channels;wireless networks;distributed channel probing;probing signal transmission;signal-to-interference ratio;SIR measurement;wireless node;channel admissibility estimation;transmission power;distributed channel allocation algorithm;simulations;TDMA/FDMA system;power control;Wireless networks;Transmitters;Channel allocation;Power control;Interference;Time division multiple access;Educational institutions;Power measurement;Admission control;Probes},
doi={10.1109/INFCOM.2001.916723},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916724,
author={Mingbo Xiao and N. B. Shroff and E. K. P. Chong},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Utility-based power control in cellular wireless systems},
year={2001},
volume={1},
number={},
pages={412-421 vol.1},
abstract={Distributed power control algorithms for systems with hard SIR constraints may diverge when infeasibility arises. We present a power control framework called utility-based power control (UBPC) by reformulating the problem using a softened SIR requirement (utility) and adding a penalty on power consumption (cost). Under this framework, the goal is to maximize the net utility, defined as utility minus cost. Although UBPC is still non-cooperative and distributed in nature, some degree of cooperation emerges: a user will automatically decrease its target SIR (and may even turn off transmission) when it senses that traffic congestion is building up. This framework enables us to improve the system convergence and to satisfy heterogeneous service requirements (such as delay and bit error rate) for integrated networks with both voice users and data users. Fairness, adaptiveness, and a high degree of flexibility can be achieved by properly tuning parameters in UBPC.},
keywords={cellular radio;radio networks;telecommunication control;power control;telecommunication traffic;distributed control;radiofrequency interference;integrated voice/data communication;adaptive systems;utility-based power control;cellular wireless systems;distributed power control algorithms;hard SIR constraints;softened SIR requirement;power consumption;cost;net utility maximisation;noncooperative power control;distributed power control;traffic congestion;system convergence;heterogeneous service requirements;delay;bit error rate;integrated networks;integrated voice/data communication;tuning parameters;fairness;radio resource management;adaptive price setting;Power control;Quality of service;Energy consumption;Convergence;Distributed algorithms;Resource management;Cost function;Distributed computing;Power engineering computing;Power engineering and energy},
doi={10.1109/INFCOM.2001.916724},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916725,
author={J. Snoeyink and S. Suri and G. Varghese},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A lower bound for multicast key distribution},
year={2001},
volume={1},
number={},
pages={422-431 vol.1},
abstract={With the rapidly growing importance of multicast in the Internet there have been a proposal, the RFC 2627, for scalable key distribution such that when the nth user joins or leaves a group, broadcasting /spl Theta/(logn) encrypted messages is sufficient to redistribute the keys. We show that this bound is also necessary for a general class of key distribution schemes and under different assumptions on user capabilities. While key distribution schemes can trade addition cost for deletion cost, for any scheme there is a sequence of 2n insertion and deletions whose total cost is /spl Omega/(nlogn). Thus, any key distribution scheme has a worst-case cost of /spl Omega/(logn) either for adding or for deleting a user.},
keywords={multicast communication;cryptography;Internet;telecommunication security;graph theory;multicast key distribution;lower bound;Internet;scalable key distribution;encrypted message broadcasting;addition cost;deletion cost;total cost;worst-case cost;key graph;Internet protocol;group security;key storage;communication costs;graph models;key distribution algorithms;data encryption;Satellite broadcasting;TV broadcasting;Multicast protocols;Costs;Web and internet services;Proposals;Security;Lifting equipment;Cryptography;Teleconferencing},
doi={10.1109/INFCOM.2001.916725},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916726,
author={P. Lassila and J. Karvo and J. Virtamo},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Efficient importance sampling for Monte Carlo simulation of multicast networks},
year={2001},
volume={1},
number={},
pages={432-439 vol.1},
abstract={We consider the problem of estimating blocking probabilities in a multicast loss system via simulation, applying the static Monte Carlo method with importance sampling. An approach is introduced where the original estimation problem is first decomposed into independent simpler sub-problems, each roughly corresponding to estimating the blocking probability contribution from a single link. Then we apply importance sampling to solve each sub-problem. The importance sampling distribution is the original distribution conditioned on that the state is in the blocking state region of a single link. Samples can be generated from this distribution using the so called inverse convolution method. Finally, a dynamic control algorithm is used for optimally allocating the samples between different sub-problems. The numerical results demonstrate that the variance reduction obtained with the method is remarkable, between 400 and 36000 in the considered examples.},
keywords={multicast communication;importance sampling;telecommunication networks;probability;convolution;inverse problems;telecommunication control;digital simulation;efficient importance sampling;Monte Carlo simulation;multicast networks;blocking probability estimation;multicast loss system;static Monte Carlo method;sub-problems;importance sampling distribution;blocking state region;inverse convolution method;dynamic control algorithm;variance reduction;optimal sample allocation;Monte Carlo methods;Convolution;Multicast algorithms;Switched systems;Laboratories;Optimal control;Heuristic algorithms;Probability;Circuits;Unicast},
doi={10.1109/INFCOM.2001.916726},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916727,
author={R. Cohen and G. Kaempfer},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={A unicast-based approach for streaming multicast},
year={2001},
volume={1},
number={},
pages={440-448 vol.1},
abstract={Network layer multicast is know as the most efficient way to support multicast sessions. However, for security, QoS and other considerations, most of the real-time application protocols can be better served by upper layer (transport or application) multicast. We propose a scheme called M-RTP for multicast RTP sessions. The idea behind this scheme is to set up the multicast RTP session over a set of unicast RTP sessions, established between the various participants (source and destinations) of the multicast session. We then address the issue of finding a set of paths with maximum bottleneck for an M-RTP session. We show that this problem is NP-complete, and propose several heuristics to solve it.},
keywords={transport protocols;computational complexity;quality of service;telecommunication network routing;unicast-based approach;multicast streaming;network layer multicast;security;QoS;real-time application protocols;upper layer multicast;M-RTP;multicast RTP sessions;unicast RTP sessions;maximum bottleneck paths;NP-complete problem;Internet;multicast routing;real time control protocol;QoS provisioning;multicast tree;minimum path set problem;widest path heuristic;double tree heuristic;approximation ratio;average performance;Unicast;Multicast protocols;Routing;Telecommunication traffic;Computer science;Operating systems;Application software;Transport protocols;Internet;Multicast algorithms},
doi={10.1109/INFCOM.2001.916727},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916734,
author={R. C. Chalmers and K. C. Almeroth},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Modeling the branching characteristics and efficiency gains in global multicast trees},
year={2001},
volume={1},
number={},
pages={449-458 vol.1},
abstract={We investigate two issues. First, what level of efficiency gain does multicast offer over unicast? Second, how does the shape of multicast trees impact multicast efficiency? We address the first issue by developing a metric to measure multicast efficiency for a number of real and synthetic datasets. We find that group sizes as small as 20 to 40 receivers offer a 60-70% reduction in the number of links traversed compared to separately delivered unicast streams. Addressing the second issue, we have found that almost all multicast trees have similar characteristics in terms of key parameters such as depth, degree frequency and average degree. A final contribution of our work is that we have taken multicast group membership data and multicast path data and compiled datasets which can be used to generate large, realistic multicast trees.},
keywords={multicast communication;trees (mathematics);network topology;packet switching;branching characteristics;efficiency gains;global multicast trees;multicast efficiency;real datasets;synthetic datasets;group sizes;receivers;unicast streams;depth;degree frequency;average degree;multicast group membership data;multicast path data;tree topology;packet duplication;Unicast;Bandwidth;Shape;Frequency;Internet;Character generation;Assembly;Topology;Computer science;Tree data structures},
doi={10.1109/INFCOM.2001.916734},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916736,
author={C. A. Courcoubetis and A. Dimakis and M. I. Reiman},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Providing bandwidth guarantees over a best-effort network: call-admission and pricing},
year={2001},
volume={1},
number={},
pages={459-467 vol.1},
abstract={This paper introduces a framework for answering questions regarding the conditions on the network load that allow a best-effort network like the Internet to support connections of given duration that require a certain quality of service. Such quality of service is expressed in terms of the percentage of time the bandwidth allocated to a connection may drop below a certain level or the maximum allowable delay in placing the call through the network waiting for more favorable loading conditions. The call-acceptance conditions, which depend on the behavior of the system over the lifetime of accepted calls, are thus based on transient models for the congestion (instead of looking at the average behavior) and attempt to exploit the time-scales of the fluctuations of the number of connections competing for bandwidth. Extensions of the model consider the case of dynamic pricing which allows connections that pay more to get larger shares of the bandwidth, and investigate the trade-off between quality of service, the size of the acceptance region, and the charge to be paid by the connection. Under this framework we introduce an option contract that reduces the risk of quality disruption, if a user has a fixed budget at his disposal, and calculate its price. One potential use of this methodology is towards developing a simple admission control mechanism for placing voice calls through an IP network, where the decisions can be taken by edge devices.},
keywords={Internet;quality of service;telecommunication congestion control;delays;costing;tariffs;transport protocols;bandwidth guarantees;best-effort network;call-admission;pricing;network load conditions;Internet;quality of service;QoS;bandwidth allocation;maximum allowable delay;loading conditions;call-acceptance conditions;congestion transient models;dynamic pricing;acceptance region size;option contract;budget;voice calls;IP network;edge devices;Bandwidth;Pricing;IP networks;Quality of service;Web and internet services;Delay effects;Admission control;Informatics;Computer networks;Electronic mail},
doi={10.1109/INFCOM.2001.916736},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916738,
author={D. Nandita and J. Kuri and H. S. Jamadagni},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Optimal call admission control in generalized processor sharing (GPS) schedulers},
year={2001},
volume={1},
number={},
pages={468-477 vol.1},
abstract={Generalized processor sharing (GPS) is an idealized fluid discipline with a number of desirable properties. Its packetized version PGPS is considered to be a good choice is a packet scheduling discipline to guarantee quality-of-service in IP and ATM networks. The existing connection admission control (CAC) frameworks for GPS result in a conservative resource allocation. We propose an optimal CAC algorithm for a GPS scheduler, for leaky-bucket constrained connections with deterministic delay guarantees. Our numerical results show that the optimal CAC results in a higher network utilization than the existing CACs.},
keywords={telecommunication congestion control;asynchronous transfer mode;packet switching;quality of service;transport protocols;optimisation;delays;telecommunication traffic;optimal call admission control;generalized processor sharing;GPS schedulers;packet scheduling;packetized generalized processor sharing;quality-of-service;QoS guarantee;IP networks;ATM networks;connection admission control;conservative resource allocation;optimal CAC algorithm;leaky-bucket constrained connections;deterministic delay guarantees;network utilization;Call admission control;Global Positioning System;Processor scheduling;Delay;Traffic control;Bandwidth;Scheduling algorithm;Quality of service;Resource management;Channel allocation},
doi={10.1109/INFCOM.2001.916738},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916739,
author={Teck Kiong Lee and M. Zukerman and R. G. Addie},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Admission control schemes for bursty multimedia traffic},
year={2001},
volume={1},
number={},
pages={478-487 vol.1},
abstract={We introduce a new framework for various measurement-based connection admission control (MBCAC) schemes for a multiservice network. Then, using heterogeneous bursty multimedia traffic traces, efficiency and simplicity tradeoffs are obtained by simulations. For all our MBCAC schemes, we use a procedure of 'available bandwidth' evaluation based on online measurements and an adaptive feedback mechanism. The online measurement concept is based on the use of different 'traffic histograms' that maintain records of the aggregated traffic in a link over a range of time-scales. The most complex MBCAC scheme involves measuring and then storing of all traffic information for every connection, the use of a 'warming up period' technique, and updating the histograms when a connection departs. However, for the other simpler MBCAC schemes, various aspects of the most complex scheme are eliminated or simplified. We also consider two model-based CAC schemes, i.e., Gaussian and effective bandwidth, where a priori statistical knowledge of the connections are known in advance. Given that the traffic is known beforehand, the performance of such schemes will be better than if the statistics are not exactly known. A comparison between such model-based CAC schemes with our MBCAC schemes provides a benchmark that gives the best efficiency and QoS a model-based CAC may achieve. Simulation results demonstrate that while the best efficiency achievable by the model-based gives efficiency of 80%, the most complex MBCAC schemes achieved 81% efficiency, and the simplest MBCAC schemes obtained 76% value.},
keywords={multimedia communication;telecommunication congestion control;telecommunication traffic;telecommunication services;telecommunication networks;feedback;adaptive systems;asynchronous transfer mode;packet switching;multiservice network;efficiency;measurement-based connection admission control;heterogeneous bursty multimedia traffic traces;simulations;available bandwidth;online measurements;adaptive feedback mechanism;traffic histograms;aggregated traffic;traffic information;warming up period;histograms updating;model-based CAC schemes;effective bandwidth model;Gaussian model-based approach;QoS;simulation results;ATM;Admission control;Histograms;Telecommunication traffic;Bandwidth;Traffic control;Communication system traffic control;Mathematics;Statistics;Bit rate;Electrical capacitance tomography},
doi={10.1109/INFCOM.2001.916739},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916750,
author={M. Veeraraghavan and N. Cocker and T. Moors},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Support of voice services in IEEE 802.11 wireless LANs},
year={2001},
volume={1},
number={},
pages={488-497 vol.1},
abstract={The IEEE 802.11 MAC protocol supports two modes of operation, a random access mode for non-real-time data applications, and a polling mode for real-time applications. We design and analyze a system that uses the polling mode for interactive voice traffic. With larger inter-poll periods, more voice calls can be accommodated, but at the expense of increased delay. For example, our analysis shows that with an inter-poll period of 90 ms, a maximum of 26 voice calls can be handled with a worst-case delay of 303 ms, whereas with an inter-poll period of 60 ms, a maximum of 17 voice calls can be handled with a worst-case delay of 213 ms. We also carry out an error analysis that demonstrates the need for error correction of voice packets.},
keywords={IEEE standards;telecommunication standards;wireless LAN;access protocols;telecommunication traffic;delays;packet radio networks;voice communication;IEEE 802.11 wireless LAN;voice services;MAC protocol;random access mode;nonreal-time data applications;polling mode;real-time applications;system design;system analysis;interactive voice traffic;inter-poll periods;voice calls;delay;worst-case delay;error analysis;error correction;voice packets;Wireless LAN;Local area networks;Spread spectrum communication;Error correction;Infrared spectra;Collision avoidance;Multiaccess communication;Payloads},
doi={10.1109/INFCOM.2001.916750},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916752,
author={A. Clerget and W. Dabbous},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={TUF: tag-based unified fairness},
year={2001},
volume={1},
number={},
pages={498-507 vol.1},
abstract={Finding an appropriate end-to-end congestion control scheme for each type of flow, such as real-time or multicast flows, may be difficult. But it becomes even more complex to have these schemes be friendly among themselves and with TCP. The assistance of routers within the network for fair bandwidth sharing among the flows is therefore helpful. However, most of the existing mechanisms that provide this fair sharing imply complex buffer management and maintaining flow state in the routers. We propose to realize this fair bandwidth sharing without per-flow state in the routers, using only a trivial queueing discipline. Packets are tagged near the source, depending on the nature of the flow. In the core of the network, routers use FIFO queues, and simply drop the packet with the highest tag value in case of congestion. Contrarily to other stateless fair queueing algorithms in the core routers, we do not try to maintain instantaneous flow rates equal. Instead, we take into account the responsiveness nature of the flows, and adjust loss rates such that average rates are equal. The novel approach of our scheme, called TUF, tag-based unified fairness, not only improves the overall fairness but enables us to maintain it in realistic environments, with non-negligible round trip times or bursty traffic, where other schemes fail. The corresponding cost is the need for models of the end to-end responsive natures of the flows.},
keywords={telecommunication congestion control;multicast communication;queueing theory;transport protocols;telecommunication network routing;buffer storage;packet switching;telecommunication traffic;end-to-end congestion control;real-time flows;multicast flows;TCP;network routers;fair bandwidth sharing;buffer management;queueing discipline;tag-based unified fairness;FIFO queues;packet tagging;packet dropping;stateless fair queueing algorithms;core routers;loss rates;round trip times;bursty traffic;Internet;Bandwidth;Delay;Protocols;Communication system traffic control;Traffic control;Costs;Internet;Linear predictive coding;GSM;Aggregates},
doi={10.1109/INFCOM.2001.916752},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916754,
author={A. Hu},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Video-on-demand broadcasting protocols: a comprehensive study},
year={2001},
volume={1},
number={},
pages={508-517 vol.1},
abstract={Broadcasting protocols are proved to be efficient for transmitting most of the popular videos in video-on-demand systems. We propose a generalized analytical approach to evaluate the efficiency of the broadcasting protocols and derive the theoretical lower bandwidth requirement bound for any periodic broadcasting protocols. By means of the proposed analytical tool-temporal-bandwidth map, the approach can be used to direct the design of periodic broadcasting protocols to achieve different goals, e.g., server bandwidth requirement, client waiting time, client I/O bandwidth requirement etc. As the most important performance index in a VOD system is the required server bandwidth, we give the solution to achieve the optimal bandwidth efficiency given client waiting time requirement and the length of the video. To take into account the popular compressed video with variable bit rate, the optimal approach is applied readily to the VBR videos and can achieve zero loss and best bandwidth efficiency. We give a proof why existing techniques such as smoothing and prefetching is not necessary and in some cases inefficient in broadcasting protocols. We also discuss how broadcasting schemes can be tailored to support true and interactive VOD service. An insightful comparison between broadcasting and multicasting schemes is also given.},
keywords={video on demand;digital video broadcasting;multicast communication;data compression;video coding;protocols;video-on-demand broadcasting protocols;VOD broadcasting protocols;video-on-demand systems;efficiency;lower bandwidth requirement bound;periodic broadcasting protocols;temporal-bandwidth map;analytical tool;server bandwidth requirement;client waiting time;client I/O bandwidth;performance index;VOD system;optimal bandwidth efficiency;video length;compressed video;variable bit rate;VBR videos;bandwidth efficiency;smoothing;prefetching;interactive VOD service;multicasting;Broadcasting;Protocols;Videos;Multimedia communication;Bandwidth;Bit rate;Smoothing methods;Educational institutions;Performance analysis;Prefetching},
doi={10.1109/INFCOM.2001.916754},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916771,
author={Fei Yu and V. C. M. Leung},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Mobility-based predictive call admission control and bandwidth reservation in wireless cellular networks},
year={2001},
volume={1},
number={},
pages={518-526 vol.1},
abstract={This paper presents call admission control and bandwidth reservation schemes in wireless cellular networks that have been developed based on assumptions more realistic than existing proposals. In order to guarantee the handoff dropping probability, we propose to statistically predict user mobility based on the mobility history of users. Our mobility prediction scheme is motivated by computational learning theory, which has shown that prediction is synonymous with data compression. We derive our mobility prediction scheme from data compression techniques that are both theoretically optimal and good in practice. In order to utilize resource more efficiently, we predict not only the cell to which the mobile will handoff but also when the handoff will occur. Based on the mobility prediction, bandwidth is reserved to guarantee some target handoff dropping probability. We also adaptively control the admission threshold to achieve a better balance between guaranteeing handoff dropping probability and maximizing resource utilization. Simulation results show that the proposed schemes meet our design goals and outperforms the static-reservation scheme and cell-reservation scheme.},
keywords={cellular radio;radio networks;telecommunication congestion control;probability;learning systems;adaptive control;data compression;Markov processes;mobility-based predictive call admission control;bandwidth reservation;wireless cellular networks;handoff dropping probability;user mobility prediction;mobility history;computational learning theory;data compression;adaptive control;admission threshold;resource utilization;simulation results;cell-reservation scheme;static-reservation scheme;stationary order Markov sources;Call admission control;Bandwidth;Land mobile radio cellular systems;Quality of service;Wireless networks;Data compression;Predictive models;Intelligent networks;Mobile communication;Multimedia systems},
doi={10.1109/INFCOM.2001.916771},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916772,
author={K. Kumaran and M. Mandjes},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Multiplexing regulated traffic streams: design and performance},
year={2001},
volume={1},
number={},
pages={527-536 vol.1},
abstract={The main network solutions for supporting QoS rely on traffic policing (conditioning, shaping). In particular, for IP networks the IETF has developed Intserv (individual flows regulated) and Diffserv (only aggregates regulated). The regulator proposed could be based on the (dual) leaky-bucket mechanism. This explains the interest in network element performance (loss, delay) for leaky-bucket regulated traffic. This paper describes a novel approach to the above problem. Explicitly using the correlation structure of the sources' traffic, we derive approximations for both small and large buffers. Importantly, for small (large) buffers the short-term (long-term) correlations are dominant. The large buffer result decomposes the traffic stream in a stream of constant rate and a periodic impulse stream, allowing direct application of the Brownian bridge approximation. Combining the small and large buffer results by a concave majorization, we propose a simple, fast and accurate technique to statistically multiplex homogeneous regulated sources. To address heterogeneous inputs, we present similarly efficient techniques to evaluate the performance of multiple classes of traffic, each with distinct characteristics and QoS requirements. These techniques, applicable under more general conditions, are based on optimal resource (bandwidth and buffer) partitioning. They can also be directly applied to set GPS (generalized processor sharing) weights and buffer thresholds in a shared resource system.},
keywords={multiplexing;telecommunication traffic;Internet;quality of service;transport protocols;correlation methods;buffer storage;approximation theory;regulated traffic streams multiplexing;QoS;traffic policing;traffic shaping;IP networks;IETF;Intserv;Diffserv;dual leaky-bucket mechanism;network element performance;loss performance;delay performance;leaky-bucket regulated traffic;correlation structure;buffer approximations;traffic stream decomposition;periodic impulse stream;Brownian bridge approximation;concave majorization;statistical multiplexing;homogeneous regulated sources;heterogeneous inputs;performance evaluation;multiple traffic classes;optimal resource partitioning;generalized processor sharing;GPS weights;buffer thresholds;shared resource system;Internet;Traffic control;Diffserv networks;Quality of service;Telecommunication traffic;IP networks;Aggregates;Admission control;Internet;Protocols;Resource management},
doi={10.1109/INFCOM.2001.916772},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916775,
author={C. Labovitz and A. Ahuja and R. Wattenhofer and S. Venkatachary},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={The impact of Internet policy and topology on delayed routing convergence},
year={2001},
volume={1},
number={},
pages={537-546 vol.1},
abstract={This paper examines the role inter-domain topology and routing policy play in the process of delayed Internet routing convergence. In previous work, we showed that the Internet lacks effective inter-domain path fail-over. Unlike circuit-switched networks which exhibit fail-over on the order of milliseconds, we found Internet backbone routers may take tens of minutes to reach a consistent view of the network topology after a fault. In this paper, we expand an our earlier work by exploring the impact of specific Internet provider policies and topologies on the speed of routing convergence. Based on data from the experimental injection and measurement of several hundred thousand inter-domain routing faults, we show that the time for end-to-end Internet convergence depends on the length of the longest possible backup autonomous system path between a source and destination node. We also demonstrate significant variation in the convergence behavior of Internet service providers, with the larger providers exhibiting the fastest convergence latencies. Finally, we discuss possible modifications to BGP and provider routing policies which if deployed, would improve inter-domain routing convergence.},
keywords={Internet;transport protocols;quality of service;network topology;telecommunication network routing;computer network reliability;delays;directed graphs;Internet policy;Internet topology;delayed routing convergence;inter-domain topology;inter-domain routing policy;inter-domain path fail-over;Internet backbone routers;Internet service providers;fault measurement;backup autonomous system path length;source node;destination node;BGP;QoS;directed graph;Internet;Delay;Routing;Convergence;Network topology;Circuit topology;Circuit faults;IP networks;Spine;Length measurement},
doi={10.1109/INFCOM.2001.916775},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916777,
author={Lixin Gao and T. G. Griffin and J. Rexford},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Inherently safe backup routing with BGP},
year={2001},
volume={1},
number={},
pages={547-556 vol.1},
abstract={The Internet consists of a large number of autonomous systems (ASes) that exchange routing information using the border gateway protocol (BGP). Each AS applies local policies for selecting routes and propagating routes to others, with important implications for the reliability and stability of the global system. In and of itself, BGP does not ensure that every pair of hosts can communicate. In addition, routing policies are not guaranteed be safe, and may cause protocol divergence. Backup routing is often used to increase the reliability of the network under link and router failures, at the possible expense of safety. This paper presents a general model for backup routing that increases network reliability while allowing each AS to apply local routing policies that are consistent with the commercial relationships it has with its neighbors. In addition, our model is inherently safe in the sense that the global system remains safe under any combination of link and router failures. Our model and the proof of inherent safety are cast in terms of the stable paths problem, a static formalism that captures the semantics of interdomain routing policies. Then, we describe how to realize our model in BGP with locally-implementable routing policies. To simplify the specification of local policies, we propose a new BGP attribute that conveys the avoidance level of a route. We also describe how to realize these policies without modification to BGP by using the BGP community attribute.},
keywords={Internet;telecommunication network routing;internetworking;transport protocols;computer network reliability;BGP;inherently safe backup routing;autonomous systems;Internet;routing information exchange;border gateway protocol;local policies;global system reliability;global system stability;network reliability;link failure;router failure;stable paths problem;interdomain routing policies;locally-implementable routing policies;avoidance level;IP;Routing protocols;Telecommunication network reliability;IP networks;Safety;Web and internet services;Topology;Computer networks;Stability;Engineering profession;IEEE news},
doi={10.1109/INFCOM.2001.916777},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916780,
author={S. Vutukury and J. J. Garcia-Luna-Aceves},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={MDVA: a distance-vector multipath routing protocol},
year={2001},
volume={1},
number={},
pages={557-564 vol.1},
abstract={Routing protocols using the distributed Bellman-Ford (DBF) algorithm converge very slowly to the correct routes when link costs increase, and in the case when a set of link failures results in a network partition, DBF simply fails to converge, a problem which is commonly referred to as the count-to-infinity problem. We present the first distance-vector routing algorithm, MDVA, that uses a set of loop-free invariants to prevent the count-to-infinity problem. MDVA, in addition, computes multipaths that are loop-free at every instant. In our earlier work we shows how such loop-free multipaths can be used in traffic load-balancing and minimizing delays, which otherwise are impossible to perform in current single-path routing algorithms.},
keywords={protocols;telecommunication network routing;telecommunication traffic;delays;directed graphs;computer network reliability;performance evaluation;distance-vector multipath routing protocol;distributed Bellman-Ford algorithm;MDVA;link costs;link failures;network partition;count-to-infinity problem;loop-free invariants;traffic load-balancing;delay minimisation;single-path routing algorithms;computer network;directed acyclic graph;performance analysis;Routing protocols;Partitioning algorithms;Telecommunication traffic;Delay;Computer networks;Degradation;Cost function;USA Councils;Topology;Safety},
doi={10.1109/INFCOM.2001.916780},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916782,
author={Yufei Wang and Zheng Wang and Leah Zhang},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Internet traffic engineering without full mesh overlaying},
year={2001},
volume={1},
number={},
pages={565-571 vol.1},
abstract={The overlay approach has been widely used by many service providers for traffic engineering in large Internet backbones. In the overlay approach, logical connections are set up between edge nodes to form a full mesh virtual network on top of the physical topology. IP routing is then run over the virtual network. Traffic engineering objectives are achieved through carefully routing logical connections over the physical links. Although the overlay approach has been implemented in many operational networks, it has a number of well-known scaling issues. This paper proposes a new approach, which we call the integrated approach, to achieve traffic engineering without full-mesh overlaying. In the integrated approach, IP routing runs natively over the physical topology rather than over the virtual network. Traffic engineering objectives are realized by setting appropriate link metrics in IP routing protocols. We first illustrate our approach with a simple network, then present a formal analysis of the integrated approach and a method for deriving the appropriate link weights. Our analysis shows that for any given set of optimal routes of the overlay approach with respect to a set of traffic demands, the integrated approach can achieve exactly the same result by reproducing them as shortest paths. We further extend the result to a more generic one: for any arbitrary set of routes, as long as they are not loopy, they can be converted to shortest-paths with respect to some set of positive link weights. A theoretical insight of our result is that the optimal routing (with respect to any objective function) is always shortest path routing with respect to some appropriate positive link weights.},
keywords={Internet;telecommunication traffic;electrical engineering;network topology;network routing;telecommunication network routing;transport protocols;optimisation;Internet traffic engineering;service providers;Internet backbones;overlay approach;logical connections;edge nodes;physical topology;IP routing;integrated approach;link metrics;IP routing protocols;traffic demands;shortest-paths;optimal routing;objective function;shortest path routing;positive link weights;Telecommunication traffic;Spine;Network topology;Cities and towns;Web and internet services;Linear programming;Routing protocols;Optimization;Delay;IP networks},
doi={10.1109/INFCOM.2001.916782},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916784,
author={Wee-Seng Soh and H. S. Kim},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Dynamic guard bandwidth scheme for wireless broadband networks},
year={2001},
volume={1},
number={},
pages={572-581 vol.1},
abstract={In future wireless broadband networks, bandwidth demands could fluctuate abruptly due to movement of high data rate users. Dynamic bandwidth reservation plays a key rule in ensuring that mobile calls are not disrupted after they are admitted into the network. We propose a dynamic guard bandwidth scheme that adapts the amount of guard bandwidth in both wired and wireless links according to real-time handoff predictions made by individual mobile terminals, leveraged by the expected widespread availability of GPS-capable wireless devices in the near future. We describe procedures for approximating irregular handoff-request boundary, and for estimating a mobile's remaining time to handoff and target handoff cell. Guard bandwidth is adjusted on the fly only when a handoff is anticipated to occur shortly. The scheme is robust against modifications in handoff parameters, as well as changes in terrain and manmade features that could affect radio propagation. It also caters for heterogeneous bandwidth requirements. Admission control algorithms for both new calls and handoff calls are provided. Simulation results show that our scheme is able to meet specified forced termination probability under high offered load, and that resources are not reserved unnecessarily.},
keywords={broadband networks;telecommunication congestion control;Global Positioning System;cellular radio;dynamic guard bandwidth scheme;wireless broadband networks;high data rate users;dynamic bandwidth reservation;mobile calls;real-time handoff predictions;GPS-capable wireless devices;irregular handoff-request boundary;handoff parameters;terrain;manmade features;radio propagation;heterogeneous bandwidth requirements;admission control algorithms;forced termination probability;Bandwidth;Broadband communication;Quality of service;Admission control;Wireless networks;Robustness;Radio propagation;Call admission control;Programmable control;Adaptive control},
doi={10.1109/INFCOM.2001.916784},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916786,
author={M. Barry and A. T. Campbell and A. Veres},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Distributed control algorithms for service differentiation in wireless packet networks},
year={2001},
volume={1},
number={},
pages={582-590 vol.1},
abstract={This paper investigates differentiated services in wireless packet networks using a fully distributed approach that supports service differentiation, radio monitoring and admission control. Service differentiation is based on the IEEE 802.11 distributed coordination function (DCF) originally designed to support best-effort data services. We extend the distributed coordination function to provide service differentiation for delay sensitive and best-effort traffic. Two distributed estimation algorithms are proposed and analyzed. A virtual MAC (VMAC) algorithm passively monitors the radio channel and estimates locally achievable service levels. The virtual MAC estimates key MAC level statistics related to service quality such as delay, delay variation, packet collision and packet loss. We show the efficiency of the virtual MAC algorithm and consider significantly overlapping cells and highly bursty traffic mixes. A virtual source (VS) algorithm utilizes the virtual MAC to estimate application level service quality. The virtual source allows application parameters to be tuned in response to dynamic channel conditions based on "virtual delay curves". We demonstrate through simulation that when these distributed virtual algorithms are applied to the admission control of the radio channel then a globally stable state can be maintained without the need for complex centralized radio resource management. Finally, we discuss a distributed service level management scheme that builds on the proposed algorithms to offer continuous service with handoff.},
keywords={distributed control;access protocols;packet radio networks;telecommunication traffic;telecommunication network management;IEEE standards;telecommunication standards;delays;Internet;quality of service;carrier sense multiple access;land mobile radio;computer network management;distributed control algorithms;service differentiation;wireless packet networks;differentiated services;radio monitoring;admission control;IEEE 802.11 distributed coordination function;best-effort data services;delay sensitive traffic;best-effort traffic;virtual MAC algorithm;VMAC algorithm;radio channel;MAC level statistics;service quality;delay;delay variation;packet collision;packet loss;overlapping cells;bursty traffic;virtual source algorithm;VS algorithm;DCF;application level service quality;dynamic channel conditions;virtual delay curves;distributed virtual algorithms;globally stable state;distributed service level management scheme;continuous service;Distributed control;Delay estimation;Admission control;Wireless sensor networks;Communication system traffic control;Algorithm design and analysis;Statistical distributions;Road accidents;Traffic control;Resource management},
doi={10.1109/INFCOM.2001.916786},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916788,
author={A. Das and A. Ghose and A. Razdan and H. Saran and R. Shorey},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Enhancing performance of asynchronous data traffic over the Bluetooth wireless ad-hoc network},
year={2001},
volume={1},
number={},
pages={591-600 vol.1},
abstract={Emerging technologies such as Bluetooth are expected to become a ubiquitous solution for providing short range, low power, low cost, pico-cellular wireless connectivity. Bluetooth is a master driven time division duplex (TDD) system that supports an asynchronous channel for data traffic as well as synchronous channels for voice traffic. Data applications running over Bluetooth such as http, ftp and real audio will need transport layer protocols such as TCP and UDP to send packets over the wireless links. In this paper we study several schemes designed to improve the performance of asynchronous data traffic over a Bluetooth piconet that supports multiple active slaves. We propose and compare a number of segmentation and reassembly policies and MAC scheduling algorithms with a view towards enhancing the performance of transport layer sessions. We investigate the effect of different FEC and ARQ schemes at the baseband level, using a two-state Markov channel model for the Bluetooth RF link. We also study how the presence of circuit-switched voice impacts the performance of data traffic.},
keywords={telecommunication traffic;scheduling;integrated voice/data communication;packet radio networks;circuit switching;automatic repeat request;synchronisation;transport protocols;access protocols;forward error correction;Markov processes;performance;asynchronous data traffic;Bluetooth wireless ad-hoc network;pico-cellular wireless connectivity;master driven time division duplex system;TDD system;asynchronous channel;synchronous channels;voice traffic;http data;ftp data;real audio data;transport layer protocols;TCP;UDP;packets;Bluetooth piconet;active slaves;SAR policies;MAC scheduling algorithms;transport layer sessions;FEC;ARQ;two-state Markov channel model;RF link;circuit-switched voice;segmentation and reassembly policies;Bluetooth;Costs;Transport protocols;Wireless application protocol;Personal area networks;Scheduling algorithm;Automatic repeat request;Baseband;Radio frequency;Circuits},
doi={10.1109/INFCOM.2001.916788},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{916791,
author={G. Karmani and K. N. Sivarajan},
booktitle={Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
title={Capacity evaluation for CDMA cellular systems},
year={2001},
volume={1},
number={},
pages={601-610 vol.1},
abstract={In this paper, we find bounds and approximations for the capacity of mobile cellular communication networks based on code division multiple access (CDMA). We develop efficient analytic techniques for capacity calculations of CDMA cellular networks. Each cell is modeled as an independent M/G//spl infin/ queue and traffic capacity assessed based on the maximum Erlang traffic that leads to acceptable link quality with high probability. Subsequently, approximations and bounds for the outage probability and hence traffic capacity are obtained using asymptotic expansions and large deviations theory. Numerical examples, considering uniform and normalized truncated Gaussian user density in the system are evaluated. The propagation model we consider takes care of distance and lognormal shadowing losses.},
keywords={code division multiple access;cellular radio;queueing theory;telecommunication traffic;capacity evaluation;CDMA cellular systems;bounds;approximations;mobile cellular communication networks;code division multiple access;analytic techniques;independent M/G//spl infin/ queue;traffic capacity;maximum Erlang traffic;link quality;outage probability;asymptotic expansions and large deviations theory;normalized truncated Gaussian user density;uniform user density;propagation model;distance;lognormal shadowing losses;Multiaccess communication;Interference;Traffic control;Telecommunication traffic;Shadow mapping;Random variables;Capacity planning;Propagation losses;Frequency division multiaccess;Time division multiple access},
doi={10.1109/INFCOM.2001.916791},
ISSN={0743-166X},
month={April},}

