@INPROCEEDINGS{8486267,
author={J. Krolikowski and A. Giovanidis and M. Di Renzo},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Optimal Cache Leasing from a Mobile Network Operator to a Content Provider},
year={2018},
volume={},
number={},
pages={2744-2752},
abstract={Caching popular content at the wireless edge is recently proposed as a means to reduce congestion at the backbone of cellular networks. The two main actors involved are Mobile Network Operators (MNOs) and Content Providers (CPs). In this work, we consider the following arrangement: an MNO pre-installs memory on its wireless equipment (e.g. Base Stations) and invites a unique CP to use them, with monetary cost. The CP will lease memory space and place its content; the MNO will associate network users to stations. For a given association policy, the MNO may help (or not) the CP to offload traffic, depending on whether the association takes into account content placement. We formulate an optimization problem from the CP perspective, which aims at maximizing traffic offloading with minimum leasing costs. This is a joint optimization problem that can include any association policy, and can also derive the optimal one. We present a general exact solution using Benders decomposition. It iteratively updates decisions of the two actors separately and converges to the global optimum. We illustrate the optimal CP leasing/placement strategy and hit probability gains under different association policies. Performance is maximised when the MNO association follows CP actions.},
keywords={cache storage;cellular radio;optimisation;telecommunication traffic;optimal cache leasing;Content provider;wireless edge;cellular networks;main actors;Mobile Network Operators;MNO pre-installs memory;wireless equipment;monetary cost;memory space;network users;account content placement;CP perspective;traffic offloading;minimum leasing costs;joint optimization problem;optimal CP leasing/placement strategy;MNO association;CP actions;congestion reduction;Base Stations;association policies;Wireless communication;Data centers;Optimization;Communication system security;Conferences;Base stations;Cache memory},
doi={10.1109/INFOCOM.2018.8486267},
ISSN={},
month={April},}
@INPROCEEDINGS{8486371,
author={X. Tang and C. Wang and X. Yuan and Q. Wang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Non-Interactive Privacy-Preserving Truth Discovery in Crowd Sensing Applications},
year={2018},
volume={},
number={},
pages={1988-1996},
abstract={In crowd sensing, truth discovery (TD) refers to finding reliable information from noisy/biased data collected from different providers. To protect providers' data while enabling truth distillation, privacy-preserving truth discovery (PPTD) has received wide attention recently. However, all existing approaches require iterative interaction between server(s) and individual providers, which inevitably demand all providers to be always online. Otherwise, the protocol would fail or expose extra provider information. In this paper, we design and implement the first non-interactive PPTD system that completely removes the online requirement with strong privacy guarantees. Our framework follows the same two-server model from the best-known prior solution, and leverages Yao's Garbled Circuit (GC). Yet, we devise non-trivial speedup techniques for TD-optimized implementation. Firstly, we identify reusable computations in TD to accelerate the circuit generation. Secondly, we securely evaluate the burdensome non-linear functions in TD via customized approximation with accuracy and improved efficiency. Thirdly, we reduce the online execution time by bridging together latest advancements of component-based GC and various computations needed in TD. Unlike prior arts, our framework does not reveal any intermediate results, and further supports “late-join” providers without protocol suspension/restart. The practical performance of our proof-of-concept implementation is verified through extensive evaluations.},
keywords={data privacy;iterative methods;mobile computing;nonlinear functions;online requirement;nonlinear functions;crowd sensing applications;reliable information;noisy/biased data;truth distillation;iterative interaction;noninteractive PPTD system;Non-Interactive Privacy-Preserving Truth Discovery;Yao's Garbled Circuit;Protocols;Servers;Estimation;Security;Sensors;Privacy;Systems architecture},
doi={10.1109/INFOCOM.2018.8486371},
ISSN={},
month={April},}
@INPROCEEDINGS{8485819,
author={J. Palacios and G. Bielsa and P. Casari and J. Widmer},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Communication-Driven Localization and Mapping for Millimeter Wave Networks},
year={2018},
volume={},
number={},
pages={2402-2410},
abstract={Millimeter wave (mmWave) communications are an essential component of 5G-and-beyond ultra-dense Gbit/s wireless networks, but also pose significant challenges related to the communication environment. Especially beam-training and tracking, device association, and fast handovers for highly directional mmWave links may potentially incur a high overhead. At the same time, such mechanisms would benefit greatly from accurate knowledge about the environment and device locations that can be provided through simultaneous localization and mapping (SLAM) algorithms. In this paper we tackle the above issues by proposing CLAM, a distributed mmWave SLAM algorithm that works with no initial information about the network deployment or the environment, and achieves low computational complexity thanks to a fundamental reformulation of the angle-differences-of-arrival mm Wave anchor location estimation problem. All information required by CLAM is collected by a mmWave device thanks to beam training and tracking mechanisms inherent to mm Wave networks, at no additional overhead. Our results show that CLAM achieves submeter accuracy in the great majority of cases. These results are validated via an extensive experimental measurement campaign carried out with 60-GHz mmWave hardware.},
keywords={5G mobile communication;cellular radio;computational complexity;direction-of-arrival estimation;distributed algorithms;indoor radio;millimetre wave communication;mobile robots;mobility management (mobile radio);radio tracking;SLAM (robots);telecommunication control;CLAM;distributed mmWave SLAM algorithm;network deployment;beam training;tracking mechanisms;mm Wave networks;millimeter wave communications;wireless networks;communication environment;device association;highly directional mmWave links;device locations;low computational complexity;millimeter wave networks;angle-differences-of-arrival mm-Wave anchor location estimation problem;mmWave device;mmWave hardware;communication-driven localization;5G-and-beyond ultra-dense gigabits wireless networks;directional mmWave links;beam tracking mechanism;simultaneous localization and mapping algorithms;frequency 60 GHz;Shape;Simultaneous localization and mapping;Training;Estimation;Standards;Shape measurement;Handover},
doi={10.1109/INFOCOM.2018.8485819},
ISSN={},
month={April},}
@INPROCEEDINGS{8486263,
author={A. Blenk and P. Kalmbach and J. Zerwas and M. Jarschel and S. Schmid and W. Kellerer},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={NeuroViNE: A Neural Preprocessor for Your Virtual Network Embedding Algorithm},
year={2018},
volume={},
number={},
pages={405-413},
abstract={Network virtualization enables increasingly diverse network services to cohabit and share a given physical infrastructure and its resources, with the possibility to rely on different network architectures and protocols optimized towards specific requirements. In order to ensure a predictable performance despite shared resources, network virtualization requires a strict performance isolation and hence, resource reservations. Moreover, the creation of virtual networks should be fast and efficient. The underlying NP-hard algorithmic problem is known as the Virtual Network Embedding (VNE) problem and has been studied intensively over the last years. This paper presents NeuroViNE, a novel approach to speed up and improve a wide range of existing VNE algorithms: NeuroViNE is based on a search space reduction mechanism and preprocesses a problem instance by extracting relevant subgraphs, i.e., good combinations of substrate nodes and links. These subgraphs can then be fed to an existing algorithm for faster and more resource-efficient embeddings. NeuroViNE relies on a Hopfield network, and its performance benefits are investigated in simulations for random networks, real substrate networks, and data center networks.},
keywords={computational complexity;computer centres;graph theory;Hopfield neural nets;optimisation;random processes;resource allocation;search problems;virtualisation;NeuroViNE;neural preprocessor;Virtual Network Embedding algorithm;network virtualization;shared resources;strict performance isolation;resource reservations;Virtual Network Embedding problem;resource-efficient embeddings;Hopfield network;random networks;substrate networks;data center networks;network services;network architectures;physical infrastructure;NP-hard algorithmic problem;search space reduction mechanism;subgraphs extraction;Substrates;Neurons;Bandwidth;Heuristic algorithms;Manganese;Conferences;Virtualization},
doi={10.1109/INFOCOM.2018.8486263},
ISSN={},
month={April},}
@INPROCEEDINGS{8486268,
author={H. Cai and T. Wolf},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Self-Adapting Quorum-Based Neighbor Discovery in Wireless Sensor Networks},
year={2018},
volume={},
number={},
pages={324-332},
abstract={Neighbor discovery is a critical first step in establishing communication in a wireless ad-hoc network. Existing quorum-based neighbor discovery algorithms only consider a pair of nodes and ensure that this pair can communicate at least once in a bounded interval. However, when the node density of a wireless network increases, collisions are more likely to happen, which makes these quorum-based algorithms inefficient in practice. We propose a novel self-adapting quorum-based neighbor discovery algorithm that can dynamically adjust its cycle pattern to decrease the impact of such collisions. We first assess the collision problem in wireless networks when using quorum-based neighbor discovery algorithms and then establish a theoretical framework to analyze the discovery delay when considering collision effects. Guided by these theoretical results, we design a self-adapting mechanism for cycle patterns in quorum-based algorithms. Simulation results show that our algorithm can achieve complete neighbor discovery in less time than existing quorum-based neighbor discovery algorithms.},
keywords={mobile radio;wireless sensor networks;quorum-based neighbor discovery algorithms;ad-hoc network;wireless sensor networks;complete neighbor discovery;quorum-based algorithms;discovery delay;self-adapting quorum-based neighbor discovery algorithm;Protocols;Schedules;Wireless sensor networks;Heuristic algorithms;Delays;Ad hoc networks;Analytical models},
doi={10.1109/INFOCOM.2018.8486268},
ISSN={},
month={April},}
@INPROCEEDINGS{8486410,
author={Y. Zou and X. Lin and D. Aliprantis and M. Chen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Robust Multi-stage Power Grid Operations with Energy Storage},
year={2018},
volume={},
number={},
pages={2483-2491},
abstract={The uncertainty and variability of renewable generation pose significant challenges to reliable power-grid operations. This paper designs robust online strategies for jointly operating energy storage units and fossil-fuel generators to achieve provably reliable grid operations at all times under high renewable uncertainty, without the need of renewable curtailment. In particular, we jointly consider two power system operations, namely day-ahead reliability assessment commitment (RAC) and real-time dispatch. We first extend the concept of “safe-dispatch sets” to our setting. While finding such safe-dispatch sets and checking their non-emptiness provide crucial answers to both RAC and real-time dispatch, their computation incurs high complexity in general. To develop computationally-efficient solutions, we first study a single-bus case with one generator-storage pair, where we derive necessary conditions and sufficient conditions for the safe-dispatch sets. Our results reveal fundamental trade-offs between storage capacity and generator ramp-up/-down limits to ensure grid reliability. Then, for the more general multi-bus scenario, we split the net-demand among virtual generator-storage pairs (VGSPs) and apply our single-bus decision strategy to each VGSP. Simulation results on an IEEE 30-bus system show that, compared with state-of-art solutions, our scheme requires significantly less storage to ensure reliable grid operation without any renewable curtailment.},
keywords={energy storage;power generation dispatch;power generation economics;power generation reliability;power generation scheduling;power grids;renewable energy sources;day-ahead reliability assessment commitment;RAC;generator ramp-up limits;generator down limits;reliable grid operation;IEEE 30-bus system show;single-bus decision strategy;virtual generator-storage pairs;general multibus scenario;grid reliability;storage capacity;generator-storage pair;single-bus case;computationally-efficient solutions;safe-dispatch sets;real-time dispatch;power system operations;renewable curtailment;high renewable uncertainty;provably reliable grid operations;fossil-fuel generators;energy storage units;robust online strategies;reliable power-grid operations;renewable generation;robust multistage power grid operations;Generators;Reliability;Uncertainty;Power system reliability;Energy storage;Real-time systems;ISO},
doi={10.1109/INFOCOM.2018.8486410},
ISSN={},
month={April},}
@INPROCEEDINGS{8486312,
author={C. Duan and L. Yang and H. Jia and Q. Lin and Y. Liu and L. Xie},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Robust Spinning Sensing with Dual-RFID-Tags in Noisy Settings},
year={2018},
volume={},
number={},
pages={855-863},
abstract={Conventional spinning inspection systems, equipped with separated sensors (e.g., accelerometer, laser, etc.) and communication modules, are either very expensive and/or suffering from occlusion and narrow field of view. The recently proposed RFID-based sensing solution draws much attention due to its intriguing features, such as being cost-effective, applicable to occluded objects and auto-identification, etc. However, this solution only works in quiet settings where the reader and spinning object remain absolutely stationary, as their shaking would ruin the periodicity and sparsity of the spinning signal, making it impossible to be recovered. This work introduces Tagtwins, a robust spinning sensing system that can work in noisy settings. It addresses the challenge by attaching dual RFID tags on the spinning surface and developing a new formulation of spinning signal that is shaking-resilient, even if the shaking involves unknown trajectories. Our main contribution lies in two newly developed techniques, relative spinning signal and dual compressive reading. We analytically demonstrate that our solution can work in various settings. We have implemented Tagtwins with COTS RFID devices and evaluated it extensively. Experimental results show that Tagtwins can inspect the rotation frequency with high accuracy and robustness.},
keywords={compressed sensing;inspection;radiofrequency identification;COTS RFID devices;dual-RFID-tags;noisy settings;separated sensors;communication modules;spinning object;robust spinning sensing system;dual RFID tags;spinning surface;relative spinning signal;dual compressive reading;spinning inspection systems;RFID-based sensing solution;Spinning;Noise measurement;Robustness;Frequency-domain analysis;Radio frequency;Robot sensing systems;RFID;spinning sensing;robust;dual-tag},
doi={10.1109/INFOCOM.2018.8486312},
ISSN={},
month={April},}
@INPROCEEDINGS{8486402,
author={C. Lin and Z. Wang and J. Deng and L. Wang and J. Ren and G. Wu},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={mTS: Temporal-and Spatial-Collaborative Charging for Wireless Rechargeable Sensor Networks with Multiple Vehicles},
year={2018},
volume={},
number={},
pages={99-107},
abstract={Benefited from recent breakthrough in wireless power transfer technology, the lifetime of wireless sensor networks (WSNs) can be prolonged significantly, generating the concept of wireless rechargeable sensor networks (WRSNs). While most recent works have been focusing on WRSNs with a single wireless charging vehicle (WCV), we investigate the issue of multiple WCVs' on-line collaborative charging schedules in this work. In our design, termed mTS, the network area is divided into subdomains for designated WCVs. Each WCV schedules its charging scheduling path by responding to the interdependency of temporal and spatial correlations from different charging requests. Higher priorities are given to sensor requests with a mixture of closer charging deadlines and closer distances. We further analyze the system performance with an M/M/n/mTS queueing model. Our further study through simulations revealed that our scheme excels in successful charging rate, sensor survival rate, and other related performance metrics. Our field experiments further confirmed these results and showed some further interesting findings on different charging hardware and methods.},
keywords={inductive power transmission;queueing theory;wireless sensor networks;wireless rechargeable sensor networks;wireless power transfer technology;WRSNs;single wireless charging vehicle;multiple WCVs;on-line collaborative charging schedules;network area;WCV schedules;charging scheduling path;temporal correlations;spatial correlations;sensor requests;sensor survival rate;charging requests;charging deadlines;charging rate;charging hardware;M/M/n/mTS queueing model;Nickel;Wireless sensor networks;Scheduling;Task analysis;Measurement;Clustering algorithms;Wireless communication},
doi={10.1109/INFOCOM.2018.8486402},
ISSN={},
month={April},}
@INPROCEEDINGS{8485853,
author={Z. Xu and J. Tang and J. Meng and W. Zhang and Y. Wang and C. H. Liu and D. Yang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Experience-driven Networking: A Deep Reinforcement Learning based Approach},
year={2018},
volume={},
number={},
pages={1871-1879},
abstract={Modern communication networks have become very complicated and highly dynamic, which makes them hard to model, predict and control. In this paper, we develop a novel experience-driven approach that can learn to well control a communication network from its own experience rather than an accurate mathematical model, just as a human learns a new skill (such as driving, swimming, etc). Specifically, we, for the first time, propose to leverage emerging Deep Reinforcement Learning (DRL) for enabling model-free control in communication networks; and present a novel and highly effective DRL-based control framework, DRL-TE, for a fundamental networking problem: Traffic Engineering (TE). The proposed framework maximizes a widely-used utility function by jointly learning network environment and its dynamics, and making decisions under the guidance of powerful Deep Neural Networks (DNNs). We propose two new techniques, TE-aware exploration and actor-critic-based prioritized experience replay, to optimize the general DRL framework particularly for TE. To validate and evaluate the proposed framework, we implemented it in ns-3, and tested it comprehensively with both representative and randomly generated network topologies. Extensive packet-level simulation results show that 1) compared to several widely-used baseline methods, DRL-TE significantly reduces end-to-end delay and consistently improves the network utility, while offering better or comparable throughput; 2) DRL-TE is robust to network changes; and 3) DRL-TE consistently outperforms a state-of-the-art DRL method (for continuous control), Deep Deterministic Policy Gradient (DDPG), which, however, does not offer satisfying performance.},
keywords={learning (artificial intelligence);mathematical analysis;neurocontrollers;telecommunication control;telecommunication network topology;telecommunication traffic;model-free control;TE-aware exploration;deep deterministic policy gradient;communication network topologies;mathematical model;deep neural networks;deep reinforcement learning based approach;experience-driven approach;general DRL-TE framework;traffic engineering;DNN;actor-critic-based prioritized experience replay;packet-level simulation;DDPG;Mathematical model;Communication networks;Queueing analysis;Resource management;Predictive models;Delays;Aerospace electronics;Experience-driven Networking;Deep Reinforcement Learning;Traffic Engineering},
doi={10.1109/INFOCOM.2018.8485853},
ISSN={},
month={April},}
@INPROCEEDINGS{8485981,
author={X. Zhang and Z. Qian and S. Zhang and X. Li and X. Wang and S. Lu},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={COBRA: Toward Provably Efficient Semi-Clairvoyant Scheduling in Data Analytics Systems},
year={2018},
volume={},
number={},
pages={513-521},
abstract={Typical data analytics systems abstract jobs as directed acyclic graphs (DAGs). It is crucial to maximize throughput and speedup completions for DAG jobs in practice. Existing works propose clairvoyant schedulers optimizing these goals, however, they assume complete job information as a prior knowledge which limits their applicability. Instead, we remove the complete prior knowledge assumption and rely solely on a partial prior information, which is more practical. And we design a semi-clairvoyant task scheduler Cobra working within each job. Cobra adaptively adjusts its resource desires in a multiplicative-increase multiplicative-decrease (MIMD) manner according to nearly past resource utilizations and the current waiting tasks. On the other hand, Cobra seeks to satisfy task locality preferences by allowing each task to wait for some time that is bounded by a parameterized threshold. Surprisingly, even with the partial prior job information, we theoretically prove, Cobra, when working with the widely used fair job scheduler, is O(1)-competitive with respect to both makespan and average job response time. We experimentally validate that the performance promotion of Cobra in both real system deployment and trace-driven simulations.},
keywords={data analysis;directed graphs;processor scheduling;resource allocation;complete prior knowledge assumption;semiclairvoyant task scheduler Cobra;multiplicative-increase multiplicative-decrease manner;task locality preferences;partial prior job information;average job response time;directed acyclic graphs;speedup completions;DAG jobs;fair job scheduler;real system deployment;semiclairvoyant scheduling;trace-driven simulations;data analytics systems abstract jobs;Task analysis;Containers;Time factors;Dynamic scheduling;Data analysis;Processor scheduling},
doi={10.1109/INFOCOM.2018.8485981},
ISSN={},
month={April},}
@INPROCEEDINGS{8486294,
author={J. Narm and H. Jot and Y. Kim and P. Porras and V. Yegneswaran and S. Shin},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Barista: An Event-centric NOS Composition Framework for Software-Defined Networks},
year={2018},
volume={},
number={},
pages={980-988},
abstract={As the network operating system (NOS) is the strategic control center of a software-defined network (SDN), its design is critical to the welfare of the network. Contemporary research has largely focused on specialized NOSs that seek to optimize controller design across one or a few dimensions (e.g., scalability, performance, or security) due to fundamental differences in architectural trade-offs needed to support competing demands. We thus designed Barista, as a new framework that enables flexible and customizable instantiations of network operating systems (NOSs) supporting diverse design choices. The Barista framework incorporates two mechanisms to harmonize architectural differences across design choices: component synthesis and dynamic event control. First, the modular design of the Barista framework enables flexible composition of functionalities prevalent in contemporary SDN controllers. Second, its event-handling mechanism enables dynamic adjustment of control flows in a NOS. These capabilities allow operators to easily enable functionalities and dynamically handle associated events, thereby satisfying network operating requirements. Our results demonstrate that Barista can synthesize NOSs with many functionalities found in commodity NOSs with competitive performance profiles.},
keywords={control system synthesis;formal specification;network operating systems;optimal control;software architecture;software defined networking;Web services;strategic control center;software-defined network;event-centric NOS composition framework;network operating requirements;control flows;event-handling mechanism;contemporary SDN controllers;modular design;dynamic event control;network operating system;customizable instantiations;Security;Scalability;Conferences;Network operating systems;Computer architecture;Robustness},
doi={10.1109/INFOCOM.2018.8486294},
ISSN={},
month={April},}
@INPROCEEDINGS{8485827,
author={X. Liu and L. Ying},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={On Achieving Zero Delay with Power-of-d-Choices Load Balancing},
year={2018},
volume={},
number={},
pages={297-305},
abstract={Power-of-d-choices is a popular load balancing algorithm for many-server systems such as large-scale data centers. For each incoming job, the algorithm probes d servers, chosen uniformly at random from a total of N servers, and routes the job to the least loaded one. It is well known that power-of-d-choices reduces queueing delays by orders of magnitude compared to the policy that routes each incoming job to a randomly selected server. The question to be addressed in this paper is how large d needs to be so that power-of-d-choices achieves asymptotic zero delay like the join-the-shortest-queue (JSQ) algorithm, which is a special case of power-of-d-choices with d=N. We are interested in the heavy-traffic regime where the load of the system, denoted by λ, approaches to one as N increases, and assume λ = 1-γN-αfor and . This paper establishes that when d=ω-([1/(1-λ)]), the probability that an incoming job is routed to a busy server is asymptotically zero, i.e. a job experiences zero queueing delay with probability one asymptotically; and when d=O([1/(1-λ)])' the probability that a job is routed to a busy server is lower bounded by a positive constant independent of N. Therefore, our results show that d=ω([1/(1-λ)]) is sufficient and almost necessary for achieving zero delay with the power-of-d-choices load balancing policy.},
keywords={computational complexity;probability;queueing theory;resource allocation;telecommunication traffic;load balancing algorithm;large-scale data centers;JSQ algorithm;heavy-traffic regime;zero queueing delay;busy server;join-the-shortest-queue algorithm;asymptotic zero delay;many-server systems;power-of-d-choices load balancing policy;Servers;Delays;Load management;Steady-state;Data centers;Conferences;Probes},
doi={10.1109/INFOCOM.2018.8485827},
ISSN={},
month={April},}
@INPROCEEDINGS{8485849,
author={S. Byeon and H. Kwon and Y. Son and C. Yang and S. Choi},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={RECONN: Receiver-Driven Operating Channel Width Adaptation in IEEE 802.11ac WLANs},
year={2018},
volume={},
number={},
pages={1655-1663},
abstract={State-of-the-art IEEE 802.11ac supports wide bandwidth operation, which enables aggregating multiple 20 MHz channels up to 160 MHz bandwidth, as a key feature to achieve high throughput. In this paper, our experiment results reveal various situations where bandwidth adaptation without changing the receiver's baseband bandwidth, called operating channel width (OCW), leads to poor reception performance due surprisingly to time-domain interference not overlapping with the incoming desired signal in frequency domain. To cope with this problem, we develop RECONN, a standard-compliant and receiver-driven OCWadaptation scheme with ease of implementation. Our prototype implementation in commercial 802.11ac devices shows that RECONN achieves up to 1.85× higher throughput by completely eliminating time-domain interference. To our best knowledge, this is the first work to discover the time-domain interference problem, and to develop OCW adaptation scheme in 802.11ac system.},
keywords={bandwidth allocation;time-domain analysis;wireless LAN;bandwidth adaptation;frequency domain;802.11ac devices;RECONN;time-domain interference problem;802.11ac system;receiver-driven OCW adaptation scheme;receiver-driven operating channel width adaptation;baseband bandwidth;frequency 20.0 MHz;bandwidth 160.0 MHz;Interference;Bandwidth;Time-domain analysis;Throughput;Wireless LAN;Baseband;Frequency-domain analysis},
doi={10.1109/INFOCOM.2018.8485849},
ISSN={},
month={April},}
@INPROCEEDINGS{8486300,
author={Y. Niu and F. Liu and Z. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Load Balancing Across Microservices},
year={2018},
volume={},
number={},
pages={198-206},
abstract={With the advent of cloud container technology, enterprises develop applications through microservices, breaking monolithic software into a suite of small services whose instances run independently in containers. User requests are served by a series of microservices forming a chain, and the chains often share microservices. Existing load balancing strategies either incur significant networking overhead or ignore the competition for shared microservices across chains. Furthermore, typical load balancing solutions leverage a hybrid technique by combining HTTP with message queue to support microservice communications, bringing additional operational complexity. To address these challenges, we propose a chain-oriented load balancing algorithm (COLBA) based solely on message queues, which balances load based on microservice requirements of chains to minimize response time. We model the load balancing problem as a non-cooperative game, and leverage Nash bargaining to coordinate microservice allocation across chains. Employing convex optimization with rounding, we efficiently solve the problem that is proven NP-hard. Extensive trace-driven simulations demonstrate that COLBA reduces the overall average response time at least by 13% compared with existing load balancing strategies.},
keywords={game theory;queueing theory;resource allocation;cloud container technology;shared microservices;message queue;microservice communications;chain-oriented load balancing algorithm;microservice requirements;microservice allocation;Load management;Time factors;Containers;Computer architecture;Load modeling;Conferences;Logic gates},
doi={10.1109/INFOCOM.2018.8486300},
ISSN={},
month={April},}
@INPROCEEDINGS{8486251,
author={J. Ye and K. Leung and V. O. K. Li and S. H. Low},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Combating Bufferbloat in Multi-Bottleneck Networks: Equilibrium, Stability, and Algorithms},
year={2018},
volume={},
number={},
pages={648-656},
abstract={Bufferbloat is a phenomenon where router buffers are constantly being filled, resulting in high queueing delay and delay variation. Larger buffer size and more delay-sensitive applications on the Internet have made this phenomenon a pressing issue. Active queue management (AQM) algorithms, which play an important role in combating bufferbloat, have not been widely deployed due to complicated manual parameter tuning. Moreover, AQM algorithms are often designed and analyzed based on models with a single bottleneck link, rendering their performance and stability unclear in multi-bottleneck networks. In this paper, we propose a general framework to combat bufferbloat in multi-bottleneck networks. We first conduct an equilibrium analysis for a general multi-bottleneck TCP/ AQM system and develop an algorithm to compute the equilibrium point. We then decompose the system into single-bottleneck subsystems and derive sufficient conditions for the local asymptotic stability of the subsystems. Using the proposed framework, we present a case study to analyze the stability of the recently proposed Controlled Delay (CoDel) in multi-bottleneck networks and devise Self-tuning CoDel to improve the system stability and performance. Extensive simulation results show that Self-tuning CoDel effectively stabilizes queueing delay in multi-bottleneck scenarios, and thus contributes to combating bufferbloat.},
keywords={asymptotic stability;delays;queueing theory;telecommunication congestion control;telecommunication network management;transport protocols;single bottleneck link;multibottleneck networks;single-bottleneck subsystems;combating bufferbloat;high queueing delay;delay variation;delay-sensitive applications;active queue management algorithms;AQM algorithms;Controlled Delay;buffer size;general multibottleneck TCP/AQM system;local asymptotic stability;self-tuning CoDel;Stability analysis;Asymptotic stability;Delays;Mathematical model;Nickel;Heuristic algorithms;Internet},
doi={10.1109/INFOCOM.2018.8486251},
ISSN={},
month={April},}
@INPROCEEDINGS{8485929,
author={D. Yuan and H. Lin and J. Widmer and M. Hollick},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Optimal Joint Routing and Scheduling in Millimeter-Wave Cellular Networks},
year={2018},
volume={},
number={},
pages={1205-1213},
abstract={Millimeter-wave (mmWave) communication is a promising technology to cope with the expected exponential increase in data traffic in 5G networks. mmWave networks typically require a very dense deployment of mmWave base stations (mmBS). To reduce cost and increase flexibility, wireless backhauling is needed to connect the mmBSs. The characteristics of mmWave communication, and specifically its high directionality, imply new requirements for efficient routing and scheduling paradigms. We propose an efficient scheduling method, so-called schedule-oriented optimization, based on matching theory that optimizes QoS metrics jointly with routing. It is capable of solving any scheduling problem that can be formulated as a linear program whose variables are link times and QoS metrics. As an example of the schedule-oriented optimization, we show the optimal solution of the maximum throughput fair scheduling (MTFS). Practically, the optimal scheduling can be obtained even for networks with over 200 mmBSs. To further increase the runtime performance, we propose an efficient edge-coloring based approximation algorithm with provable performance bound. It achieves over 80% of the optimal max-min throughput and runs 5 to 100 times faster than the optimal algorithm in practice. Finally, we extend the optimal and approximation algorithms for the cases of multi-RF-chain mmBSs and integrated backhaul and access networks.},
keywords={approximation theory;cellular radio;linear programming;millimetre wave communication;quality of service;telecommunication network routing;telecommunication scheduling;linear programming;mmWave cellular networks;schedule-oriented optimization;maximum throughput fair scheduling method;multiRF-chain mmBS;5G networks;MTFS;edge-coloring based approximation algorithm;optimal maxmin throughput;access networks;QoS metrics;matching theory;mmWave communication;wireless backhauling;mmWave base stations;data traffic;millimeter-wave communication;millimeter-wave cellular networks;optimal joint routing;Schedules;Optimal scheduling;Throughput;Radio frequency;Routing;Base stations},
doi={10.1109/INFOCOM.2018.8485929},
ISSN={},
month={April},}
@INPROCEEDINGS{8485961,
author={X. Zhang and Y. Hu and P. P. C. Lee and P. Zhou},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Toward Optimal Storage Scaling via Network Coding: From Theory to Practice},
year={2018},
volume={},
number={},
pages={1808-1816},
abstract={To adapt to the increasing storage demands and varying storage redundancy requirements, practical distributed storage systems need to support storage scaling by relocating currently stored data to different storage nodes. However, the scaling process inevitably transfers substantial data traffic over the network. Thus, minimizing the bandwidth cost of the scaling process is critical in distributed settings. In this paper, we show that optimal storage scaling is achievable in erasure-coded distributed storage based on network coding, by allowing storage nodes to send encoded data during scaling. We formally prove the information-theoretically minimum scaling bandwidth. Based on our theoretical findings, we also build a distributed storage system prototype NCScale, which realizes network-coding-based scaling while preserving the necessary properties for practical deployment. Experiments on Amazon EC2 show that the scaling time can be reduced by up to 50% over the state-of-the-art.},
keywords={network coding;storage management;distributed settings;network coding;encoded data;information-theoretically minimum scaling bandwidth;distributed storage system prototype NCScale;network-coding-based scaling;scaling time;scaling process;substantial data traffic;redundancy requirements;distributed storage systems;optimal storage scaling;Bandwidth;Maintenance engineering;Redundancy;Network coding;Encoding;Reed-Solomon codes;Distributed databases},
doi={10.1109/INFOCOM.2018.8485961},
ISSN={},
month={April},}
@INPROCEEDINGS{8485984,
author={P. Gawlowicz and A. Zubow and A. Wolisz},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Enabling Cross-technology Communication between LTE Unlicensed and WiFi},
year={2018},
volume={},
number={},
pages={144-152},
abstract={LTE in Unlicensed (LTE-U) constitutes a new source of interference in the 5 GHz ISM band with a potentially strong impact on WiFi performance. Cross-technology interference and radio resource management are the best ways to assure efficient coexistence but require proper signaling channels. We present LtFi, a system which enables to set-up a cross-technology communication between nodes of co-located LTE-U and WiFi networks. LtFi follows a two-step approach: using an innovative side channel on their air-interface LTE-U BSs are broadcasting connection and identification information to adjacent WiFi nodes, which is used in a subsequent step to create a bi-directional control channel over the wired backhaul. The simple LtFi is fully compliant with LTE-U and works with COTS WiFi hardware. The achievable data rate on the air-interface based broadcast side channel (up to 665 bps) is sufficient for this and multiple other purposes. Experimental evaluation of a fully operational prototype has demonstrated reliable data transmission even in crowded wireless environments for LTE-U receive power levels down to -92 dBm. Moreover, system-level simulations demonstrate accurate recognition of the complete set of interfering LTE-U BSs in a typical LTE-U multi-cell environment.},
keywords={Long Term Evolution;wireless LAN;LTE Unlicensed;WiFi performance;radio resource management;co-located LTE-U;WiFi networks;two-step approach;innovative side channel;air-interface LTE-U BSs;adjacent WiFi nodes;bi-directional control channel;simple LtFi;COTS WiFi hardware;system-level simulations;typical LTE-U multicell environment;cross-technology communication;ISM band;LTE-U BSs;frequency 5.0 GHz;Wireless fidelity;Receivers;Long Term Evolution;Interference;Modulation;Conferences;Bidirectional control;Cross-technology communication;LTE-U;WiFi;coexistence;cooperation;heterogeneous networks},
doi={10.1109/INFOCOM.2018.8485984},
ISSN={},
month={April},}
@INPROCEEDINGS{8486232,
author={G. Bielsal and J. Palacios and A. Loch and D. Steinmetzer and P. Casari and J. Widmer},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Indoor Localization Using Commercial Off-The-Shelf 60 GHz Access Points},
year={2018},
volume={},
number={},
pages={2384-2392},
abstract={The very large bandwidth available in the 60 GHz band allows, in principle, to design highly accurate positioning systems. Integrating such systems with standard protocols (e.g., IEEE 802.11ad) is crucial for the deployment of location-based services, but it is also challenging and limits the design choices. Another key problem is that consumer-grade 60 GHz hardware only provides coarse channel state information, and has highly irregular beam shapes due to its cost-efficient design. In this paper, we explore the location accuracy that can be achieved using such hardware, without modifying the 802.11ad standard. We consider a typical 802.11ad indoor network with multiple access points (APs). Each AP collects the coarse signal-to-noise ratio of the directional beacons that clients transmit periodically. Given the irregular beam shapes, the challenge is to relate each beacon to a set of transmission angles that allows to triangulate a user. We design a location system based on particle filters along with linear programming and Fourier analysis. We implement and evaluate our algorithm on commercial off-the-shelf 802.11ad hardware in an office scenario with mobile human blockage. Despite the strong limitations of the hardware, our system operates in real-time and achieves sub-meter accuracy in 70% of the cases.},
keywords={Fourier analysis;indoor communication;linear programming;wireless channels;wireless LAN;802.11ad indoor network;multiple access points;coarse signal-to-noise ratio;directional beacons;standard protocols;IEEE 802.11ad;location-based services;coarse channel state information;linear programming;particle filters;frequency 60.0 GHz;Hardware;Signal to noise ratio;Shape;Phased arrays;Estimation;Standards},
doi={10.1109/INFOCOM.2018.8486232},
ISSN={},
month={April},}
@INPROCEEDINGS{8485989,
author={H. Wang and H. Shen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Proactive Incast Congestion Control in a Datacenter Serving Web Applications},
year={2018},
volume={},
number={},
pages={19-27},
abstract={With the rapid development of web applications in datacenters, network latency becomes more important to user experience. The network latency will be greatly increased by incast congestion, in which a huge number of requests arrive at the front-end server simultaneously. Previous incast problem solutions usually handle the data transmission between the data servers and the front-end server directly, and they are not sufficiently effective in proactively avoiding incast congestion. To further improve the effectiveness, in this paper, we propose a Proactive Incast Congestion Control system (PICC). Since each connection has bandwidth limit, PICC novelly limits the number of data servers concurrently connected to the front-end server to avoid the incast congestion through data placement. Specifically, the front-end server gathers popular data objects (i.e., frequently requested data objects) into as few data servers as possible, but without overloading them. It also re-allocates the data objects that are likely to be concurrently or sequentially requested into the same server. As a result, PICC reduces the number of data servers concurrently connected to the front-end server (which avoids the incast congestion), and also the number of connection establishments (which reduces the network latency). Since the selected data servers tend to have long queues to send out data, to reduce the queuing latency, PICC incorporates a queuing delay reduction algorithm that assigns higher transmission priorities to data objects with smaller sizes and longer queuing times. The experimental results on simulation and a real cluster based on a benchmark show the superior performance of PICC over previous incast congestion problem solutions.},
keywords={cloud computing;computer centres;file servers;queueing theory;telecommunication congestion control;telecommunication traffic;PICC;data transmission;Proactive Incast Congestion Control system;data placement;Web applications;datacenter;queuing delay reduction algorithm;Servers;Delays;Bandwidth;Silicon;Time-frequency analysis;Conferences;Throughput},
doi={10.1109/INFOCOM.2018.8485989},
ISSN={},
month={April},}
@INPROCEEDINGS{8486320,
author={X. Fei and F. Liu and H. Xu and H. Jin},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Adaptive VNF Scaling and Flow Routing with Proactive Demand Prediction},
year={2018},
volume={},
number={},
pages={486-494},
abstract={With the evolution of Network Function Virtual-izaiton (NFV), enterprises are increasingly outsourcing their network functions to the cloud. However, using virtualized network functions (VNFs) to provide flexible services in today's cloud is challenging due to the inherent difficulty in intelligently scaling VNFs to cope with traffic fluctuations. To best utilize cloud resources, NFV providers need to dynamically scale the VNF deployments and reroute traffic demands for their customers. Since most existing work is reactive in nature, we seek a proactive approach to provision new instances for overloaded VNFs ahead of time based on the estimated flow rates. We formulate the VNF provisioning problem in order that the cost incurred by inaccurate prediction and VNF deployment is minimized. In the proposed online algorithm, we first employ an efficient online learning method which aims at minimizing the error in predicting the service chain demands. We then derive the requested instances with adaptive processing capacities and call two other algorithms for new instance assignment and service chain rerouting, respectively, while achieving good competitive ratios. The joint online algorithm is proven to provide good performance guarantees by both theoretical analysis and trace-driven simulation.},
keywords={cloud computing;estimation theory;learning (artificial intelligence);outsourcing;prediction theory;resource allocation;telecommunication network routing;telecommunication traffic;virtualisation;instance assignment;joint online algorithm;adaptive VNF scaling;flow routing;proactive demand prediction;virtualized network functions;traffic fluctuations;NFV providers;VNF deployments;proactive approach;VNF provisioning problem;service chain demands;adaptive processing capacities;service chain rerouting;Network Function Virtualization;cloud resources;traffic demands rerouting;flow rates estimation;online learning method;Prediction algorithms;Routing;Cloud computing;Bandwidth;Servers;Outsourcing;Conferences},
doi={10.1109/INFOCOM.2018.8486320},
ISSN={},
month={April},}
@INPROCEEDINGS{8486409,
author={G. D. Nguyen and S. Kompella and C. Kam and J. E. Wieselthier and A. Ephremides},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Information Freshness Over an Interference Channel: A Game Theoretic View},
year={2018},
volume={},
number={},
pages={908-916},
abstract={Communication over an interference channel, which is fundamental and pervasive in the wireless and wireline environment, is often intended to carry information among different transmitter-receiver pairs. For applications that require time critical updates, it is desirable to maintain the freshness of the received information, which is quantified by the age metric (unlike the familiar delay metric). In this paper, we consider the case of two transmitter-receiver pairs, and address the impact of interference on information freshness by formulating a two-player “interference” game, in which each player is a transmitter desiring to maintain the freshness of the information updates it sends to its receiver. The strategy of a player is the choice of power level at which it will transmit. We then derive both Nash and Stackelberg strategies for the game. Our analysis shows that the Stackelberg strategy uses less power than the Nash strategy, and that it dominates the Nash strategy (i.e., the Stackelberg total cost function is lower than the Nash total cost function). Our obtained Nash and Stackelberg strategies are desirable user operating points in competitive situations.},
keywords={game theory;radio receivers;radio transmitters;radiofrequency interference;wireless channels;interference channel;game theoretic view;wireless environment;wireline environment;time critical updates;two-player interference game;transmitter-receiver pairs;Stackelberg total cost function strategy;Nash total cost function strategy;Receivers;Transmitters;Games;Interference;Integrated circuit modeling;Measurement;Age of information;information freshness;game theory;interference channel;Nash strategy;Stackelberg strategy},
doi={10.1109/INFOCOM.2018.8486409},
ISSN={},
month={April},}
@INPROCEEDINGS{8485942,
author={P. Castagno and V. Mancuso and M. Sereno and M. A. Marsan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={A Simple Model of MTC in Smart Factories},
year={2018},
volume={},
number={},
pages={2591-2599},
abstract={In this paper we develop a simple, yet accurate, performance model to understand if and how evolutions of traditional cellular network protocols can be exploited to allow large numbers of devices to gain control of transmission resources in smart factory radio access networks. The model results shed light on the applicability of evolved access procedures and help understand how many devices can be served per base station. In addition, considering the simultaneous presence of different traffic classes, we investigate the effectiveness of prioritised access, exploiting access class barring techniques. Our model shows that, even with the sub-millisecond time slots foreseen in LTE Advanced Pro and 5G, a base station can accommodate at most few thousand devices to guarantee access latencies below 100 ms with high transmission success probabilities. This calls for a rethinking of wireless access strategies to avoid ultra-dense cell deployments within smart factory infrastructures.},
keywords={5G mobile communication;cellular radio;Long Term Evolution;protocols;radio access networks;telecommunication traffic;smart factory infrastructures;MTC;performance model;traditional cellular network protocols;transmission resources;smart factory radio access networks;evolved access procedures;base station;prioritised access;access class barring techniques;sub-millisecond time slots;LTE Advanced Pro;access latencies;high transmission success probabilities;wireless access strategies;traffic classes;5G mobile communication;Base stations;Smart manufacturing;Analytical models;Conferences;Computational modeling;Performance evaluation},
doi={10.1109/INFOCOM.2018.8485942},
ISSN={},
month={April},}
@INPROCEEDINGS{8485898,
author={P. Castagno and V. Mancuso and M. Sereno and M. Ajmone Marsan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Closed form Expressions for the Performance Metrics of Data Services in Cellular Networks},
year={2018},
volume={},
number={},
pages={585-593},
abstract={In this paper we study the queuing system that describes the operations of data services in cellular networks, e.g., UMTS, LTE/LTE-A, and most likely the forthcoming 5G standard. The main characteristic of all these systems is that after service access, resources remain allocated to the end user for some time before release, so that if the same user requests access to service again, before a system timeout, the same resources are still available. For the resulting queuing model, we express the blocking probability in closed form, and we also provide recursive expressions in the number of connections that can be handled by the base station. Closed form expressions are also derived for other useful performance metrics, i.e., throughput and network service time. Analytical results are validated against results of a detailed simulation model, and compared to traditional queueing models results, such as the Erlang B formula iteratively applied to the resources that are not blocked by potentially returning users. Our analysis complements the performance evaluation of the other key mechanism used to access data services in cellular networks, namely the random access, which precedes the resource allocation and utilization phase studied in this paper.},
keywords={3G mobile communication;Long Term Evolution;performance evaluation;probability;queueing theory;resource allocation;closed form expressions;cellular networks;queuing system;blocking probability;recursive expressions;network service time;performance evaluation;random access;resource allocation;LTE-LTE-A;5G standard;queuing model;simulation model;data services;performance metrics;UMTS;user request access;Erlang B formula;Base stations;Cellular networks;Analytical models;Closed-form solutions;Throughput;Measurement;Queueing analysis},
doi={10.1109/INFOCOM.2018.8485898},
ISSN={},
month={April},}
@INPROCEEDINGS{8486246,
author={C. Zeng and F. Liu and S. Chen and W. Jiang and M. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Demystifying the Performance Interference of Co-Located Virtual Network Functions},
year={2018},
volume={},
number={},
pages={765-773},
abstract={Network function virtualization (NFV) decouples network functions from the dedicated hardware and enables them running on commodity servers, facilitating widespread deployment of virtualized network functions (VNFs). Network operators tend to deploy VNFs in virtual machines (VMs) due to VM's ease of duplication and migration, which enables flexible VNF placement and scheduling. Efforts have been paid to provide efficient VNF placement approaches, aiming at minimizing the resource cost of VNF deployment and reducing the latency of service chain. However, existing placement approaches may result in hardware resource competition of co-located VNFs, leading to performance degradation. In this paper, we present a measurement study on the performance interference among different types of co-located VNFs and analyze how VNFs' competitive hardware resources and the characteristics of packet affect the performance interference. We disclose that the performance interference between co-located VNFs is ubiquitous, which causes the performance degradation, in terms of VNFs' throughput, ranging from 12.36% to 50.3%, and the competition of network I/O bandwidth plays a key role in the performance interference. Based on our measurement results, we give some advices on how to design more efficient VNF placement approaches.},
keywords={computer networks;interference;virtual machines;virtualisation;performance interference demystifying;colocated VNF placement approaches;colocated virtual network functions;VM;network I-O bandwidth;hardware resource competition;scheduling;virtual machines;Interference;Servers;Bandwidth;Degradation;Hardware;Resource management;Throughput},
doi={10.1109/INFOCOM.2018.8486246},
ISSN={},
month={April},}
@INPROCEEDINGS{8486387,
author={J. Verhoeff and N. S. N. Akshay Uttama and M. Zuniga Zamalloa and B. Humala},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Monitoring LED Lights with Current Signatures},
year={2018},
volume={},
number={},
pages={342-350},
abstract={Artificial lighting is a pervasive element in our daily lives. Researchers from different communities are investigating challenges and opportunities related to artificial lighting but from different angles: energy disaggregation, to monitor the status of light bulbs in buildings; and communication, to transmit information wirelessly. We argue that there is an unexplored synergy between these two communities. When a light bulb modulates its intensity for communication, it also affects the current it draws. This current signature is unique and could be used by energy disaggregation methods to identify the lights' status. These signatures however will be exposed to interference (collisions of signatures) and distortions due to power line effects. To overcome these problems, we build upon coding schemes to assign interference-resilient signatures, and we develop custom hardware to ameliorate distortions introduced by power lines. We validate our framework in a proof-of-concept testbed, perform simulations to test scalability, and use energy traces from real homes to evaluate the impact of other electric loads.},
keywords={encoding;interference (signal);LED lamps;lighting;optical distortion;power cables;current signature;artificial lighting;pervasive element;light bulb;energy disaggregation methods;power line effects;interference-resilient signatures;energy traces;LED light monitoring;coding schemes;proof-of-concept testbed;test scalability;electric loads;Buildings;Lighting;Monitoring;Meters;Interference;Light emitting diodes;Distortion},
doi={10.1109/INFOCOM.2018.8486387},
ISSN={},
month={April},}
@INPROCEEDINGS{8486307,
author={I. Kadota and A. Sinha and E. Modiano},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Optimizing Age of Information in Wireless Networks with Throughput Constraints},
year={2018},
volume={},
number={},
pages={1844-1852},
abstract={Age of Information (AoI) is a performance metric that captures the freshness of the information from the perspective of the destination. The AoI measures the time that elapsed since the generation of the packet that was most recently delivered to the destination. In this paper, we consider a single-hop wireless network with a number of nodes transmitting time-sensitive information to a Base Station and address the problem of minimizing the Expected Weighted Sum AoI of the network while simultaneously satisfying timely-throughput constraints from the nodes. We develop three low-complexity transmission scheduling policies that attempt to minimize AoI subject to minimum throughput requirements and evaluate their performance against the optimal policy. In particular, we develop a randomized policy, a Max-Weight policy and a Whittle's Index policy, and show that they are guaranteed to be within a factor of two, four and eight, respectively, away from the minimum AoI possible. In contrast, simulation results show that Max-Weight outperforms the other policies, both in terms of AoI and throughput, in every network configuration simulated, and achieves near optimal performance.},
keywords={communication complexity;minimisation;radio networks;telecommunication scheduling;single-hop wireless network;low-complexity transmission scheduling policies;base station;Whittle's index policy;AoI;max-weight policy;age of informatio;time-sensitive information transmission;expected weighted sum minimization;Throughput;Monitoring;Sensor phenomena and characterization;Measurement;Optimized production technology},
doi={10.1109/INFOCOM.2018.8486307},
ISSN={},
month={April},}
@INPROCEEDINGS{8486321,
author={M. H. Mazhar and Z. Shafiq},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Real-time Video Quality of Experience Monitoring for HTTPS and QUIC},
year={2018},
volume={},
number={},
pages={1331-1339},
abstract={The widespread deployment of end-to-end encryption protocols such as HTTPS and QUIC has reduced the visibility for operators into traffic on their networks. Network operators need the visibility to monitor and mitigate Quality of Experience (QoE) impairments in popular applications such as video streaming. To address this problem, we propose a machine learning based approach to monitor QoE metrics for encrypted video traffic. We leverage network and transport layer information as features to train machine learning classifiers for inferring video QoE metrics such as startup delay and rebuffering events. Using our proposed approach, network operators can detect and react to encrypted video QoE impairments in real-time. We evaluate our approach for YouTube adaptive video streams using HTTPS and QUIC. The experimental evaluations show that our approach achieves up to 90% classification accuracy for HTTPS and up to 85 % classification accuracy for QUIC.},
keywords={cryptographic protocols;learning (artificial intelligence);quality of experience;telecommunication traffic;video streaming;real-time video quality of experience monitoring;encrypted video QoE impairments;rebuffering events;video QoE metrics;transport layer information;encrypted video traffic;machine learning;video streaming;network operators;end-to-end encryption protocols;QUIC;HTTPS;Quality of experience;Streaming media;Measurement;Cryptography;Monitoring;Machine learning;Real-time systems},
doi={10.1109/INFOCOM.2018.8486321},
ISSN={},
month={April},}
@INPROCEEDINGS{8486362,
author={M. Shit and X. Lin and S. Fahmy and D. Shin},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Competitive Online Convex Optimization with Switching Costs and Ramp Constraints},
year={2018},
volume={},
number={},
pages={1835-1843},
abstract={We investigate competitive online algorithms for online convex optimization (OCO) problems with linear in-stage costs, switching costs and ramp constraints. While OCO problems have been extensively studied in the literature, there are limited results on the corresponding online solutions that can attain small competitive ratios. We first develop a powerful computational framework that can compute an optimized competitive ratio based on the class of affine policies. Our computational framework can handle a fairly general class of costs and constraints. Compared to other competitive results in the literature, a key feature of our proposed approach is that it can handle scenarios where infeasibility may arise due to hard feasibility constraints. Second, we design a robustification procedure to produce an online algorithm that can attain good performance for both average-case and worst-case inputs. We conduct a case study on Network Functions Virtualization (NFV) orchestration and scaling to demonstrate the effectiveness of our proposed methods.},
keywords={computational complexity;convex programming;virtualisation;competitive online convex optimization;switching costs;ramp constraints;online convex optimization problems;OCO problems;optimized competitive ratio;hard feasibility constraints;online algorithm;computational framework;network functions virtualization;Robustness;Uncertainty;Switches;Network function virtualization;Heuristic algorithms;Convex functions;Conferences},
doi={10.1109/INFOCOM.2018.8486362},
ISSN={},
month={April},}
@INPROCEEDINGS{8485946,
author={M. Zheleva and P. Bogdanov and T. Larock and P. Schmitt},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={AirVIEW: Unsupervised transmitter detection for next generation spectrum sensing},
year={2018},
volume={},
number={},
pages={1673-1681},
abstract={The current paradigm of exclusive spectrum assignment and allocation is creating artificial spectrum scarcity that has a dramatic impact on network performance and user experience. Thus, governments, industry and academia have endeavored to create novel spectrum management mechanisms that allow multi-tiered access. A key component of such an approach is deep understanding of spectrum utilization in time, frequency and space. To address this challenge, we propose AirVIEW, a one-pass, unsupervised spectrum characterization approach for rapid transmitter detection with high tolerance to noise. AirVIEW autonomously learns its parameters and employs wavelet decomposition in order to amplify and reliably detect transmissions at a given time instant. We show that AirVIEW can robustly identify transmitters even when their power is only 5dBm above the noise floor. Furthermore, we demonstrate AirVIEW's ability to inform next-generation Dynamic Spectrum Access by characterizing essential transmitter properties in wideband spectrum measurements from 50MHz to 4.4GHz.},
keywords={multi-access systems;radio spectrum management;radio transmitters;resource allocation;signal detection;wavelet transforms;next generation spectrum sensing;spectrum assignment;transmitter detection;AirVIEW;wavelet decomposition;artificial spectrum scarcity;unsupervised transmitter detection;wideband spectrum measurements;next-generation Dynamic Spectrum Access;unsupervised spectrum characterization approach;spectrum utilization;multitiered access;spectrum management mechanisms;user experience;frequency 50.0 MHz to 4.4 GHz;Radio transmitters;Robustness;Noise measurement;Next generation networking;Time-frequency analysis;Floors},
doi={10.1109/INFOCOM.2018.8485946},
ISSN={},
month={April},}
@INPROCEEDINGS{8486021,
author={R. Cziva and C. Anagnostopoulos and D. P. Pezaros},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Dynamic, Latency-Optimal vNF Placement at the Network Edge},
year={2018},
volume={},
number={},
pages={693-701},
abstract={Future networks are expected to support low-latency, context-aware and user-specific services in a highly flexible and efficient manner. One approach to support emerging use cases such as, e.g., virtual reality and in-network image processing is to introduce virtualized network functions (vNF)s at the edge of the network, placed in close proximity to the end users to reduce end-to-end latency, time-to-response, and unnecessary utilisation in the core network. While placement of vNFs has been studied before, it has so far mostly focused on reducing the utilisation of server resources (i.e., minimising the number of servers required in the network to run a specific set of vNFs), and not taking network conditions into consideration such as, e.g., end-to-end latency, the constantly changing network dynamics, or user mobility patterns. In this paper, we formulate the Edge vNF placement problem to allocate vNFs to a distributed edge infrastructure, minimising end-to-end latency from all users to their associated vNFs. We present a way to dynamically re-schedule the optimal placement of vNFs based on temporal network-wide latency fluctuations using optimal stopping theory. We then evaluate our dynamic scheduler over a simulated nation-wide backbone network using real-world ISP latency characteristics. We show that our proposed dynamic placement scheduler minimises vNF migrations compared to other schedulers (e.g., periodic and always-on scheduling of a new placement), and offers Quality of Service guarantees by not exceeding a maximum number of latency violations that can be tolerated by certain applications.},
keywords={Internet;quality of service;telecommunication scheduling;telecommunication traffic;virtual reality;virtualisation;end-to-end latency;context-aware services;dynamic placement scheduler;quality of service;latency violations;real-world ISP latency characteristics;simulated nation-wide backbone network;temporal network-wide latency fluctuations;optimal placement;distributed edge infrastructure;Edge vNF placement problem;user mobility patterns;constantly changing network dynamics;network conditions;core network;end users;virtualized network functions;in-network image processing;virtual reality;user-specific services;network Edge;latency-optimal vNF placement;Dynamic scheduling;Bandwidth;Topology;Conferences;Servers;Virtualization;Internet;Network Function Virtualization;Latency;Edge Network;Resource Orchestration;Optimal Stopping Theory},
doi={10.1109/INFOCOM.2018.8486021},
ISSN={},
month={April},}
@INPROCEEDINGS{8486421,
author={A. Sehati and M. Ghaderi},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Online Energy Management in IoT Applications},
year={2018},
volume={},
number={},
pages={1286-1294},
abstract={This paper considers energy management on LTE-enabled Internet of Things (IoT) devices. A characteristic feature of IoT applications is the periodic generation of small messages, whose transmission over LTE is highly energy inefficient. In this paper, we consider application message bundling to alleviate the effect of short message transmissions on energy consumption. Specifically, we model the interplay between energy consumption and the extended DRX mechanism introduced in LTE to deal with IoT traffic. We formulate bundling as a cost minimization problem and develop an online algorithm to solve the problem. Detailed analysis shows that, depending on DRX and application parameters, our algorithm is 1, 2, or 4-competitive with respect to the optimal offline algorithm that knows the entire sequence of application messages a priori. We evaluate the performance of the proposed algorithm and the accuracy of our analysis in a range of realistic scenarios using both model-driven simulations and real experiments on an IoT testbed. Our results show that, i) depending on application requirements, energy savings ranging from zero to about 100% can be achieved using our algorithm, and ii) ignoring DRX could significantly overestimate or underestimate energy consumption.},
keywords={energy consumption;energy management systems;Internet of Things;Long Term Evolution;telecommunication power management;energy consumption;extended DRX mechanism;IoT traffic;cost minimization problem;online algorithm;optimal offline algorithm;application messages;IoT testbed;application requirements;energy savings;online energy management;LTE-enabled Internet;characteristic feature;periodic generation;application message bundling;short message transmissions;Internet of Things devices;Delays;Long Term Evolution;Energy consumption;Internet of Things;Smart phones;Energy management;Computational modeling},
doi={10.1109/INFOCOM.2018.8486421},
ISSN={},
month={April},}
@INPROCEEDINGS{8485906,
author={K. Cai and X. Liu and Y. J. Chen and J. C. S. Lui},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={An Online Learning Approach to Network Application Optimization with Guarantee},
year={2018},
volume={},
number={},
pages={2006-2014},
abstract={Network application optimization is essential for improving the performance of the application as well as its user experience. The network application parameters are crucial in making proper decisions for network application optimizations. However, many works are impractical by assuming a priori knowledge of the parameters which are usually unknown and need to be estimated. There have been studies that consider optimizing network application in an online learning context using multi-armed bandit models. However, existing frameworks are problematic as they only consider to find the optimal decisions to minimize the regret, but neglect the constraints (or guarantee) requirements which may be excessively violated. In this paper, we propose a novel online learning framework for network application optimizations with guarantee. To the best of our knowledge, we are the first to formulate the stochastic constrained multi-armed bandit model with time-varying “multi-level rewards” by taking both “regret” and “violation” into consideration. We are also the first to design a constrained bandit policy, Learning with Minimum Guarantee (LMG), with provable sub-linear regret and violation bounds. We illustrate how our framework can be applied to several emerging network application optimizations, namely, (1) opportunistic multichannel selection, (2) data-guaranteed crowdsensing, and (3) stability-guaranteed crowdsourced transcoding. To show the effectiveness of LMG in optimizing these applications with different minimum requirements, we also conduct extensive simulations by comparing LMG with existing state-of-the-art policies.},
keywords={crowdsourcing;learning (artificial intelligence);optimisation;stochastic processes;ubiquitous computing;network application optimization;network application parameters;online learning;network application optimizations;multilevel rewards;learning with minimum guarantee;LMG;stochastic constrained multiarmed bandit model;data-guaranteed crowdsensing;opportunistic multichannel selection;stability-guaranteed crowdsourced transcoding;Optimization;Compounds;Stochastic processes;Throughput;Transcoding;Task analysis;Random processes},
doi={10.1109/INFOCOM.2018.8485906},
ISSN={},
month={April},}
@INPROCEEDINGS{8486324,
author={M. Noormohammadpour and C. S. Raghavendra and S. Kandula and S. Rao},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={QuickCast: Fast and Efficient Inter-Datacenter Transfers Using Forwarding Tree Cohorts},
year={2018},
volume={},
number={},
pages={225-233},
abstract={Several organizations have built multiple datacenters connected via dedicated wide area networks over which large inter-datacenter transfers take place. Since many such transfers move the same data from one source to multiple destinations, using multicast forwarding trees can reduce bandwidth needs and improve completion times. However, using a single forwarding tree per transfer can lead to poor performance as the slowest receiver dictates the completion time for all receivers. Using multiple forwarding trees per transfer alleviates this concern-the average receiver could finish early; however, if done naively, bandwidth usage would also increase and it is apriori unclear how best to partition receivers, how to construct the multiple trees and how to determine the rate and schedule of flows on these trees. This paper presents QuickCast, a first solution to these problems. Using simulations on real-world network topologies, we see that QuickCast can speed up the average receiver's completion time by as much as 10× while only using 1.04× more bandwidth; further, the completion time for all receivers also improves by as much as faster at high loads. Thereby, while some implementation challenges remain, we advocate using a cohort of forwarding trees.},
keywords={computer centres;multicast communication;telecommunication network topology;telecommunication scheduling;trees (mathematics);wide area networks;QuickCast;efficient inter-datacenter transfers;forwarding tree cohorts;multiple datacenters;dedicated wide area networks;multiple destinations;multicast forwarding trees;completion time;single forwarding tree;multiple forwarding trees;bandwidth usage;partition receivers;multiple trees;real-world network topologies;Receivers;Bandwidth;Optimization;Topology;Wide area networks;Network topology;Software Defined WAN;Datacenter;Scheduling;Completion Times;Replication},
doi={10.1109/INFOCOM.2018.8486324},
ISSN={},
month={April},}
@INPROCEEDINGS{8486253,
author={Q. Liu and L. Deng and H. Zeng and M. Chen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={A Tale of Two Metrics in Network Delay Optimization},
year={2018},
volume={},
number={},
pages={2123-2131},
abstract={We consider the scenario where a source streams a flow at fixed rate to a receiver across a network, possibly using multiple paths. Transmission over a link incurs a delay modeled as a non-negative, non-decreasing and differentiable function of the link aggregated transmission rate. This setting models various practical network communication scenarios. We study network delay optimization concerning two popular metrics, namely maximum delay and average delay experienced by the flow. A well-known pessimistic result says that a flow cannot simultaneously achieve optimal maximum delay and optimal average delay, or even within constant-ratio gaps to the two optimums. In this paper, we pose an optimistic note on the fundamental compatibility of the two delay metrics. Specifically, we design two polynomial-time solutions to deliver (1 -ε) fraction of the flow with maximum delay and average delay simultaneously within 1/ε to the optimums for any ε ∈ (0,1). Hence, the two delay metrics are “largely” compatible. The ratio 1/ε is independent to the network size and link delay function, and we show that it is tight or near-tight. Simulations based on real-world continent-scale network topology verify our theoretical findings. Note that the proposed delay gap 1/ε, upon sacrificing ε fraction of the flow rate, is guaranteed even under the worst theoretical case setting. Our simulation results show that the empirical delay gaps observed under practical settings can be much smaller than 1/ε. Our results are of particular interest to delay-centric networking applications that can tolerate a small fraction of traffic loss, including cloud video conferencing that recently attracts substantial attention.},
keywords={computational complexity;delays;optimisation;telecommunication network topology;telecommunication traffic;network delay optimization;optimal maximum delay;optimal average delay;delay metrics;network size;real-world continent-scale network topology;flow rate;empirical delay gaps;delay-centric networking applications;link aggregated transmission rate;practical network communication scenarios;polynomial-time solutions;traffic loss;cloud video conferencing;Delays;Optimization;Network topology;Routing;Approximation algorithms;Data models},
doi={10.1109/INFOCOM.2018.8486253},
ISSN={},
month={April},}
@INPROCEEDINGS{8486432,
author={H. Xu and S. Hao and A. Sari and H. Wang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Privacy Risk Assessment on Email Tracking},
year={2018},
volume={},
number={},
pages={2519-2527},
abstract={Today's online marketing industry has widely employed email tracking techniques, such as embedding a tiny tracking pixel, to track email opens of potential customers and measure marketing effectiveness. However, email tracking could allow miscreants to collect metadata information associated with email reading without user awareness and then leverage the information for stealthy surveillance, which has raised serious privacy concerns. In this paper, we present an in-depth and comprehensive study on the privacy implications of email tracking. First, we develop an email tracking system and perform realworld tracking on hundreds of solicited crowdsourcing participants. We estimate the amount of privacy-sensitive information available from email reading, assess privacy risks of information leakage, and demonstrate how easy it is to launch a long-term targeted surveillance attack in real scenarios by simply sending an email with tracking capability. Second, we investigate the prevalence of email tracking through a large-scale measurement, which includes more than 44,000 email samples obtained over a period of seven years. Third, we conduct a user study to understand users' perception of privacy infringement caused by email tracking. Finally, we evaluate existing countermeasures against email tracking and propose guidelines for developing more comprehensive and fine-grained prevention solutions.},
keywords={data privacy;electronic mail;marketing data processing;meta data;risk management;Web sites;tiny tracking pixel;email reading;email tracking system;email tracking techniques;privacy risk assessment;metadata information;privacy-sensitive information;online marketing industry;Electronic mail;Privacy;Target tracking;Servers;Metadata;Crowdsourcing;Surveillance},
doi={10.1109/INFOCOM.2018.8486432},
ISSN={},
month={April},}
@INPROCEEDINGS{8486278,
author={Q. Lin and L. Dengt and J. Sun and M. Chen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Optimal Demand-Aware Ride-Sharing Routing},
year={2018},
volume={},
number={},
pages={2699-2707},
abstract={We consider the problem of exploring travel demand statistics to optimize ride-sharing routing, in which the driver of a vehicle determines a route to transport multiple customers with similar itineraries and schedules in a cost-effective and timely manner. This problem is important for unleashing economical and societal benefits of ride-sharing. Meanwhile, it is challenging due to the need of (i) meeting travel delay requirements of customers, and (ii) making online decisions without knowing the exact travel demands beforehand. We present a general framework for exploring the new design space enabled by the demand-aware approach. We show that the demand-aware ride-sharing routing is fundamentally a two-stage stochastic optimization problem. We show that the problem is NP-Complete in the weak sense. We exploit the two-stage structure to design an optimal solution with pseudo-polynomial time complexity, which makes it amenable for practical implementation. We carry out extensive simulations based on real-world travel demand traces of Manhattan. The results show that using our demand-aware solution instead of the conventional greedy-routing scheme increases the driver's revenue by 10%. The results further show that as compared to the case without ride-sharing, our ride-sharing solution reduces the customers' payment by 9% and the total vehicle travel time (indicator of greenhouse gas emission) by 17%. The driver can also get 26% extra revenues per slot by participating in ride-sharing.},
keywords={computational complexity;greedy algorithms;scheduling;statistical analysis;stochastic processes;stochastic programming;vehicle routing;optimal demand-aware ride-sharing routing;travel demand statistics;multiple customers;schedules;societal benefits;pseudopolynomial time complexity;greedy-routing scheme;itineraries;stochastic optimization problem;unleashing economical benefits;transport;travel delay requirements;online decisions;NP-complete;Manhattan;drivers revenue;Vehicles;Routing;Roads;Delays;Space exploration;Planning;Conferences},
doi={10.1109/INFOCOM.2018.8486278},
ISSN={},
month={April},}
@INPROCEEDINGS{8486343,
author={A. Chakraborty and A. Bhattacharya and S. Kamal and S. R. Das and H. Gupta and P. M. Djuric},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Spectrum Patrolling with Crowdsourced Spectrum Sensors},
year={2018},
volume={},
number={},
pages={1682-1690},
abstract={We use a crowdsourcing approach for RF spectrum patrolling, where heterogeneous, low-cost spectrum sensors are deployed widely and are tasked with detecting unauthorized transmissions in a collaborative fashion while consuming only a limited amount of resources. We pose this as a collaborative signal detection problem where the individual sensor's detection performance may vary widely based on their respective hardware or software configurations, but are hard to model using traditional approaches. Still an optimal subset of sensors and their configurations must be chosen to maximize the overall detection performance subject to given resource (cost) limitations. We present the challenges of this problem in crowdsourced settings and present a set of methods to address them. The proposed methods use data-driven approaches to model individual sensors and develops mechanisms for sensor selection and fusion while accounting for their correlated nature. We present performance results using examples of commodity-based spectrum sensors and show significant improvements relative to baseline approaches.},
keywords={mobile computing;radio spectrum management;sensor fusion;signal detection;data-driven approaches;commodity-based spectrum sensors;baseline approaches;RF spectrum patrolling;collaborative signal detection problem;sensor fusion selection;crowdsourced spectrum sensor approach;Sensor fusion;Measurement;Task analysis;Hardware;Crowdsourcing;Signal detection},
doi={10.1109/INFOCOM.2018.8486343},
ISSN={},
month={April},}
@INPROCEEDINGS{8486290,
author={S. Chiang and J. Kuo and S. Shen and D. Yang and W. Chen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Online Multicast Traffic Engineering for Software-Defined Networks},
year={2018},
volume={},
number={},
pages={414-422},
abstract={Previous research on SDN traffic engineering mostly focuses on static traffic, whereas dynamic traffic, though more practical, has drawn much less attention. Especially, online SDN multicast that supports IETF dynamic group membership (i.e., any user can join or leave at any time) has not been explored. Different from traditional shortest-path trees (SPT) and graph theoretical Steiner trees (ST), which concentrate on routing one tree at any instant, online SDN multicast traffic engineering is more challenging because it needs to support dynamic group membership and optimize a sequence of correlated trees without the knowledge of future join and leave, whereas the scalability of SDN due to limited TCAM is also crucial. In this paper, therefore, we formulate a new optimization problem, named Online Branch-aware Steiner Tree (OBST), to jointly consider the bandwidth consumption, SDN multicast scalability, and rerouting overhead. We prove that OBST is NP-hard and does not have a |Dmax|1-ε-competitive algorithm for any , where |Dmax| is the largest group size at any time. We design a |Dmax|-competitive algorithm equipped with the notion of the budget, the deposit, and Reference Tree to achieve the tightest bound. The simulations and implementation on real SDNs with YouTube traffic manifest that the total cost can be reduced by at least 25% compared with SPT and ST, and the computation time is small for massive SDN.},
keywords={computational complexity;Internet;multicast communication;optimisation;social networking (online);software defined networking;telecommunication network routing;telecommunication traffic;trees (mathematics);graph theoretical Steiner trees;bandwidth consumption;rerouting overhead;TCAM;OBST;NP-hard problem;online branch-aware Steiner tree;shortest-path trees;dynamic traffic;static traffic;software-defined networks;massive SDN;YouTube traffic;online SDN multicast traffic engineering;IETF dynamic group membership;Unicast;Steiner trees;Optical switches;Routing;Bandwidth;Scalability},
doi={10.1109/INFOCOM.2018.8486290},
ISSN={},
month={April},}
@INPROCEEDINGS{8486356,
author={S. Ji and T. Du and Z. Hong and T. Wang and R. Beyah},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Quantifying Graph Anonymity, Utility, and De-anonymity},
year={2018},
volume={},
number={},
pages={1736-1744},
abstract={In this paper, we study the correlation of graph da-ta's anonymity, utility, and de-anonymity. Our main contributions include four perspectives. First, to the best of our knowledge, we conduct the first Anonymity-Utility-De-anonymity (AUD) correlation quantification for graph data and obtain close-forms for such correlation under both a preliminary mathematical model and a general data model. Second, we integrate our AUD quantification to SecGraph [31], a recently published Secure Graph data sharing/publishing system, and extend it to Sec-Graph+. Compared to SecGraph, SecGraph+ is an improved and enhanced uniform and open-source system for comprehensively studying graph anonymization, de-anonymization, and utility evaluation. Third, based on our AUD quantification, we evaluate the anonymity, utility, and de-anonymity of 12 real world graph datasets which are generated from various computer systems and services. The results show that the achievable anonymity/de-anonymity depends on multiple factors, e.g., the preserved data utility, the quality of the employed auxiliary data. Finally, we apply our AUD quantification to evaluate the performance of state-of-the-art anonymization and de-anonymization techniques. Interestingly, we find that there is still significant space to improve state-of-the-art de-anonymization attacks. We also explicitly and quantitatively demonstrate such possible improvement space.},
keywords={data privacy;graph theory;security of data;Graph Anonymity;Anonymity-Utility-De-anonymity correlation quantification;AUD quantification;graph anonymization;utility evaluation;data model;data utility;auxiliary data;SecGraph;Secure Graph data sharing/publishing system;Sec-Graph+;Correlation;Data models;Erbium;Measurement;Electronic mail;Conferences;Mathematical model},
doi={10.1109/INFOCOM.2018.8486356},
ISSN={},
month={April},}
@INPROCEEDINGS{8486354,
author={J. Hu and J. Huang and W. Lv and Y. Zhou and J. Wang and T. He},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={CAPS: Coding-based Adaptive Packet Spraying to Reduce Flow Completion Time in Data Center},
year={2018},
volume={},
number={},
pages={2294-2302},
abstract={Modern data-center applications generate a diverse mix of short and long flows with different performance requirements and weaknesses. The short flows are typically delay-sensitive but to suffer the head-of-line blocking and out-of-order problems. Recent solutions prioritize the short flows to meet their latency requirements, while damaging the throughput-sensitive long flows. To solve these problems, we design a Coding-based Adaptive Packet Spraying (CAPS) that effectively mitigates the negative impact of short and long flows on each other. To exploit the availability of multiple paths and avoid the head-of-line blocking, CAPS spreads the packets of short flows to all paths, while the long flows are limited to a few paths with Equal Cost Multi Path (ECMP). Meanwhile, to resolve the out-of-order problem with low overhead, CAPS encodes the short flows using forward error correction (FEC) technology and adjusts the coding redundancy according to the blocking probability. The coding layer is deployed between the TCP and IP layers, without any modifications on the existing TCP/IP protocols. The experimental results of NS2 simulation and Mininet implementation show that CAPS significantly reduces the average flow completion time of short flows by ~30% -70% over the state-of-the-art multipath transmission schemes and achieves the high throughput for long flows with negligible traffic overhead.},
keywords={computer centres;forward error correction;multipath channels;probability;protocols;telecommunication traffic;transport protocols;CAPS;Coding-based Adaptive Packet Spraying;head-of-line blocking;throughput-sensitive long flows;data-center;flow completion time reduction;equal cost multipath;ECMP;forward error correction;TCP layers;IP layers;TCP/IP protocols;FEC;Mininet;NS2 simulation;Encoding;Switches;Delays;Spraying;Out of order;Forward error correction;Data centers;Data center;TCP;packet spray;multipath},
doi={10.1109/INFOCOM.2018.8486354},
ISSN={},
month={April},}
@INPROCEEDINGS{8486423,
author={R. Yang and C. Feng and L. Wang and W. Wu and K. Wu and J. Wang and Y. Xu},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={On the Optimal Monitor Placement for Inferring Additive Metrics of Interested Paths},
year={2018},
volume={},
number={},
pages={2141-2149},
abstract={In the “network-as-a-service” paradigm, network operators have a strong need to know the metrics of critical paths running services to their users/tenants. However, it is usually prohibitive to directly measure the metrics of all such paths due to the measuring overhead. A practical solution is to use network tomography to infer the metrics of such paths based on observations from a small number of monitoring nodes. This problem is termed as path identifiability problem, a new problem that largely differs from existing link identifiability problems. we show that the new problem is harder than link identifiability problems, in the sense that fewer monitors are required for identifying the metrics of given paths than for identifying the metrics of links along the paths. To solve the problem, we develop sufficient and necessary conditions for the identifiability of a given set of interested paths, and design an efficient algorithm that deploys the minimum number of monitors. Experiments show a saving of up to 40% fewer monitors that guarantee the identifiability of a given set of paths.},
keywords={graph theory;network theory (graphs);telecommunication networks;tomography;optimal monitor placement;network-as-a-service paradigm;network operators;critical paths;network tomography;monitoring nodes;path identifiability problem;link identifiability problems;additive metrics;necessary conditions;sufficient conditions;Monitoring;Computer science;Tomography;Conferences;Maximum likelihood detection;Delays;Network Tomography;Communication Network;Monitor Placement},
doi={10.1109/INFOCOM.2018.8486423},
ISSN={},
month={April},}
@INPROCEEDINGS{8486015,
author={J. Beauquier and J. Burman and F. Dufoulon and S. Kutten},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Fast Beeping Protocols for Deterministic MIS and (Δ + 1)-Coloring in Sparse Graphs},
year={2018},
volume={},
number={},
pages={1754-1762},
abstract={The beeping model is an extremely restrictive broadcast communication model that relies only on carrier sensing. We consider two problems in this model: (Δ+1)-vertex coloring and maximal independent set (MIS), for a network of unknown size n and unknown maximum degree Δ. Solving these problems allows to overcome communication interferences, and to break symmetry, a core component of many distributed protocols. The presented results apply to general graphs, but are efficient in graphs with low edge density (sparse graphs), such as bounded degree graphs, planar graphs and graphs of bounded arboricity. We present O(Δ2log n + Δ3) time deterministic uniform MIS and coloring protocols, which are asymptotically time optimal for bounded degree graphs. Furthermore, we devise O(a2log2n+a3log n) time MIS and coloring protocols, as well as O(a2Δ2log2n + a3Δ3log n) time 2-hop MIS and 2-hop coloring protocols, where a is the arboricity of the communication graph. Building upon the 2-hop coloring protocols, we show how the strong CONGEST model can be simulated and by using this simulation we obtain an O ( a) -coloring protocol. No results about coloring with less than Δ + 1 colors were known up to now in the beeping model.},
keywords={computational complexity;graph colouring;network theory (graphs);protocols;set theory;fast beeping protocols;deterministic MIS;beeping model;extremely restrictive broadcast communication model;maximal independent set;distributed protocols;2-hop coloring protocols;communication graph;sparse graphs coloring;vertex coloring;CONGEST model;Protocols;Computational modeling;Color;Collision avoidance;Complexity theory;Conferences;Radio networks},
doi={10.1109/INFOCOM.2018.8486015},
ISSN={},
month={April},}
@INPROCEEDINGS{8486019,
author={H. Yu and G. Iosifidis and B. Shou and J. Huang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Market Your Venue with Mobile Applications: Collaboration of Online and Offline Businesses},
year={2018},
volume={},
number={},
pages={1934-1942},
abstract={Many mobile applications (abbrev. apps) reward the users who physically visit some locations tagged as POIs (places-of-interest) by the apps. In this paper, we study the POI-based collaboration between apps and venues (e.g., restaurants and cafes). On the one hand, an app charges a venue and tags the venue as a POI, which attracts users to visit the venue and potentially increases the venue's sales. On the other hand, the venue can invest in the app-related infrastructure (e.g., Wi-Fi networks and smartphone chargers), which enhances the users' experience of using the app. However, the existing POI pricing schemes of the apps (e.g., Pokemon Go and Snapchat) cannot incentivize the venue's infrastructure investment, and hence cannot achieve the most effective app-venue collaboration. We model the interactions among an app, a venue, and users by a three-stage Stackelberg game, and design an optimal two-part pricing scheme for the app. This scheme has a charge-with-subsidy structure: the app first charges the venue for becoming a POI, and then subsidizes the venue every time a user interacts with the POI. Compared with the existing pricing schemes, our two-part pricing better incentivizes the venue's investment, attracts more users to interact with the POI, and achieves a much larger app revenue. We analyze the impacts of the app's and venue's characteristics on the app's optimal revenrevenueue, and show that the apps with small and large congestion effects should collaborate with opposite types of venues.},
keywords={game theory;marketing data processing;mobile computing;pricing;smart phones;application related infrastructure;POI pricing schemes;Market Your Venue;offline business;online business;places-of-interest;three-stage Stackelberg game;optimal two-part pricing;mobile applications;Pricing;Games;Investment;Collaboration;Advertising;Wireless fidelity},
doi={10.1109/INFOCOM.2018.8486019},
ISSN={},
month={April},}
@INPROCEEDINGS{8486411,
author={L. Wang and L. Jiao and T. He and J. Li and M. Mühlhäuser},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Service Entity Placement for Social Virtual Reality Applications in Edge Computing},
year={2018},
volume={},
number={},
pages={468-476},
abstract={While social Virtual Reality (VR) applications such as Facebook Spaces are becoming popular, they are not compatible with classic mobile-or cloud-based solutions due to their processing of tremendous data and exchange of delay-sensitive metadata. Edge computing may fulfill these demands better, but it is still an open problem to deploy social VR applications in an edge infrastructure while supporting economic operations of the edge clouds and satisfactory quality-of-service for the users. This paper presents the first formal study of this problem. We model and formulate a combinatorial optimization problem that captures all intertwined goals. We propose ITEM, an iterative algorithm with fast and big “moves” where in each iteration, we construct a graph to encode all the costs and convert the cost optimization into a graph cut problem. By obtaining the minimum s-t cut via existing max-flow algorithms, we can simultaneously determine the placement of multiple service entities, and thus, the original problem can be addressed by solving a series of graph cuts. Our evaluations with large-scale, real-world data traces demonstrate that ITEM converges fast and outperforms baseline approaches by more than 2 × in one-shot placement and around 1.3 × in dynamic, online scenarios where users move arbitrarily in the system.},
keywords={cloud computing;graph theory;iterative methods;meta data;optimisation;social networking (online);virtual reality;service entity placement;social Virtual Reality applications;edge computing;social VR applications;edge clouds;quality-of-service;combinatorial optimization problem;iterative algorithm;cost optimization;graph cut problem;delay-sensitive metadata exchange;max-flow algorithms;Cloud computing;Edge computing;Optimization;Quality of service;Delays;Social network services;Urban areas},
doi={10.1109/INFOCOM.2018.8486411},
ISSN={},
month={April},}
@INPROCEEDINGS{8486310,
author={W. R. KhudaBukhsh and B. Alt and S. Kar and A. Rizk and H. Koeppl},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Collaborative Uploading in Heterogeneous Networks: Optimal and Adaptive Strategies},
year={2018},
volume={},
number={},
pages={1-9},
abstract={Collaborative uploading describes a type of crowd-sourcing scenario in networked environments where a device utilizes multiple paths over neighboring devices to upload content to a centralized processing entity such as a cloud service. Intermediate devices may aggregate and preprocess this data stream. Such scenarios arise in the composition and aggregation of information, e.g., from smart phones or sensors. We use a queuing theoretic description of the collaborative uploading scenario, capturing the ability to split data into chunks that are then transmitted over multiple paths, and finally merged at the destination. We analyze replication and allocation strategies that control the mapping of data to paths and provide closed-form expressions that pinpoint the optimal strategy given a description of the paths' service distributions. Finally, we provide an online path-aware adaptation of the allocation strategy that uses statistical inference to sequentially minimize the expected waiting time for the uploaded data. Numerical results show the effectiveness of the adaptive approach compared to the proportional allocation and a variant of the join-the-shortest-queue allocation, especially for bursty path conditions.},
keywords={cloud computing;queueing theory;telecommunication traffic;replication strategies;closed-form expressions;composition;data stream;intermediate devices;cloud service;centralized processing entity;neighboring devices;networked environments;crowd-sourcing scenario;heterogeneous networks;bursty path conditions;adaptive approach;uploaded data;online path-aware adaptation;optimal strategy;allocation strategies;multiple paths;collaborative uploading scenario;queuing theoretic description;sensors;smart phones;aggregation;Resource management;Delays;Collaboration;Sensors;Cloud computing;Closed-form solutions},
doi={10.1109/INFOCOM.2018.8486310},
ISSN={},
month={April},}
@INPROCEEDINGS{8485933,
author={N. Xiao and P. Yang and Y. Yan and H. Zhou and X. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Motion-Fi: Recognizing and Counting Repetitive Motions with Passive Wireless Backscattering},
year={2018},
volume={},
number={},
pages={2024-2032},
abstract={Recently several ground-breaking RF-based motion-recognition systems were proposed to detect and/or recognize macro/micro human movements. These systems often suffer from various interferences caused by multiple-users moving simultaneously, resulting in extremely low recognition accuracy. To tackle this challenge, we propose a novel system, called Motion-Fi, which marries battery-free wireless backscattering and device-free sensing. Motion-Fi is an accurate, interference tolerable motion-recognition system, which counts repetitive motions without using scenario-dependent templates or profiles and enables multi-users performing certain motions simultaneously because of the relatively short transmission range of backscattered signals. Although the repetitive motions are fairly well detectable through the backscattering signals in theory, in reality they get blended into various other system noises during the motion. Moreover, irregular motion patterns among users will lead to expensive computation cost for motion recognition. We build a backscattering wireless platform to validate our design in various scenarios for over 6 months when different persons, distances and orientations are incorporated. In our experiments, the periodicity in motions could be recognized without any learning or training process, and the accuracy of counting such motions can be achieved within 5% count error. With little efforts in learning the patterns, our method could achieve 93.1% motion-recognition accuracy for a variety of motions. Moreover, by leveraging the periodicity of motions, the recognition accuracy could be further improved to nearly 100% with only 3 repetitions. Our experiments also show that the motions of multiple persons separated by around 2 meters cause little accuracy reduction in the counting process.},
keywords={backscatter;feature extraction;image motion analysis;learning (artificial intelligence);radiofrequency interference;backscattering signals;irregular motion patterns;motion recognition;backscattering wireless platform;ground-breaking RF-based motion-recognition systems;extremely low recognition accuracy;battery-free wireless backscattering;interference tolerable motion-recognition system;Backscatter;Wireless communication;Wireless sensor networks;Antennas;Wireless fidelity;Impedance;Interference},
doi={10.1109/INFOCOM.2018.8485933},
ISSN={},
month={April},}
@INPROCEEDINGS{8486345,
author={L. Maccari and L. Ghiro and A. Guerrieri and A. Montresor and R. L. Cigno},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={On the Distributed Computation of Load Centrality and its Application to DV Routing},
year={2018},
volume={},
number={},
pages={2582-2590},
abstract={Centrality metrics are a key instrument for graph analysis and play a central role in many problems related to networking such as service placement, robustness analysis and network optimization. Betweenness centrality is one of the most popular and well-studied metric. While distributed algorithms to compute this metric exist, they are either approximated or limited to certain topologies (directed acyclic graphs or trees). Exact distributed algorithms for betweenness centrality are computationally complex, because its calculation requires the knowledge of all possible shortest paths within the graph. In this paper we consider load centrality, a metric that usually converges to betweenness, and we present the first distributed and exact algorithm to compute it. We prove its convergence, we estimate its complexity and we show it is directly applicable-with minimal modifications-to any distance-vector routing protocol based on Bellman-Ford. We finally implement it on top of the Babel routing protocol and we show that, exploiting centrality, we can significantly reduce Babel's convergence time upon node failure without increasing signalling overhead. Our contribution is relevant in the realm of wireless distributed networks, but the algorithm can be adopted in any distributed system where it is not possible, or computationally impractical, to reconstruct the whole network graph at each node and compute betweenness centrality with the classical approach based on Dijkstra's algorithm.},
keywords={computational complexity;directed graphs;distributed algorithms;routing protocols;minimal modifications-to any distance-vector routing protocol;Babel routing protocol;wireless distributed networks;distributed system;network graph;Dijkstra's algorithm;load centrality;DV routing;centrality metrics;key instrument;graph analysis;central role;networking;service placement;robustness analysis;network optimization;betweenness centrality;directed acyclic graphs;trees;exact distributed algorithms;convergence time;Measurement;Routing protocols;Topology;Routing;Network topology;Convergence;Indexes;Multi-hop networks;Mesh networks;Ad-hoc networks;Bellman-Ford;Load centrality;Distributed Algorithms;Failure recovery},
doi={10.1109/INFOCOM.2018.8486345},
ISSN={},
month={April},}
@INPROCEEDINGS{8486284,
author={W. Wong and S. -. G. Chan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Distributed Joint AP Grouping and User Association for MU-MIMO Networks},
year={2018},
volume={},
number={},
pages={252-260},
abstract={Interference Alignment (IA) has emerged as a promising interference coordination approach for cooperative MIMO systems. Due to heavy CSI feedback overhead, APs (Access Points) need to be partitioned into cooperation groups no larger than a certain size where only APs in the same group are able to cooperate with IA. We consider a general MIMO network using a hybrid interference coordination approach, i.e. intra-group interference is managed with IA, while inter-group interference is overcome with traditional orthogonal multiple access techniques. Users are usually non-uniformly distributed. Their throughput can be improved by association optimization. We study the novel problem of minimizing AP load by joint AP grouping and user association. The problem is shown to be NP-hard. Based on alternating direction optimization, we propose DAGA (Distributed Joint AP Grouping and User Association) to tackle the problem. DAGA is distributed and uses only long-term CSI. Based on current AP grouping, it produces an approximated user association solution which is at most elogm (m is the number of APs) times of the optimum. Based on current user association, it adjusts AP grouping with local search. Extensive simulation results show that it substantially outperforms other comparison schemes.},
keywords={MIMO communication;optimisation;radio networks;radiofrequency interference;heavy CSI feedback overhead;cooperation groups;general MIMO network;hybrid interference coordination approach;intra-group interference;traditional orthogonal multiple access techniques;association optimization;AP load;approximated user association solution;current user association;MU-MIMO networks;interference alignment;distributed Joint AP Grouping;cooperative MIMO systems;Interference;Optimization;Array signal processing;Antennas;Conferences;MIMO communication;Approximation algorithms;MU-MIMO network;Interference alignment;Load balancing;Joint Optimization;Approximation algorithm},
doi={10.1109/INFOCOM.2018.8486284},
ISSN={},
month={April},}
@INPROCEEDINGS{8486380,
author={X. Zhang and C. Wu and Z. Huang and Z. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Occupation-Oblivious Pricing of Cloud Jobs via Online Learning},
year={2018},
volume={},
number={},
pages={2456-2464},
abstract={State-of-the-art cloud platforms adopt pay-as-you-go pricing, where users pay for the resources on demand according to occupation time. Simple and intuitive as it is, such a pricing scheme is a mismatch for new workloads today such as large-scale machine learning, whose completion time is hard to estimate beforehand. To supplement existing cloud pricing schemes, we propose an occupation-oblivious online pricing mechanism for cloud jobs without pre-specified time duration and for users who prefer a pre-determined cost for job execution. Our strategy posts unit resource prices upon user arrival and decides a fixed charge for completing the user's job, without the need to know how long the job is to occupy the requested resources. At the core of our design is a novel multi-armed bandit based online learning algorithm for estimating unknown input by exploration and exploitation of past resource sales, and deciding resource prices to maximize profit of the cloud provider in an online setting. Our online learning algorithm achieves a low regret sublinear with the time horizon, in terms of overall provider profit, compared with an omniscient benchmark. We also conduct trace-driven simulations to verify efficacy of the algorithm in real-world settings.},
keywords={cloud computing;computer aided instruction;learning (artificial intelligence);pricing;resource prices;cloud platform;pay-as-you-go pricing;pre-specified time duration;occupation-oblivious online pricing mechanism;existing cloud pricing schemes;completion time;large-scale machine learning;pricing scheme;occupation time;cloud jobs;occupation-oblivious pricing;cloud provider;resource sales;online learning algorithm;job execution;pre-determined cost;Cloud computing;Pricing;Training;Machine learning;Graphics processing units;Servers;Google},
doi={10.1109/INFOCOM.2018.8486380},
ISSN={},
month={April},}
@INPROCEEDINGS{8485980,
author={R. Vaze},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Online Knapsack Problem Under Expected Capacity Constraint},
year={2018},
volume={},
number={},
pages={2159-2167},
abstract={Online knapsack problem is considered, where items arrive in a sequential fashion that have two attributes; value and weight. Each arriving item has to be accepted or rejected on its arrival irrevocably. The objective is to maximize the sum of the value of the accepted items such that the sum of their weights is below a budget/capacity. Conventionally a hard budget/capacity constraint is considered, for which variety of results are available. In modern applications, e.g., in wireless networks, data centres, cloud computing, etc., enforcing the capacity constraint in expectation is sufficient. With this motivation, we consider the knapsack problem with an expected capacity constraint. For the special case of knapsack problem, called the secretary problem, where the weight of each item is unity, we propose an algorithm whose probability of selecting any one of the optimal items is equal to 1 -1/e and provide a matching lower bound. For the general knapsack problem, we propose an algorithm whose competitive ratio is shown to be 1/4e that is significantly better than the best known competitive ratio of 1/10e for the knapsack problem with the hard capacity constraint.},
keywords={computational complexity;knapsack problems;optimisation;secretary problem;general knapsack problem;hard capacity constraint;online knapsack problem;capacity constraint;hard budget;Approximation algorithms;Cloud computing;Resource management;Conferences;Capacity planning;Load management;Measurement},
doi={10.1109/INFOCOM.2018.8485980},
ISSN={},
month={April},}
@INPROCEEDINGS{8485838,
author={W. Sun and R. Zhang and W. Lou and Y. Thomas Hou},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={REARGUARD: Secure Keyword Search Using Trusted Hardware},
year={2018},
volume={},
number={},
pages={801-809},
abstract={Search over encrypted data (SE) enables a client to delegate his search task to a third-party server that hosts a collection of encrypted documents while still guaranteeing some measure of query privacy. Software-based solutions using diverse cryptographic primitives have been extensively explored, leading to a rich set of secure search indexes and algorithm designs. However, each scheme can only implement a small subset of information retrieval (IR) functions and often with considerable search information leaked. Recently, the hardware-based secure execution has emerged as an effective mechanism to securely execute programs in an untrusted software environment. In this paper, we exploit the hardware-based execution environment (TEE) and explore a software and hardware combined approach to address the challenging secure search problem. For functionality, our design can support the same spectrum of plaintext IR functions. For security, we present oblivious keyword search techniques to mitigate the index search trace leakage. We build a prototype of the system using Intel SGX. We demonstrate that the proposed system provides broad support of a variety of search functions and achieves computation efficiency comparable to plaintext data search with elevated security protection.},
keywords={cryptography;data privacy;indexing;query processing;trusted computing;hardware-based secure execution;untrusted software environment;hardware-based execution environment;hardware combined approach;plaintext IR functions;index search trace leakage;search functions;plaintext data search;elevated security protection;REARGUARD;secure keyword search;trusted hardware;encrypted data;search task;third-party server;encrypted documents;query privacy;software-based solutions;secure search indexes;information retrieval functions;search information;keyword search techniques;cryptographic primitives;secure search problem;Indexes;Encryption;Software;Keyword search;Hardware},
doi={10.1109/INFOCOM.2018.8485838},
ISSN={},
month={April},}
@INPROCEEDINGS{8486419,
author={M. Leconte and A. Destounis and G. Paschos},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Traffic Engineering with Precomputed Pathbooks},
year={2018},
volume={},
number={},
pages={234-242},
abstract={This paper addresses a major challenge in traffic engineering: the selection of a set of paths that minimizes routing cost for a random traffic matrix. We introduce the concept of pathbook: a small set of paths to which we restrict routing. The use of pathbook accelerates centralized traffic engineering algorithms, and therefore is appealing for instantiating, configuring, and optimizing large software-based networks. However, restricting routing to a few paths may lead to higher cost or infeasibility. To this end, we introduce the problem of pathbook design, wherein we search for a pathbook of constrained size that minimizes the expected routing cost of the random traffic matrix, which represents a prediction of the future traffic. The pathbook design problem is of combinatorial nature, and we show that it is NP-hard. We then study its convex relaxation for which we propose an optimal algorithm based on the projected subgradient method. For large networks, the subgradient vector is of prohibitive dimensions, hence we propose a coordinate-descent method using the Gauss-Southwell rule, which prescribes a move along the direction of largest subgradient element. We test the performance of our solution on dynamic traffic matrices from GEANT and find that our Gauss-Southwell pathbooks can accelerate standard methods by two orders of magnitude.},
keywords={computational complexity;convex programming;gradient methods;matrix algebra;minimisation;radio networks;software defined networking;telecommunication network routing;telecommunication traffic;vectors;routing cost minimization;centralized traffic engineering algorithms;NP-hard problem;convex relaxation;coordinate-descent method;prohibitive dimensions;Gauss-Southwell rule;Gauss-Southwell pathbooks;dynamic traffic matrices;projected subgradient method;optimal algorithm;pathbook design problem;expected routing cost;software-based networks;random traffic matrix;precomputed pathbooks;Routing;Acceleration;Bandwidth;Optimization;Conferences;Robustness;Quality of service},
doi={10.1109/INFOCOM.2018.8486419},
ISSN={},
month={April},}
@INPROCEEDINGS{8486430,
author={A. Anand and G. De Veciana and S. Shakkottai},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Joint Scheduling of URLLC and eMBB Traffic in 5G Wireless Networks},
year={2018},
volume={},
number={},
pages={1970-1978},
abstract={Emerging 5G systems will need to efficiently support both broadband traffic (eMBB) and ultra-low-latency (URLLC) traffic. In these systems, time is divided into slots which are further sub-divided into minislots. From a scheduling perspective, eMBB resource allocations occur at slot boundaries, whereas to reduce latency URLLC traffic is pre-emptively overlapped at the minislot timescale, resulting in selective superposition/puncturing of eMBB allocations. This approach enables minimal URLLC latency at a potential rate loss to eMBB traffic. We study joint eMBB and URLLC schedulers for such systems, with the dual objectives of maximizing utility for eMBB traffic while satisfying instantaneous URLLC demands. For a linear rate loss model (loss to eMBB is linear in the amount of superposition/puncturing), we derive an optimal joint scheduler. Somewhat counter-intuitively, our results show that our dual objectives can be met by an iterative gradient scheduler for eMBB traffic that anticipates the expected loss from URLLC traffic, along with an URLLC demand scheduler that is oblivious to eMBB channel states, utility functions and allocations decisions of the eMBB scheduler. Next we consider a more general class of (convex) loss models and study optimal online joint eMBB/URLLC schedulers within the broad class of channel state dependent but time-homogeneous policies. We validate the characteristics and benefits of our schedulers via simulation.},
keywords={5G mobile communication;radio networks;resource allocation;scheduling;telecommunication traffic;joint scheduling;eMBB traffic;eMBB resource allocations;latency URLLC traffic;eMBB allocations;optimal joint scheduler;URLLC demand scheduler;eMBB channel states;joint eMBB-URLLC schedulers;minimal URLLC latency;instantaneous URLLC;time-homogeneous policies;5G wireless networks;broadband traffic;Resource management;5G mobile communication;Wireless communication;Broadband communication;Reliability;Bandwidth;Random variables;wireless scheduling;URLLC traffic;5G systems},
doi={10.1109/INFOCOM.2018.8486430},
ISSN={},
month={April},}
@INPROCEEDINGS{8486302,
author={Y. Shabara and C. E. Koksal and E. Ekici},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Linear Block Coding for Efficient Beam Discovery in Millimeter Wave Communication Networks},
year={2018},
volume={},
number={},
pages={2285-2293},
abstract={The surge in mobile broadband data demands is expected to surpass the available spectrum capacity below 6 GHz. This expectation has prompted the exploration of millimeter wave (mm-wave) frequency bands as a candidate technology for next generation wireless networks. However, numerous challenges to deploying mm-wave communication systems, including channel estimation, need to be met before practical deployments are possible. This work addresses the mm-wave channel estimation problem and treats it as a beam discovery problem in which locating beams with strong path reflectors is analogous to locating errors in linear block codes. We show that a significantly small number of measurements (compared to the original dimensions of the channel matrix) is sufficient to reliably estimate the channel. We also show that this can be achieved using a simple and energy-efficient transceiver architecture.},
keywords={block codes;broadband networks;channel estimation;linear codes;millimetre wave communication;mobile radio;network coding;next generation networks;radio networks;wireless channels;mm-wave channel estimation problem;beam discovery problem;strong path reflectors;linear block codes;channel matrix;energy-efficient transceiver architecture;efficient beam discovery;millimeter wave communication networks;mobile broadband data demands;mm-wave communication systems;spectrum capacity;next generation wireless networks;error location;frequency 6.0 GHz;Channel estimation;Receivers;Sparse matrices;Block codes;Sensors;Measurement uncertainty;Array signal processing},
doi={10.1109/INFOCOM.2018.8486302},
ISSN={},
month={April},}
@INPROCEEDINGS{8485913,
author={F. Wu and Y. Sun and L. Chen and J. Xu and K. Srinivasan and N. B. Shroff},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={High Throughput Low Delay Wireless Multicast via Multi-Channel Moving Window Codes},
year={2018},
volume={},
number={},
pages={2267-2275},
abstract={A fundamental challenge in wireless multicast has been how to simultaneously achieve high-throughput and low-delay for reliably serving a large number of users. In this paper, we show how to harness substantial throughput and delay gains by exploiting multi-channel resources. We develop a new scheme called Multi-Channel Moving Window Codes (MC-MWC) for multi-channel multi-session wireless multicast. The salient features of MC-MWC are three-fold. (i) High throughput: we show that MC-MWC achieves order-optimal throughput in the many-user many-channel asymptotic regime. Moreover, the number of channels required by a conventional channel-allocation based scheme is shown to be doubly-exponentially larger than that required by MC-MWC. (ii) Low delay: using large deviations theory, we show that the delay of MC-MWC decreases linearly with the number of channels, while the delay reduction of conventional schemes is no more than a finite constant. (iii) Low feedback overhead: the feedback overhead of MC-MWC is a constant that is independent of both the number of receivers in each session and the number of sessions in the network. Finally, our trace-driven simulation and numerical results validate the analytical results and show that the implementation complexity of MC-MWC is low.},
keywords={channel allocation;delays;feedback;multicast communication;network coding;telecommunication traffic;wireless channels;conventional channel-allocation based scheme;many-channel asymptotic regime;order-optimal throughput;multichannel multisession wireless multicast;MC-MWC;multichannel resources;delay gains;low-delay;high-throughput;MultiChannel Moving Window Codes;High throughput Low delay wireless multicast;Receivers;Delays;Throughput;Wireless communication;Merging;Transmitters;Encoding},
doi={10.1109/INFOCOM.2018.8485913},
ISSN={},
month={April},}
@INPROCEEDINGS{8486397,
author={D. Yu and Y. Zhang and Y. Huang and H. Jin and J. Yu and Q. Hua},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Exact Implementation of Abstract MAC Layer via Carrier Sensing},
year={2018},
volume={},
number={},
pages={1196-1204},
abstract={In this paper, we present the first algorithm for exactly implementing the abstract MAC (absMAC) layer in the physical SINR model. The absMac layer, first presented by Kuhn et al. in [15], provides reliable local broadcast communication, with timing guarantees stated in terms of a collection of abstract delay functions, such that high-level algorithms can be designed in terms of these functions, independent of specific channel behavior. The implementation of absMAC layer is to design a distributed algorithm for the local broadcast communication primitives over a particular communication model that defines concrete channel behaviors, and the objective is minimizing the bounds of the abstract delay functions. Halldórsson et al. [10] have shown that in the standard SINR model (synchronous communication, without physical carrier sensing or location information), there cannot be efficient exact implementations. In this work, we show that physical carrier sensing, a commonly seen function performed by wireless devices, can help get efficient exact implementation algorithms. Specifically, we propose an algorithm that exactly implements the absMAC layer. The algorithm provides asymptotically optimal bounds for both acknowledgement and progress functions defined in the absMAC layer. Our algorithm can lead to many new faster algorithms for solving high-level problems in the SINR model. We demonstrate this by giving algorithms for problems of Consensus, Multi-Message Broadcast and Single-Message Broadcast. It deserves to point out that our implementation algorithm is designed based on an optimal algorithm for a General Local Broadcast (GLB) problem, which takes the number of distinct messages into consideration for the first time. The GLB algorithm can handle much more communication scenarios apart from those defined in the absMAC layer. Simulation results show that our proposed algorithms perform well in reality.},
keywords={access protocols;broadcast communication;delays;distributed algorithms;radio networks;telecommunication network reliability;wireless channels;efficient exact implementation algorithms;GLB algorithm;communication model;concrete channel behaviors;general local broadcast problem;consensus problem;multimessage broadcast problem;single-message broadcast problem;synchronous communication;carrier sensing;wireless devices;standard SINR model;distributed algorithm;absMAC layer;specific channel behavior;high-level algorithms;abstract delay functions;reliable local broadcast communication;physical SINR model;abstract MAC layer;Interference;Signal to noise ratio;Sensors;Delays;Wireless sensor networks;Distributed algorithms;Probabilistic logic},
doi={10.1109/INFOCOM.2018.8486397},
ISSN={},
month={April},}
@INPROCEEDINGS{8485910,
author={C. Zhang and F. Yang and G. Li and Q. Zhai and Y. Jiang and D. Xuan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={MV-Sports: A Motion and Vision Sensor Integration-Based Sports Analysis System},
year={2018},
volume={},
number={},
pages={1070-1078},
abstract={Recently, intelligent sports analytics is becoming a hot area in both industry and academia for coaching, practicing tactic and technical analysis. With the growing trend of bringing sports analytics to live broadcasting, sports robots and common playfield, a low cost system that is easy to deploy and performs real-time and accurate sports analytics is very desirable. However, existing systems, such as Hawk-Eye, cannot satisfy these requirements due to various factors. In this paper, we present MV-Sports, a cost-effective system for real-time sports analysis based on motion and vision sensor integration. Taking tennis as a case study, we aim to recognize player shot types and measure ball states. For fine-grained player action recognition, we leverage motion signal for fast action highlighting and propose a long short term memory (LSTM)-based framework to integrate MV data for training and classification. For ball state measurement, we compute the initial ball state via motion sensing and devise an extended kalman filter (EKF)-based approach to combine ball motion physics-based tracking and vision positioning-based tracking to get more accurate ball state. We implement MV-Sports on commercial off-the-shelf (COTS) devices and conduct real-world experiments to evaluate the performance of our system. The results show our approach can achieve accurate player action recognition and ball state measurement with sub-second latency.},
keywords={computer vision;data integration;image motion analysis;image sensors;Kalman filters;learning (artificial intelligence);neural nets;nonlinear filters;object recognition;object tracking;pattern classification;sensor fusion;sport;video signal processing;MV-Sports;intelligent sports analytics;tactic analysis;technical analysis;sports robots;cost-effective system;real-time sports analysis;fine-grained player action recognition;long short term memory-based framework;ball state measurement;motion sensing;ball motion physics-based tracking;vision positioning;motion signal;extended Kalman filter-based approach;player action recognition;coaching;tactic practicing;live broadcasting;motion-vision sensor integration;LSTM-based framework;MV data integration;classification;EKF-based approach;vision positioning-based tracking;Tracking;Real-time systems;Sensors;Cameras;Position measurement;Motion segmentation},
doi={10.1109/INFOCOM.2018.8485910},
ISSN={},
month={April},}
@INPROCEEDINGS{8486412,
author={T. Deng and J. Yao and H. Guan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Maximizing Profit of Cloud Service Brokerage with Economic Demand Response},
year={2018},
volume={},
number={},
pages={1907-1915},
abstract={Cloud service brokerage (CSB), which procures cloud services from multiple cloud service providers (CSPs) and resells them to cloud customers, has been put forward to facilitate the delivery of cloud services. However, it is challenging to address the economic issues of CSB incurred by insufficient provisioning problem in response to dynamic conditions, for example, dynamic customer demands, dynamic cloud service prices and different availabilities of CSPs. In this paper, we propose a novel mechanism called CSB Demand Response (DR-CSB), which aims to maximize the profit of CSB under dynamic customer demands with respect to the capacity and availability constraints, to mitigate the insufficient provisioning problem. To this end, we formulate an optimization problem of profit maximization for the CSB, and employ economic demand response mechanism to allow cloud customers to adjust their consumptions with dynamic cloud service prices. Our evaluations driven by Google cluster-usage traces have verified that the DR-CSB not only can help the CSB to achieve the profit maximization, but also can handle the impact of the dynamic conditions in CSB. As the result shows, the profit of CSB with implementing DR-CSB can increase by up to 20%, and customers also achieve a 37% aggregated cost saving, compared with the scenario without DR-CSB.},
keywords={cloud computing;economics;optimisation;pricing;profitability;dynamic customer demands;dynamic cloud service prices;CSB Demand Response;DR-CSB;profit maximization;economic demand response mechanism;cloud customers;cloud service brokerage;cloud services;multiple cloud service providers;optimization problem;Google cluster-usage traces;cloud service brokerage;profit;demand response;cost},
doi={10.1109/INFOCOM.2018.8486412},
ISSN={},
month={April},}
@INPROCEEDINGS{8486210,
author={J. Li and X. Ma and L. Guodong and X. Luo and J. Zhang and W. Li and X. Guan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Can We Learn what People are Doing from Raw DNS Queries?},
year={2018},
volume={},
number={},
pages={2240-2248},
abstract={Domain Name System (DNS) is one of the pillars of today's Internet. Due to its appealing properties such as low data volume, wide-ranging applications and encryption free, DNS traffic has been extensively utilized for network monitoring. Most existing studies of DNS traffic, however, focus on domain name reputation. Little attention has been paid to understanding and profiling what people are doing from DNS traffic, a fundamental problem in the areas including Internet demographics and network behavior analysis. Consequently, simple questions like “How to determine whether a DNS query for www.google.com means searching or any other behaviors?” cannot be answered by existing studies. In this paper, we take the first step to identify user activities from raw DNS queries. We advance a multiscale hierarchical framework to tackle two practical challenges, i.e., behavior ambiguity and behavior polymorphism. Under this framework, a series of novel methods, such as pattern upward mapping and multi-scale random forest classifier, are proposed to characterize and identify user activities of interest. Evaluation using both synthetic and real-world DNS traces demonstrates the effectiveness of our method.},
keywords={Internet;invasive software;query processing;telecommunication traffic;real-world DNS;behavior polymorphism;behavior ambiguity;network behavior analysis;domain name reputation;DNS traffic;low data volume;Domain Name System;raw DNS queries;Conferences;Monitoring;Forestry;Google;Training;Internet;Encryption},
doi={10.1109/INFOCOM.2018.8486210},
ISSN={},
month={April},}
@INPROCEEDINGS{8485940,
author={K. Sankhe and U. Muncuk and M. Y. Naderi and K. Chowdhury},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Talking When No One is Listening: Piggybacking City-scale IoT Control Signals Over LTE},
year={2018},
volume={},
number={},
pages={1547-1555},
abstract={This paper presents FreeIoT, a control plane paradigm that allows fine grained signaling for city-scale IoT deployments without installing any additional infrastructure. FreeIoT overlays control/wake-up information for sensors over existing standards compliant LTE through the following contributions: First, we develop a novel encoding scheme that changes the spatial positioning of Almost Blank Subframes (ABS) within a standard LTE frame to convey control information. ABS was originally defined in the standard to allow coexistence between the macro-cell eNB and nearby small cells, which FreeIoT leverages as a side channel for IoT signaling. Our approach works with any number of ABS settings chosen by the LTE eNB, and accordingly adjusts the encoding of control messages at maximum possible transmission rates. Second, a session management protocol is introduced to maintain contextual information of the control signaling. This allows FreeIoT to handle situations where the control message may span multiple frames, or when the LTE operator temporarily reduces the number of ABS. FreeIoT also incorporates an error detection and correction mechanism to counter channel and fading errors. Finally, we implement a proof of concept testbed to validate the operation of FreeIoT using a software defined LTE eNB and custom-designed RF energy harvesting circuit interfaced with off-the-shelf sensors.},
keywords={energy harvesting;Internet of Things;Long Term Evolution;protocols;city-scale IoT control signals;control plane paradigm;fine grained signaling;control/wake-up information;ABS;standard LTE frame;control information;macro-cell eNB;nearby small cells;IoT signaling;LTE eNB;control message;maximum possible transmission rates;contextual information;control signaling;LTE operator;encoding scheme;FreeIoT;Almost Blank Subframes;error detection mechanism;error correction mechanism;Long Term Evolution;Sensors;Encoding;Radio frequency;Indexes;Modulation},
doi={10.1109/INFOCOM.2018.8485940},
ISSN={},
month={April},}
@INPROCEEDINGS{8485833,
author={H. Yu and M. J. Neely},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Learning Aided Optimization for Energy Harvesting Devices with Outdated State Information},
year={2018},
volume={},
number={},
pages={1853-1861},
abstract={This paper considers utility optimal power control for energy harvesting wireless devices with a finite capacity battery. The distribution information of the underlying wireless environment and harvestable energy is unknown and only outdated system state information is known at the device controller. This scenario shares similarity with Lyapunov opportunistic optimization and online learning but is different from both. By a novel combination of Zinkevich's online gradient learning technique and the drift-plus-penalty technique from Lyapunov opportunistic optimization, this paper proposes a learning-aided algorithm that achieves utility within O (ϵ) of the optimal, for any desired ϵ > 0, by using a battery with an 0 (1/ϵ) capacity. The proposed algorithm has low complexity and makes power investment decisions based on system history, without requiring knowledge of the system state or its probability distribution.},
keywords={energy harvesting;gradient methods;learning (artificial intelligence);optimisation;power control;probability;online gradient learning technique;power investment decisions;drift-plus-penalty technique;Lyapunov opportunistic optimization;outdated system state information;underlying wireless environment;finite capacity battery;energy harvesting wireless devices;utility optimal power control;outdated state information;Batteries;Wireless communication;Power control;Wireless sensor networks;Heuristic algorithms;Energy harvesting;Optimization},
doi={10.1109/INFOCOM.2018.8485833},
ISSN={},
month={April},}
@INPROCEEDINGS{8485988,
author={T. Oda and C. Joe-Wong},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={MOVI: A Model-Free Approach to Dynamic Fleet Management},
year={2018},
volume={},
number={},
pages={2708-2716},
abstract={Modern vehicle fleets, e.g., for ridesharing platforms and taxi companies, can reduce passengers' waiting times by proactively dispatching vehicles to locations where pickup requests are anticipated in the future. Yet it is unclear how to best do this: optimal dispatching requires optimizing over several sources of uncertainty, including vehicles' travel times to their dispatched locations, as well as coordinating between vehicles so that they do not attempt to pick up the same passenger. While prior works have developed models for this uncertainty and used them to optimize dispatch policies, in this work we introduce a model-free approach. Specifically, we propose MOVI, a Deep Q-network (DQN)-based framework that directly learns the optimal vehicle dispatch policy. Since DQNs scale poorly with a large number of possible dispatches, we streamline our DQN training and suppose that each individual vehicle independently learns its own optimal policy, ensuring scalability at the cost of less coordination between vehicles. We then formulate a centralized receding-horizon control (RHC) policy to compare with our DQN policies. To compare these policies, we design and build MOVI as a large-scale realistic simulator based on 15 million taxi trip records that simulates policy-agnostic responses to dispatch decisions. We show that the DQN dispatch policy reduces the number of unserviced requests by 76% compared to without dispatch and 20% compared to the RHC approach, emphasizing the benefits of a model-free approach and suggesting that there is limited value to coordinating vehicle actions. This finding may help to explain the success of ridesharing platforms, for which drivers make individual decisions.},
keywords={dispatching;optimisation;transportation;model-free approach;dynamic fleet management;optimal dispatching;Deep Q-network-based framework;optimal vehicle dispatch policy;centralized receding-horizon control policy;simulates policy-agnostic responses;ridesharing platforms;dispatch policy;vehicle fleets;Public transportation;Vehicles;Uncertainty;Real-time systems;Dispatching;Computational modeling;Training},
doi={10.1109/INFOCOM.2018.8485988},
ISSN={},
month={April},}
@INPROCEEDINGS{8486311,
author={Z. Zheng and R. Srikant and G. Chen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Pricing for Revenue Maximization in Inter-DataCenter Networks},
year={2018},
volume={},
number={},
pages={28-36},
abstract={As more applications and businesses move to the cloud, pricing for inter-datacenter links has become an important problem. In this paper, we study revenue maximizing pricing from the perspective of a network provider in inter-datacenter networks. Designing a practical bandwidth pricing scheme requires us to jointly consider the requirements of envy-freeness and arbitrage-freeness, where envy-freeness guarantees the fairness of resource allocation and arbitrage-freeness induces users to truthfully reveal their data transfer requests. Considering the non-convexity of the revenue maximization problem and the lack of information about the users' utilities, we propose a framework for computationally efficient pricing to approximately maximize revenue in a range of environments. We first study the case of a single link accessed by many users, and design a (1 + E)-approximation pricing scheme with polynomial time complexity and information complexity. Based on dynamic programming, we then extend the pricing scheme for the tollbooth network, preserving the (1 + E) approximation ratio and the computational complexity. For the general network setting, we analyze the revenue generated by uniform pricing, which determines a single per unit price for all potential users. We show that when users have similar utilities, uniform pricing can achieve a good approximation ratio, which is independent of network topology and data transfer requests. The pricing framework can be extended to multiple time slots, enabling time-dependent pricing.},
keywords={approximation theory;computational complexity;computer centres;dynamic programming;pricing;resource allocation;telecommunication network topology;inter-datacenter networks;inter-datacenter links;practical bandwidth pricing scheme;envy-freeness;arbitrage-freeness;data transfer requests;revenue maximization problem;computationally efficient pricing;single link;approximation pricing scheme;polynomial time complexity;information complexity;tollbooth network;computational complexity;general network setting;uniform pricing;unit price;potential users;good approximation ratio;network topology;pricing framework;time-dependent pricing;Pricing;Data transfer;Wide area networks;Bandwidth;Computational complexity;Data centers;Network topology},
doi={10.1109/INFOCOM.2018.8486311},
ISSN={},
month={April},}
@INPROCEEDINGS{8485912,
author={J. Yu and W. Gong and J. Liu and L. Chen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Fast and Reliable Tag Search in Large-Scale RFID Systems: A Probabilistic Tree-based Approach},
year={2018},
volume={},
number={},
pages={1133-1141},
abstract={Searching for a particular group of tags in an RFID system is a key service in such important Internet-of-Things applications as inventory management. When the system scale is large with a massive number of tags, deterministic search can be prohibitively expensive, and probabilistic search has been advocated, seeking a balance between reliability and time efficiency. Given a failure probability [1/(O(K))], where K is the number of tags, state-of-the-art solutions have achieved a time cost of O(K log K) through multi-round hashing and verification. Further improvement however faces a critical bottleneck of repetitively verifying each individual target tag in each round. In this paper, we present a novel Tree-based Tag Search (TTS) that approaches O (K) through batched verification. TTS smartly hashes multiple tags into each internal tree node and adaptively controls the node degrees. It conducts bottom-up search to verify tags group by group with the number of groups decreasing rapidly. We derive the optimal hash code length and node degrees to accommodate hash collisions, and demonstrate the superiority of TTS through both theoretical analysis and extensive simulations. In particular, we show that, with increasing reliability demand and system size, TTS achieves an even higher performance gain, making it a highly scalable solution.},
keywords={computational complexity;file organisation;formal verification;Internet of Things;inventory management;probability;radiofrequency identification;search problems;trees (mathematics);failure probability;TTS;batched verification;internal tree node;large-scale RFID systems;probabilistic Tree-based approach;RFID system;inventory management;deterministic search;probabilistic search;target tag;Internet-of-Things;Tree-based Tag Search;multiple tag hashing;hash code length;Reliability;Radiofrequency identification;Search problems;Servers;Probabilistic logic;Conferences;RF signals},
doi={10.1109/INFOCOM.2018.8485912},
ISSN={},
month={April},}
@INPROCEEDINGS{8486026,
author={C. Chen and W. Wang and B. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Performance-Aware Fair Scheduling: Exploiting Demand Elasticity of Data Analytics Jobs},
year={2018},
volume={},
number={},
pages={504-512},
abstract={Efficient resource management is of paramount importance in today's production clusters. In this paper, we identify the demand elasticity of data-parallel jobs. Demand elasticity allows jobs to run with a significantly less amount of resources than they ideally need, at the expense of only a modest performance penalty. Our EC2 experiment using popular Spark benchmark suites confirms that running a job using 50% of demanded slots is sufficient to achieve at least 75% of the ideal performance. We show that such an elasticity is an intrinsic property of data-parallel jobs and can be exploited to speed up average job completion. In this regard, we propose Performance-Aware Fair (PAF) scheduler to identify the demand elasticity and use it to improve the average job performance, while still attaining near-optimal isolation guarantee close to fair sharing. PAF starts with a fair allocation and iteratively adjusts it by transferring resources from one job to another, improving the performance of resource-taker without penalizing resource-giver by a noticeable amount. We implemented PAF in Spark and evaluated its effectiveness through both EC2 experiments and large-scale simulations. Evaluation results show that compared with fair allocation, PAF improves the average job performance by 13%, while penalizing resource-givers by no more than 1%.},
keywords={cloud computing;cluster computing;data analysis;parallel processing;resource allocation;scheduling;Performance-Aware Fair scheduling;demand elasticity;data analytics jobs;data-parallel jobs;Performance-Aware Fair scheduler;PAF;fair allocation;resource management;Spark benchmark suites;Task analysis;Elasticity;Resource management;Sparks;Data analysis;Runtime;Parallel processing},
doi={10.1109/INFOCOM.2018.8486026},
ISSN={},
month={April},}
@INPROCEEDINGS{8486285,
author={H. Du and P. Li and H. Zhou and W. Gong and G. Luo and P. Yang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={WordRecorder: Accurate Acoustic-based Handwriting Recognition Using Deep Learning},
year={2018},
volume={},
number={},
pages={1448-1456},
abstract={This paper presents WordRecorder, an efficient and accurate handwriting recognition system that identifies words using acoustic signals generated by pens and paper, thus enabling ubiquitous handwriting recognition. To achieve this, we carefully craft a new deep-learning based acoustic sensing framework with three major components, i.e., segmentation, classification, and word suggestion. First, we design a dual-window approach to segment the raw acoustic signal into a series of words and letters by exploiting subtle acoustic signal features of handwriting. Then we integrate a set of simple yet effective signal processing techniques to further refine raw acoustic signals into normalized spectrograms which are suitable for deep-learning classification. After that, we customize a deep neural network that is suitable for smart devices. Finally, we incorporate a word suggestion module to enhance the recognition performance. Our framework achieves both computation efficiency and desirable classification accuracy simultaneously. We prototype our design using off-the-shelf smartwatches and conduct extensive evaluations. Our results demonstrate that WordRecorder robustly archives 81% accuracy rate for trained users, and 75% for users without training, across a range of different environment, users, and writing habits.},
keywords={acoustic signal processing;handwriting recognition;image classification;image segmentation;learning (artificial intelligence);neural nets;ubiquitous computing;deep learning;ubiquitous handwriting recognition;dual-window approach;raw acoustic signal;deep-learning classification;deep neural network;WordRecorder;handwriting recognition system;acoustic sensing;word suggestion;raw acoustic signals;segmentation;smart devices;Acoustics;Handwriting recognition;Writing;Microsoft Windows;Feature extraction;Conferences;Machine learning},
doi={10.1109/INFOCOM.2018.8486285},
ISSN={},
month={April},}
@INPROCEEDINGS{8486327,
author={S. Xue and L. Zhang and A. Li and X. Li and C. Ruan and W. Huang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={AppDNA: App Behavior Profiling via Graph-based Deep Learning},
year={2018},
volume={},
number={},
pages={1475-1483},
abstract={Better understanding of mobile applications' behaviors would lead to better malware detection/classification and better app recommendation for users. In this work, we design a framework AppDNA to automatically generate a compact representation for each app to comprehensively profile its behaviors. The behavior difference between two apps can be measured by the distance between their representations. As a result, the versatile representation can be generated once for each app, and then be used for a wide variety of objectives, including malware detection, app categorizing, plagiarism detection, etc. Based on a systematic and deep understanding of an app's behavior, we propose to perform a function-call-graph-based app profiling. We carefully design a graph-encoding method to convert a typically extremely large call-graph to a 64-dimension fix-size vector to achieve robust app profiling. Our extensive evaluations based on 86,332 benign and malicious apps demonstrate that our system performs app profiling (thus malware detection, classification, and app recommendation) to a high accuracy with extremely low computation cost: it classifies 4024 (benign/malware) apps using around 5.06 second with accuracy about 93.07%; it classifies 570 malware's family (total 21 families) using around 0.83 second with accuracy 82.3%; it classifies 9,730 apps' functionality with accuracy 33.3% for a total of 7 categories and accuracy of 88.1 % for 2 categories.},
keywords={graph theory;invasive software;learning (artificial intelligence);mobile computing;pattern classification;app recommendation;function-call-graph-based app profiling;graph-encoding method;malicious apps;app behavior profiling;malware detection;benign apps;mobile applications behaviors;malware classification;AppDNA;graph-based deep learning;Malware;Feature extraction;Encoding;Task analysis;Plagiarism;Neural networks;Machine learning},
doi={10.1109/INFOCOM.2018.8486327},
ISSN={},
month={April},}
@INPROCEEDINGS{8486299,
author={H. Wang and J. Wang and W. Dang and J. Xue and F. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Squeezing the Gap: An Empirical Study on DHCP Performance in a Large-scale Wireless Network},
year={2018},
volume={},
number={},
pages={1628-1636},
abstract={Dynamic Host Configuration Protocol (DHCP) is widely used to dynamically assign IP addresses. However, due to little knowledge on the behavior and performance of DHCP, it is challenging to configure a proper lease time in complicated wireless network. In this paper, we conduct the largest known measurement on the behavior and performance of DHCP based on the wireless network of T University (TWLAN). TWLAN has more than 59,000 users, 10,000 wireless access points and 130,000 IP addresses. We find the performance of DHCP is far from satisfactory: (1) The non-authenticated devices lead to a waste of 25% of IP addresses at the rush hour. (2) A device does not generate traffic for 67 % of the lease time on average. Meanwhile, we find devices of different locations and operating systems show diverse online patterns. A unified lease time setting could result in an inefficient utilization of addresses. To address the problems, taking account of authentication information and device online patterns, we propose a new leasing strategy. The results show it reduces the number of assigned addresses by 24 % and reduces the time during which an IP address is occupied by 17 % without sianificantly Increasing the DHCP server load.},
keywords={IP networks;protocols;radio networks;telecommunication traffic;wireless LAN;IP address;DHCP server load;large-scale wireless network;Dynamic Host Configuration Protocol;complicated wireless network;TWLAN;unified lease time setting;IP networks;Authentication;Wireless networks;Servers;Object recognition;Performance evaluation;Buildings;DHCP;measurement;performance;optimization},
doi={10.1109/INFOCOM.2018.8486299},
ISSN={},
month={April},}
@INPROCEEDINGS{8486407,
author={K. Xue and X. Zhang and Q. Xia and D. S. L. Wei and H. Yue and F. Wu},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={SEAF: A Secure, Efficient and Accountable Access Control Framework for Information Centric Networking},
year={2018},
volume={},
number={},
pages={2213-2221},
abstract={Information Centric Networking (ICN) has been regarded as an ideal architecture for the next-generation network to handle users' increasing demand for content delivery with in-network cache. While making better use of network resources and providing better delivery service, an effective access control mechanism is needed due to wide dissemination of contents. However, in the existing solutions, making cache-enabled routers or content providers authenticate users' requests causes high computation overhead and unnecessary delay. Also, straightforward utilization of advanced encryption algorithms increases the opportunities for DoS attacks. Besides, privacy protection and service accountability are rarely taken into account in this scenario. In this paper, we propose a secure, efficient, and accountable access control framework, called SEAF, for ICN, in which authentication is performed at the network edge to block unauthorized requests at the very beginning. We adopt group signature to achieve anonymous authentication, and use hash chain technique to greatly reduce the overhead when users make continuous requests for the same file. Furthermore, the content providers can affirm the service amount received from the network and extract feedback information from the signatures and hash chains. By formal security analysis and the comparison with related works, we show that SEAF achieves the expected security goals and possesses more useful features. The experimental results also demonstrate that our design is efficient for routers and content providers, and introduces only slight delay for users' content retrieval.},
keywords={authorisation;cache storage;computer network security;cryptography;data privacy;Internet;secure, efficient and accountable access control framework;information centric networking;network edge;service accountability;privacy protection;content providers;cache-enabled routers;effective access control mechanism;delivery service;network resources;in-network cache;content delivery;next-generation network;ICN;SEAF;Access control;Authentication;Encryption;Delays;Privacy},
doi={10.1109/INFOCOM.2018.8486407},
ISSN={},
month={April},}
@INPROCEEDINGS{8485868,
author={D. Tian and J. Zhou and M. Chen and Z. Sheng and Q. Ni and V. C. M. Leung},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Cooperative Content Transmission for Vehicular Ad Hoc Networks using Robust Optimization},
year={2018},
volume={},
number={},
pages={90-98},
abstract={Vehicular ad hoc networks (VANETs) have a potential to promote vehicular telematics and infotainment applications, where a key and challenging issue is the design of robust and efficient vehicular content transmissions to combat the lossy inter-vehicle links. In this paper, we focus on the robust optimization of content transmissions over cooperative VANETs. We first derive a stochastic model for estimation of time-varying inter-vehicle distance, which is dependent of the vehicle real-time kinematics and the distribution of the initial space headway. With this model, we analytically formulate the transient inter-vehicle connectivity assuming Nakagami fading channels for the physical (PHY) layer. We also model the contention nature of the medium access control (MAC) layer, on which we are based to evaluate the throughput achieved by each vehicle equipped with dedicated short-range communication (DSRC). Combining these models, we derive a closed-formed expression for the upper bound of the probability of failure in intact-content transmissions. Based upon this theoretical bound, we develop a robust optimization model for assigning content data traffic among different cooperative transmission paths, where the objective is to minimize the maximum likelihood of unsuccessful content transmissions over the cooperative VANET. We mathematically transform the optimization model to another equivalent form, such that it can be practically deployed. Finally, we validate our theoretical development with extensive simulations. Numerical results are also provided to confirm the power of cooperation in boosting the VANET performance as well as demonstrate the advantage of the proposed robust optimization in terms of content data reception reliability.},
keywords={access protocols;Nakagami channels;optimisation;probability;telecommunication network reliability;vehicular ad hoc networks;cooperative content transmission;content data reception reliability;VANET performance;content data traffic;robust optimization model;intact-content transmissions;medium access control layer;contention nature;physical layer;Nakagami fading channels;transient inter-vehicle connectivity;initial space headway;real-time kinematics;time-varying inter-vehicle distance;lossy inter-vehicle links;vehicular telematics;vehicular ad hoc networks;Fading channels;Robustness;Optimization;Stochastic processes;Mathematical model;Electronic mail;Relays},
doi={10.1109/INFOCOM.2018.8485868},
ISSN={},
month={April},}
@INPROCEEDINGS{8485978,
author={K. Qian and C. Wu and F. Xiao and Y. Zheng and Y. Zhang and Z. Yang and Y. Liu},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Acousticcardiogram: Monitoring Heartbeats using Acoustic Signals on Smart Devices},
year={2018},
volume={},
number={},
pages={1574-1582},
abstract={Vital signs such as heart rate and heartbeat interval are currently measured by electrocardiograms (ECG) or wearable physiological monitors. These techniques either require contact with the patient's skin or are usually uncomfortable to wear, rendering them too expensive and user-unfriendly for daily monitoring. In this paper, we propose a new noninvasive technology to generate an Acousticcardiogram (ACG) that precisely monitors heartbeats using inaudible acoustic signals. ACG uses only commodity microphones and speakers commonly equipped on ubiquitous off-the-shelf devices, such as smartphones and laptops. By transmitting an acoustic signal and analyzing its reflections off human body, ACG is capable of recognizing the heart rate as well as heartbeat rhythm. We employ frequency-modulated sound signals to separate reflection of heart from that of background motions and breath, and continuously track the phase changes of the acoustic data. To translate these acoustic data into heart and breath rates, we leverage the dual microphone design on COTS mobile devices to suppress direct echo from speaker to microphones, identify heart rate in frequency domain, and adopt an advanced algorithm to extract individual heartbeats. We implement ACG on commercial devices and validate its performance in real environments. Experimental results demonstrate ACG monitors user's heartbeat accurately, with median heart rate estimation error of 0.6 beat per minute (bpm), and median heartbeat interval estimation error of 19 ms.},
keywords={acoustic signal processing;biomedical telemetry;body sensor networks;medical signal processing;microphones;patient monitoring;pneumodynamics;monitoring heartbeats;acoustic signal;smart devices;vital signs;wearable physiological monitors;user-unfriendly;daily monitoring;noninvasive technology;precisely monitors heartbeats;inaudible acoustic signals;commodity microphones;speaker;off-the-shelf devices;heartbeat rhythm;frequency-modulated sound signals;background motions;acoustic data;breath rates;dual microphone design;COTS mobile devices;individual heartbeats;commercial devices;ACG monitors user;acousticcardiogram;median heartbeat interval estimation error;median heart rate estimation error;time 19.0 ms;Heart beat;Monitoring;Biomedical monitoring;Microphones;Sonar;Smart devices},
doi={10.1109/INFOCOM.2018.8485978},
ISSN={},
month={April},}
@INPROCEEDINGS{8485970,
author={L. Wang and W. Wang and B. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Utopia: Near-optimal Coflow Scheduling with Isolation Guarantee},
year={2018},
volume={},
number={},
pages={891-899},
abstract={Performance and service isolation come as two top objectives for coflow scheduling. However, the common wisdom is that these two objectives are often conflicting with each other and cannot be achieved simultaneously. Existing coflow scheduling frameworks either focus only on minimizing the average coflow completion time (CCT) (e.g., Varys), or providing optimal isolation between contending coflows by means of fair network sharing (e.g., HUG). In this paper, we make an attempt to achieve the best of both worlds through a novel coflow scheduler, Utopia, to attain near-optimal performance with provable isolation guarantee. This is particularly challenging given the correlation of bandwidth demands across multiple links from coflows. We show that Utopia is capable of reducing the average CCT dramatically, while still guaranteeing that no coflow will ever be delayed beyond a constant time than its CCT in a fair scheme. Both trace-driven simulation and EC2 deployment confirm that Utopia outperforms the fair sharing policy by 1.8 × in terms of average CCT, while producing no completion time delay for a single coflow. Even compared with performance-optimal Varys, Utopia speeds up average coflow completion by 9%.},
keywords={delays;telecommunication scheduling;fair network;Utopia;near-optimal performance;provable isolation guarantee;average CCT;constant time;fair scheme;fair sharing policy;completion time delay;single coflow;performance-optimal Varys;near-optimal coflow scheduling;service isolation;common wisdom;coflow scheduling frameworks;average coflow completion time;optimal isolation;contending coflows;Bandwidth;Resource management;Fabrics;Delays;Conferences;Correlation;Production},
doi={10.1109/INFOCOM.2018.8485970},
ISSN={},
month={April},}
@INPROCEEDINGS{8485806,
author={J. Chen and F. Tang and H. Zhang and L. T. Yang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Lightweight Retransmission for Random Access in Satellite Networks},
year={2018},
volume={},
number={},
pages={549-557},
abstract={Existing random access protocols designed for satellite networks have poor performance in short burst communications because of the difficulty on global time synchronization and frequent collisions. In this paper, we propose a Lightweight Retransmission (LwR) mechanism for random access in satellite networks to reduce collisions and get rid of synchronization requirement. In our LwR, only partial bits in a packet are retransmitted. Firstly, we formulate the lightweight retransmission problem and prove that it is NP-hard. Next, we focus on the construction of partial replicas, which is the core of our LwR, and propose regular and random construction methods. Especially, we prove the sufficient conditions for successfully decoding two conflicted packets by ZigZag. Finally, we propose an algebraic model and derive the upper and lower bounds of successfully decoding probability under different construction methods. Both theoretical analysis and experimental results reveal that the random construction method achieves higher decoding probability than the regular construction method. Simulation results also demonstrate that our LwR significantly outperforms related schemes designed for satellite networks.},
keywords={access protocols;computational complexity;decoding;optimisation;satellite communication;synchronisation;lightweight retransmission mechanism;NP-hard;conflicted packet decoding;algebraic model;decoding probability;random access protocols;random construction method;regular construction methods;synchronization requirement;satellite networks;global time synchronization;short burst communications;Decoding;Satellites;Synchronization;Throughput;Silicon carbide;Optimization;Conferences},
doi={10.1109/INFOCOM.2018.8485806},
ISSN={},
month={April},}
@INPROCEEDINGS{8485889,
author={F. Cecchi and S. C. Borst and J. S. H. van Leeuwaarden and P. A. Whiting},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Optimal Activation Rates in Ultra-Dense Wireless Networks with Intermittent Traffic Sources},
year={2018},
volume={},
number={},
pages={2672-2680},
abstract={As the Internet-of-Things (IoT) emerges, connecting immense numbers of sensors and devices, the continual growth in wireless communications increasingly manifests itself in terms of a larger and denser population of nodes with intermittent traffic patterns. A crucial issue that arises in these conditions is how to set the activation rates as a function of the network density and traffic intensity. Depending on the scaling of the activation rates, dense node populations may either result in excessive activations and potential collisions, or long delays that may increase with the number of nodes, even at low load. Motivated by the above issues, we examine optimal activation rate scalings in ultra-dense networks with intermittent traffic sources. We establish stability conditions, and provide closed-form expressions which indicate that the mean delay is roughly inversely proportional to the nominal activation rate. We also discuss a multi-scale mean-field limit, and use the associated fixed point to determine the buffer content and delay distributions. The results provide insight in the scalings that minimize the delay while preventing excessive activation attempts. Extensive simulation experiments demonstrate that the mean-field asymptotics yield highly accurate approximations, even when the number of nodes is moderate.},
keywords={delays;Internet;radio networks;telecommunication traffic;ultra-dense networks;intermittent traffic sources;stability conditions;mean delay;nominal activation rate;multiscale mean-field limit;excessive activation attempts;optimal activation rates;ultra-dense wireless networks;Internet-of-Things;immense numbers;sensors;devices;continual growth;wireless communications;intermittent traffic patterns;network density;traffic intensity;dense node populations;excessive activations;optimal activation rate scalings;Delays;Aggregates;Multiaccess communication;Sociology;Statistics;Throughput},
doi={10.1109/INFOCOM.2018.8485889},
ISSN={},
month={April},}
@INPROCEEDINGS{8486226,
author={H. Liu and X. Li and L. Zhang and Y. Xie and Z. Wu and Q. Dai and G. Chen and C. Wan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Finding the Stars in the Fireworks: Deep Understanding of Motion Sensor Fingerprint},
year={2018},
volume={},
number={},
pages={126-134},
abstract={With the proliferation of mobile devices and various sensors (e.g., GPS, magnetometer, accelerometers, gyroscopes) equipped, richer services, e.g. location based services, are provided to users. A series of methods have been proposed to protect the users' privacy, especially the trajectory privacy. Hardware fingerprinting has been demonstrated to be a surprising and effective source for identifying/authenticating devices. In this work, we show that a few data samples collected from the motion sensors are enough to uniquely identify the source mobile device, i.e., the raw motion sensor data serves as a fingerprint of the mobile device. Specifically, we first analytically understand the fingerprinting capacity using features extracted from hardware data. To capture the essential device feature automatically, we design a multi-LSTM neural network to fingerprint mobile device sensor in real-life uses, instead of using handcrafted features by existing work. Using data collected over 6 months, for arbitrary user movements, our fingerprinting model achieves 93 % F -score given one second data, while the state-of-the-art work achieves 79% F-score. Given ten seconds randomly sampled data, our model can achieve 98.8% accuracy. We also propose a novel generative model to modify the original sensor data and yield anonymized data with little fingerprint information while retain good data utility.},
keywords={data privacy;feature extraction;message authentication;mobile computing;neural nets;sensor fusion;fingerprinting capacity;hardware data;multiLSTM neural network;fingerprint mobile device sensor;arbitrary user movements;fingerprinting model;anonymized data;fingerprint information;motion sensor fingerprint;trajectory privacy;hardware fingerprinting;source mobile device;raw motion sensor data;device feature;sensor data;data utility;features extraction;devices authentication;Feature extraction;Mobile handsets;Hardware;Data models;Robustness;Neural networks;Fingerprint recognition},
doi={10.1109/INFOCOM.2018.8486226},
ISSN={},
month={April},}
@INPROCEEDINGS{8485850,
author={S. Jiang and D. He and C. Yang and C. Xu and G. Luo and Y. Chen and Y. Liu and J. Jiang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Accelerating Mobile Applications at the Network Edge with Software-Programmable FPGAs},
year={2018},
volume={},
number={},
pages={55-62},
abstract={Recently, Edge Computing has emerged as a new computing paradigm dedicated for mobile applications for performance enhancement and energy efficiency purposes. Specifically, it benefits today's interactive applications on power-constrained devices by offloading compute-intensive tasks to the edge nodes which is in close proximity. Meanwhile, Field Programmable Gate Array (FPGA) is well known for its excellence in accelerating compute-intensive tasks such as deep learning algorithms in a high performance and energy efficiency manner due to its hardware-customizable nature. In this paper, we make the first attempt to leverage and combine the advantages of these two, and proposed a new network-assisted computing model, namely FPGA-based edge computing. As a case study, we choose three computer vision (CV)-based interactive mobile applications, and implement their backend computation parts on FPGA. By deploying such application-customized accelerator modules for computation offloading at the network edge, we experimentally demonstrate that this approach can effectively reduce response time for the applications and energy consumption for the entire system in comparison with traditional CPU-based edge/cloud offloading approach.},
keywords={cloud computing;computer vision;field programmable gate arrays;interactive systems;learning (artificial intelligence);mobile computing;power aware computing;deep learning algorithms;network-assisted computing model;edge computing;FPGA;energy consumption;power-constrained devices;offloading compute-intensive tasks;edge nodes;Field Programmable Gate Array;interactive mobile applications;energy efficiency;computer vision;software-Programmable FPGA;Cloud computing;Field programmable gate arrays;Servers;Acceleration;Computational modeling;Edge computing;Time factors},
doi={10.1109/INFOCOM.2018.8485850},
ISSN={},
month={April},}
@INPROCEEDINGS{8486205,
author={H. Guo and Z. Sun},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Full-Duplex Metamaterial-Enabled Magnetic Induction Networks in Extreme Environments},
year={2018},
volume={},
number={},
pages={558-566},
abstract={Many important applications in the extreme environment require wireless communications to connect smart devices. Metamaterial-enhanced magnetic induction (M2I) has been proposed as a promising solution thanks to its long communication range in the lossy medium. M 2I communication relies on magnetic coupling, which makes it intrinsically full-duplex without self-interference. Moreover, the engineered active metamaterial provides reconfigurability in communication range and interference. In this paper, the new networking paradigm based on the reconfigurable and full-duplex M 2I communication technique is investigated. In particular, the theoretical analysis and electromagnetic simulation are first provided to prove the feasibility. Then, a medium access control protocol is proposed to avoid collisions. Finally, the capacity and delay of the full-duplex M2I network are derived to show the advantage of the new networking paradigm. The analysis in this paper indicates that in a full-duplex M 2I network, the distance between the source and destination can be arbitrarily long and the end-to-end delay can be as short as a single hop delay. As a result, each node in such network can reach any other node by one hop, which can greatly enhance the network robustness and efficiency. It is important for timely transmission of emergent information or real-time control signals.},
keywords={access protocols;electromagnetic induction;magnetic materials;metamaterials;radio networks;wireless communications;smart devices;lossy medium;magnetic coupling;engineered active metamaterial;medium access control protocol;end-to-end delay;self-interference;full-duplex M2I communication technique;electromagnetic simulation;real-time control signals;full-duplex M2I wireless networks;full duplex metamaterial-enabled magnetic induction wireless networks;Relays;Metamaterials;Magnetic materials;Antennas;Delays;Couplings;Receivers},
doi={10.1109/INFOCOM.2018.8486205},
ISSN={},
month={April},}
@INPROCEEDINGS{8486315,
author={M. C. Luizelli and D. Raz and Y. Sa'ar},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Optimizing NFV Chain Deployment through Minimizing the Cost of Virtual Switching},
year={2018},
volume={},
number={},
pages={2150-2158},
abstract={Network Function Virtualization (NFV) is a novel paradigm that enables flexible and scalable implementation of network services on cloud infrastructure. A key factor in the success of NFV is the ability to dynamically allocate physical resources according to the demand. This is particularly important when dealing with the data plane since additional resources are required in order to support the virtual switching of the packets between the Virtual Network Functions (VNFs). The exact amount of these resources depends on the way service chains are deployed and the amount of network traffic being handled. Thus, orchestrating service chains that require high traffic throughput is a very complex task and most existing solutions either concentrate on handcrafted tuning of the servers to achieve the needed performance level, or present theoretical placement functions that assume that the switching cost is part of the input. In this work, we bridge this gap by presenting a deployment algorithm for service chains that optimizes performance by minimizing the actual cost of virtual switching. The results are based on extensive measurements of the actual switching cost and the performance of service chains in a realistic NFV environment. Our evaluation indicates that this new algorithm significantly reduces virtual switching resource utilization when compared to the de-facto standard placement in OpenStack/Nova - allowing a much higher acceptance ratio of network services.},
keywords={computer networks;resource allocation;switching networks;telecommunication traffic;virtualisation;network traffic;high traffic throughput;theoretical placement functions;virtual switching resource utilization;network function virtualization;NFV chain deployment optimization;cloud infrastructure;physical resource allocation;VNF;virtual network functions;OpenStack-Nova method;Servers;Switches;Virtual machine monitors;Conferences;Virtualization;Cloud computing;Task analysis},
doi={10.1109/INFOCOM.2018.8486315},
ISSN={},
month={April},}
@INPROCEEDINGS{8485826,
author={X. Wang and J. Ma and Y. Miao and R. Yang and Y. Chang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={EPSMD: An Efficient Privacy-Preserving Sensor Data Monitoring and Online Diagnosis System},
year={2018},
volume={},
number={},
pages={819-827},
abstract={With the development of Mobile Healthcare Monitoring Network (MHMN), patients' personal data collected by body sensors not only allows patients to monitor their health or make online pre-diagnosis but also enable clinicians to make proper decisions by utilizing data mining technique. However, the sensitive data privacy is still a major concern. In this paper, we first propose an Efficient Privacy-preserving Sensor data Monitoring and online Diagnosis (EPSMD) system for outsourced computing, then furnish an improved Multidimensional Range Query Technique (MRQT) to gain a broad range of applications in practice. In addition, a privacy-preserving naive Bayesian classifier based on MRQT is designed to protect patients' data in data mining and online diagnosis efficiently. Security analysis proves that patients' data privacy can be well protected without loss of data confidentiality, and performance evaluation demonstrates the efficiency and accuracy in data monitoring and disease pre-diagnosis, respectively.},
keywords={Bayes methods;data mining;data protection;diseases;health care;medical diagnostic computing;mobile computing;patient monitoring;pattern classification;query processing;Mobile Healthcare Monitoring Network;privacy-preserving naive Bayesian classifier;data confidentiality;disease pre-diagnosis;data mining;data privacy;privacy-preserving sensor data monitoring;online diagnosis system;Multidimensional Range Query Technique;patient data protection;EPSMD system;Monitoring;Cloud computing;Cryptography;Bayes methods;Data privacy;Privacy},
doi={10.1109/INFOCOM.2018.8485826},
ISSN={},
month={April},}
@INPROCEEDINGS{8485969,
author={T. Zhou and B. Xiao and Z. Cai and M. Xu and X. Liu},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={From Uncertain Photos to Certain Coverage: a Novel Photo Selection Approach to Mobile Crowdsensing},
year={2018},
volume={},
number={},
pages={1979-1987},
abstract={Traditional mobile crowdsensing photo selection process focuses on selecting photos from participants to a server. The server may contain tons of photos for a certain area. A new problem is how to select a set of photos from the server to a smartphone user when the user requests to view an area (e.g., a hot spot). The challenge of the new problem is that the photo set should attain both photo coverage and view quality (e.g., with clear Points of Interest). However, contributions of these geo-tagged photos could be uncertain for a target area due to unavailable information of photo shooting direction and no reference photos. In this paper, we propose a novel and generic server-to-requester photo selection approach. Our approach leverages a utility measure to quantify the contribution of a photo set, where photos' spatial distribution and visual correlation are jointly exploited to evaluate their performance on photo coverage and view quality. Finding the photo set with the maximum utility is proven to be NP-hard. We then propose an approximation algorithm based on a greedy strategy with rigorous theoretical analysis. The effectiveness of our approach is demonstrated with real-world datasets. The results show that the proposal outperforms other approaches with much higher photo coverage and better view quality.},
keywords={approximation theory;greedy algorithms;information retrieval;mobile computing;smart phones;photo set;geo-tagged photos;photo shooting direction;generic server-to-requester photo selection approach;photo selection approach;mobile crowdsensing photo selection process;photo coverage;approximation algorithm;greedy strategy;Servers;Sensors;Correlation;Visualization;Mobile handsets;Uncertainty;Cameras},
doi={10.1109/INFOCOM.2018.8485969},
ISSN={},
month={April},}
@INPROCEEDINGS{8486329,
author={C. Hu and W. Bao and D. Wang},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={IoT Communication Sharing: Scenarios, Algorithms and Implementation},
year={2018},
volume={},
number={},
pages={1556-1564},
abstract={Nowadays, manufacturers want to collect the data of their sold-products to the cloud, so that they can conduct analysis and improve the operation, maintenance and services of their products. Manufacturers are looking for a self-contained solution for data transmission since their products are typically deployed in a large number of different buildings, and it is neither feasible to negotiate with each building to use the building's network (e.g., WiFi) nor practical to establish its own network infrastructure. ISPs are aware of this market. Since the readily available 3G/4G is over costly for most IoT devices, ISPs are developing new choices. Nevertheless, it can be expected that the choices from ISPs will not be fine-grained enough to match hundreds or thousands of requirements on different costs and data volumes from the IoT applications. To address this problem, we for the first time propose IoT communication sharing (ICS). We first clarify the ICS scenarios. We then formulate the IoT communication sharing (ICS) problem, and develop a set of algorithms with provable performance. We further present our implementation of a fully functioning system. Our evaluations show that ICS and our algorithms can lead to a cost reduction of five times and eight times respectively for the two real-world cases.},
keywords={data communication;Internet of Things;ICS scenarios;IoT communication sharing problem;data transmission;IoT devices;ISP;internet service providers;data volumes;Buildings;Integrated circuits;Maintenance engineering;Wireless fidelity;Computational modeling;Cloud computing;Wireless sensor networks},
doi={10.1109/INFOCOM.2018.8486329},
ISSN={},
month={April},}
@INPROCEEDINGS{8485948,
author={G. Grigoryan and Y. Liu and M. Leczinsky and J. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={VeriTable: Fast Equivalence Verification of Multiple Large Forwarding Tables},
year={2018},
volume={},
number={},
pages={621-629},
abstract={Due to network practices such as traffic engineering and multi-homing, the number of routes-also known as IP prefixes-in the global forwarding tables has been increasing significantly in the last decade and continues growing in a super linear trend. One of the most promising solutions is to use smart Forwarding Information Base (FIB) aggregation algorithms to aggregate the prefixes and convert a large table into a small one. Doing so poses a research question, however, i.e., how can we quickly verify that the original table yields the same forwarding behaviors as the aggregated one? We answer this question in this paper, including addressing the challenges caused by the longest prefix matching (LPM) lookups. In particular, we propose the VeriTable algorithm that can employ a single tree/trie traversal to quickly check if multiple forwarding tables are forwarding equivalent, as well as if they could result in routing loops or black holes. The VeriTable algorithm significantly outperforms the state-of-the-art work for both IPv4 and IPv6 tables in every aspect, including the total running time, memory access times and memory consumption.},
keywords={computer networks;IP networks;telecommunication network routing;telecommunication traffic;trees (mathematics);fast equivalence verification;multiple large Forwarding tables;network practices;traffic engineering;multihoming;VeriTable algorithm;IPv6 tables;Forwarding Information Base aggregation algorithms;Routing;IP networks;Routing protocols;Binary trees;Memory management;Engines;Heuristic algorithms},
doi={10.1109/INFOCOM.2018.8485948},
ISSN={},
month={April},}
@INPROCEEDINGS{8485824,
author={S. Zawoad and R. Hasan and K. Islam},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={SECProv: Trustworthy and Efficient Provenance Management in the Cloud},
year={2018},
volume={},
number={},
pages={1241-1249},
abstract={The black-box nature of clouds introduces a lack of trusts in clouds. Since provenance can provide a complete history of an entity, trustworthy provenance management for data, application, or workflow can make the cloud more accountable. Current research on cloud provenance mainly focuses on collecting provenance records and trusting the cloud providers in managing the provenance records. However, a dishonest cloud provider can alter the provenance records, as the records are stored within the control of the cloud provider. To solve this problem, we first propose CloProv - a provenance model to capture the complete provenance of any type of entities in the cloud. We analyze the threats on the CloProv model considering collusion among malicious users and dishonest cloud providers. Based on the threat model, we propose a secure data provenance scheme - SECProv for cloud-based, multi-user, shared data storage systems. We integrate SECProv with the object storage module of an open source cloud framework - OpenStack Swift and analyze the efficiency of the proposed scheme.},
keywords={cloud computing;public domain software;security of data;storage management;trusted computing;provenance records;provenance model;dishonest cloud provider;black-box nature;clouds;cloud provenance;secure data provenance scheme;SECProv;provenance management trustworthy;provenance management efficiency;open source cloud framework;OpenStack Swift;CloProv;object storage modul;shared data storage systems;Cloud computing;Data models;History;Conferences},
doi={10.1109/INFOCOM.2018.8485824},
ISSN={},
month={April},}
@INPROCEEDINGS{8485863,
author={A. Trotta and F. D. Andreagiovanni and M. Di Felice and E. Natalizio and K. R. Chowdhury},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={When UAVs Ride A Bus: Towards Energy-efficient City-scale Video Surveillance},
year={2018},
volume={},
number={},
pages={1043-1051},
abstract={This paper proposes a network architecture and supporting optimization framework that allows Unmanned Aerial Vehicles (UAVs) to perform city-scale video monitoring of a set of Points of Interest (PoI). Our approach is systems-driven, relying on experimental studies to identify the permissible number of hops for multi-UAV video relaying in a noisy 3-D environment. Our architecture itself is innovative in the sense that it defines a mathematical framework for selecting the UAVs for periodic re-charging by landing on public transportation buses, and then `riding' the bus to the successive chosen Pol. Specifically, we show that our UAV scheduler can be modeled as an instance of multicommodity flow problems, and mathematically solved through Mixed Integer Linear Programming (MILP) techniques. Thus, our centralized formulation identifies the UAV, the next bus, and the next PoI, given the information about energy thresholds, the bus routes in the city and their next arrival times, to ensure persistent and reliable video coverage of all PoIs in the city. Finally, our work is validated via emulation of a city environment with live traffic updates from a real bus transportation network.},
keywords={autonomous aerial vehicles;energy conservation;integer programming;linear programming;public administration;public transport;road traffic;scheduling;video surveillance;persistent video coverage;bus transportation network;energy-efficient city-scale video surveillance;supporting optimization framework;Unmanned Aerial Vehicles;city-scale video monitoring;public transportation buses;UAV scheduler;multiUAV video relaying;Mixed Integer Linear Programming;Points of Interest;urban area surveillance;Urban areas;Relays;Streaming media;Monitoring;Unmanned aerial vehicles;Batteries;Charging stations},
doi={10.1109/INFOCOM.2018.8485863},
ISSN={},
month={April},}
@INPROCEEDINGS{8486254,
author={J. Liu},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={High-Order Momentum: Improving Latency and Convergence for Wireless Network Optimization},
year={2018},
volume={},
number={},
pages={1862-1870},
abstract={In recent years, the rapid growth of mobile data demands has introduced many stringent requirements on latency and convergence performance in wireless network optimization. To address these challenges, several momentum-based algorithms have been proposed to improve the classical queue-length-based algorithmic framework (QLA). By combining queue-length updates and one-slot weight changes (known as the first-order momentum), it has been shown that these algorithms dramatically improve delay and convergence compared to QLA, while maintaining the same throughput-optimality and low-complexity. These exciting attempts have sparked a lot of conjectures about whether it is useful to further exploit high-order momentum information to improve delay and convergence speed. In this paper, we show that the answer is yes. Specifically, we first propose a new weight updating scheme that enables the incorporation of high-order momentum. We then prove the throughput-optimality and queue-stability of the proposed high-order momentum-based approach and characterize its delay and convergence performances. Through these analytical results, we finally show that delay and convergence would continue to improve as more high-order momentum information is utilized.},
keywords={optimisation;queueing theory;radio networks;wireless network optimization;mobile data demands;convergence performance;momentum-based algorithms;classical queue-length-based algorithmic framework;QLA;one-slot weight changes;throughput-optimality;high-order momentum information;weight updating scheme;queue-stability;high-order momentum-based approach;Optimization;Convergence;Delays;Wireless networks;Queueing analysis;Conferences},
doi={10.1109/INFOCOM.2018.8486254},
ISSN={},
month={April},}
@INPROCEEDINGS{8486293,
author={N. Zhang and K. Sun and D. Shands and W. Lou and Y. T. Hou},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={TruSense: Information Leakage from TrustZone},
year={2018},
volume={},
number={},
pages={1097-1105},
abstract={With the emergence of Internet of Things, mobile devices are generating more network traffic than ever. TrustZone is a hardware-enabled trusted execution environment for ARM processors. While TrustZone is effective in providing the much-needed memory isolation, we observe that it is possible to derive secret information from secure world using the cache contention, due to its high-performance cache sharing design. In this work, we propose TruSense to study the timing-based cache side-channel information leakage of TrustZone. TruSense can be launched from not only the normal world operating system but also a non-privileged user application. Without access to virtual-to-physical address mapping in user applications, we devise a novel method that uses the expected channel statistics to allocate memory for cache probing. We also show how an attacker might use the less accurate performance event interface as a timer. Using the T-table based AES implementation in OpenSSL 1.0.1f as an example, we demonstrate how a normal world attacker can steal fine-grained secret in the secure world. We also discuss possible mitigations for the information leakage.},
keywords={cache storage;cryptography;Internet of Things;mobile computing;trusted computing;TruSense;TrustZone;mobile devices;ARM processors;memory isolation;cache contention;high-performance cache sharing design;timing-based cache side-channel information leakage;nonprivileged user application;cache probing;hardware-enabled trusted execution;Internet of Things;T-table based AES implementation;OpenSSL 1.0;Side-channel attacks;Kernel;Program processors;Timing;Hardware},
doi={10.1109/INFOCOM.2018.8486293},
ISSN={},
month={April},}
@INPROCEEDINGS{8486417,
author={N. Ghose and L. Lazos and M. Li},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={SFIRE: Secret-Free-in-band Trust Establishment for COTS Wireless Devices},
year={2018},
volume={},
number={},
pages={1529-1537},
abstract={We address the problem of trust establishment between wireless devices that do not share any prior secrets. This includes the mutual authentication and agreement to a common key that can be used to further bootstrap essential cryptographic mechanisms. We propose SFIRE, a secret-free trust establishment protocol that allows the secure pairing of commercial off-the-shelf (COTS) wireless devices with a hub. Compared to the state-of-the-art, SFIRE does not require any out-of-band channels, special hardware, or firmware modification, but can be applied to any COTS device. Moreover, SFIRE is resistant to the most advanced active signal manipulations that include recently demonstrated signal nullification at an intended receiver. These security properties are achieved in-band with the assistance of a helper device such as a smartphone and by using the RSS fluctuation patterns to build a robust “RSS authenticator”. We perform extensive experiments using COTS devices and USRP radios and verify the validity of the proposed protocol.},
keywords={cryptographic protocols;radio networks;telecommunication security;commercial off-the-shelf wireless devices;USRP radios;robust RSS authenticator;advanced active signal manipulations;out-of-band channels;SFIRE;secret-free trust establishment protocol;bootstrap essential cryptographic mechanisms;mutual authentication;COTS wireless devices;secret-free-in-band trust establishment;Wireless communication;Communication system security;Protocols;Wireless sensor networks;Performance evaluation;Channel estimation;Security},
doi={10.1109/INFOCOM.2018.8486417},
ISSN={},
month={April},}
@INPROCEEDINGS{8485860,
author={K. Ji and G. Quan and J. Tan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Asymptotic Miss Ratio of LRU Caching with Consistent Hashing},
year={2018},
volume={},
number={},
pages={450-458},
abstract={To efficiently scale data caching infrastructure to support emerging big data applications, many caching systems rely on consistent hashing to group a large number of servers to form a cooperative cluster. These servers are organized together according to a random hash function. They jointly provide a unified but distributed hash table to serve swift and voluminous data item requests. Different from the single least-recently-used (LRU) server that has already been extensively studied, theoretically characterizing a cluster that consists of multiple LRU servers remains yet to be explored. These servers are not simply added together; the random hashing complicates the behavior. To this end, we derive the asymptotic miss ratio of data item requests on a LRU cluster with consistent hashing. We show that these individual cache spaces on different servers can be effectively viewed as if they could be pooled together to form a single virtual LRU cache space parametrized by an appropriate cache size. This equivalence can be established rigorously under the condition that the cache sizes of the individual servers are large. For typical data caching systems this condition is common. Our theoretical framework provides a convenient abstraction that can directly apply the results from the simpler single LRU cache to the more complex LRU cluster with consistent hashing.},
keywords={Big Data;cache storage;file organisation;file servers;asymptotic miss ratio;LRU caching;consistent hashing;data caching infrastructure;big data applications;random hash function;swift data item requests;voluminous data item requests;multiple LRU servers;random hashing;individual cache spaces;single virtual LRU cache space;appropriate cache size;cache sizes;individual servers;typical data caching systems;simpler single LRU cache;complex LRU cluster;distributed hash table;Servers;Distributed databases;Partitioning algorithms;Conferences;Clustering algorithms;Random variables;Electronic mail},
doi={10.1109/INFOCOM.2018.8485860},
ISSN={},
month={April},}
@INPROCEEDINGS{8485954,
author={G. Calvigioni and R. Aparicio-Pardo and L. Sassatelli and J. Leguay and P. Medagliani and S. Paris},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Quality of Experience-based Routing of Video Traffic for Overlay and ISP Networks},
year={2018},
volume={},
number={},
pages={935-943},
abstract={The surge of video traffic is a challenge for service providers that need to maximize Quality of Experience (QoE) while optimizing the cost of their infrastructure. In this paper, we address the problem of routing multiple HTTP-based Adaptive Streaming (HAS) sessions to maximize QoE. We first design a QoS-QoE model incorporating different QoE metrics which is able to learn online network variations and predict their impact on representative classes of adaptation logic, video motion and client resolution. Different QoE metrics are then combined into a QoE score based on ITU-T Rec. P.1202.2. This rich score is used to formulate the routing problem. We show that, even with a piece-wise linear QoE function in the objective, the routing problem without controlled rate allocation is non-linear. We therefore express a routing-plus-rate allocation problem and make it scalable with a dual subgradient approach based on Lagrangian relaxation where subproblems select a single path for each request with a trivial search, thereby connecting explicitly QoE, QoE and HAS bitrate. We show with ns-3 simulations that our algorithm provides values for HAS QoE metrics (quality, rebufferings, variation) equivalent to MILP and better than QoS-based approaches.},
keywords={overlay networks;quality of experience;quality of service;resource allocation;telecommunication network routing;video signal processing;video streaming;video traffic;QoS-QoE model;online network variations;video motion;client resolution;routing problem;piece-wise linear QoE function;routing-plus-rate allocation problem;HAS QoE metrics;Quality of Experience-based Routing;Overlay Networks;ISP Networks;HTTP-based Adaptive Streaming sessions;Lagrangian relaxation;Quality of experience;Routing;Measurement;Quality of service;Streaming media;Bandwidth;Resource management},
doi={10.1109/INFOCOM.2018.8485954},
ISSN={},
month={April},}
@INPROCEEDINGS{8485891,
author={G. Quan and K. Ji and J. Tan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={LRU Caching with Dependent Competing Requests},
year={2018},
volume={},
number={},
pages={459-467},
abstract={Least-recently-used (LRU) caching systems have been widely used, and are increasingly deployed driven by emerging trends for big data. In a typical scenario, these systems are used to serve multiple flows of dependent data item requests that are also correlated over time. These flows compete for the limited cache space. Characterizing the miss ratios of these competing flows can facilitate the design and improve the system performance. The existing asymptotic analyses for correlated requests give explicit results for Zipf's distributions with the index greater than a critical value (one). Consequently, the asymptotic result is inaccurate around this critical point, which notably is also the typical parameter region reported by many empirical measurements. In contrast, we derive the asymptotic miss ratios of multiple flows for a large class of truncated heavy-tailed data item popularity distributions with time dependency. Importantly, it significantly improves the accuracy in numerical computations when the index of a Zipf's distribution is close to one. Moreover, the result generalizes beyond Zipf's distributions, e.g., to Weibull, for multiple flows of correlated data item requests. Our asymptotic result directly exploits the critical properties of the distribution and the truncated support region. As our versatile expression is explicit, it avoids the numerical computations required by the characteristic time approximation. Interestingly, it also validates the characteristic time approximation with new forms for multiple flows of competing requests that are correlated over time under certain conditions.},
keywords={Big Data;cache storage;statistical distributions;LRU caching;dependent competing requests;big data;dependent data item requests;cache space;Zipf's distribution;data item popularity distributions;least-recently-used caching systems;Correlation;Weibull distribution;Conferences;Indexes;Market research;Big Data;Numerical models},
doi={10.1109/INFOCOM.2018.8485891},
ISSN={},
month={April},}
@INPROCEEDINGS{8486006,
author={T. Zhao and J. Liu and Y. Wang and H. Liu and Y. Chen},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={PPG-based Finger-level Gesture Recognition Leveraging Wearables},
year={2018},
volume={},
number={},
pages={1457-1465},
abstract={This paper subverts the traditional understanding of Photoplethysmography (PPG) and opens up a new direction of the utility of PPG in commodity wearable devices, especially in the domain of human computer interaction of fine-grained gesture recognition. We demonstrate that it is possible to leverage the widely deployed PPG sensors in wrist-worn wearable devices to enable finger-level gesture recognition, which could facilitate many emerging human-computer interactions (e.g., sign-language interpretation and virtual reality). While prior solutions in gesture recognition require dedicated devices (e.g., video cameras or IR sensors) or leverage various signals in the environments (e.g., sound, RF or ambient light), this paper introduces the first PPG-based gesture recognition system that can differentiate fine-grained hand gestures at finger level using commodity wearables. Our innovative system harnesses the unique blood flow changes in a user's wrist area to distinguish the user's finger and hand movements. The insight is that hand gestures involve a series of muscle and tendon movements that compress the arterial geometry with different degrees, resulting in significant motion artifacts to the blood flow with different intensity and time duration. By leveraging the unique characteristics of the motion artifacts to PPG, our system can accurately extract the gesture-related signals from the significant background noise (i.e., pulses), and identify different minute finger-level gestures. Extensive experiments are conducted with over 3600 gestures collected from 10 adults. Our prototype study using two commodity PPG sensors can differentiate nine finger-level gestures from American Sign Language with an average recognition accuracy over 88%, suggesting that our PPG-based finger-level gesture recognition system is promising to be one of the most critical components in sign language translation using wearables.},
keywords={blood vessels;gesture recognition;human computer interaction;image motion analysis;medical image processing;photoplethysmography;sensors;commodity wearable devices;human-computer interactions;blood flow;finger-level gesture recognition leveraging wearables;minute finger-level gestures;arterial geometry;motion artifacts;American sign language;PPG-based finger-level gesture recognition system;commodity PPG sensors;gesture-related signals;fine-grained hand gestures;wrist-worn wearable devices;fine-grained gesture recognition;human computer interaction;Gesture recognition;Wearable sensors;Assistive technology;Wrist;Blood;Biomedical monitoring},
doi={10.1109/INFOCOM.2018.8486006},
ISSN={},
month={April},}
@INPROCEEDINGS{8486303,
author={M. Leconte and G. S. Paschos and P. Mertikopoulos and U. C. Kozat},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={A Resource Allocation Framework for Network Slicing},
year={2018},
volume={},
number={},
pages={2177-2185},
abstract={Telecommunication networks are converging to a massively distributed cloud infrastructure interconnected with software defined networks. In the envisioned architecture, services will be deployed flexibly and quickly as network slices. Our paper addresses a major bottleneck in this context, namely the challenge of computing the best resource provisioning for network slices in a robust and efficient manner. With tractability in mind, we propose a novel optimization framework which allows fine-grained resource allocation for slices both in terms of network bandwidth and cloud processing. The slices can be further provisioned and auto-scaled optimally based on a large class of utility functions in real-time. Furthermore, by tuning a slice-specific parameter, system designers can trade off traffic-fairness with computing-fairness to provide a mixed fairness strategy. We also propose an iterative algorithm based on the alternating direction method of multipliers (ADMM) that provably converges to the optimal resource allocation and we demonstrate the method's fast convergence in a wide range of quasi-stationary and dynamic settings.},
keywords={cloud computing;iterative methods;optimisation;resource allocation;software defined networking;telecommunication traffic;optimal resource allocation;network slicing;telecommunication networks;massively distributed cloud infrastructure;software defined networks;resource provisioning;network bandwidth;ADMM;alternating direction method of multipliers;iterative algorithm;computing-fairness;traffic-fairness;cloud processing;Resource management;Cloud computing;Bandwidth;Routing;Network slicing;Conferences;Computer architecture},
doi={10.1109/INFOCOM.2018.8486303},
ISSN={},
month={April},}
@INPROCEEDINGS{8486360,
author={B. Alipour and L. Tonetto and A. Y. Ding and R. Ketabi and J. Ott and A. Helmy},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Flutes vs. Cellos: Analyzing Mobility-Traffic Correlations in Large WLAN Traces},
year={2018},
volume={},
number={},
pages={1637-1645},
abstract={Two major factors affecting mobile network performance are mobility and traffic patterns. Simulations and analytical-based performance evaluations rely on models to approximate factors affecting the network. Hence, the understanding of mobility and traffic is imperative to the effective evaluation and efficient design of future mobile networks. Current models target either mobility or traffic, but do not capture their interplay. Many trace-based mobility models have largely used pre-smartphone datasets (e.g., AP-logs), or much coarser granularity (e.g., cell-towers) traces. This raises questions regarding the relevance of existing models, and motivates our study to revisit this area. In this study, we conduct a multidimensional analysis, to quantitatively characterize mobility and traffic spatio-temporal patterns, for laptops and smartphones, leading to a detailed integrated mobility-traffic analysis. Our study is data-driven, as we collect and mine capacious datasets (with 30TB, 300k devices) that capture all of these dimensions. The investigation is performed using our systematic (FLAMeS) framework. Overall, dozens of mobility and traffic features have been analyzed. The insights and lessons learnt serve as guidelines and a first step towards future integrated mobility-traffic models. In addition, our work acts as a stepping-stone towards a richer, morerealistic suite of mobile test scenarios and benchmarks.},
keywords={mobile radio;performance evaluation;telecommunication traffic;wireless LAN;WLAN traces;mobile network performance;analytical-based performance evaluations;approximate factors;future mobile networks;trace-based mobility models;pre-smartphone datasets;traffic spatio-temporal patterns;traffic features;mobile test scenarios;mobility-traffic correlation analysis;integrated mobility-traffic analysis;multidimensional analysis;laptops;smartphones;FLAMeS framework;Flutes;Cellos;memory size 30.0 TByte;temperature 300.0 K;Smart phones;Portable computers;Wireless LAN;Correlation;Systematics;Fires;Conferences},
doi={10.1109/INFOCOM.2018.8486360},
ISSN={},
month={April},}
@INPROCEEDINGS{8486273,
author={T. Kim and W. Lee},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Exploiting Residual Channel for Implicit Wi-Fi Backscatter Networks},
year={2018},
volume={},
number={},
pages={1268-1276},
abstract={The emerging deployment of IoT devices increasingly requires more energy-and-cost-efficient wireless links between devices. Nowadays backscatter networks, one of the most feasible technology to meet the requirement in IoT spaces, have evolved for better usability and wider coverage. The most likely consequence of the evolution is Wi-Fi backscatter networks that harmonize with widely deployed commercial devices. However recent Wi-Fi backscatter techniques are stuck in front of several hurdles. The backscatter techniques along with 802.11b devices impair the spectral efficiency of wireless channels and break backward compatibility. Meanwhile, the backscatter techniques along with the other types of 802.11 devices support only per-packet backscatter resulting poor performance. To tackle all these problems, we propose a flicker detector that achieves per-symbol in-band backscatter by exploiting residual channel of Wi-Fi packets. Our approach shows robust performance without any modification on the hardware and any side effect on wireless channels. Extensive experiments on a software-defined radio testbed demonstrate that our approach overcomes the hurdles of existing Wi-Fi backscatter networks.},
keywords={backscatter;Internet of Things;software radio;wireless channels;wireless LAN;IoT spaces;spectral efficiency;wireless channels;software-defined radio;flicker detector;802.11b devices;implicit Wi-Fi backscatter networks;Wi-Fi backscatter techniques;wireless links;backscatter networks;IoT devices;Wi-Fi packets;residual channel;per-symbol in-band backscatter;per-packet backscatter;Backscatter;Receivers;Wireless fidelity;OFDM;Wireless communication;Detectors;Hardware;Backscatter;Wi-Fi;Internet of Things},
doi={10.1109/INFOCOM.2018.8486273},
ISSN={},
month={April},}
@INPROCEEDINGS{8485884,
author={Y. Chen and Y. Huang and Y. Shi and Y. Thomas Hou and W. Lou and S. Kompella},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={A General Model for DoF-based Interference Cancellation in MIMO Networks With Rank-Deficient Channels},
year={2018},
volume={},
number={},
pages={900-907},
abstract={In recent years, degree-of-freedom (DoF) based models were proven to be very successful in studying MIMO-based wireless networks. However, most of these studies assume channel matrix is of full-rank. Such assumption, although attractive, quickly becomes problematic as the number of antennas increases and propagation environment is not close to ideal. In this paper, we address this problem by developing a general theory for DoF-based model under rank-deficient conditions. We start with a fundamental understanding on how MIMO's DoFs are consumed for spatial multiplexing (SM) and interference cancellation (IC) in the presence of rank deficiency. Based on this understanding, we develop a general DoF model that can be used for identifying DoF region of a multi-link MIMO network and for studying DoF scheduling in MIMO networks. Specifically, we found that shared DoF consumption at transmit and receive nodes is critical for optimal allocation of DoF for IC. The results of this paper serve as an important tool for future research of many-antenna based MIMO networks.},
keywords={interference suppression;MIMO communication;radiofrequency interference;space division multiplexing;telecommunication scheduling;wireless channels;degree-of-freedom based models;propagation environment;many-antenna based MIMO networks;IC;interference cancellation;spatial multiplexing;SM;MIMO DoF scheduling model;multilink MIMO based wireless networks;rank-deficient channel matrix;DoF-based interference cancellation model;MIMO communication;Integrated circuit modeling;Nickel;Interference;Antennas;Multiplexing;MIMO;rank deficiency;degree of freedom (DoF);interference cancellation},
doi={10.1109/INFOCOM.2018.8485884},
ISSN={},
month={April},}
@INPROCEEDINGS{8486374,
author={X. Zheng and Y. He and X. Guo},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={StripComm: Interference-Resilient Cross-Technology Communication in Coexisting Environments},
year={2018},
volume={},
number={},
pages={171-179},
abstract={Cross- Technology Communication (CTC) is an emerging technique to enable the direct communication among different wireless technologies. A main category of the existing proposals on CTC propose to modulate packets at the sender side, and demodulate them into 1 and 0 bits at the receiver side. The performance of those proposals is likely to degrade in a densely coexisting environment. Solely judged according to the received signal strength, a symbol 0 that is modulated as packet absence is generally indistinguishable from dynamic interference. In this paper, we propose StripComm, interference-resilient CTC in coexisting environments. A sender in StripComm adopts an interference-resilient coding scheme that contains both presence and absence of packets in one symbol. The receiver strips the interference from the interested signal by exploiting the self-similarity of StripComm signals. We prototype StripComm with commercial WiFi, ZigBee devices and a software radio platform. The theoretical and experimental evaluation demonstrate that StripComm offers a data rate up to 1.1K bps with a SER (Symbol Error Rate) lower than 0.01 and a data rate of 0.89K bps even against strong interference.},
keywords={encoding;error statistics;radiofrequency interference;software radio;wireless LAN;Zigbee;coexisting environments;direct communication;received signal strength;packet absence;dynamic interference;interference-resilient CTC;interference-resilient coding scheme;interested signal;wireless technologies;symbol error rate;interference-resilient cross-technology communication;StripComm signal;temperature 1.1 K;temperature 0.89 K;word length 1.0 bit;word length 0.0 bit;Interference;Wireless fidelity;Receivers;ZigBee;Wireless communication;Encoding;Signal to noise ratio},
doi={10.1109/INFOCOM.2018.8486374},
ISSN={},
month={April},}
@INPROCEEDINGS{8485840,
author={D. Xiao and X. Li and D. B. H. Cline and D. Loguinov},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Estimation of DNS Source and Cache Dynamics under Interval-Censored Age Sampling},
year={2018},
volume={},
number={},
pages={1358-1366},
abstract={Since inception, DNS has used a TTL-based replication scheme that allows the source (i.e., an authoritative domain server) to control the frequency of record eviction from client caches. Existing studies of DNS predominantly focus on reducing query latency and source bandwidth, both of which are optimized by increasing the cache hit rate. However, this causes less-frequent contacts with the source and results in higher staleness of retrieved records. Given high data-churn rates at certain providers (e.g., dynamic DNS, CDNs) and importance of consistency to their clients, we propose that cache models include the probability of freshness as an integral performance measure. We derive this metric under general update/download processes and present a novel framework for measuring its value using remote observation (i.e., without access to the source or the cache). Besides freshness, our methods can estimate the inter-update distribution of DNS records, cache hit rate, distribution of TTL, and query arrival rate from other clients. Furthermore, these algorithms do not require any changes to the existing infrastructure/protocols.},
keywords={cache storage;peer-to-peer computing;probability;query processing;data-churn rates;interval-censored age sampling;query latency;inter-update distribution;query arrival rate;DNS records;general update/download processes;integral performance measure;freshness;cache models;dynamic DNS;retrieved records;cache hit rate;source bandwidth;client caches;record eviction;authoritative domain server;TTL-based replication scheme;cache dynamics;DNS source;Servers;Internet;Delays;Conferences;Random variables;Frequency control},
doi={10.1109/INFOCOM.2018.8485840},
ISSN={},
month={April},}
@INPROCEEDINGS{8485975,
author={J. Tang and X. Tang and J. Yuan},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={Towards Profit Maximization for Online Social Network Providers},
year={2018},
volume={},
number={},
pages={1178-1186},
abstract={Online Social Networks (OSNs) attract billions of users to share information and communicate where viral marketing has emerged as a new way to promote the sales of products. An OSN provider is often hired by an advertiser to conduct viral marketing campaigns. The OSN provider generates revenue from the commission paid by the advertiser which is determined by the spread of its product information. Meanwhile, to propagate influence, the activities performed by users such as viewing video ads normally induce diffusion cost to the OSN provider. In this paper, we aim to find a seed set to optimize a new profit metric that combines the benefit of influence spread with the cost of influence propagation for the OSN provider. Under many diffusion models, our profit metric is the difference between two submodular functions which is challenging to optimize as it is neither submodular nor monotone. We design a general two-phase framework to select seeds for profit maximization and develop several bounds to measure the quality of the seed set constructed. Experimental results with real OSN datasets show that our approach can achieve high approximation guarantees and significantly outperform the baseline algorithms, including state-of-the-art influence maximization algorithms.},
keywords={advertising data processing;information dissemination;profitability;social networking (online);OSN provider;advertiser;product information;viral marketing campaigns;influence maximization algorithms;profit maximization;online social network providers;influence propagation;information dissemination;Measurement;Social network services;Diffusion processes;Conferences;Electronic mail;Approximation algorithms;Integrated circuit modeling},
doi={10.1109/INFOCOM.2018.8485975},
ISSN={},
month={April},}
@INPROCEEDINGS{8486358,
author={E. Aryafar and A. Keshavarz-Haddad},
booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},
title={PAFD: Phased Array Full-Duplex},
year={2018},
volume={},
number={},
pages={261-269},
abstract={We present the design and implementation of PAFD, a design methodology that enables full-duplex (FD) in hybrid beamforming systems with constant amplitude phased array antennas. The key novelty in PAFD's design is construction of analog beamformers that maximize the beamforming gains in the desired directions while simultaneously reducing the self-interference (SI). PAFD is implemented on the WARP platform, and its performance is extensively evaluated in both indoor and outdoor environments. Our experimental results reveal that (i) PAFD sacrifices a few dB in beamfomring gain to provide large amounts of reduction in SI power; (ii) the reduction in SI is dependent on the number of phased array antennas and increases as the number of antennas increases; and (iii) finally, PAFD significantly outperforms half-duplex (HD) for small cells even in presence of high interference caused by uplink clients to the downlink clients. The gains increase with a larger array size or less multipath in the propagation environment.},
keywords={antenna phased arrays;array signal processing;cellular radio;indoor radio;interference suppression;multiplexing;radiofrequency interference;phased array full-duplex;analog beamformers;beamforming gains;SI power;phased array antennas;half-duplex;PAFD design;hybrid beamforming systems;self-interference;WARP platform;Phased arrays;Array signal processing;Gain;Radio frequency;Phase shifters},
doi={10.1109/INFOCOM.2018.8486358},
ISSN={},
month={April},}

