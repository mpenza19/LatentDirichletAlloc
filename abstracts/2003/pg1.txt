@INPROCEEDINGS{1209181,
author={A. B. MacKenzie and S. B. Wicker},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Stability of multipacket slotted Aloha with selfish users and perfect information},
year={2003},
volume={3},
number={},
pages={1583-1590 vol.3},
abstract={Aloha is perhaps the simplest and most-studied medium access control protocol in existence. Only in the recent past, however, have researchers begun to study the performance of Aloha in the presence of selfish users. In this paper, we present a game-theoretic model of multipacket slotted Aloha with perfect information. We show that this model must have an equilibrium and we characterize this equilibrium. Using the tools of stochastic processes, we then establish the equilibrium stability region for some well-known channel models.},
keywords={authorisation;protocols;game theory;medium access control;game-theoretic model;multipacket slotted Aloha;stochastic process;stability region;channel model;Stability;Access protocols;Game theory;Microeconomics;Communication system control;Media Access Protocol;Centralized control;Stochastic processes;Communication networks;Cellular networks},
doi={10.1109/INFCOM.2003.1209181},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209182,
author={Samrat Ganguly and Badri Nath and Navin Goyal},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal bandwidth reservation schedule in cellular networks},
year={2003},
volume={3},
number={},
pages={1591-1602 vol.3},
abstract={Efficient bandwidth allocation strategy with simultaneous fulfillment of QoS requirement of a user in a mobile cellular network is still a critical and an important practical issue. We explore the problem of finding the reservation schedule that would minimize the amount of time for which bandwidth has to be allocated in a cell while meeting the QoS constraint. With the knowledge about the arrival and residence time distribution of a user in a cell, the above problem can be optimally solved using a dynamic programming based approach in polynomial time. To be able to use the solution, we provide a mechanism for constructing the arrival/residence time distribution based on the measurement of hand-off events in a cell. The above solution allows us to propose an optimal time based bandwidth reservation and call admission scheme. By being scalable and distributed, the proposed scheme justifies for practical implementation. Simulations results are also presented to show the effectiveness of the scheme to achieve the target QoS level and optimal bandwidth utilization.},
keywords={cellular radio;telecommunication congestion control;scheduling;minimisation;bandwidth allocation;quality of service;dynamic programming;QoS requirement;mobile cellular network;QoS constraint;dynamic programming;bandwidth reservation;optimal bandwidth utilization;optimization;Bandwidth;Intelligent networks;Land mobile radio cellular systems;Quality of service;Resource management;Processor scheduling;Computer science;Channel allocation;Mobile computing;Dynamic programming},
doi={10.1109/INFCOM.2003.1209182},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209183,
author={Dongxu Shen and Zhengang Pan and Kai-Kit Wong and V. O. K. Li},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Effective throughput: a unified benchmark for pilot-aided OFDM/SDMA wireless communication systems},
year={2003},
volume={3},
number={},
pages={1603-1613 vol.3},
abstract={In this paper, we study the uplink performance of an orthogonal frequency division multiplexing (OFDM) wireless system where multiple antennas are utilized at the base station (BS). Further, capacity can be greatly enhanced through spatial division multiple access (SDMA), so that several users can transmit packets simultaneously to the BS. The system performance is determined by various transmission techniques, including methods for channel estimation, modulation, as well as channel coding. Conventional parameters such as packet error rate (PER) and bit error rate (BER) are unable to reflect the actual system performance because no consideration is given to the overheads incurred by the transmission techniques. Therefore, we are motivated to propose a novel concept called effective throughput to characterize the capacity available to users by incorporating all these factors. The effective throughput for a user can be viewed as the average number of successfully received data bits in an OFDM symbol after excluding erroneously received packets and the overheads due to channel estimation and coding. It also directly relates to the transmission delay of a user packet. The system effective throughput is the aggregated effective throughput of all users. Simulation results demonstrate that effective throughput can serve as a useful and more meaningful benchmark parameter in optimizing system performance.},
keywords={OFDM modulation;packet radio networks;mobile radio;antenna arrays;space division multiple access;channel estimation;modulation;channel coding;orthogonal frequency division multiplexing;OFDM;wireless system;multiple antenna;base station;spatial division multiple access;SDMA;system performance;channel estimation;modulation;channel coding;packet error rate;PER;bit error rate;BER;effective throughput;transmission delay;simulation;antenna array;Throughput;Multiaccess communication;Wireless communication;System performance;Channel estimation;Bit error rate;Base stations;Modulation coding;OFDM modulation;Channel coding},
doi={10.1109/INFCOM.2003.1209183},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209184,
author={M. Akar and U. Mitra},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Joint power and handoff control using a hybrid systems framework},
year={2003},
volume={3},
number={},
pages={1614-1621 vol.3},
abstract={Power control and handoff are two significant problems for cellular wireless systems. While both problems have received considerable attention of late, the problems are not often treated in a joint manner. Combined downlink power control and handoff design for cellular communication systems using a hybrid system framework is considered herein. Two new algorithms are proposed. The first one is a hard handoff/power control algorithm that endeavors a tradeoff between three performance criteria: transmitted power, number of handoffs and call quality. The second algorithm is a joint soft handoff/power control algorithm that takes into account the effect of the number of base stations in the active set in addition to the above performance criteria. The significance of the algorithms is that they incorporate the effects of channel fading and mobility, and achieve a tradeoff between the satisfaction levels of the mobile user and the network operator, thereby provide satisfactory service for the user while reducing the burden on the network such as undesired switching between base stations. The tradeoffs involved in both algorithms are verified through simulations.},
keywords={power control;telecommunication control;cellular radio;power control;cellular wireless system;cellular communication system;hybrid system framework;transmitted power;call quality;channel fading;mobility;mobile user;network operator;undesired switching;Control systems;Base stations;Power control;Fading;Bismuth;Equations;Algorithm design and analysis;Design optimization;Minimization methods;Interchannel interference},
doi={10.1109/INFCOM.2003.1209184},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209185,
author={Cheng-Shang Chang and Duan-Shin Lee and Chi-Yao Yue},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Providing guaranteed rate services in the load balanced Birkhoff-von Neumann switches},
year={2003},
volume={3},
number={},
pages={1622-1632 vol.3},
abstract={In this paper, we propose two schemes for the load balanced Birkhoff-von Neumann switches to provide guaranteed rate services. As in [C. S. Chang et al., (2002)], the first scheme is based on an earliest deadline first (EDF) scheduling policy. In such a scheme, we assign every packet of a guaranteed rate flow a targeted departure time that is the departure time from the corresponding work conserving link with capacity equal to the guaranteed rate. By adding a jitter control mechanism in front of the buffer at the second stage and running the EDF policy at the output buffer, we show that the end-to-end delay for every packet of a guaranteed rate flow is bounded by the sum of its targeted departure time and a constant that only depends on the number of flows and the size of the switch. Our second scheme is a frame based scheme as in [I. Keslassy et al., (2002)]. There, time slots are grouped into fix size frames. Packets are placed in appropriate bins (buffers) according to their arrival times and their flows. We show that if the incoming traffic satisfies certain assumptions, then the end-to-end delay for every packet and the size of the central buffers are both bounded by constants that only depend on the size of the switches and the frame size. The second scheme is much simpler than the first one in many aspects: (i) the online complexity is O(1) as there is no need for EDF, (ii) central buffers are finite and thus can be built into a single chip, (iii) connection patterns of the two switch fabrics are changed less frequently, (iv) there is no need for resequencing-and-output buffer after the second stage, and (v) variable length packets may be handled without segmentation and reassembly.},
keywords={buffer storage;scheduling;delays;packet switching;multistage interconnection networks;Birkhoff-von Neumann switch;earliest deadline first;EDF;targeted departure time;frame based scheme;online complexity;central buffer;finite single chip;connection pattern;resequencing output buffer;multicasting flow;variable length packet;multistage switch;Packet switching;Optical switches;Delay;Communication switching;Optical buffering;Optical packet switching;Round robin;Bandwidth;Jitter;Size control},
doi={10.1109/INFCOM.2003.1209185},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209186,
author={Prashanth Pappu and Jyoti Parwatikar and J. Turner and K. Wong},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Distributed queueing in scalable high performance routers},
year={2003},
volume={3},
number={},
pages={1633-1642 vol.3},
abstract={This paper presents and evaluates distributed queueing algorithms for regulating the flow of traffic through large, high performance routers. Distributed queueing has a similar objective to crossbar-scheduling mechanisms used in routers with relatively small port counts, and shares some common high level characteristics. However, the need to minimize communication overhead rules out the iterative methods that are typically used for crossbar scheduling, while the ability to sub-divide the available bandwidth among different ports provides a degree of freedom that is absent in the crossbar scheduling context, where inputs must be matched to outputs. Our algorithms are based on four ideas (1) backlog-proportional-allocation of output bandwidth, (2) urgency-proportional-allocation of input bandwidth, (3) dynamic reallocation of bandwidth and (4) deferred underflow. Our algorithms guarantee congestion-free operation of the switch fabric. Our performance results show that for uniform random traffic, even a very modest speedup is sufficient to reduce the loss of output link bandwidth due to sub-optimal rate allocation to negligible levels, and that even under extreme conditions, a speedup of two is sufficient to eliminate such bandwidth loss.},
keywords={queueing theory;distributed algorithms;telecommunication network routing;bandwidth allocation;packet switching;distributed queueing algorithm;high performance router;crossbar-scheduling;communication overhead rule;bandwidth;backlog-proportional-allocation;dynamic reallocation;fabric switch;switching system;scalable router;Switches;Traffic control;Bandwidth;Fabrics;Packet switching;Telecommunication traffic;Iterative algorithms;Processor scheduling;Computer science;Iterative methods},
doi={10.1109/INFCOM.2003.1209186},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209187,
author={M. Yang and S. Q. Zheng},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={An efficient scheduling algorithm for CIOQ switches with space-division multiplexing expansion},
year={2003},
volume={3},
number={},
pages={1643-1650 vol.3},
abstract={Recently, CIOQ switches have attracted interest from both academic and industrial communities due to their ability of achieving 100% throughput and perfectly emulating OQ switch performance with a small speedup factor S. To achieve a speedup factor S, a conventional CIOQ switch requires the switch matrix and the memory to operate S times faster than the line rate. In this paper, we propose to use a CIOQ switch with space-division multiplexing expansion and grouped inputs/outputs (SDMG CIOQ switch for short) to achieve speedup while only requiring the switch matrix and the memory to operate at the line rate. The cell scheduling problem for the SDMG CIOQ switch is abstracted as a maximum bipartite k-matching problem. Using fluid model, we prove that any maximal size k-matching algorithm on an SDMG CIOQ switch with an expansion factor 2 can achieve 100% throughput assuming input arrivals satisfy the strong law of large numbers and no inputs/outputs are oversubscribed. We further propose an efficient and starvation-free maximal size k-matching scheduling algorithm, kFRR, for the SDMG CIOQ switch. Simulation results show that kFRR achieves 100% throughput with an expansion factor 2 under two SLLN traffic models, uniform traffic and polarized traffic, confirming our analysis.},
keywords={queueing theory;scheduling;space division multiplexing;OQ switch;speedup factor;switch matrix;space-division multiplexing expansion;bipartite matching problem;fluid model;kFRR SDMG CIOQ switch;traffic model;polarized traffic;Scheduling algorithm;Switches;Throughput;Job shop scheduling;Traffic control;Packet switching;Impedance matching;Iterative algorithms;Computer science;Computer industry},
doi={10.1109/INFCOM.2003.1209187},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209188,
author={Y. Ganjali and A. Keshavarzian and Devavrat Shah},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Input queued switches: cell switching vs. packet switching},
year={2003},
volume={3},
number={},
pages={1651-1658 vol.3},
abstract={Input Queued (IQ) switches have been very well studied in the recent past. The main problem in the IQ switches concerns scheduling. The main focus of the research has been the fixed length packet-known as cells-case. The scheduling decision becomes relatively easier for cells compared to the variable length packet case as scheduling needs to be done at a regular interval of fixed cell time. In real traffic dividing the variable packets into cells at the input side of the switch and then reassembling these cells into packets on the output side achieve it. The disadvantages of this cell-based approach are the following: (a) bandwidth is lost as division of a packet may generate incomplete cells, and (b) additional overhead of segmentation and reassembling cells into packets. This motivates the packet scheduling: scheduling is done in units of arriving packet sizes and in nonpreemptive fashion. In M.A. Marsan et al. (2001) the problem of packet scheduling was first considered. They show that under any admissible Bernoulli i.i.d. arrival traffic a simple modification of maximum weight matching (MWM) algorithm is stable, similar to cell-based MWM. In this paper, we study the stability properties of packet based scheduling algorithm for general admissible arrival traffic pattern. We first show that the result of Marsan et al. extends to general regenerative traffic model instead of just admissible traffic, that is, packet based MWM is stable. Next we show that there exists an admissible traffic pattern under which any work-conserving (that is maximal type) scheduling algorithm will be unstable. This suggests that the packet based MWM will be unstable too. To overcome this difficulty we propose a new class of "waiting" algorithms. We show that "waiting"-MWM algorithm is stable for any admissible traffic using fluid limit technique.},
keywords={queueing theory;packet switching;scheduling;Input Queued switch;IQ switch;fixed length packet;variable length packet;reassembling cell;bandwidth packet;packet scheduling algorithm;Bernoulli i.i.d. arrival traffic;maximum weight matching;traffic pattern;waiting-MWM algorithm;fluid limit technique;Packet switching;Switches;Scheduling algorithm;Traffic control;Bandwidth;Throughput;Delay;Stability;Algorithm design and analysis;Switching systems},
doi={10.1109/INFCOM.2003.1209188},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209189,
author={Sudeept Bhatnagar and Badri Nath},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Distributed admission control to support guaranteed services in core-stateless networks},
year={2003},
volume={3},
number={},
pages={1659-1669 vol.3},
abstract={The core-stateless service architecture alleviates the scalability problems of the integrated service framework while maintaining its guaranteed service semantics. The admission control methods proposed to support core-stateless guaranteed services have significant drawbacks: We propose a scalable and robust distributed admission control architecture to support core-stateless guaranteed services. Our architecture maintains high network utilization while ensuring that resources are not over-allocated. In our architecture, admission control is performed at the ingress edge routers of a request on an edge-to-edge path basis. A token-passing mechanism is used as the resource management framework. The token helps in dynamic and fair division of bandwidth and allows completely distributed resource allocation on a link unless it is close to saturation. The edge routers co-operate to provide fault tolerance effectively acting as a resilient overlay network. Our admission control framework can support statistical guarantees and diffserv architecture's premium service as well. The resource management part of our architecture is well-suited to aid QoS routing algorithms. Analytical and simulation results are presented to show the effectiveness of our architecture.},
keywords={distributed control;protocols;quality of service;network routing;fault tolerance;resource allocation;Internet;distributed admission control architecture;core-stateless network;core-stateless guaranteed service architecture;integrated service framework;network utilization;token-passing mechanism;resource management framework;dynamic bandwidth division;distributed resource allocation;ingress edge router;edge-to-edge path basis;fault tolerance;overlay network;diffserv architecture;QoS routing algorithm;Internet;Admission control;Resource management;Scalability;Intserv networks;Robust control;Bandwidth;Fault tolerance;Diffserv networks;Routing;Analytical models},
doi={10.1109/INFCOM.2003.1209189},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209190,
author={D. H. Lorenz and A. Orda and D. Raz},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal partition of QoS requirements for many-to-many connections},
year={2003},
volume={3},
number={},
pages={1670-1679 vol.3},
abstract={The problems related to supporting multicast connections with quality of service (QoS) requirements are studied. We investigate the problem of optimal resource allocation in the context of performance dependent costs. In this context each network element can offer several QoS guarantees, each associated with a different cost. This is a natural extension to the commonly used bi-criteria model, where each link is associated with a single delay and a single cost. This framework is simple yet strong enough to model many practical interesting networking problems. The fundamental multicast resource allocation problem under this framework is how to optimally allocate QoS requirements on the links of the multicast tree. One needs to partition the end-to-end QoS requirement along the various paths in a tree. The goal is to satisfy the end-to-end QoS requirement with minimum cost. Previous studies under this framework considered single-source multicast connections, where the end-to-end QoS requirement is specified from the source to all other multicast group members. In this paper we extend these results to the more general, and considerably harder case of multicast sessions, where the end-to-end requirement hold for every path between any two multicast group members. Our aim is to provide rigorous solutions, with proven performance guarantees, by way of algorithmic analysis. The problem under investigation is NP hard for general cost functions, thus we first present a pseudopolynomial exact solution. From this solution we derive two efficient /spl epsi/-approximate solutions. One achieves optimal cost, but may violate the end-to-end delay requirement by a factor of (1 + /spl epsi/), and the other strictly obeys the bounds and achieves a cost within a factor of (1+/spl epsi/) of the optimum. Furthermore, we present improved results for discrete cost functions, and give a simple linear-time exact polynomial solution for a specific, and practically interesting, family of convex cost functions.},
keywords={quality of service;multicast communication;resource allocation;optimisation;polynomials;QoS requirements optimal partition;end-to-end quality of service requirement;QoS guarantees;many-to-many connection;multicast optimal resource allocation;performance dependent cost;network element;bi-criteria model;multicast tree link;multicast connection;multicast session;NP hard problem;pseudopolynomial exact solution;/spl epsi/-approximate solution;optimal cost;discrete cost function;linear-time exact polynomial solution;convex cost function family;Quality of service;Delay;Cost function;Resource management;Call conference;Distributed computing;Computer science;Multicast algorithms;Performance analysis;Algorithm design and analysis},
doi={10.1109/INFCOM.2003.1209190},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209191,
author={J. Liebeherr and S. D. Patek and A. Burchard},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Statistical per-flow service bounds in a network with aggregate provisioning},
year={2003},
volume={3},
number={},
pages={1680-1690 vol.3},
abstract={Scalability concerns of QoS implementations have stipulated service architectures where QoS is not provisioned separately to each flow, but instead to aggregates of flows. This paper determines stochastic bounds for the service experienced by a single flow when resources are managed for aggregates of flows and when the scheduling algorithms used in the network are not known. Using a recently developed statistical network calculus, per-flow bounds can be calculated for backlog, delay, and the burstiness of output traffic.},
keywords={telecommunication traffic;statistical analysis;quality of service;stochastic processes;calculus of communicating systems;per-flow service stochastic bound;flow aggregate provisioning network;QoS implementation;quality of service;statistical network calculus;scheduling algorithm;admission control;statistical flow multiplexing;network traffic backlog;network traffic delay;network traffic burstiness;Intelligent networks;Aggregates;Scheduling algorithm;Telecommunication traffic;Switches;Scalability;Calculus;Communication system traffic control;Fluid flow measurement;Computer science},
doi={10.1109/INFCOM.2003.1209191},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209192,
author={A. Kuzmanovic and E. W. Knightly},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={TCP-LP: a distributed algorithm for low priority data transfer},
year={2003},
volume={3},
number={},
pages={1691-1701 vol.3},
abstract={Service prioritization among different traffic classes is an important goal for the future Internet. Conventional approaches to solving this problem consider the existing best-effort class as the low-priority class, and attempt to develop mechanisms that provide "better-than-best-effort" service. In this paper, we explore the opposite approach, and devise a new distributed algorithm to realize a low-priority service (as compared to the existing best effort) from the network endpoints. To this end, we develop TCP Low Priority (TCP-LP), a distributed algorithm whose goal is to utilize only the excess network bandwidth as compared to the "fair share" of bandwidth as targeted by TCP. The key mechanisms unique to TCP-LP congestion control are the use of one-way packet delays for congestion indications and a TCP-transparent congestion avoidance policy. Our simulation results show that: (1) TCP-LP is largely non-intrusive to TCP traffic; (2) both single and aggregate TCP-LP flows are able to successfully utilize excess network bandwidth; moreover, multiple TCP-LP flows share excess bandwidth fairly; (3) substantial amounts of excess bandwidth are available to low-priority class, even in the presence of "greedy" TCP flows; (4) the response times of web connections in the best-effort class decrease by up to 90% when long-lived bulk data transfers use TCP-LP rather than TCP.},
keywords={transport protocols;distributed algorithms;Internet;telecommunication congestion control;data communication;telecommunication traffic;TCP-LP flow;distributed algorithm;low priority data transfer;excess network bandwidth utilization;TCP-LP congestion control;one-way packet delay;congestion indication;TCP-transparent congestion avoidance policy;Internet;network traffic;Web connection;Distributed algorithms;Bandwidth;Communication system traffic control;IP networks;Protocols;Peer to peer computing;Delay estimation;Web and internet services;Traffic control;Aggregates},
doi={10.1109/INFCOM.2003.1209192},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209193,
author={N. Li and J. C. Hou and L. Sha},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Design and analysis of an MST-based topology control algorithm},
year={2003},
volume={3},
number={},
pages={1702-1712 vol.3},
abstract={In this paper, we present a minimum spanning tree (MST) based topology control algorithm, called local minimum spanning tree (LMST), for wireless multi-hop networks. In this algorithm, each node builds its local minimum spanning tree independently and only keeps on-tree nodes that are one-hop away as its neighbors in the final topology. We analytically prove several important properties of LMST: (1) the topology derived under LMST preserves the network connectivity; (2) the node degree of any node in the resulting topology is bounded by 6; and (3) the topology can be transformed into one with bidirectional links (without impairing the network connectivity) after removal of all uni-directional links. These results are corroborated in the simulation study.},
keywords={radio networks;telecommunication control;network topology;telecommunication network management;minimum spanning tree;MST based topology control algorithm;local minimum spanning tree;LMST;wireless multihop network;on-tree node;network connectivity;node degree;bi-directional link;topology management;Algorithm design and analysis;Network topology;Spread spectrum communication;Bidirectional control;Interference;Wireless networks;Power control;Communication system control;Computer science;Energy management},
doi={10.1109/INFCOM.2003.1209193},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209194,
author={Seema Bandyopadhyay and E. J. Coyle},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={An energy efficient hierarchical clustering algorithm for wireless sensor networks},
year={2003},
volume={3},
number={},
pages={1713-1723 vol.3},
abstract={A wireless network consisting of a large number of small sensors with low-power transceivers can be an effective tool for gathering data in a variety of environments. The data collected by each sensor is communicated through the network to a single processing center that uses all reported data to determine characteristics of the environment or detect an event. The communication or message passing process must be designed to conserve the limited energy resources of the sensors. Clustering sensors into groups, so that sensors communicate information only to clusterheads and then the clusterheads communicate the aggregated information to the processing center, may save energy. In this paper, we propose a distributed, randomized clustering algorithm to organize the sensors in a wireless sensor network into clusters. We then extend this algorithm to generate a hierarchy of clusterheads and observe that the energy savings increase with the number of levels in the hierarchy. Results in stochastic geometry are used to derive solutions for the values of parameters of our algorithm that minimize the total energy spent in the network when all sensors report data through the clusterheads to the processing center.},
keywords={distributed algorithms;wireless sensor networks;randomised algorithms;transceivers;message passing;stochastic processes;computational geometry;energy efficient hierarchical clustering algorithm;wireless sensor network;low-power transceiver;environment characteristics determination;event detection;message passing process;sensor energy resource;distributed algorithm;randomized algorithm;stochastic geometry;information processing center;Voronoi tessellations;Energy efficiency;Clustering algorithms;Wireless sensor networks;Sensor phenomena and characterization;Transceivers;Event detection;Message passing;Process design;Energy resources;Stochastic processes},
doi={10.1109/INFCOM.2003.1209194},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209195,
author={O. Dousse and F. Baccelli and P. Thiran},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Impact of interferences on connectivity in ad hoc networks},
year={2003},
volume={3},
number={},
pages={1724-1733 vol.3},
abstract={The impact of interferences on the connectivity of large-scale ad-hoc networks is studied using percolation theory. We assume that a bi-directional connection can be set up between two nodes if the signal to noise ratio at the receiver is larger than some threshold. The noise is the sum of the contribution of interferences from all other nodes, weighted by a coefficient /spl gamma/, and of a background noise. We find that there is a critical value of /spl gamma/ above which the network is made of disconnected clusters of nodes. We also prove that if /spl gamma/ is nonzero but small enough, there exist node spatial densities for which the network contains a large (theoretically infinite) cluster of nodes, enabling distant nodes to communicate in multiple hops. Since small values of /spl gamma/ cannot be achieved without efficient CDMA codes, we investigate the use of a very simple TDMA scheme, where nodes can emit only every n-th time slot. We show qualitatively that it even achieves a better connectivity than the previous system with a parameter /spl gamma//n.},
keywords={ad hoc networks;percolation;time division multiple access;radio receivers;radiofrequency interference;interference impact;large-scale ad hoc network connectivity;percolation theory;bi-directional connection;receiver signal to noise ratio;node cluster;node spatial density;multiple hop node communication;TDMA;Interference;Intelligent networks;Ad hoc networks;Multiaccess communication;Context modeling;Attenuation;Computer networks;Background noise;Power system modeling;Large-scale systems},
doi={10.1109/INFCOM.2003.1209195},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209196,
author={D. Niculescu and Badri Nath},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Ad hoc positioning system (APS) using AOA},
year={2003},
volume={3},
number={},
pages={1734-1743 vol.3},
abstract={Position information of individual nodes is useful in implementing functions such as routing and querying in ad-hoc networks. Deriving position information by using the capability of the nodes to measure time of arrival (TOA), time difference of arrival (TDOA), angle of arrival (AOA) and signal strength have been used to localize nodes relative to a frame of reference. The nodes in an ad-hoc network can have multiple capabilities and exploiting one or more of the capabilities can improve the quality of positioning. In this paper, we show how AOA capability of the nodes can be used to derive position information. We propose a method for all nodes to determine their orientation and position in an ad-hoc network where only a fraction of the nodes have positioning capabilities, under the assumption that each node has the AOA capability.},
keywords={ad hoc networks;direction-of-arrival estimation;telecommunication network routing;ad hoc positioning system;APS;angle of arrival;AOA;ad-hoc network;node position information;time of arrival;TOA;time difference of arrival;TDOA;signal strength;positioning quality;node orientation;digital compass;Ad hoc networks;Routing;Global Positioning System;Position measurement;Time measurement;Time difference of arrival;Humans;Meteorology;Cost function;Protocols},
doi={10.1109/INFCOM.2003.1209196},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209197,
author={Z. Fu and P. Zerfos and H. Luo and S. Lu and L. Zhang and M. Gerla},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={The impact of multihop wireless channel on TCP throughput and loss},
year={2003},
volume={3},
number={},
pages={1744-1753 vol.3},
abstract={This paper studies TCP performance over multihop wireless networks that use the IEEE 802.11 protocol as the access method. Our analysis and simulations show that, given a specific network topology and flow patterns, there exists a TCP window size W*, at which TCP achieves best throughput via improved spatial channel reuse. However, TCP does not operate around W*, and typically grows its average window size much larger; this leads to decreased throughput and increased packet loss. The TCP throughput reduction can be explained by its loss behavior. Our results show that network overload is mainly signified by wireless link contention in multihop wireless networks. As long as the buffer size at each node is reasonably large (say, larger than 10 packets), buffer overflow-induced packet loss is rare and packet drops due to link-layer contention dominate. Link-layer drops offer the first sign for network overload. We further show that multihop wireless links collectively exhibit graceful drop behavior: as the offered load increases, the link contention drop probability also increases, but saturates eventually. In general, the link drop probability is insufficient to stabilize the average TCP window size around W*. Consequently, TCP suffers from reduced throughput due to reduced spatial reuse. We further propose two techniques, link RED and adaptive pacing, through which we are able to improve TCP throughput by 5% to 30% in various simulated topologies. Some simulation results are also validated by real hardware experiments.},
keywords={network topology;packet radio networks;radio links;transport protocols;access protocols;multihop wireless channel;TCP loss;IEEE 802.11 protocol;network access method;network topology;network overload;flow patterns;TCP window size;TCP throughput reduction;buffer overflow-induced packet loss;link contention drop probability;link RED;adaptive pacing;hardware experiments;Throughput;Spread spectrum communication;Wireless networks;Buffer overflow;Analytical models;Network topology;Computer science;Performance loss;Wireless application protocol;Access protocols},
doi={10.1109/INFCOM.2003.1209197},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209198,
author={Rajiv Chakravorty and Sachin Katti and Crowcroft J and Pratt I},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Flow aggregation for enhanced TCP over wide-area wireless},
year={2003},
volume={3},
number={},
pages={1754-1764 vol.3},
abstract={Throughout the world, GSM cellular mobile networks are being upgraded to support the "always-on" General Packet Radio Service (GPRS). Despite the apparent availability of levels of bandwidth not dissimilar to that provided by conventional fixed-wire telephone modems, the user experience using GPRS is currently considerably worse. In this paper we examine the performance of TCP and HTTP over GPRS, and show how certain network characteristics interact badly with TCP to yield problems such as: link under-utilization for short-lived flows, excess queueing for long-lived flows, ACK compression, poor loss recovery, and gross unfairness between competing flows. We present the design and implementation of a transparent TCP proxy that mitigates many of these problems without requiring any changes to the TCP implementations in either mobile or fixed-wire end systems. The proxy transparently splits TCP connections into two halves, the wired and wireless sides. Connections destined for the same mobile host are treated as an aggregate due to their statistical dependence. We demonstrate packet scheduling and flow control algorithms that use information shared between the connections to maximise performance of the wireless link while inter-working with unmodified TCP peers. We also demonstrate how fairness between flows and response to loss is improved, and that queueing and hence network latency is reduced. We conclude that installing such a proxy into GPRS network would be of significant benefit to users.},
keywords={packet radio networks;cellular radio;transport protocols;enhanced TCP performance;GSM cellular mobile networks;general packet radio service network;HTTP performance;network characteristics;link under-utilization;ACK compression;mobile wire end systems;wide-area wireless;flow aggregation;fixed-wire end systems;packet scheduling;flow control algorithms;wireless link performance;Ground penetrating radar;Scheduling algorithm;GSM;Cellular networks;Packet radio networks;Availability;Bandwidth;Telephony;Modems;Performance loss},
doi={10.1109/INFCOM.2003.1209198},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209199,
author={L. Galluccio and G. Morabito and S. Palazzo},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={An analytical study of a tradeoff between transmission power and FEC for TCP optimization in wireless networks},
year={2003},
volume={3},
number={},
pages={1765-1773 vol.3},
abstract={It is well known that TCP has performance problems when wireless links are involved in the end-to-end connection. This is due to the high bit error rate characterizing wireless links. Appropriate power management and error correction can improve the link reliability observed by TCP and increase the throughput performance accordingly. In the literature, the effects of transmission power and error correction capability on TCP performance have been considered separately, so far. We study the tradeoff between power management and error correction. To this end, an analytical framework to maximize a user satisfaction function, defined as the ratio between the TCP throughput and a cost function, is introduced. The proposed analytical framework does not depend on the specific wireless system and does not rely on any TCP throughput approximation formula. The benefits of joint power management and error control are demonstrated in several relevant case studies.},
keywords={forward error correction;optimisation;power control;telecommunication control;transport protocols;radio links;transmission power;FEC;TCP optimization;wireless networks;TCP performance problems;wireless links;bit error rate;power management;satisfaction function;cost function;TCP throughput approximation formula;error control;forward error correction;Intelligent networks;Wireless networks;Forward error correction;Energy management;Error correction;Throughput;Power system management;Cost function;Redundancy;Bit error rate},
doi={10.1109/INFCOM.2003.1209199},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209200,
author={R. Hsieh and Z. G. Zhou and A. Seneviratne},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={S-MIP: a seamless handoff architecture for mobile IP},
year={2003},
volume={3},
number={},
pages={1774-1784 vol.3},
abstract={As the number of Mobile IP (MIP) [C. Perkins, (1996)] users grow, so will the demand for delay sensitive real-time applications, such as audio streaming, that require seamless handoff, namely, a packet lossless Quality-of-Service guarantee during a handoff. Two well-known approaches in reducing the MIP handoff latency have been proposed in the literature. One aims to reduce the (home) network registration time through a hierarchical management structure, while the other tries to minimize the lengthy address resolution delay by address pre-configuration through what is known as the fast-handoff mechanism. We present a novel seamless handoff architecture, S-MIP, that builds on top of the hierarchical approach [H. Soliman et al. (2002)] and the fast-handoff mechanism [G. Dommety et al. (2002)], in conjunction with a newly developed handoff algorithm based on pure software-based movement tracking techniques [Z.-G. Zhou et al. (2002)]. Using a combination of simulation and mathematical analysis, we argue that our architecture is capable of providing packet lossless handoff with latency similar to that of L2 handoff delay when using the 802.11 access technology. More importantly, S-MIP has a signaling overhead equal to that of the well-known 'integrated' hierarchical MIP with fast-handoff scheme [H. Soliman et al. (2002)], within the portion of the network that uses wireless links. In relation to our S-MIP architecture, we discuss issues regarding the construction of network architecture, movement tracking, registration, address resolution, handoff algorithm and data handling.},
keywords={data handling;radio tracking;performance evaluation;IP networks;quality of service;IEEE standards;time management;mobile radio;seamless handoff architecture;delay sensitive real-time applications;audio streaming;packet lossless quality-of-service guarantee;network registration time;hierarchical management structure;address resolution delay;fast-handoff mechanism;handoff algorithm;software-based movement tracking techniques;mathematical analysis;handoff delay;802.11 access technology;signaling overhead;integrated hierarchical mobile IP;wireless links;data handling;Home automation;Delay effects;Tracking;Australia;Streaming media;Quality of service;Added delay;Analytical models;Mathematical analysis;Signal resolution},
doi={10.1109/INFCOM.2003.1209200},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209201,
author={L. -. Chen and E. Modiano},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Efficient routing and wavelength assignment for reconfigurable WDM networks with wavelength converters},
year={2003},
volume={3},
number={},
pages={1785-1794 vol.3},
abstract={We consider the problem of wavelength assignment in a reconfigurable bidirectional ring network with wavelength converters. We show that for N-node P-port bidirectional rings, a minimum number of /spl lceil/PN/4/spl rceil/ wavelengths are required to support all possible virtual topologies in a rearrangeably nonblocking fashion, and provide an algorithm that meets this bound for connected topologies using no more than /spl lceil/PN/2/spl rceil/ wavelength converters. This improves over the tight lower bound of /spl lfloor/PN/3/spl rfloor/ wavelengths required for such rings given in A. Narula-Tam et al. (2002)] if no wavelength conversion is available. We also provide another algorithm that uses more wavelengths yet requires significantly fewer converters. Both algorithms are then extended to the case of unconnected topologies using at most one additional wavelength. Finally, we develop a method that allows the wavelength converters to be arbitrarily located at any node in the ring. This gives significant flexibility in the design of the networks. For example, all /spl lceil/PN/2/spl rceil/ converters can be collocated at a single hub node, or distributed evenly among the N nodes with /spl lceil/P/2 /spl rceil/ converters at each node.},
keywords={optical wavelength conversion;wavelength division multiplexing;optical fibre networks;telecommunication network routing;network topology;routing assignment;wavelength assignment;reconfigurable WDM networks;wavelength converters;N-node P-port bidirectional rings;single hub node;graph theory;combinatorial mathematics;Wavelength routing;Wavelength assignment;WDM networks;Optical wavelength conversion;Traffic control;Network topology;Telecommunication traffic;Algorithm design and analysis;Probability;Wavelength converters},
doi={10.1109/INFCOM.2003.1209201},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209202,
author={Xiaowen Chu and Bo Li and Zhensheng Zhang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A dynamic RWA algorithm in a wavelength-routed all-optical network with wavelength converters},
year={2003},
volume={3},
number={},
pages={1795-1804 vol.3},
abstract={Existing research demonstrated that an effective routing and wavelength assignment (RWA) scheme and a wavelength converter placement algorithm are the two primary vehicles for improving the blocking performance in a wavelength-routed all-optical network. However, these issues have largely been investigated separately, in particular, the RWA has seldom considered the existence of wavelength converters. In this paper, we argue perhaps for the first time, that an effective RWA algorithm needs to take into account the presence of wavelength conversion as the latter is usually done at much earlier stage during the capacity planning. We proceed to show that existing dynamic RWA algorithms largely fail in the presence of wavelength conversion. We then propose a weighted least-congestion routing and first-fit wavelength assignment (WLCR-FF) RWA algorithm in conjunction with a simple heuristic wavelength converter placement algorithm called minimum blocking probability first (MBPF) that considers both the distribution of free wavelengths and the lengths of each route jointly. We further introduce an analytical model that can obtain the blocking performance of the proposed WLCR routing algorithm. Using both analysis and simulation, we carry out extensive numerical studies over the typical topologies including the ring, mesh-torus, and two mesh topologies, the 14-node NSFNET and the 19-node European Optical Network (EON); we compare the performance of proposed algorithm with a wide variety of existing routing algorithms including static routing, fixed-alternate routing and least-loaded routing algorithms. The results conclusively demonstrate that the proposed WLCR-FF algorithm can achieve much better blocking performance in the environment of sparse or/and full wavelength conversion.},
keywords={optical wavelength conversion;network topology;telecommunication network routing;optical fibre networks;dynamic routing and wavelength assignment scheme;RWA;wavelength-routed all-optical network;wavelength converter placement algorithm;blocking performance;capacity planning;weighted least-congestion routing and first-fit wavelength assignment;minimum blocking probability first algorithm;ring topology;mesh-torus topology;14-node NSFNET;19-node European optical network;static routing algorithms;fixed-alternate routing algorithms;least-loaded routing algorithms;Heuristic algorithms;All-optical networks;Optical wavelength conversion;Vehicle dynamics;Wavelength routing;Wavelength assignment;Analytical models;Network topology;Vehicles;Capacity planning},
doi={10.1109/INFCOM.2003.1209202},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209203,
author={P. Saengudomlert and E. H. Modiano and R. G. Gallager},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On-line routing and wavelength assignment for dynamic traffic in WDM ring and torus networks},
year={2003},
volume={3},
number={},
pages={1805-1815 vol.3},
abstract={We develop on-line routing and wavelength assignment (RWA) algorithms for WDM bidirectional ring and torus networks with N nodes. The algorithms dynamically support all k-allowable traffic matrices, where k denotes an arbitrary integer vector [k/sub 1/, k /sub 2/, ..., k/sub N/], and node i, 1/spl les/i/spl les/N, can transmit at most k/sub i/ wavelengths and receive at most k/sub i/ wavelengths. Both algorithms support the changing traffic in a rearrangeably nonblocking fashion. Our first algorithm, for a bidirectional ring, uses /spl lceil/(/spl Sigma//sub i=1//sup N/k/sub i/)/3/spl rceil/ wavelengths in each ring direction and requires at most three lightpath rearrangements per new session request regardless of the number of nodes N and the amount of traffic k. When all the k/sub i/s are equal to k, the algorithm uses /spl lceil/kN/3/spl rceil/ wavelengths, which is known to be the minimum for any off-line rearrangeably nonblocking algorithm. Our second algorithm, for a torus topology, is designed for the special case with all the k/sub i/s equal to k. For a square torus network with N nodes, the algorithm uses /spl lceil/k/spl radic/N/2/spl rceil/ wavelengths in each fiber, which is shown to be at most two times a lower bound obtained by assuming full wavelength conversion at all nodes. In addition, the algorithm requires at most /spl radic/N-1 lightpath rearrangements per new session request regardless of the amount of traffic k.},
keywords={wavelength division multiplexing;telecommunication network routing;telecommunication traffic;network topology;optical fibre networks;on-line routing assignment algorithm;wavelength assignment algorithm;bidirectional ring network dynamic traffic;k-allowable traffic matrices;arbitrary integer vector;lightpath rearrangements;off-line rearrangeably nonblocking algorithm;torus topology;square torus network;wavelength conversion;WDM networks;graph theory;Wavelength routing;Wavelength assignment;Telecommunication traffic;Intelligent networks;Wavelength division multiplexing;Optical wavelength conversion;WDM networks;Optical switches;Optical fiber networks;All-optical networks},
doi={10.1109/INFCOM.2003.1209203},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209204,
author={K. Lu and G. Xiao and I. Chlamtac},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Behavior of distributed wavelength provisioning in wavelength-routed networks with partial wavelength conversion},
year={2003},
volume={3},
number={},
pages={1816-1825 vol.3},
abstract={Distributed wavelength provisioning is becoming one of the most important technologies for supporting the next-generation wavelength-routed networks. In this paper we analyze the behavior of wavelength-routed networks with partial wavelength conversion capabilities (i.e., where wavelength conversion is available at only a subset of network nodes) when using distributed wavelength provisioning. Simulation results show that the proposed models are highly accurate for different network topologies under various traffic loads.},
keywords={wavelength division multiplexing;optical fibre networks;telecommunication network routing;optical wavelength conversion;distributed wavelength provisioning technologies;wavelength-routed networks;wavelength conversion;network nodes subset;network topologies;traffic loads;Intelligent networks;Optical wavelength conversion;WDM networks;Telecommunication traffic;Optical fiber networks;Bandwidth;Network topology;Wavelength division multiplexing;Costs;Robustness},
doi={10.1109/INFCOM.2003.1209204},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209205,
author={Z. -. Zhang and V. J. Ribeiro and S. Moon and C. Diot},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Small-time scaling behaviors of Internet backbone traffic: an empirical study},
year={2003},
volume={3},
number={},
pages={1826-1836 vol.3},
abstract={The small-time (sub-seconds) scaling behaviors of Internet backbone traffic, based on traces collected from OC3/12/48 links in a tier-1 ISP is studied. We observe that for a majority of these traces, the (second-order) scaling exponents at small time scales (1 ms - 100 ms) are fairly close to 0.5, indicating that traffic fluctuations at these time scales are (nearly) uncorrelated. In addition, the traces manifest mostly monofractal behaviors at small time scales. The objective of the paper is to understand the potential causes or factors that influence the small-time scalings of Internet backbone traffic via empirical data analysis. We analyze the traffic composition of the traces along two dimensions - flow size and flow density. Our study uncovers dense flows (i.e., flows with bursts of densely clustered packets) as the correlation-causing factor in small time scales, and reveals that the traffic composition in terms of proportions of dense vs. sparse flows plays a major role in influencing the small-time scalings of aggregate traffic.},
keywords={Internet;telecommunication traffic;small-time scaling behavior;Internet backbone traffic;OC3/12/48 links;tier-1 Internet service provider;empirical data analysis;traffic composition;flow classification;densely clustered packets;correlation-causing factor;sparse flows;Internet;Spine;Traffic control;Telecommunication traffic;Communication system traffic control;Fluctuations;Data analysis;Moon;Aggregates;IP networks},
doi={10.1109/INFCOM.2003.1209205},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209206,
author={N. X. Liu and J. S. Baras},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Statistical modeling and performance analysis of multi-scale traffic},
year={2003},
volume={3},
number={},
pages={1837-1847 vol.3},
abstract={In this paper we propose a new statistical model for multiscale traffic, and present an exact queueing analysis for the model. The model is based on the central moments and the marginal distributions of the cumulative traffic loads in different time scales. Only the first two moments are needed to characterize the traffic process, which greatly simplifies the representation and estimation. The queueing analysis uses a very general approach and can evaluate not only the steady state performance but also the transient queueing behavior. The analysis reveals that there exist two classes of packet losses, the absolute loss and the opportunistic loss, both of which can be examined exactly with the method. Based on the statistical model and the queueing analysis method, a compound model is constructed for the practical multiscale traffic, and its performance is evaluated from various aspects. This work provides a good basis for practical application of the multiscale traffic characterizations in network dimensioning and resource management.},
keywords={log normal distribution;telecommunication traffic;queueing theory;statistical analysis;statistical model;multiscale traffic;queueing analysis;transient behavior;log-normal distribution;central moments;marginal distributions;cumulative traffic load;steady state performance;packet losses;absolute loss;opportunistic loss;network performance evaluation;resource management;Performance analysis;Traffic control;Telecommunication traffic;Queueing analysis;Communication system traffic control;Fractals;Steady-state;Transient analysis;Resource management;Log-normal distribution},
doi={10.1109/INFCOM.2003.1209206},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209207,
author={M. Crovella and E. Kolaczyk},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Graph wavelets for spatial traffic analysis},
year={2003},
volume={3},
number={},
pages={1848-1857 vol.3},
abstract={A number of problems in network operations and engineering call for new methods of traffic analysis. While most existing traffic analysis methods are fundamentally temporal, there is a clear need for the analysis of traffic across multiple network links - that is, for spatial traffic analysis. In this paper we give examples of problems that can be addressed via spatial traffic analysis. We then propose a formal approach to spatial traffic analysis based on the wavelet transform. Our approach (graph wavelets) generalizes the traditional wavelet transform so that it can be applied to data elements connected via an arbitrary graph topology. We explore the necessary and desirable properties of this approach and consider some of its possible realizations. We then apply graph wavelets to measurements from an operating network. Our results show that graph wavelets are very useful for our motivating problems; for example, they can be used to form highly summarized views of an entire network's traffic load, to gain insight into a network's global traffic response to a link failure, and to localize the extent of a failure event within the network.},
keywords={graph theory;wavelet transforms;telecommunication traffic;telecommunication links;spatial traffic analysis;multiple network links;graph wavelets;wavelet transform;arbitrary graph topology;operating network;network traffic load;global traffic response;link failure;Wavelet analysis;Telecommunication traffic;Pattern analysis;Discrete wavelet transforms;Wavelet transforms;Network topology;Wavelet domain;Computer science;Statistical analysis;Capacity planning},
doi={10.1109/INFCOM.2003.1209207},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209208,
author={G. He and J. C. Hou},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On exploiting long range dependence of network traffic in measuring cross traffic on an end-to-end basis},
year={2003},
volume={3},
number={},
pages={1858-1868 vol.3},
abstract={In this paper we present three theoretically grounded methods: prediction, reconstruction and interpolation, for measuring cross traffic on the bottleneck link of an end-to-end path. The objective is to infer cross traffic as accurately as possible, while not injecting a significant amount of probe packets into the network. In the prediction-based method, we take advantage of the LRD characteristic of the cross traffic to predict the future traffic based on the recent information obtained by probe packets. In the reconstruction method, we rebuild the entire cross traffic process with the information obtained by probe packets. In the interpolation method, we periodically send closely-spaced probe packet pairs to sample cross traffic of the bottleneck link, and infer cross traffic between two sampling points using interpolation. The simulation study indicates that (i) the prediction-based and reconstruction methods can give good mean measurement of cross traffic, while the interpolation method usually captures the instantaneous value of cross traffic better; and (ii) all three methods are adaptive to the dynamic change of cross traffic and are quite robust in the presence of multiple bottleneck links on an end-to-end path.},
keywords={interpolation;mean square error methods;telecommunication traffic;Internet;telecommunication links;packet switching;cross traffic measurement;end-to-end basis;probe packets;prediction-based method;reconstruction method;interpolation method;closely-spaced probe packet pair;multiple bottleneck links;Internet;Telecommunication traffic;Intelligent networks;Traffic control;Probes;Time measurement;Interpolation;Reconstruction algorithms;Fractals;Helium;Computer science},
doi={10.1109/INFCOM.2003.1209208},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209209,
author={M. Garetto and W. Gong and D. Towsley},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Modeling malware spreading dynamics},
year={2003},
volume={3},
number={},
pages={1869-1879 vol.3},
abstract={In this paper we present analytical techniques that can be used to better understand the behavior of malware, a generic term that refers to all kinds of malicious software programs propagating on the Internet, such as e-mail viruses and worms. We develop a modeling methodology based on Interactive Markov Chains that is able to capture many aspects of the problem, especially the impact of the underlying topology on the spreading characteristics of malware. We propose numerical methods to obtain useful bounds and approximations in the case of very large systems, validating our results through simulation. An analytic methodology represents a fundamentally important step in the development of effective countermeasures for future malware activity. Furthermore, we believe our approach can help to understand a wide range of "dynamic interactions on networks", such as routing protocols and peer-to-peer applications.},
keywords={computer viruses;Internet;Markov processes;network topology;numerical analysis;malware behavior;malicious software program;Internet;e-mail viruses;e-mail worms;Interactive Markov Chains;numerical method;routing protocol;network dynamic interaction;peer-to-peer application;simulation;Internet;Electronic mail;Computer viruses;Computer worms;Topology;Viruses (medical);Computer science;Routing protocols;Peer to peer computing;Application software},
doi={10.1109/INFCOM.2003.1209209},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209210,
author={Murali Kodialam and T. V. Lakshman},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Detecting network intrusions via sampling: a game theoretic approach},
year={2003},
volume={3},
number={},
pages={1880-1889 vol.3},
abstract={In this paper, we consider the problem of detecting an intruding packet in a communication network. Detection is accomplished by sampling a portion of the packets transiting selected network links (or router interfaces). Since sampling entails incurring network costs for real-time packet sampling and packet examination hardware, we would like to develop a network packet sampling strategy to effectively detect network intrusions while not exceeding a given total sampling budget. We consider this problem in a game theoretic framework, where the intruder picks paths (or the network ingress point if only shortest path routing is possible) to minimize chances of detection and where the network operator chooses a sampling strategy to maximize the chances of detection. We formulate the game theoretic problem, and develop sampling schemes that are optimal in this game theoretic setting.},
keywords={telecommunication security;packet switching;telecommunication links;sampling methods;game theory;telecommunication network routing;communication network;router interfaces;network link;real-time packet sampling;packet examination hardware;network intrusion detection;shortest path routing;game theoretic problem;Intrusion detection;Sampling methods;Game theory;Communication networks;Routing;Drugs;Costs;Telecommunication traffic;Hardware;Computer crime},
doi={10.1109/INFCOM.2003.1209210},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209211,
author={Z. Chen and L. Gao and K. Kwiat},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Modeling the spread of active worms},
year={2003},
volume={3},
number={},
pages={1890-1900 vol.3},
abstract={Active worms spread in an automated fashion and can flood the Internet in a very short time. Modeling the spread of active worms can help us understand how active worms spread, and how we can monitor and defend against the propagation of worms effectively. In this paper, we present a mathematical model, referred to as the Analytical Active Worm Propagation (AAWP) model, which characterizes the propagation of worms that employ random scanning. We compare our model with the Epidemiological model and Weaver's simulator. Our results show that our model can characterize the spread of worms effectively. Taking the Code Red v2 worm as an example, we give a quantitative analysis for monitoring, detecting and defending against worms. Furthermore, we extend our AAWP model to understand the spread of worms that employ local subnet scanning. To the best of our knowledge, there is no model for the spread of a worm that employs the localized scanning strategy and we believe that this is the first attempt on understanding local subnet scanning quantitatively.},
keywords={Internet;invasive software;Internet;mathematical model;analytical active worm propagation model;epidemiological model;Weaver simulator;Code Red v2 worm;local subnet scan;Computer worms;Military computing;Internet;Biological system modeling;Mathematical model;Viruses (medical);Floods;Costs;Computerized monitoring;Biological information theory},
doi={10.1109/INFCOM.2003.1209211},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209212,
author={D. Moore and C. Shannon and G. M. Voelker and S. Savage},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Internet quarantine: requirements for containing self-propagating code},
year={2003},
volume={3},
number={},
pages={1901-1910 vol.3},
abstract={It has been clear since 1988 that self-propagating code can quickly spread across a network by exploiting homogeneous security vulnerabilities. However, the last few years have seen a dramatic increase in the frequency and virulence of such "worm" outbreaks. For example, the Code-Red worm epidemics of 2001 infected hundreds of thousands of Internet hosts in a very short period - incurring enormous operational expense to track down, contain, and repair each infected machine. In response to this threat, there is considerable effort focused on developing technical means for detecting and containing worm infections before they can cause such damage. This paper does not propose a particular technology to address this problem, but instead focuses on a more basic question: How well will any such approach contain a worm epidemic on the Internet? We describe the design space of worm containment systems using three key parameters - reaction time, containment strategy and deployment scenario. Using a combination of analytic modeling and simulation, we describe how each of these design factors impacts the dynamics of a worm epidemic and, conversely, the minimum engineering requirements necessary to contain the spread of a given worm. While our analysis cannot provide definitive guidance for engineering defenses against all future threats, we demonstrate the lower bounds that any such system must exceed to be useful today. Unfortunately, our results suggest that there are significant technological and administrative gaps to be bridged before an effective defense can be provided in today's Internet.},
keywords={Internet;computer viruses;telecommunication security;self-propagating code;homogeneous security vulnerabilities;Code-Red worm epidemic;Internet hosts;reaction time;containment strategy;deployment scenario;analytic modeling;simulation;design factors;definitive guidance;wide spread containment mechanisms;Internet;Computer worms;Space technology;Pathogens;Security;Software systems;Frequency;Analytical models;Design engineering;Web server},
doi={10.1109/INFCOM.2003.1209212},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209213,
author={F. Baccelli and D. Hong},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Flow level simulation of large IP networks},
year={2003},
volume={3},
number={},
pages={1911-1921 vol.3},
abstract={The aim of this paper is to simulate the interaction of a large number of TCP controlled flows and UDP flows sharing many routers/links, from the knowledge of the network parameters (capacity, buffer size, topology, scheduling) and of the characteristics of each TCP (RTT, route etc.) and UDP flow. This work is based on the description via some fluid evolution equations, of the joint evolution of the window sizes of all flows over a single bottleneck router/link, as function of the synchronization rate. It is shown that the generalization of this fluid dynamics to a network composed of several routers can be described via equations allowing one to simulate the interaction of e.g. millions of TCP flows on networks composed of tens of thousands of links and routers on a standard workstation. The main output of the simulator are the mean value and the fluctuations of the throughput obtained by each flow, the localization of the bottleneck routers/links, the losses on each of them and the time evolution of aggregated input traffic at each router or link. The method is validated against NS simulations. We show that several important statistical properties of TCP traffic which were identified on traces are also present on traffic generated by our simulator: for instance, aggregated traffic generated by this representation exhibits the same short time scale statistical properties as those observed on real traces. Similarly, the experimental laws describing the fairness of the bandwidth sharing operated by TCP over a large network are also observed on the simulations.},
keywords={IP networks;transport protocols;synchronisation;network topology;telecommunication network routing;flow level simulation;IP networks;TCP characteristics;UDP flows;fluid evolution equations;joint evolution;flow window size;bottleneck router;bottleneck link;synchronization rate;network parameters;fluid dynamics;standard workstation;flow throughput mean value;throughput fluctuations;router loss;aggregated input traffic time evolution;NS simulations;TCP bandwidth;network topology;IP networks;Traffic control;TCPIP;Equations;Telecommunication traffic;Fluid flow control;Size control;Network topology;Fluid dynamics;Workstations},
doi={10.1109/INFCOM.2003.1209213},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209214,
author={Y. Shavitt and T. Tankel},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Big-Bang simulation for embedding network distances in Euclidean space},
year={2003},
volume={3},
number={},
pages={1922-1932 vol.3},
abstract={Embedding of a graph metric in Euclidean space efficiently and accurately is an important problem in general with applications in topology aggregation, closest mirror selection, and application level routing. We propose a new graph embedding scheme called Big-Bang simulation (BBS), which simulates an explosion of particles under force field derived from embedding error. BBS is shown to be significantly more accurate, compared to all other embedding methods including GNP. We report an extensive simulation study of BBS compared with several known embedding scheme and show its advantage for distance estimation (as in the IDMaps project), mirror selection and topology aggregation.},
keywords={simulation;network topology;telecommunication network routing;Big-Bang simulation;BBS;network embedding;Euclidean space;graph metric;topology aggregation;closest mirror selection;application level routing;error embedding;GNP;distance estimation;Intelligent networks;Mirrors;Routing;Extraterrestrial measurements;Network topology;Euclidean distance;Explosions;Economic indicators;Network servers;Joining processes},
doi={10.1109/INFCOM.2003.1209214},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209215,
author={P. Zheng and L. M. Ni},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={EMPOWER: a network emulator for wireline and wireless networks},
year={2003},
volume={3},
number={},
pages={1933-1942 vol.3},
abstract={The increasing need of protocol development environments and network performance evaluation tools gives rise to the research of flexible, scalable, and accurate network emulators. The desired network emulator should be able to facilitate the emulation of either wireline or wireless networks. In the case when network topology is critical to the underlying network protocol, the emulator should provide specific mechanisms to emulate network topology. In this paper, we present a distributed network emulation system EMPOWER, which not only can fulfill those requirements, but also can generate user-defined network conditions and traffic dynamics at packet level. EMPOWER is highly scalable in that each emulator node could be configured to emulate multiple network nodes. Some significant research issues such as topology mapping scheme and scalability of the emulator are discussed and addressed. Preliminary emulation results show that EMPOWER is capable of assisting the study of both wireless and wireline network protocols and applications.},
keywords={protocols;network topology;telecommunication traffic;packet radio networks;mobile radio;EMPOWER;network emulator;wireline networks;wireless networks;protocol;network performance evaluation tools;distributed network emulation system;network topology;user-defined network conditions;traffic dynamics;network nodes;topology mapping scheme;emulator scalability;Wireless networks;Emulation;Network topology;Wireless application protocol;Computer science;Telecommunication traffic;Testing;Communication system traffic control;Traffic control;Bit error rate},
doi={10.1109/INFCOM.2003.1209215},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209216,
author={R. Pan and Balaji Prabhakar and K. Psounis and D. Wischik},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={SHRiNK: A method for scaleable performance prediction and efficient network simulation},
year={2003},
volume={3},
number={},
pages={1943-1953 vol.3},
abstract={In networks and in Web server farms, it is useful to collect performance measurements, to monitor the state of the system, and to perform simulations. However, the sheer volume of traffic in large high-speed network systems makes it hard to monitor their performance or to simulate them efficiently. And the heterogeneity of the Internet means it is time-consuming and difficult to devise the traffic models and analytic tools which would allow us to work with summary statistics. We explore a method to side-step these problems by combining sampling, modeling and simulation. Our hypothesis is this: if we take a sample of the input traffic, and feed it into a suitably scaled version of the system, we can extrapolate from the performance of the scaled system to that of the original. Our main findings are: When we scale an IP network which is shared by TCP-like, UDP and Web flows; and which is controlled by a variety of active queue management schemes, then performance measures such as queueing delay and drop probability are left virtually unchanged. We show this in theory and in simulations. This makes it possible to capture the performance of large networks quite faithfully using smaller scale replicas.},
keywords={telecommunication traffic;network topology;Internet;queueing theory;IP networks;transport protocols;SHRiNK;scaleable performance prediction;network simulation;Web server farms;system state;traffic sheer volume;high-speed network systems;Internet heterogeneity;input traffic;IP network;TCP;UDP;Web flows;active queue management schemes;queueing delay;drop probability;Predictive models;Traffic control;Monitoring;Telecommunication traffic;Web server;Measurement;Performance evaluation;High-speed networks;Internet;Statistical analysis},
doi={10.1109/INFCOM.2003.1209216},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209217,
author={M. Grossglauser and M. Vetterli},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Locating nodes with EASE: last encounter routing in ad hoc networks through mobility diffusion},
year={2003},
volume={3},
number={},
pages={1954-1964 vol.3},
abstract={Routing in large-scale mobile ad hoc networks is challenging because all the nodes are potentially moving. Geographic routing can partially alleviate this problem, as nodes can make local routing decisions based solely on the destinations' geographic coordinates. However, geographic routing still requires an efficient location service, i.e., a distributed database recording the location of every destination node. Devising efficient, scalable, and robust location services has received considerable attention in recent years. The main purpose of this paper is to show that node mobility can be exploited to disseminate destination location information without incurring any communication overhead. We achieve this by letting each node maintain a local database of the time and location of its last encounter with every other node in the network. This database is consulted by packets to obtain estimates of their destination's current location. As a packet travels towards its destination, it is able to successively refine an estimate of the destination's precise location, because node mobility has "diffused" estimates of that location. We define and analyze a very simple algorithm called EASE (exponential age search) and show that in a model where N nodes perform independent random walks on a square lattice, the length of the routes computed by EASE are on the same order as the distance between the source and destination even for very large N. Therefore, without exchanging any explicit location information, the length of EASE routes are within a constant factor of routes obtained with perfect information. We discuss refinements of the EASE algorithm and evaluate it through extensive simulations. We discuss general conditions such that the mobility diffusion effect leads to efficient routes without an explicit location service. In practical settings, where these conditions may not always be met, we believe that the mobility diffusion effect can complement existing location services and enhance their robustness and scalability.},
keywords={telecommunication network routing;ad hoc networks;distributed databases;telecommunication computing;mobile radio;EASE;exponential age search;geographic routing;last encounter routing;node mobility;packet;Exponential Age Search;ad hoc networks;mobility diffusion;routing decisions;distributed database;destination location information;Routing;Ad hoc networks;Robustness;Large-scale systems;Mobile ad hoc networks;Distributed databases;Information analysis;Performance analysis;Algorithm design and analysis;Lattices},
doi={10.1109/INFCOM.2003.1209217},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209218,
author={U. C. Kozat and L. Tassiulas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Network layer support for service discovery in mobile ad hoc networks},
year={2003},
volume={3},
number={},
pages={1965-1975 vol.3},
abstract={Service discovery is an integral part of the ad hoc networking to achieve stand-alone and self-configurable communication networks. In this paper, we discuss possible service discovery architectures along with the required network support for their implementation, and we propose a distributed service discovery architecture which relies on a virtual backbone for locating and registering available services within a dynamic network topology. Our proposal consists of two independent components: (i) formation of a virtual backbone and (ii) distribution of service registrations, requests, and replies. The first component creates a mesh structure from a subset of a given network graph that includes the nodes acting as service brokers and a subset of paths (which we refer as virtual links) connecting them. Service broker nodes (SBNs) constitute a dominating set, i.e. all the nodes in the network are either in this set or only one-hop away from at least one member of the set. The second component establishes subtrees rooted at service requesting nodes and registering servers for efficient dissemination of the service discovery probing messages. Extensive simulation results are provided for comparison of performance measures. i.e. latency, success rate, and control message overhead, when different architectures and network support mechanisms are utilized in service discovery.},
keywords={ad hoc networks;telecommunication services;mobile radio;protocols;network topology;network layer support;service discovery protocol;mobile ad hoc networks;virtual backbone;network topology;SBN;service broker nodes;service requesting nodes;servers registering;Intelligent networks;Mobile ad hoc networks;Protocols;Communication networks;Network servers;Computer architecture;Spine;Proposals;Educational institutions;Network topology},
doi={10.1109/INFCOM.2003.1209218},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209219,
author={Y. -. Hu and A. Perrig and D. B. Johnson},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Packet leashes: a defense against wormhole attacks in wireless networks},
year={2003},
volume={3},
number={},
pages={1976-1986 vol.3},
abstract={As mobile ad hoc network applications are deployed, security emerges as a central requirement. In this paper, we introduce the wormhole attack, a severe attack in ad hoc networks that is particularly challenging to defend against. The wormhole attack is possible even if the attacker has not compromised any hosts, and even if all communication provides authenticity and confidentiality. In the wormhole attack, an attacker records packets (or bits) at one location in the network, tunnels them (possibly selectively) to another location, and retransmits them there into the network. The wormhole attack can form a serious threat in wireless networks, especially against many ad hoc network routing protocols and location-based wireless security systems. For example, most existing ad hoc network routing protocols, without some mechanism to defend against the wormhole attack, would be unable to find routes longer than one or two hops, severely disrupting communication. We present a new, general mechanism, called packet leashes, for detecting and thus defending against wormhole attacks, and we present a specific protocol, called TIK, that implements leashes.},
keywords={ad hoc networks;telecommunication security;routing protocols;mobile radio;packet leashes;wormhole attacks;wireless networks;mobile ad hoc network;routing protocols;location-based wireless security systems;TIK protocol;Intelligent networks;Wireless networks;Ad hoc networks;Mobile ad hoc networks;Routing protocols;Communication system security;Mobile communication;NASA;Military communication;Business communication},
doi={10.1109/INFCOM.2003.1209219},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209220,
author={S. Zhong and J. Chen and Y. R. Yang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Sprite: a simple, cheat-proof, credit-based system for mobile ad-hoc networks},
year={2003},
volume={3},
number={},
pages={1987-1997 vol.3},
abstract={Mobile ad hoc networking has been an active research area for several years. How to stimulate cooperation among selfish mobile nodes, however, is not well addressed yet. In this paper, we propose Sprite, a simple, cheat-proof, credit-based system for stimulating cooperation among selfish nodes in mobile ad hoc networks. Our system provides incentive for mobile nodes to cooperate and report actions honestly. Compared with previous approaches, our system does not require any tamper-proof hardware at any node. Furthermore, we present a formal model of our system and prove its properties. Evaluations of a prototype implementation show that the overhead of our system is small. Simulations and analysis show that mobile nodes can cooperate and forward each other's messages, unless the resource of each node is extremely low.},
keywords={ad hoc networks;mobile radio;Sprite;cheat-proof credit-based system;mobile ad-hoc networks;mobile nodes;prototype;Sprites (computer);Ad hoc networks;Mobile ad hoc networks;Mobile computing;Computer science;Military computing;Spread spectrum communication;Protocols;Fault diagnosis;Costs},
doi={10.1109/INFCOM.2003.1209220},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209221,
author={Cheng-Shang Chang and Duan-Shin Lee and Chao-Kai Tu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Using switched delay lines for exact emulation of FIFO multiplexers with variable length bursts},
year={2003},
volume={3},
number={},
pages={1998-2007 vol.3},
abstract={It has been studied extensively in the literature how one achieves exact emulation of First In First Out (FIFO) multiplexers for fixed size cells (or packets) using optical crossbar switches and fiber delay lines (SDL). In this paper, we take a step further and propose a new architecture that achieves exact emulation of FIFO multiplexers for variable length bursts. Our architecture consists of two blocks: a cell scheduling block and an FIFO multiplexer for fixed size cells. Both blocks are made of SDL units. The objective of the cell scheduling block is to schedule cells in a burst to the right input at the right time so that cells in the same burst depart contiguously from the multiplexer for fixed size cells. We show that cell scheduling can be done efficiently by keeping track of a single state variable, called the total virtual waiting time in this paper. Moreover, the delay through the cell scheduling block is bounded above by a constant that only depends on the number of inputs and the maximum number of cells in a burst. Such a delay bound provides a limit on the number of fiber delay lines needed in the cell scheduling block.},
keywords={delays;optical delay lines;multiplexing equipment;packet switching;optical fibre networks;scheduling;First In First Out multiplexers;FIFO multiplexers emulation;variable length bursts;cell scheduling block;fixed size cells;switched delay lines;optical multiplexers;multistage switches;conflict resolution;cell contiguity;total virtual waiting time;delay bound;optical crossbar switches;fiber delay lines;Delay lines;Emulation;Multiplexing;Optical buffering;Optical switches;Optical packet switching;Optical fibers;High speed optical techniques;Communication switching;Chaotic communication},
doi={10.1109/INFCOM.2003.1209221},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209222,
author={Z. Rosberg and Hai Le Vu and M. Zukerman and J. White},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Blocking probabilities of optical burst switching networks based on reduced load fixed point approximations},
year={2003},
volume={3},
number={},
pages={2008-2018 vol.3},
abstract={This paper provides a framework for analysis and performance evaluation of Optical Burst Switching (OBS) networks. In particular, a new reduced load fixed point approximation model to evaluate blocking probabilities in OBS networks is introduced. The model is versatile enough to cover known OBS reservation policies such as Just-Enough-Time (JET), Just-In-Time (JIT), Burst Segmentation and Route-dependent Priorities. The accuracy of the model is confirmed by simulation and the various policies are compared.},
keywords={packet switching;optical fibre networks;optical burst switching network performance evaluation;reduced load fixed point approximation model;blocking probabilities;optical burst switching reservation policies;just-enough-time policy;just-in-time policy;JIT policy;burst segmentation priority;route-dependent priority;optical burst switching network analysis;Optical burst switching;Optical packet switching;Optical wavelength conversion;Payloads;Optical switches;Packet switching;Communication switching;Optical buffering;Bandwidth;Wavelength division multiplexing},
doi={10.1109/INFCOM.2003.1209222},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209223,
author={L. Xu and H. G. Perros and G. N. Rouskas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A queueing network model of an edge optical burst switching node},
year={2003},
volume={3},
number={},
pages={2019-2029 vol.3},
abstract={We consider an edge optical burst switching (OBS) node with or without converters, and with no buffering. The OBS node serves a number of users, each connected to the switch over a fiber link that supports multiple wavelengths. Each wavelength is associated with a 3-state Markovian burst arrival process. The arrival process permits short and long bursts to be modeled. We model the edge OBS node as a closed nonproduct-form queueing network, with multiple heterogeneous classes, and we develop a suite of approximate decomposition algorithms to analyze it. Our approximate algorithms have a good accuracy, and they provide insight into the effect of various system parameters on the performance of the edge OBS node.},
keywords={network analysis;packet switching;queueing theory;optical switches;switching networks;Markov processes;wavelength division multiplexing;edge optical burst switching node;converters;fiber link;multiple wavelengths;3-state Markovian burst arrival process;short burst;long burst;closed nonproduct-form queueing network;multiple heterogeneous classes;approximate decomposition algorithms;queueing network system parameters;queueing network model;Optical burst switching;Switches;Queueing analysis;Wavelength routing;Optical packet switching;Packet switching;Analytical models;Computer science;Switching converters;Optical buffering},
doi={10.1109/INFCOM.2003.1209223},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209224,
author={Jeyashanker Ramamirtham and J. Turner},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Time sliced optical burst switching},
year={2003},
volume={3},
number={},
pages={2030-2038 vol.3},
abstract={Time Sliced Optical Burst Switching is a proposed variant of optical burst switching, in which switching is done in the time domain, rather than the wavelength domain. This eliminates the need for wavelength converters, the largest single cost component of systems that switch in the wavelength domain. We examine some of the key design issues for routers that implement time sliced optical packet switching. In particular, we focus on the design of the Optical Time Slot Interchangers (OTSIs) needed to effect the required time domain switching. We introduce a novel nonblocking OTSI design and also show how blocking OTSIs can be used to implement the required switching operations. We study the performance of systems using blocking OTSIs and demonstrate that near ideal statistical multiplexing performance can be achieved using even quite inexpensive, blocking OTSI designs. These results suggest that optical technology may one day be able to provide a cost-effective alternative to electronics in packet switching systems.},
keywords={packet switching;telecommunication network routing;optical fibre networks;time sliced optical burst switching;router design;time sliced optical packet switching;time domain switching;nonblocking optical time slot interchangers design;blocking optical time slot interchangers;switching operations;ideal statistical multiplexing performance;Optical burst switching;Optical buffering;Optical packet switching;Optical wavelength conversion;Optical fiber networks;Optical switches;Costs;Wavelength division multiplexing;Burst switching;Optical design},
doi={10.1109/INFCOM.2003.1209224},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209225,
author={T. Alpcan and T. Basar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A utility-based congestion control scheme for Internet-style networks with delay},
year={2003},
volume={3},
number={},
pages={2039-2048 vol.3},
abstract={In this paper, we develop, analyze and implement a congestion control scheme obtained in a noncooperative game framework where each user's cost function is composed of a pricing function, proportional to the queueing delay experienced by the user, and a fairly general utility function which captures the user demand for bandwidth. Using a network model based on fluid approximations and through a realistic modeling of queues, we establish the existence of a unique equilibrium as well as its global asymptotic stability for a general network topology. We also provide sufficient conditions for system stability when there is a bottleneck link shared by multiple users experiencing nonnegligible communication delays. Based on these theoretical foundations, we implement a window-based, end-to-end congestion control scheme, and simulate it in ns-2 network simulator on various network topologies with sizable propagation delays.},
keywords={network topology;telecommunication congestion control;Internet;delays;queueing theory;game theory;noncooperative game framework;user cost function;pricing function;queueing delay;general utility function;network model;fluid approximations;realistic queue modeling;global asymptotic stability;general network topology;network system stability;nonnegligible communication delays;window-based congestion control scheme;end-to-end congestion control scheme;ns-2 network simulator;sizable propagation delays;utility-based congestion control scheme;Internet-style networks;bottleneck link;control theory;mathematical optimization;IP networks;Delay;Network topology;Proportional control;Cost function;Pricing;Queueing analysis;Bandwidth;Asymptotic stability;Sufficient conditions},
doi={10.1109/INFCOM.2003.1209225},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209226,
author={J. Wang and L. Li and S. H. Low and J. C. Doyle},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Can shortest-path routing and TCP maximize utility},
year={2003},
volume={3},
number={},
pages={2049-2056 vol.3},
abstract={TCP-AQM protocol can be interpreted as distributed primal-dual algorithms over the Internet to maximize aggregate utility. In this paper, we study whether TCP-AQM together with shortest-path routing can maximize utility with appropriate choice of link cost, on a slower timescale, over both source rates and routes. We show that this is generally impossible because the addition of route maximization makes the problem NP-hard. We exhibit an inevitable tradeoff between routing instability and utility maximization. For the special case of ring network, we prove rigorously that shortest-path routing based purely on congestion prices is unstable. Adding a sufficiently large static component to link cost, stabilizes it, but the maximum utility achievable by shortest-path routing decreases with the weight on the static component. We present simulation results to illustrate that these conclusions generalize to general network topology, and that routing instability can reduce utility to less than that achievable by the necessarily stable static routing.},
keywords={network topology;Internet;telecommunication network routing;transport protocols;optimisation;telecommunication congestion control;TCP-AQM protocol;distributed primal-dual algorithms;Internet;aggregate utility maximization;shortest-path routing;network link cost;route maximization;ring network;congestion prices;static component;general network topology;stable static routing;TCP;source rates;routing instability;Routing;Costs;Aggregates;Internet;Multicast algorithms;Stability;Unicast;Protocols;Network topology;Traffic control},
doi={10.1109/INFCOM.2003.1209226},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209227,
author={L. Libman and A. Orda},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal sliding-window strategies in networks with long round-trip delays},
year={2003},
volume={3},
number={},
pages={2057-2067 vol.3},
abstract={A method commonly used for packet flow control over connections with long round-trip delays is "sliding windows". In general, for a given loss rate, a larger window size achieves a higher average throughput, but also a higher rate of spurious packet transmissions, rejected by the receiver merely for arriving out-of-order. We analyze the problem of optimal flow control quantitatively, for a connection that has a cost per unit time and a cost for every transmitted packet (these costs can have generic interpretations, not necessarily in terms of money). The optimal strategy is defined as one that minimizes the expected cost/throughput ratio, and is allowed to transmit several copies of a packet within a window. We derive bounds on the performance of the optimal strategy; in particular, we show that the optimal cost/throughput ratio increases merely logarithmically with the time price. We present a method for computing the optimal strategy, and demonstrate that a simple and efficient 'greedy' algorithm is sufficient to find a near-optimal solution.},
keywords={delays;optimisation;packet switching;telecommunication congestion control;optimal packet flow control;sliding windows;packet loss rate;window size;spurious packet transmissions;packet throughput ratio;optimal strategy bounds;efficient greedy algorithm;near-optimal solution;optimal sliding-window strategies;long round-trip delays;packet transmission cost;Intelligent networks;Throughput;Cost function;Propagation losses;Out of order;Optimal control;Propagation delay;Forward error correction;Protocols;Satellites},
doi={10.1109/INFCOM.2003.1209227},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209228,
author={M. Adler and J. -. Cai and J. K. Shapiro and D. Towsley},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Estimation of congestion price using probabilistic packet marking},
year={2003},
volume={3},
number={},
pages={2068-2078 vol.3},
abstract={One key component of recent pricing-based congestion control schemes is an algorithm for probabilistically setting the Explicit Congestion Notification bit at routers so that a receiver can estimate the sum of link congestion prices along a path. We consider two such algorithms - a well-known algorithm called Random Exponential Marking (REM) and a novel algorithm called Random Additive Marking (RAM). We show that if link prices are unbounded, a class of REM-like algorithms are the only ones possible. Unfortunately, REM computes a biased estimate of total price and requires setting a parameter for which no uniformly good choice exists in a network setting. However, we show that if prices can be bounded and therefore normalized, then there is an alternate class of feasible algorithms, of which RAM is representative and furthermore, only the REM-like and RAM-like classes are possible. For properly normalized link prices, RAM returns an optimal price estimate (in terms of mean squared error), outperforming REM even if the REM parameter is chosen optimally. RAM does not require setting a parameter like REM, but does require a router to know its position along the path taken by a packet. We present an implementation of RAM for the Internet that exploits the existing semantics of the time-to-live field in IP to provide the necessary path position information.},
keywords={telecommunication congestion control;estimation theory;packet switching;protocols;Internet;mean square error methods;telecommunication network routing;pricing-based congestion control schemes;explicit congestion notification bit;routers;link congestion prices;random exponential marking;random additive marking;normalized link prices;optimal price estimate;optimal random exponential marking parameter;Internet;random additive marking path position information;congestion price estimation;probabilistic packet marking;unbounded link prices;bounded link prices;biased total price estimate;IP;mean squared error;Read-write memory;Protocols;Computer networks;Computer science;Shape control;Internet;Lagrangian functions;Constraint optimization;Aggregates;Cost function},
doi={10.1109/INFCOM.2003.1209228},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209229,
author={K. Harfoush and A. Bestavros and J. Byers},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Measuring bottleneck bandwidth of targeted path segments},
year={2003},
volume={3},
number={},
pages={2079-2089 vol.3},
abstract={Accurate measurement of network bandwidth is crucial for network management applications as well as flexible Internet applications and protocols which actively manage and dynamically adapt to changing utilization of network resources. Extensive work has focused on two approaches to measuring bandwidth: measuring it hop-by-hop, and measuring it end-to-end along a path. Unfortunately, best-practice techniques for the former are inefficient, and techniques for the latter are only able to observe bottlenecks visible at end-to-end scope. In this paper, we develop end-to-end probing methods which can measure bottleneck bandwidth along arbitrary, targeted subpaths of a path in the network, including subpaths shared by a set of flows. We evaluate our technique through extensive ns simulations, then provide a comparative Internet performance evaluation against hop-by-hop techniques. We also describe a number of applications which we foresee as standing to benefit from solutions to this problem, ranging from network troubleshooting and capacity provisioning to optimizing the layout of application-level overlay networks to optimized replica placement.},
keywords={computer network management;Internet;protocols;performance evaluation;capacity management (computers);bottleneck network bandwidth measurement;targeted path segment;network management application;protocol;hop-by-hop measurement;end-to-end measurement;ns simulation;Internet performance evaluation;network troubleshooting;capacity provisioning;application-level overlay network;network resource utilization;network layout optimization;Bandwidth;Time measurement;Computer science;IP networks;Peer to peer computing;Network servers;Fluid flow measurement;Computer network management;Resource management;Application software},
doi={10.1109/INFCOM.2003.1209229},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209230,
author={R. S. Prasad and C. Dovrolis and B. A. Mah},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={The effect of layer-2 store-and-forward devices on per-hop capacity estimation},
year={2003},
volume={3},
number={},
pages={2090-2100 vol.3},
abstract={Tools such as pathchar, clink, and pchar attempt to measure the capacity of every layer-3 (L3) hop in a network path. These tools use the same underlying measurement methodology, which we refer to as Variable Packet Size (VPS) probing. The key assumption in VPS is that each L3 hop along a path increases the delay of a packet by a "serialization latency", which is the ratio of the packet size over that hop's capacity. Unfortunately, the capacity estimates of VPS tools are sometimes wrong. In this paper, we investigate the source of these errors, and show that the presence of layer-2 (L2) store-and-forward devices, such as Ethernet switches, have a detrimental effect on the accuracy of VPS tools. Specifically, each L2 store-and-forward device introduces an additional serialization latency in a packet's delay, which results in consistent underestimation of that L3 hop's capacity. We analyze this negative effect, deriving the measured capacity of an L3 hop as a function of the L2 link capacities at that hop. Experimental results in local, campus, and ISP networks verify the model, illustrating that L2 devices should be expected in networks of diverse type and size. Finally, we characterize some other sources of error in VPS tools, such as queueing delays, limited clock resolution, variation in ICMP generation delays, and error propagation along the measured path.},
keywords={local area networks;error analysis;packet switching;layer-2 store-and-forward device;per-hop capacity estimation;pathchar;clink;pchar;layer-3 hop;network path;variable packet size probing;packet delay;link capacity;Internet service provider;ISP network;queueing delay;clock resolution;ICMP generation delay;error propagation;serialization latency;Ethernet switch;Size measurement;Switches;Propagation delay;Time measurement;Ethernet networks;Clocks;Character generation;Jacobian matrices;Monitoring;US Department of Energy},
doi={10.1109/INFCOM.2003.1209230},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209231,
author={G. Liang and B. Yu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Pseudo likelihood estimation in network tomography},
year={2003},
volume={3},
number={},
pages={2101-2111 vol.3},
abstract={Network monitoring and diagnosis are key to improving network performance. The difficulties of performance monitoring lie in today's fast growing Internet, accompanied by increasingly heterogeneous and unregulated structures. Moreover, these tasks become even harder since one cannot rely on the collaboration of individual routers and servers to directly measure network traffic. Even though the aggregatory nature of possible network measurements gives rise to inverse problems, existing methods for solving inverse problems are usually computationally intractable or statistically inefficient. In this paper, a pseudo likelihood approach is proposed to solve a group of network tomography problems. The basic idea of pseudo likelihood is to form simple subproblems and construct a product of marginal likelihood of subproblems by the ignoring their dependences. As a result, it keeps a good balance between the computational complexity and the statistical efficiency of the parameter estimation. Some statistical properties of the pseudo likelihood estimator, such as consistency and asymptotic normality, are established. A pseudo expectation-maximization (EM) algorithm is developed to maximize the pseudo log-likelihood function. Two examples with simulated or real data are used to illustrate the pseudo likelihood proposal: (1) internal link delay distribution inference through multicast end-to-end measurements; (2) origin-destination matrix estimation through link traffic counts.},
keywords={tomography;monitoring;Internet;inverse problems;multicast communication;network topology;computational complexity;parameter estimation;telecommunication network routing;pseudo likelihood estimation;network tomography;network performance monitoring;network diagnosis;Internet;heterogeneous structure;unregulated structure;router;server;network traffic;inverse problem;subproblem marginal likelihood;computational complexity;statistical efficiency;parameter estimation;statistical property;asymptotic normality;pseudo expectation-maximization algorithm;EM algorithm;internal link delay distribution;multicast end-to-end measurement;origin-destination matrix estimation;network traffic count;multicast tree;pseudo log-likelihood function;Tomography;Monitoring;Inverse problems;Delay estimation;Internet;Collaboration;Network servers;Web server;Telecommunication traffic;Computer networks},
doi={10.1109/INFCOM.2003.1209231},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209232,
author={K. G. Anagnostakis and M. Greenwald and R. S. Ryger},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={cing: measuring network-internal delays using only existing infrastructure},
year={2003},
volume={3},
number={},
pages={2112-2121 vol.3},
abstract={Several techniques have been proposed for measuring network-internal delays. However, those that rely on router responses have questionable performance, and all proposed alternatives require either new functionality in routers or the existence of a measurement infrastructure. In this paper we revisit the feasibility of measuring network-internal delays using only existing infrastructure, focusing on the use of ICMP timestamp probes to routers. We present network measurements showing that ICMP timestamp is widely supported and that TTL-responses often perform poorly, and we analyze the effect of path instability and routing irregularities on the performance and applicability of using ICMP timestamp. We also confirm that router responses rarely introduce errors in our measurements. Finally, we present a practical algorithm for clock artifact removal that addresses problems with previous methods and has been found to perform well in our setting.},
keywords={telecommunication network routing;delay estimation;cing;network-internal delay measurement;ICMP timestamp probe;router response;TTL-response;path instability effect;routing irregularity effect;Delay estimation;Probes;Measurement techniques;Computational Intelligence Society;Performance evaluation;Performance analysis;Routing;Clocks;Throughput;Fluid flow measurement},
doi={10.1109/INFCOM.2003.1209232},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209233,
author={S. Weber and G. de Veciana},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Network design for rate adaptive media streams},
year={2003},
volume={3},
number={},
pages={2122-2132 vol.3},
abstract={Rate adaptive multimedia streams offer significant system and client benefits over nonadaptive streams. These benefits come at the price of increased complexity in providing adequate network support and difficulty in understanding how rate adaptation protocols affect client perceived QoS. In this paper we define quality of service in terms of the mean rate seen by the client. We identify an intuitive optimal adaptation policy that maximizes QoS. We suggest an appropriate scaling regime for rate adaptive streams and identify asymptotic QoS for large capacity networks under the optimal adaptation policy. Implementation of the optimal adaptation policy presents several obstacles that render it infeasible. We define a multiclass admission control policy that achieves asymptotically equivalent QoS to that achieved under the optimal adaptation policy, but without the need for dynamic adaptation. Our work carries implications for network designers and content providers.},
keywords={quality of service;multimedia communication;telecommunication congestion control;large capacity network design;rate adaptive multimedia stream;quality of service;asymptotic QoS;optimal adaptation policy;multiclass admission control policy;dynamic adaptation;nonadaptive stream;content provider;scaling regime;Streaming media;Quality of service;Video compression;Multimedia systems;Protocols;Bandwidth;Admission control;IP networks;Performance evaluation;Statistical analysis},
doi={10.1109/INFCOM.2003.1209233},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209234,
author={C. Law and K. -. Siu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Distributed construction of random expander networks},
year={2003},
volume={3},
number={},
pages={2133-2143 vol.3},
abstract={A novel distributed algorithm for constructing random overlay networks that are composed of d Hamilton cycles is presented. The protocol is completely decentralized as no globally-known server is required. The constructed topologies are expanders with O(log/sub d/ n) diameter with high probability. Our construction is highly scalable because both the processing and the space requirements at each node grow logarithmically with the network size. A new node can join the network in O(log/sub d/ n) time with O(d log/sub d/ n) messages. A node can leave in O(1) time with O(d) messages. The protocol is robust against an offline adversary selecting the sequence of the join and leave operations. We also discuss a layered construction of the random expander networks in which any node can be located in O(log n) time. The random expander networks have applications in community discovery, distributed lookup service, and dynamic connectivity.},
keywords={distributed algorithms;protocols;computer networks;network topology;distributed algorithm;random expander network layered construction;overlay network;Hamilton cycle;decentralized protocol;node space requirement;network size;community discovery;distributed lookup service;dynamic connectivity;globally-known server;Peer to peer computing;Protocols;Sampling methods;Distributed algorithms;Network servers;Graph theory;Network topology;Robustness;Construction industry;Eigenvalues and eigenfunctions},
doi={10.1109/INFCOM.2003.1209234},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209235,
author={S. -. Park and A. Khrabrov and D. M. Pennock and S. Lawrence and C. L. Giles and L. H. Ungar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Static and dynamic analysis of the Internet's susceptibility to faults and attacks},
year={2003},
volume={3},
number={},
pages={2144-2154 vol.3},
abstract={The susceptibility of the Internet to random faults, malicious attacks, and mixtures of faults and attacks are analyzed. We analyze actual Internet data, as well as simulated data created with network models. The network models generalize previous research, and allow generation of graphs ranging from uniform to preferential, and from static to dynamic. We introduce new metrics for analyzing the connectivity and performance of networks which improve upon metrics used in earlier research. Previous research has shown that preferential networks like the Internet are more robust to random failures compared to uniform networks. We find that preferential networks, including the Internet, are more robust only when more than 95% of failures are random faults, and robustness is measured with average diameter. The advantage of preferential networks disappears with alternative metrics, and when a small fraction of faults are attacks. We also identify dynamic characteristics of the Internet which can be used to create improved network models. This model should allow more accurate analysis for the future Internet, for example facilitating the design of network protocols with optimal performance in the future, or predicting future attack and fault tolerance. We find that the Internet is becoming more preferential as it evolves. The average diameter has been stable or even decreasing as the number of nodes has been increasing. The Internet is becoming more robust to random failures over time, but has also become more vulnerable to attacks.},
keywords={Internet;protocols;fault tolerance;telecommunication security;static analysis;dynamic analysis;Internet susceptibility;malicious attack;simulated data;network model;network performance analysis;network connectivity analysis;preferential network;uniform network;network protocol;random fault tolerance prediction;Internet;IP networks;Robustness;Degradation;Performance analysis;Fault tolerance;Computer science;Information science;Information analysis;Data analysis},
doi={10.1109/INFCOM.2003.1209235},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209236,
author={J. Kaur and H. M. Vin},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Core-stateless guaranteed throughput networks},
year={2003},
volume={3},
number={},
pages={2155-2165 vol.3},
abstract={End-to-end throughput guarantee is an important service semantics that network providers would like to offer to their customers. A network provider can offer such service semantics by deploying a network where each router employs a fair packet scheduling algorithm. Unfortunately, these scheduling algorithms require every router to maintain per-flow state and perform per-packet flow classification; these requirements limit the scalability of the routers. In this paper, we propose the Core-stateless Guaranteed Throughput (CSGT) network architecture-the first work-conserving architecture that, without maintaining per-flow state or performing per-packet flow classification in core routers, provides to flows throughput guarantees that are within an additive constant of what is attained by a network of core-stateful fair routers.},
keywords={telecommunication network routing;Internet;network topology;core-stateless guaranteed throughput network;Internet;network provider;network service semantic;core router;fair packet scheduling algorithm;per-packet flow classification;per-flow state maintaining;end-to-end throughput;Throughput;Scheduling algorithm;Scalability;Clocks;Computer science;Computer networks;Service oriented architecture;Commercialization;IP networks;Web and internet services},
doi={10.1109/INFCOM.2003.1209236},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209237,
author={K. Sripanidkulchai and B. Maggs and H. Zhang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Efficient content location using interest-based locality in peer-to-peer systems},
year={2003},
volume={3},
number={},
pages={2166-2176 vol.3},
abstract={Locating content in decentralized peer-to-peer systems is a challenging problem. Gnutella, a popular file-sharing application, relies on flooding queries to all peers. Although flooding is simple and robust, it is not scalable. We explore how to retain the simplicity of Gnutella, while addressing its inherent weakness: scalability. We propose a content location solution in which peers loosely organize themselves into an interest-based structure on top of the existing Gnutella network. Our approach exploits a simple, yet powerful principle called interest-based locality, which posits that if a peer has a particular piece of content that one is interested in, it is very likely that it will have other items that one is interested in as well. When using our algorithm, called interest-based shortcuts, a significant amount of flooding can be avoided, making Gnutella a more competitive solution. In addition, shortcuts are modular and can be used to improve the performance of other content location mechanisms including distributed hash table schemes. We demonstrate the existence of interest-based locality in five diverse traces of content distribution applications, two of which are traces of popular peer-to-peer file-sharing applications. Simulation results show that interest-based shortcuts often resolve queries quickly in one peer-to-peer hop, while reducing the total load in the system by a factor of 3 to 7.},
keywords={Internet;file organisation;interest-based locality;decentralized peer-to-peer systems;Gnutella network;file-sharing application;flooding queries;content location mechanism;distributed hash table;Peer to peer computing;Robustness;Scalability;Floods;Internet;Availability;Contracts;Content management;Costs;Engineering profession},
doi={10.1109/INFCOM.2003.1209237},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209238,
author={J. Xu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On the fundamental tradeoffs between routing table size and network diameter in peer-to-peer networks},
year={2003},
volume={3},
number={},
pages={2177-2187 vol.3},
abstract={We study a fundamental tradeoff issue in designing distributed hash table (DHT) in peer-to-peer networks: the size of the routing table v.s. the network diameter. It was observed by Ratnasamy et al. that existing DHT schemes either (a) have a routing table of size /spl Oscr/(log/sub 2/n) and network diameter of /spl Omega/(log/sub 2/n), or (b) have a routing table of size d and network diameter of /spl Omega/(n/sup 1/d/). They asked whether this represents the best asymptotic "state-efficiency" tradeoffs. Our first major result is to show that there are straightforward routing algorithms, which achieve better asymptotic tradeoffs. However, such algorithms all cause severe congestion on certain network nodes, which is undesirable in a P2P network. We then rigorously define the notion of "congestion" and conjecture that the above tradeoffs are asymptotically optimal for a congestion-free network. In studying this conjecture, we have thoroughly clarified the role that "congestion-free" plays in this "state-efficiency" tradeoff. Our second major result is to prove that the aforementioned tradeoffs are asymptotically optimal for uniform algorithms. Furthermore, for uniform algorithms, we find that the routing table size of /spl Omega/(log/sub 2/n) is a magic threshold point that separates two different "state-efficiency" regions. Our third and final result is to study the exact (instead of asymptotic) optimal tradeoffs for uniform algorithms. We propose a new routing algorithm that reduces the routing table size and the network diameter of Chord both by 21.4% without introducing any other protocol overhead, based on a novel number-theoretical technique.},
keywords={Internet;telecommunication network routing;telecommunication congestion control;distributed hash table;DHT;network routing algorithms;asymptotic tradeoffs;routing table size;network diameter;peer-to-peer networks;congestion-free network;magic threshold point;state-efficiency regions;uniform algorithms;number-theoretical technique;Intelligent networks;Peer to peer computing;Costs;Educational institutions;Computer networks;Distributed computing;Routing protocols;Scalability;Floods;Data structures},
doi={10.1109/INFCOM.2003.1209238},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209239,
author={Z. Ge and D. R. Figueiredo and Sharad Jaiswal and J. Kurose and D. Towsley},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Modeling peer-peer file sharing systems},
year={2003},
volume={3},
number={},
pages={2188-2198 vol.3},
abstract={Peer-peer networking has recently emerged as a new paradigm for building distributed networked applications. We develop simple mathematical models to explore and illustrate fundamental performance issues of peer-peer file sharing systems. The modeling framework introduced and the corresponding solution methods are flexible enough to accommodate different characteristics of such systems. Through the specification of model parameters, we apply our framework to three different peer-peer architectures: centralized indexing, distributed indexing with flooded queries, and distributed indexing with hashing directed queries. Using our model, we investigate the effects of system scaling, freeloaders, file popularity and availability on system performance. In particular, we observe that a system with distributed indexing and flooded queries cannot exploit the full capacity of peer-peer systems. We further show that peer-peer file sharing systems can tolerate a significant number of freeloaders without suffering much performance degradation. In many cases, freeloaders can benefit from the available spare capacity of peer-peer systems and increase overall system throughput. Our work shows that simple models coupled with efficient solution methods can be used to understand and answer questions related to the performance of peer-peer file sharing systems.},
keywords={Internet;distributed processing;file organisation;query processing;file sharing systems;peer-peer network;distributed network applications;mathematical models;centralized indexing;distributed indexing;flooded queries;hashing directed queries;freeloaders;performance degradation;spare capacity;system throughput;Peer to peer computing;Indexing;Network servers;System performance;Degradation;Throughput;Computer science;Application software;Mathematical model;Availability},
doi={10.1109/INFCOM.2003.1209239},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209240,
author={T. S. E. Ng and Y. -. Chu and S. G. Rao and K. Sripanidkulchai and H. Zhang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Measurement-based optimization techniques for bandwidth-demanding peer-to-peer systems},
year={2003},
volume={3},
number={},
pages={2199-2209 vol.3},
abstract={Measurement-based optimization is one important strategy to improve the performance of bandwidth-demanding peer-to-peer systems. However, to date, we have little quantitative knowledge of how well basic lightweight measurement-based techniques such as RTT probing, 10KB TCP probing, and bottleneck bandwidth probing may work in practice in the peer-to-peer environment. By conducting trace-based analyses, we find that the basic techniques can help achieve 40 to 50% optimal performance. To deepen our understanding, we analyze some of the intrinsic properties of these techniques. Our analyses reveal the inherent difficulty of the peer selection problem due to the extreme heterogeneity in the peer-to-peer environment, and that the basic techniques are limited because their primary strength lies in eliminating the low-performance peers rather than reliably identifying the best-performing one. However, our analyses also reveal two key insights that can potentially be exploited by applications. First, for adaptive applications that can continuously change communication peers, the basic techniques are highly effective in guiding the adaption process. In our experiments, typically an 80% optimal peer can be found by trying less than 5 candidates. Secondly, we find that the basic techniques are highly complementary and can potentially be combined to better identify a high-performance peer, thus even applications that cannot adapt may benefit. Using media file sharing and overlay multicast streaming as case studies, we have systematically experimented with several simple combined peer selection techniques. Our results show that for the nonadaptive media file sharing application, a simple combined technique can boost performance to 60% optimal. In contrast, for the continuously adaptive overlay multicast application, we find that a basic technique with even low-fidelity network information is sufficient to ensure good performance. We believe our findings will help guide the future designs of high-performance peer-to-peer systems.},
keywords={file organisation;transport protocols;Internet;multicast communication;telecommunication network routing;network measurement-based optimization;peer-to-peer systems;RTT probing;TCP probing;bottleneck bandwidth probing;trace-based analysis;peer selection techniques;Internet;media file sharing;overlay multicast streaming;Peer to peer computing;Bandwidth;Streaming media;Space exploration;Performance analysis;Technological innovation;Large-scale systems;Contracts;Engineering profession;Government},
doi={10.1109/INFCOM.2003.1209240},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209241,
author={J. Cartigny and D. Simplot and I. Stojmenovic},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Localized minimum-energy broadcasting in ad-hoc networks},
year={2003},
volume={3},
number={},
pages={2210-2217 vol.3},
abstract={In the minimum energy broadcasting problem, each node can adjust its transmission power in order to minimize total energy consumption but still enable a message originated from a source node to reach all the other nodes in an ad-hoc wireless network. In all existing solutions each node requires global network information (including distances between any two neighboring nodes in the network) in order to decide its own transmission radius. We describe a new localized protocol where each node requires only the knowledge of its distance to all neighboring nodes and distances between its neighboring nodes (or, alternatively, geographic position of itself and its neighboring nodes). In addition to using only local information, our protocol is shown experimentally to be comparable to the best known globalized BIP solution. Our solutions are based on the use of relative neighborhood graph, which preserves connectivity and is defined in localized manner.},
keywords={ad hoc networks;wireless sensor networks;power consumption;routing protocols;broadcasting;localized minimum-energy broadcasting;ad-hoc wireless networks;transmission power;total energy consumption;global network information;transmission radius;localized protocol;globalized BIP solution;relative neighborhood graph;Broadcasting;Intelligent networks;Ad hoc networks;Protocols;Network topology;Energy consumption;Wireless sensor networks;Computer science;Wireless networks;Batteries},
doi={10.1109/INFCOM.2003.1209241},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209242,
author={W. H. Yuen and R. D. Yates and S. -. Mau},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Exploiting data diversity and multiuser diversity in noncooperative mobile infostation networks},
year={2003},
volume={3},
number={},
pages={2218-2228 vol.3},
abstract={In wireless networks, it is often assumed that all nodes cooperate to relay packets for each other. Although this is a plausible model for military or mission based networks, it is unrealistic for commercial networks and future pervasive computing environments. We address the issue of noncooperation between nodes in the context of content distribution in mobile infostation networks. We assume all nodes have common interest in all files cached in the fixed infostations. In addition to downloading files from the fixed infostations, nodes act as mobile infostations and exchange files when they are in proximity. We stipulate a social contract such that an exchange occurs only when each node can obtain something it wants from the exchange. Our social contract enables much higher system efficiency compared to downloading from fixed infostations only while not requiring true cooperation among nodes. We show by analysis and simulations that network performance depends on the node density, mobility and the number of files that are being disseminated. Our results point to the existence of data diversity for mobile infostation networks. The achievable throughput increases as the number of files of interest to all users increases. We have also extended the common interest model to the case where nodes have dissimilar interests. Our simulation results show that as mobile nodes change from having identical interests to mutually exclusive interests, the network performance degrades dramatically. We propose an alternative user strategy when nodes have partially overlapping interests and show that the network capacity can be significantly improved by exploiting multiuser diversity inherent in mobile infostation networks. We conclude that data diversity and multiuser diversity exist in noncooperative mobile infostation networks and can be exploited.},
keywords={ad hoc networks;mobile radio;mobile computing;multicast communication;data communication;data diversity;multiuser diversity;noncooperative mobile infostation networks;wireless networks;military networks;mission based networks;pervasive computing;content distribution;network performance;Intelligent networks;Relays;Throughput;Spread spectrum communication;Motion pictures;Contracts;Routing;Power control;Wireless networks;Military computing},
doi={10.1109/INFCOM.2003.1209242},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209243,
author={J. Luo and P. T. Eugster and J. -. Hubaux},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Route driven gossip: probabilistic reliable multicast in ad hoc networks},
year={2003},
volume={3},
number={},
pages={2229-2239 vol.3},
abstract={Traditionally, reliable multicast protocols are deterministic in nature. It is precisely this determinism that tends to become their limiting factor when aiming at reliability and scalability, particularly in highly dynamic networks, e.g., ad hoc networks. As probabilistic protocols, gossip-based multicast protocols, recently (re-)discovered in wired networks, appear to be a viable means to "fight fire with fire" by exploiting the nondeterministic nature of ad hoc networks. We present a protocol that is designed to meet a more practical specification of probabilistic reliability; this gossip-based multicast protocol, called route driven gossip (RDG), can be deployed on any basic on-demand routing protocol. RDG is custom-tailored to ad hoc networks, achieving a high level of reliability without relying on any inherent multicast primitive. We illustrate our RDG protocol by layering it on top of the "bare" DSR protocol. We prove the reliability and scalability of RDG through both analysis and simulation.},
keywords={ad hoc networks;multicast protocols;routing protocols;telecommunication network reliability;route driven gossip protocol;ad hoc networks;multicast protocols;dynamic networks;probabilistic protocols;wired networks;on-demand routing protocol;DSR protocol;RDG protocol reliability;RDG protocol scalability;Intelligent networks;Ad hoc networks;Multicast protocols;Peer to peer computing;Scalability;Telecommunication network reliability;Computer network reliability;Routing protocols;Computer networks;Fires},
doi={10.1109/INFCOM.2003.1209243},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209244,
author={J. Wu and F. Dai},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Broadcasting in ad hoc networks based on self-pruning},
year={2003},
volume={3},
number={},
pages={2240-2250 vol.3},
abstract={We propose a general framework for broadcasting in ad hoc networks through self-pruning. The approach is based on selecting a small subset of hosts (also called nodes) to form a forward node set to carry out a broadcast process. Each node, upon receiving a broadcast packet, determines whether to forward the packet based on two neighborhood coverage conditions. These coverage conditions depend on neighbor connectivity and history of visited nodes, and in general, resort to global network information. Using local information such as k-hop neighborhood information, the forward node set is selected through a distributed and local pruning process. The forward node set can be constructed and maintained through either a proactive process (i.e., "up-to-date") or a reactive process (i.e., "on-the-fly"). Several existing broadcast algorithms can be viewed as special cases of the coverage conditions with k-hop neighborhood information. Simulation results show that new algorithms, which are more efficient than existing ones, can be derived from the coverage conditions, and self-pruning based on 2- or 3-hop neighborhood information is relatively cost-effective.},
keywords={ad hoc networks;broadcasting;mobile computing;mobile radio;ad hoc networks;self-pruning process;global network information;k-hop neighborhood information;distributed pruning process;local pruning process;forward node set;proactive process;reactive process;broadcast algorithms;Broadcasting;Intelligent networks;Ad hoc networks;Mobile computing;Computer networks;Wireless networks;Floods;Computer science;Electronic mail;History},
doi={10.1109/INFCOM.2003.1209244},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209245,
author={X. Cao and Vishal Anand and Y. Xiong and C. Qiao},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Performance evaluation of wavelength band switching in multifiber all-optical networks},
year={2003},
volume={3},
number={},
pages={2251-2261 vol.3},
abstract={Wavelength band switching (WBS) has only recently attracted attention from the optical networking industry for its practical importance in reducing the control complexity and cost of optical cross-connects (OXCs). However, WBS-related problems of theoretical interest have not been addressed thoroughly by the research community, and many issues are still wide open. In particular, WBS is different from wavelength routing, and thus techniques developed for wavelength-routed networks (including e.g., those for traffic grooming) cannot be directly applied to effectively address WBS-related problems. In this paper, we first propose a new multigranular OXC (MG-OXC) architecture for WBS, which is more flexible than any existing WBS node architectures. We also adopt the most powerful waveband assignment strategy, and develop an efficient heuristic algorithm called Balanced Path routing with Heavy-Traffic first (BPHT). To verify its near-optimality, we also develop an integer linear programming (ILP) model. Both the ILP and the BPHT algorithms can handle the case with multiple fibers per link and hence are more general than our previous single-fiber solutions X. Cao et al. (2002). We conduct a comprehensive evaluation of the benefits of WBS through detailed analysis and simulations. We show that the proposed heuristic BPHT can perform much better than a heuristic which applies the optimal routing and wavelength assignment (RWA) method. We also show that WBS using BPHT is even more beneficial in multifiber networks than in single-fiber networks in terms of reducing the port count. Our analytical and simulation results also provide valuable insights into the effect of wavelength band granularity, as well as the trade-offs between the wavelength-hop and the port count required in WBS networks.},
keywords={optical fibre networks;integer programming;telecommunication network routing;linear programming;wavelength division multiplexing;performance evaluation;wavelength band switching;multifiber all-optical network;optical networking industry;control complexity reduction;optical cross-connect cost;multigranular-optical cross-connect architecture;waveband assignment strategy;Balanced Path routing with Heavy-Traffic algorithm;BPHT algorithm;integer linear programming model;ILP model;multifiber network;network port count reduction;single-fiber network;wavelength band granularity effect;wavelength-hop;All-optical networks;Optical fiber networks;Wavelength routing;Analytical models;Industrial control;Optical control;Costs;Communication system traffic control;Heuristic algorithms;Integer linear programming},
doi={10.1109/INFCOM.2003.1209245},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209246,
author={K. Laevens and H. Bruneel},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Analysis of a single-wavelength optical buffer},
year={2003},
volume={3},
number={},
pages={2262-2267 vol.3},
abstract={We present a detailed analysis of the loss performance in an optical buffer having access to a single outgoing channel. Such a system - consisting of a number of fiber delay lines - differs significantly from a conventional electronic buffer, in that only a discrete set of delays can be realized for contention resolution. This leads to an underutilization of the channel capacity, which reduces overall performance. Our analysis does not require any special assumptions about the burst- or packet-size distribution, which allows us to study the impact this distribution has on performance. For the important special case of fixed-sized bursts, it reveals, amongst others, that matching fiber delay line length with burst duration is not necessarily the optimal solution in terms of loss performance. It further reveals that, in general, this optimal solution is function not only of burst-size characteristics, but of the offered load as well, making the buffer design process a delicate task.},
keywords={optical delay lines;optical fibre losses;telecommunication switching;optical fibre communication;single-wavelength optical buffer analysis;optical loss performance;channel capacity;fixed-sized burst;fiber delay line length;burst duration;burst-size characteristics;buffer design;burst switching;loss probability;Optical buffering;Delay lines;Performance analysis;Optical losses;Performance loss;Wavelength division multiplexing;Delay effects;Optical fiber losses;Optical fiber networks;Capacity planning},
doi={10.1109/INFCOM.2003.1209246},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209247,
author={J. Xu and C. Qiao and J. Li and G. Xu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Efficient channel scheduling algorithms in optical burst switched networks},
year={2003},
volume={3},
number={},
pages={2268-2278 vol.3},
abstract={Optical burst switching (OBS) is a promising paradigm for the next-generation Internet. In OBS, a key problem is to schedule bursts on wavelength channels whose bandwidth may become fragmented with the so-called void (or idle) intervals with both fast and bandwidth efficient algorithms so as to reduce burst loss. To date, only two scheduling algorithms, called Horizon and LAUC-VF, have been proposed, which trade off bandwidth efficiency for fast running time and vice versa, respectively. In this paper, we propose several novel algorithms for scheduling bursts in OBS networks with and without fiber delay lines (FDLs). In networks without FDLs, our proposed Min-SV algorithm can schedule a burst successfully in O(logm) time, where m is the total number of void intervals, as long as there is a suitable void interval. Simulation results suggest that our algorithm achieves a loss rate which is at least as low as the best previously known algorithm LAUC-VF, but can run much faster. In fact, its speed can be almost the same as Horizon (which has a much higher loss rate). In networks with FDLs, our proposed batching FDL algorithm considers a batch of FDLs simultaneously to find a suitable FDL to delay a burst which would otherwise be discarded due to contention, instead of considering the FDLs one by one. The average search time of this algorithm is therefore significantly reduced from that of the existing sequential search algorithms.},
keywords={optical delay lines;optical fibre networks;packet switching;scheduling;channel scheduling algorithm;optical burst switched network;optical burst switching;Internet;wavelength channel;void interval;burst loss reduction;burst scheduling algorithm;Horizon algorithm;latest available unused channel-void filling algorithm;LAUC-VF algorithm;bandwidth efficiency;fiber delay line;minimum-starting void algorithm;Min-SV algorithm;O(logm) time;batching fiber delay line algorithm;burst delay;Scheduling algorithm;Intelligent networks;Optical fiber networks;Optical packet switching;Bandwidth;Optical buffering;Switching circuits;Processor scheduling;Delay lines;Computer science},
doi={10.1109/INFCOM.2003.1209247},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209248,
author={C. Fan and M. Maier and M. Reisslein},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={The AWG/spl par/PSC network: a performance enhanced single-hop WDM network with heterogeneous protection},
year={2003},
volume={3},
number={},
pages={2279-2289 vol.3},
abstract={Single-hop WDM networks based on a central passive star coupler (PSC) or arrayed-waveguide grating (AWG) hub have received a great deal of attention as promising solutions for the quickly increasing traffic in metropolitan and local area networks. These single-hop networks suffer from a single point of failure: if the central hub fails, then all network connectivity is lost. To address this single point of failure in an efficient manner, we propose a novel single-hop WDM network, the AWG/spl par/PSC network. The AWG/spl par/PSC network consists of an AWG in parallel with a PSC. The AWG and PSC provide heterogeneous protection for each other; the AWG/spl par/PSC network remains functional when either the AWG or the PSC fails. If both AWG and PSC are functional, the AWG/spl par/PSC network uniquely combines the respective strengths of the two devices. By means of analysis and verifying simulations we find that the throughput of the AWG/spl par/PSC network is significantly larger than the total throughput obtained by combining the throughput of a stand-alone AWG network with the throughput of a stand-alone PSC network. We also find that the AWG/spl par/PSC network gives over a wide operating range a better throughput-delay performance than a network consisting of either two load sharing PSCs in parallel or two load sharing AWGs in parallel.},
keywords={arrayed waveguide gratings;wavelength division multiplexing;waveguide couplers;metropolitan area networks;local area networks;optical fibre networks;computer network reliability;access protocols;single-hop WDM network;heterogeneous protection;central passive star coupler network;arrayed-waveguide grating hub network;metropolitan area network;local area network;network failure;functional network;network throughput;network operating range;throughput-delay performance;medium access control;WDM networks;Protection;Arrayed waveguide gratings;Throughput;Telecommunication traffic;Broadcasting;Media Access Protocol;Bandwidth;Spread spectrum communication;Local area networks},
doi={10.1109/INFCOM.2003.1209248},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209249,
author={H. Choe and S. H. Low},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Stabilized Vegas},
year={2003},
volume={3},
number={},
pages={2290-2300 vol.3},
abstract={We show that the current TCP Vegas algorithm can become unstable in the presence of network delay and propose a modification that stabilizes it. The stabilized Vegas remains completely source-based and can be implemented without any network support. We suggest an incremental deployment strategy for stabilized Vegas when the network contains a mix of links, some with active queue management and some without.},
keywords={transport protocols;delays;network topology;queueing theory;telecommunication network management;stabilized Vegas;TCP Vegas algorithm;network delay;source-based Vegas;network support;incremental deployment strategy;network link;active queue management;Loss measurement;Stability analysis;Protocols;Internet;Aggregates;Nonlinear dynamical systems;Delay effects;Delay systems;Delay lines;Algorithm design and analysis},
doi={10.1109/INFCOM.2003.1209249},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209250,
author={Y. Gao and J. C. Hou},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A state feedback control approach to stabilizing queues for ECN-enabled TCP connections},
year={2003},
volume={3},
number={},
pages={2301-2311 vol.3},
abstract={In this paper, we present an analytical TCP model that takes into account of several issues that were ignored in the other existing models (such as those in F. Kelly (2001) and V. Mishra et al. (2000)), i.e., the congestion window is not gradually decreased at the rate of /spl omega//sup 2/p/2, but suddenly halved upon receipt of congestion indication and the congestion window is halved at most once during one round-trip time (RTT). We also include the delayed ACK option in the model. With the use of state feedback control theory, we then design, based on the enhanced TCP model, an AQM controller to stabilize the queue length at routers. The performance of the new controller is shown, via ns-2 simulation to outperform several other schemes under a variety of network scenarios and traffic loads, in terms of fluctuation in the queue length, link utilization, and packet loss ratio.},
keywords={transport protocols;telecommunication congestion control;state feedback;routing protocols;queueing theory;Internet;state feedback control theory;queue stabilizing;explicit congestion notification;TCP/IP;congestion window;congestion indication;round-trip time;delayed acknowledgement option;active queue management controller;controller performance;ns-2 simulation;traffic load;queue length fluctuation;link utilization;packet loss ratio;State feedback;Analytical models;TCPIP;Internet;Communication system traffic control;Traffic control;Automatic control;Queueing analysis;Performance loss;Statistical analysis},
doi={10.1109/INFCOM.2003.1209250},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209251,
author={A. Gurtov and R. Ludwig},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Responding to spurious timeouts in TCP},
year={2003},
volume={3},
number={},
pages={2312-2322 vol.3},
abstract={Delays on Internet paths, especially including wireless links, can be highly variable. On the other hand, a current trend for modern TCPs is to deploy a fine-grain retransmission timer with a lower minimum timeout value than 1 s suggested by RFC2988. Spurious TCP timeouts cause unnecessary retransmissions and congestion control back-off. The Eifel algorithm detects spurious TCP timeouts and recovers by restoring the connection state saved before the timeout. This paper presents an enhanced version of the Eifel response to spurious timeouts and illustrates its performance benefits on paths with a high delay-bandwidth product. The refinements concern the following issues (1) an efficient operation in presence of packet losses (2) appropriate restoration of congestion control, and (3) adapting the retransmit timer to avoid further spurious timeouts. In our simulations the Eifel algorithm on paths with a high delay-bandwidth product can increase throughput by up to 250% and at the same decrease the load on the network by 3%. The proposed response also shows adequate performance on heavily congested paths.},
keywords={transport protocols;radio links;telecommunication congestion control;delays;Internet;spurious TCP timeout response;Internet path delay;wireless link;retransmission timer;minimum timeout value;congestion control restoration;Eifel algorithm;connection state restoration;Eifel response;high delay-bandwidth product;packet losses;network throughput;congested path performance;Bandwidth;Delay;Detection algorithms;Clocks},
doi={10.1109/INFCOM.2003.1209251},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1209252,
author={B. Atkin and K. P. Birman},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Evaluation of an adaptive transport protocol},
year={2003},
volume={3},
number={},
pages={2323-2333 vol.3},
abstract={Applications on mobile computers must adapt to high variability in wireless network performance. Extending the semantics of transport protocols to offer more control over communication to the user allows applications to adapt their behavior to bandwidth variability. We examine adding bandwidth notifications, priorities and timeliness guarantees to a network API as a method for achieving greater application control over bursty traffic. Experiments demonstrate that the extended API allows applications to adjust to bandwidth variations effectively. We also compare three different implementations of the API: two which run on top of TCP, and one new protocol, ATP, which performs comparably to the TCP extensions, but has better performance for some workloads, including a workload simulating remote file system traffic.},
keywords={mobile computing;application program interfaces;wireless LAN;transport protocols;telecommunication congestion control;adaptive transport protocol evaluation;mobile computer application;wireless network performance;transport protocol semantics;bandwidth variability;bandwidth notification;network priority;network timeliness guarantee;API application control;bursty traffic;API implementation;TCP;workload performance;workload simulating remote file system traffic;Transport protocols;Bandwidth;Application software;Communication system traffic control;Mobile computing;Computer applications;Computer networks;High performance computing;Wireless networks;Communication system control},
doi={10.1109/INFCOM.2003.1209252},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208917,
author={Y. Qiu and P. Marbach},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Bandwidth allocation in ad hoc networks: a price-based approach},
year={2003},
volume={2},
number={},
pages={797-807 vol.2},
abstract={Pricing is considered as a means to stimulate cooperation in ad hoc networks: users can charge other users a price for relaying their data packets. Assuming that users set prices to maximize their own net benefit, we propose an iterative price and rate adaption algorithm. We show that this algorithm converges to a socially optimal bandwidth allocation. We use a numerical case study to illustrate our results.},
keywords={ad hoc networks;bandwidth allocation;pricing;optimal bandwidth allocation;ad hoc network;price-based approach;data packet;iterative price;rate adaption algorithm;Channel allocation;Intelligent networks;Ad hoc networks;Relays;Costs;Bandwidth;Batteries;Interference;Pricing;Telecommunication traffic},
doi={10.1109/INFCOM.2003.1208917},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208918,
author={Vikram Srinivasan and Pavan Nuggehalli and C. F. Chiasserini and R. R. Rao},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Cooperation in wireless ad hoc networks},
year={2003},
volume={2},
number={},
pages={808-817 vol.2},
abstract={In wireless ad hoc networks, nodes communicate with far off destinations using intermediate nodes as relays. Since wireless nodes are energy constrained, it may not be in the best interest of a node to always accept relay requests. On the other hand, if all nodes decide not to expend energy in relaying, then network throughput will drop dramatically. Both these extreme scenarios (complete cooperation and complete noncooperation) are inimical to the interests of a user. In this paper we address the issue of user cooperation in ad hoc networks. We assume that nodes are rational, i.e., their actions are strictly determined by self interest, and that each node is associated with a minimum lifetime constraint. Given these lifetime constraints and the assumption of rational behavior, we are able to determine the optimal throughput that each node should receive. We define this to be the rational Pareto optimal operating point. We then propose a distributed and scalable acceptance algorithm called generous tit-for-tat (GTFT). The acceptance algorithm is used by the nodes to decide whether to accept or reject a relay request. We show that GTFT results in a Nash equilibrium and prove that the system converges to the rational and optimal operating point.},
keywords={ad hoc networks;game theory;Pareto optimisation;wireless ad hoc network;optimal network throughput;rational Pareto optimal operating point;distributed acceptance algorithm;scalable acceptance algorithm;generous tit-for-tat algorithm;Nash equilibrium;relay request;intermediate node communication;economics;game theory;system design;user cooperation;lifetime constraint;Intelligent networks;Ad hoc networks;Relays;Throughput;Telecommunication traffic;Mobile ad hoc networks;Portable computers;Nash equilibrium;Power generation economics;Environmental economics},
doi={10.1109/INFCOM.2003.1208918},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208919,
author={P. Bjorklund and P. Varbrand and Di Yuan},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Resource optimization of spatial TDMA in ad hoc radio networks: a column generation approach},
year={2003},
volume={2},
number={},
pages={818-824 vol.2},
abstract={Wireless communications using ad hoc networks are receiving an increasing interest. The most attractive feature of ad hoc networks is the flexibility. The network is set up by a number of units in an ad hoc manner, without the need of any fixed infrastructure. Communication links are established between two units if the signal strength is sufficiently high. As not all pairs of nodes can establish direct links, the traffic between two units may have to be relayed through other units. This is known as the multihop functionality. Design of ad hoc networks is a challenging task. In this paper we study the problem of resource allocation with spatial TDMA (STDMA) as the access control scheme. Previous work for this problem has mainly focused on heuristics, whose performance is difficult to analyze when optimal solutions are not known. We develop, for both node-oriented and link-oriented allocation strategies, mathematical programming formulations for resource optimization. We further present a column generation approach, which, in our numerical experiments, constantly yields optimal or near-optimal solutions. Our results provide important benchmarks when evaluating heuristic on-line algorithms for resource optimization using STDMA.},
keywords={ad hoc networks;mathematical programming;time division multiple access;resource optimization;time division multiple access;spatial TDMA;ad hoc radio network;column generation approach;wireless communication link;signal strength;multihop functionality;access control scheme;node-oriented allocation strategy;link-oriented allocation strategy;mathematical programming formulation;heuristic on-line algorithm;Time division multiple access;Radio network;Ad hoc networks;Resource management;Wireless communication;Communication system traffic control;Relays;Access control;Performance analysis;Mathematical programming},
doi={10.1109/INFCOM.2003.1208919},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208920,
author={F. Bai and Narayanan Sadagopan and A. Helmy},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={IMPORTANT: a framework to systematically analyze the Impact of Mobility on Performance of Routing Protocols for Adhoc Networks},
year={2003},
volume={2},
number={},
pages={825-835 vol.2},
abstract={A mobile ad hoc network (MANET) is a collection of wireless mobile nodes forming a temporary network without using any existing infrastructure. Since not many MANETs are currently deployed, research in this area is mostly simulation based. Random waypoint is the commonly used mobility model in these simulations. Random waypoint is a simple model that may be applicable to some scenarios. However, we believe that it is not sufficient to capture some important mobility characteristics of scenarios in which MANETs may be deployed. Our framework aims to evaluate the impact of different mobility models on the performance of MANET routing protocols. We propose various protocol independent metrics to capture interesting mobility characteristics, including spatial and temporal dependence and geographic restrictions. In addition, a rich set of parameterized mobility models is introduced including random waypoint, group mobility, freeway and Manhattan models. Based on these models several 'test-suite' scenarios are chosen carefully to span the metric space. We demonstrate the utility of our test-suite by evaluating various MANET routing protocols, including DSR, AODV and DSDV. Our results show that the protocol performance may vary drastically across mobility models and performance rankings of protocols may vary with the mobility models used. This effect can be explained by the interaction of the mobility characteristics with the connectivity graph properties. Finally, we attempt to decompose the routing protocols into mechanistic "building blocks" to gain a deeper insight into the performance variations across protocols in the face of mobility.},
keywords={ad hoc networks;mobile radio;routing protocols;routing protocol performance;mobile ad hoc network;wireless mobile node;random waypoint;parameterized mobility model impact;protocol independent metric;spatial dependence;temporal dependence;geographic restriction;group mobility;freeway model;Manhattan model;DSR;AODV;DSDV;connectivity graph property;scenario mobility characteristics;test-suite scenario;Performance analysis;Routing protocols;Mobile ad hoc networks;Traffic control;Wireless communication;Computer science;Mobile computing;Testing;Performance gain;Telecommunication traffic},
doi={10.1109/INFCOM.2003.1208920},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208921,
author={M. Heusse and F. Rousseau and G. Berger-Sabbatel and A. Duda},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Performance anomaly of 802.11b},
year={2003},
volume={2},
number={},
pages={836-843 vol.2},
abstract={The performance of the IEEE 802.11b wireless local area networks is analyzed. We have observed that when some mobile hosts use a lower bit rate than the others, the performance of all hosts is considerably degraded. Such a situation is a common case in wireless local area networks in which a host far away from an access point is subject to important signal fading and interference. To cope with this problem, the host changes its modulation type, which degrades its bit rate to some lower value. Typically, 802.11b products degrade the bit rate from 11 Mb/s to 5.5, 2, or 1 Mb/s when repeated unsuccessful frame transmissions are detected. In such a case, a host transmitting for example at 1 Mb/s reduces the throughput of all other hosts transmitting at 11 Mb/s to a low value below 1 Mb/s. The basic CSMA/CA channel access method is at the root of this anomaly: it guarantees an equal long term channel access probability to all hosts. When one host captures the channel for a long time because its bit rate is low, it penalizes other hosts that use the higher rate. We analyze the anomaly theoretically by deriving simple expressions for the useful throughput, validate them by means of simulation, and compare with several performance measurements.},
keywords={carrier sense multiple access;fading;mobile radio;modulation;radiofrequency interference;wireless LAN;IEEE 802.11b performance anomaly;wireless local area network;WLAN;mobile host;bit rate;signal fading;signal interference;modulation type;frame transmission;carrier sense multiple access;CSMA/CA channel access method;channel access probability;Bit rate;Degradation;Wireless LAN;Performance analysis;Throughput;Fading;Interference;Multiaccess communication;Analytical models;Measurement},
doi={10.1109/INFCOM.2003.1208921},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208922,
author={G. Bianchi and I. Tinnirello},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Kalman filter estimation of the number of competing terminals in an IEEE 802.11 network},
year={2003},
volume={2},
number={},
pages={844-852 vol.2},
abstract={Throughput performance of the IEEE 802.11 distributed coordination function (DCF) is very sensitive to the number n of competing stations. The contribute of this paper is threefold. First, we show that n can be expressed as function of the collision probability encountered on the channel; hence, it can be estimated based on run-time measurements. Second, we show that the estimation of n, based on exponential smoothing of the measured collision probability (specifically, an ARMA filter), results to be a biased estimation, with poor performance in terms of accuracy/tracking trade-offs. Third, we propose a methodology to estimate n, based on an extended Kalman filter coupled with a change detection mechanism. This approach shows both high accuracy as well as prompt reactivity to changes in the network occupancy status. Numerical results show that, although devised in the assumption of saturated terminals, our proposed approach results effective also in non-saturated conditions, and specifically in tracking the average number of competing terminals.},
keywords={autoregressive moving average processes;Kalman filters;wireless LAN;Kalman filter estimation;competing terminal estimation;IEEE 802.11 network;throughput performance;distributed coordination function;collision probability function;run-time measurement;exponential smoothing;ARMA filter;biased estimation;tracking trade-off;change detection mechanism;network occupancy status;Intelligent networks;Throughput;Access protocols;Physical layer;Switches;Runtime;Smoothing methods;Filters;Collision avoidance;Multiaccess communication},
doi={10.1109/INFCOM.2003.1208922},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208923,
author={Y. Younggoo Kwon and Y. Yuguang Fang and H. Latchman},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A novel MAC protocol with fast collision resolution for wireless LANs},
year={2003},
volume={2},
number={},
pages={853-862 vol.2},
abstract={Design of efficient medium access control (MAC) protocols with both high throughput performance and high-degree of fairness performance is a major focus in distributed contention-based MAC protocol research. In this paper, we propose a novel and efficient contention-based MAC protocol for wireless local area networks, namely, the fast collision resolution (FCR) algorithm. This algorithm is developed based on the following innovative ideas: to speed up the collision resolution, we actively redistribute the backoff timers for all active nodes; to reduce the average number of idle slots, we use smaller contention window sizes for nodes with successful packet transmissions and reduce the backoff timers exponentially fast when a fixed number of consecutive idle slots are detected. We show that the proposed FCR algorithm provides high throughput performance and low latency in wireless LANs. The extensive simulation studies show that the FCR algorithm could significantly improve the performance of the IEEE 802.11 MAC protocol if our efficient collision resolution algorithm is used and that the fairly scheduled FCR (FS-FCR) algorithm could simultaneously achieve high throughput performance and a high degree of fairness.},
keywords={access protocols;packet radio networks;wireless LAN;IEEE 802.11 medium access control protocol;distributed contention-based MAC protocol;fast collision resolution algorithm;wireless local area network;wireless LAN;throughput performance;backoff timer reduction;contention window size;packet transmission;active node;idle slot average number reduction;Media Access Protocol;Wireless application protocol;Wireless LAN;Local area networks;Access protocols;Throughput;Scheduling algorithm;Multiaccess communication;Signal resolution;Delay},
doi={10.1109/INFCOM.2003.1208923},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208924,
author={S. Pilosof and Ramachandran Ramjee and D. Raz and Y. Shavitt and Prasun Sinha},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Understanding TCP fairness over wireless LAN},
year={2003},
volume={2},
number={},
pages={863-872 vol.2},
abstract={As local area wireless networks based on the IEEE 802.11 standard see increasing public deployment, it is important to ensure that access to the network by different users remains fair. While fairness issues in 802.11 networks have been studied before, this paper is the first to focus on TCP fairness in 802.11 networks in the presence of both mobile senders and receivers. In this paper, we evaluate extensively through analysis, simulation, and experimentation the interaction between the 802.11 MAC protocol and TCP. We identify four different regions of TCP unfairness that depend on the buffer availability at the base station, with some regions exhibiting significant unfairness of over 10 in terms of throughput ratio between upstream and downstream TCP flows. We also propose a simple solution that can be implemented at the base station above the MAC layer that ensures that different TCP flows share the 802.11 bandwidth equitably irrespective of the buffer availability at the base station.},
keywords={access protocols;mobile radio;transport protocols;wireless LAN;transport control protocol;TCP fairness;wireless local area network;wireless LAN;IEEE 802.11 standard network;public deployment;mobile sender;mobile receiver;media access control;802.11 MAC protocol;buffer availability;base station;throughput ratio;downstream TCP flow;upstream TCP flow;network access;Wireless LAN;Base stations;Bandwidth;Media Access Protocol;Wireless networks;Analytical models;Throughput;Femtocell networks;Computer science;USA Councils},
doi={10.1109/INFCOM.2003.1208924},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208925,
author={P. Tinnakornsrisuphap and A. M. Makowski},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Limit behavior of ECN/RED gateways under a large number of TCP flows},
year={2003},
volume={2},
number={},
pages={873-883 vol.2},
abstract={A stochastic model of an ECN/RED gateway with competing TCP sources sharing the capacity is considered. As the number of competing flows becomes large, the queue behavior at the gateway can be described by a two-dimensional recursion and the throughput behavior of individual TCP flows becomes asymptotically independent. The steady-state regime of the limiting behavior can be calculated from a well-known TCP throughput model with fixed loss probability. In addition, a central limit theorem is presented, yielding insight into the relationship between the queue fluctuation and the marking probability function. We confirm the results by simulations and discuss their implications for network dimensioning.},
keywords={Internet;queueing theory;stochastic processes;telecommunication congestion control;transport protocols;ECN/RED gateway limit behavior;TCP flow;stochastic model;two-dimensional recursion;asymptotically independent;fixed loss probability;central limit theorem;queue fluctuation;marking probability function;network dimensioning;steady-state regime;throughput behavior;Throughput;Educational institutions;Traffic control;Aggregates;Bandwidth;Stochastic systems;Steady-state;Probability;Queueing analysis;Fluctuations},
doi={10.1109/INFCOM.2003.1208925},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208926,
author={S. Deb and Sanjay Shakkottai and R. Srikant},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Stability and convergence of TCP-like congestion controllers in a many-flows regime},
year={2003},
volume={2},
number={},
pages={884-894 vol.2},
abstract={With the rapid growth of Internet, parameter design and analysis for large-scale networks has become a topic of active interest. Since simulation of such large scale systems is not easy, deterministic fluid models have been widely used for both qualitative understanding of the behavior, as well as parameter design for such networks. In this paper, we first study a deterministic fluid model for Internet congestion control when there are multiple TCP-like flows present. We provide conditions under which such a system is globally asymptotically stable in the presence of feedback delay. We then study the corresponding system with the addition of web mice and other nonresponsive flows modeled as stochastic disturbances. We show that, when there are a large number of flows, choosing parameters based on the global stability criterion for the deterministic system (with the noise replaced by its mean value) ensures global stability for the stochastic system as well. Numerical examples and simulation results with some popular active queue management mechanisms validate the parameter choices from analysis. The results indicate that a system with multiple TCP-like flows is globally stable as long as the bandwidth-delay product per flow is not very small.},
keywords={Internet;stability;stochastic systems;telecommunication congestion control;transport protocols;TCP-like congestion controller convergence;parameter design;large-scale network analysis;deterministic fluid model;feedback delay;nonresponsive flow;Web mice;stochastic disturbance;stochastic system global stability;active queue management mechanism;bandwidth-delay product;Internet congestion control;globally asymptotically stable system;Convergence;Large-scale systems;Stochastic systems;Stability criteria;IP networks;Internet;Fluid flow control;Feedback;Delay;Mice},
doi={10.1109/INFCOM.2003.1208926},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208927,
author={F. Baccelli and D. Hong},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Interaction of TCP flows as billiards},
year={2003},
volume={2},
number={},
pages={895-905 vol.2},
abstract={The aim of this paper is to analyze the performance of a large number of long lived TCP controlled flows sharing many routers (or links), from the knowledge of the network parameters (capacity, buffer size, topology) and of the characteristics of each TCP flow (RTT, route etc.) when taking synchronization into account. It is shown that the dynamics of such a network can be described in terms of iterate of random piecewise affine maps, or geometrically as a billiards in the Euclidean space with as many dimensions as the number of flow classes and as many reflection facets as there are routers. This class of billiards exhibits both periodic and non-periodic asymptotic oscillations, the characteristics of which are extremely sensitive to the parameters of the network. It is also shown that for large populations and in the presence of synchronization, aggregated throughputs exhibit fluctuations that are due to the network as a whole, that follow some complex fractal patterns, and that come on top of other and more classical flow or packet level fluctuations. The consequences on TCP's fairness are exemplified on a few typical cases of small dimension.},
keywords={network topology;synchronisation;telecommunication network routing;transport protocols;TCP flows Interaction;billiards;routers;network parameters;buffer size;network topology;TCP flow characteristics;synchronization;network dynamics;random piecewise affine maps iterate;Euclidean space;flow classes;reflection facets;periodic asymptotic oscillations;nonperiodic asymptotic oscillations;aggregated throughputs fluctuation;complex fractal patterns;classical flow;packet level fluctuations;TCP fairness;Throughput;Fluctuations;Size control;Tail;Equations;Performance analysis;Network topology;Reflection;Fractals;Bandwidth},
doi={10.1109/INFCOM.2003.1208927},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208928,
author={Arzad A Kherani and Anurag Kumar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Closed loop analysis of the bottleneck buffer under adaptive window controlled transfer of http-like traffic},
year={2003},
volume={2},
number={},
pages={906-915 vol.2},
abstract={An Internet link carrying http-like traffic, i.e., transfer of finite volume files starting at random time instants is considered. These file transfers are controlled by an adaptive window protocol (AWP); an example of such a protocol is TCP. We provide an analysis for the auto-covariance function of the AWP controlled traffic into the link's buffer; this traffic, in general, is not an on-off process. The analysis establishes that, for Pareto distributed file sizes with infinite second moment, the traffic into the link buffer is long range dependent (LRD). We also develop an analysis for obtaining the stationary distribution of the link buffer occupancy under an AWP controlled transfer of files sampled from some distribution. The analysis provides a necessary and a sufficient condition for the finiteness of the mean link buffer content; these conditions have explicit dependence on the AWP used and the file size distribution. This establishes the sensitivity of the buffer occupancy process to the file size distribution. Combining the results from the above analyses, we provide an example in which the closed loop control of an AWP results in finite mean link buffer occupancy even though the file sizes are Pareto distributed (with infinite second moment), and the traffic into the link buffer is long range dependent. The significance of this work is threefold: (i) it provides a framework for analysing various processes related to the link buffer under AWP controlled transfer of files with a general file size distribution; (ii) it indicates that the buffer behaviour in the Internet may not be as poor as predicted from an open loop analysis of a queue fed with LRD traffic; and (iii) it shows that the buffer behaviour (and hence the throughput performance for finite buffers) is sensitive to the distribution of file sizes.},
keywords={buffer storage;Internet;Pareto distribution;telecommunication traffic;transport protocols;bottleneck buffer closed loop analysis;AWP;adaptive window protocol controlled traffic;http-like traffic;Internet;finite volume files transfer;random time instants;TCP;auto-covariance function;Pareto file size distribution;LRD;long range dependent traffic;link buffer stationary distribution;mean link buffer content finiteness;explicit dependence;buffer occupancy process;buffer behaviour;buffers throughput performance;processor sharing queue;Programmable control;Adaptive control;Traffic control;Internet;Protocols;Pareto analysis;Size control;Performance analysis;Sufficient conditions;Open loop systems},
doi={10.1109/INFCOM.2003.1208928},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208929,
author={T. C. Bressoud and R. Rastogi and M. A. Smith},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal configuration for BGP route selection},
year={2003},
volume={2},
number={},
pages={916-926 vol.2},
abstract={An Internet Service Provider must provide transit service for traffic between its customers and its providers and, at the same time, attempt to minimize network utilization and balance traffic according to the capacities of its border routers. Central to the selection of border routers for transit traffic flows is the Border Gateway Protocol (BGP) between Autonomous System (AS) peers, through which route advertisements for network prefixes determine the selection of border routers for each traffic flow. This paper examines the problem of determining an optimal set of border routers for the advertisement of network prefixes so as to minimize the cost of traffic across a transit service provider's network while maintaining egress bandwidth constraints at the border routers. Egress bandwidth constraints are considered because there is anecdotal evidence to suggest that the peering links between ASs are often bottleneck links in the Internet, and so the optimal utilization of these links is also critical. After precisely formulating the optimization problem in accordance with the operation of BGP, we relate the problem to the generalized assignment problem and develop heuristic solutions for solving it. Simulation results from an implementation show up to a 37% improvement in the utilization of the peering links when compared to hot potato routing.},
keywords={Internet;protocols;telecommunication links;telecommunication network routing;telecommunication traffic;optimal configuration;Border Gateway Protocol route selection;Internet service provider;network utilization;transit traffic flows;autonomous systems peers;border router advertisements;network prefixes;routers optimal set;egress bandwidth constraints;anecdotal evidence;bottleneck links;generalized assignment problem;heuristic solutions;simulation;interdomain routing;Telecommunication traffic;Web and internet services;Bandwidth;Communication system traffic control;Routing protocols;Access protocols;Cost function;Load management;Helium;Constraint optimization},
doi={10.1109/INFCOM.2003.1208929},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208930,
author={A. Bremler-Barr and Y. Afek and S. Schwarz},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Improved BGP convergence via ghost flushing},
year={2003},
volume={2},
number={},
pages={927-937 vol.2},
abstract={In (Ref.1), (Ref.2) it was noticed that sometimes it takes BGP a substantial amount of time and messages to converge and stabilize following the failure of some node in the Internet. In this paper we suggest a minor modification to BGP that eliminates the problem pointed out and substantially reduces the convergence time and communication complexity of BGP. Roughly speaking, our modification ensures that bad news (the failure of a node/edge) propagate fast, while good news (the establishment of a new path to a destination) propagate somewhat slower. This is achieved in BGP by allowing withdrawal messages to propagate with no delay as fast as the network forwards them, while announcements propagate as they do in BGP with a delay at each node of one minRouteAdver (except for the first wave of announcements).},
keywords={communication complexity;convergence;Internet;protocols;BGP convergence;ghost flushing solution;convergence time;Internet node failure;communication complexity;destination path establishment;withdrawal message propagation;announcement propagation;node delay;minRouteAdver;Convergence;IEEE news;Propagation delay;Routing protocols;Complexity theory;Failure analysis;Information analysis;Web and internet services;Network topology;H infinity control},
doi={10.1109/INFCOM.2003.1208930},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208931,
author={S. Siachalou and L. Georgiadis},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Efficient QoS routing},
year={2003},
volume={2},
number={},
pages={938-947 vol.2},
abstract={The problem of routing in a network where QoS constraints are placed on network traffic is considered. We provide two optimal algorithms that are based on determining the discontinuities of functions related to the optimization at hand. The proposed algorithms have pseudopolynomial worst case running time and for a wide variety of tested networks they have fairly satisfactory running times. They perform significantly better than the algorithm based on the direct application of the dynamic programming equations and can also be used in conjunction with known polynomial-time approximation algorithms to provide good average case behavior, in addition to guaranteeing polynomial worst-case running time.},
keywords={dynamic programming;polynomial approximation;quality of service;telecommunication network routing;telecommunication traffic;QoS constraints;network routing;network traffic;optimal algorithms;function discontinuity;optimization;pseudopolynomial worst case running time;tested networks;running times;dynamic programming equations;polynomial-time approximation algorithms;average case behavior;graph theory;Routing;Quality of service;Polynomials;Delay;Costs;Telecommunication traffic;Dynamic programming;Streaming media;Approximation algorithms;Equations},
doi={10.1109/INFCOM.2003.1208931},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208932,
author={E. J. Anderson and T. E. Anderson},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On the stability of adaptive routing in the presence of congestion control},
year={2003},
volume={2},
number={},
pages={948-958 vol.2},
abstract={Efficient use of network resources has long been an important problem for large-scale network operators. To this end, several recent research efforts have proposed automated methods for optimizing routes based on traffic measurements. However, these efforts have not considered the stability of the dual feedback control mechanisms of adaptive routing and congestion control, when operating together. In this paper, we demonstrate that an important class of adaptive routing algorithms can yield stable optimal routes in the presence of congestion control, provided that either the congestion control mechanism is fair or the network workload behaves under reasonable constraints. We further show that one or the other of these assumptions is necessary for this class of adaptive routing algorithms -otherwise, unstable, sub-optimal routes may result in some pathological cases.},
keywords={telecommunication congestion control;telecommunication network routing;adaptive routing algorithms;congestion control mechanism;network resources;large-scale network operators;routes automated methods;network traffic measurements;dual feedback control mechanisms;stable optimal routes;network workload;Stability;Programmable control;Adaptive control;Routing;Automatic control;Optimal control;Large-scale systems;Optimization methods;Communication system traffic control;Feedback control},
doi={10.1109/INFCOM.2003.1208932},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208933,
author={M. A. Marsan and M. Franceschinis and E. Leonardi and F. Neri and A. Tarello},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Instability phenomena in underloaded packet networks with QoS schedulers},
year={2003},
volume={2},
number={},
pages={959-969 vol.2},
abstract={Instability in packet-switching networks is normally associated with overload conditions, since queueing network models show that, in simple configurations, only overload generates instability. However, some results showing that instability can happen also in underloaded queueing networks appeared in the recent literature. Underload instabilities can be produced by complex scheduling algorithms, that bear significant resemblance to the Quality of Service (QoS) schedulers considered today for packet networks. In this paper, we study with fluid models and with adversarial queueing theory possible underload instabilities due to strict-priority schedulers and to Generalized Processor Sharing (GPS) schedulers.},
keywords={packet switching;quality of service;queueing theory;scheduling;underloaded packet-switching networks instability;QoS schedulers;Quality of Service;queueing network models;complex scheduling algorithms;fluid models;adversarial queueing theory;strict-priority schedulers;Generalized Processor Sharing schedulers;Intelligent networks;Quality of service;Scheduling algorithm;Global Positioning System;Processor scheduling;Switches;Stability;Customer service;Channel capacity;Queueing analysis},
doi={10.1109/INFCOM.2003.1208933},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208934,
author={M. A. Marsan and P. Laface and M. Meo},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Packet delay analysis in GPRS systems},
year={2003},
volume={2},
number={},
pages={970-978 vol.2},
abstract={In this paper we describe an analytical model to compute the packet delay distribution in a cell of a wireless network operating according to the GSM/GPRS standard. GSM (Global System for Mobile communications) is the most widely deployed wireless telephony standard, and GPRS (Generalized Packet Radio Service) is the technology that is now available to integrate packet data services into GSM networks. By comparing the performance estimates produced by the analytical model against those generated by detailed simulation experiments, we show that the proposed modeling technique is quite accurate. In addition, we show that the results produced by the analytical model are extremely useful in the design and planning of a wireless voice and data network.},
keywords={cellular radio;delays;Markov processes;packet radio networks;packet delay distribution;GPRS systems;Generalized Packet Radio Service;wireless network cell;GSM standard;Global System for Mobile communications;deployed wireless telephony standard;packet data services;performance analysis;simulation;analytical model;wireless voice planning;data network design;matrix analytic techniques;Markovian models;Delay;Ground penetrating radar;Analytical models;GSM;Computer networks;Distributed computing;Wireless networks;Telephony;Communication standards;Packet radio networks},
doi={10.1109/INFCOM.2003.1208934},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208935,
author={M. X. van den Broek and I. B. J. F. Adan and Sai Shankar N and S. Borst},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A novel mechanism for contention resolution in HFC networks},
year={2003},
volume={2},
number={},
pages={979-989 vol.2},
abstract={The Medium Access Control (MAC) scheme proposed by DAVIC/DVB, IEEE 802.14 and DOCSIS for the upstream channel of Hybrid Fiber Coaxial (HFC) access networks is based on a mixable contention-based/contention-less time slot assignment. Contention-less slots are assigned by the head end to end stations according to a reservation scheme. Contention-based slots are randomly accessed by active terminals without any preliminary allocation, so that collisions may occur. To resolve contention, the contention tree algorithm has been widely accepted by the DVB/DAVIC, IEEE 802.14 and DOCSIS standards for MAC because of higher throughput and lower access delay. In this paper we propose a novel contention resolution mechanism and compare its performance with that of existing procedures. The proposed procedure is termed as static arrival slot mechanism. In this mechanism, one slot in each frame is exclusively reserved for new arrivals that wish to access the channel using contention resolution, and at least one slot is reserved for resolving their contention if there was one in the arrival slot. The performance of the proposed mechanism is evaluated through analysis and simulation. The results show that the proposed mechanism outperforms existing contention resolution procedures under heavy traffic.},
keywords={access protocols;cable television;digital video broadcasting;hybrid fibre coax networks;telecommunication traffic;contention resolution mechanism;HFC networks upstream channel;hybrid fiber coaxial access networks;MAC;medium access control scheme;DAVIC;DVB;IEEE 802.14;DOCSIS standards;contention-based time slot assignment;contention-less time slot assignment;head end to end stations;reservation scheme;active terminals;contention tree algorithm;access delay;static arrival slot mechanism;frame slot;arrival slot;simulation;traffic;sojourn time;waiting time;Intelligent networks;Hybrid fiber coaxial cables;Helium;Media Access Protocol;Digital video broadcasting;Access protocols;Mathematics;Computer science;USA Councils;Delay},
doi={10.1109/INFCOM.2003.1208935},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208936,
author={Y. Xia and D. Tse},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Analysis on packet resequencing for reliable network protocols},
year={2003},
volume={2},
number={},
pages={990-1000 vol.2},
abstract={Protocols such as TCP require packets to be accepted (i.e., delivered to the receiving application) in the order they are transmitted at the sender. Packets are sometimes mis-ordered in the network. In order to deliver the arrived packets to the application in sequence, the receiver's transport layer needs to temporarily buffer out-of-order packets and resequence them as more packets arrive. Even when the application can consume the packets infinitely fast, the packets may still be delayed for resequencing. In this paper, we model packet mis-ordering by adding an IID random propagation delay to each packet and analyze the required buffer size for packet resequencing and the resequencing delay for an average packet. We demonstrate that these two quantities can be significant and show how they scale with the network bandwidth.},
keywords={buffer storage;delays;packet switching;transport protocols;packet resequence analysis;reliable network protocols;TCP;packet transmission;receivers transport layer;out-of-order packets buffer;packet delay;packet mis-order;independently and identically distributed random variables;i.i.d. random propagation delay;buffer size;average packet resequencing delay;network bandwidth;Protocols;Propagation delay;Automatic repeat request;Out of order;Buffer storage;Bandwidth;Random variables;Chromium;Feedback;Computer network reliability},
doi={10.1109/INFCOM.2003.1208936},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208937,
author={A. K. Das and R. J. Marks and M. El-Sharkawi and P. Arabshahi and A. Gray},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Minimum power broadcast trees for wireless networks: integer programming formulations},
year={2003},
volume={2},
number={},
pages={1001-1010 vol.2},
abstract={Wireless multicast/broadcast sessions, unlike wired networks, inherently reach several nodes with a single transmission. For omnidirectional wireless broadcast to a node, all nodes closer will also be reached. Heuristic algorithms for constructing the minimum power tree in wireless networks have been proposed by Wieselthier et al. and Stojmenovic et al. Recently, an evolutionary search procedure has been proposed by Marks et al. In this paper, we present three different integer programming models which can be used for an optimal solution of the minimum power broadcast/multicast problem in wireless networks. The models assume complete knowledge of the distance matrix and is therefore most suited for networks where the locations of the nodes are fixed.},
keywords={broadcasting;evolutionary computation;integer programming;multicast communication;radio networks;search problems;wireless multicast/broadcast sessions;omnidirectional wireless broadcast;heuristic algorithms;minimum power broadcast tree;wireless networks;integer programming models;distance matrix;fixed node location;Broadcasting;Wireless networks;Linear programming;Relays;Transmitters;Propagation losses;Heuristic algorithms;Multicast algorithms;Signal processing;Receiving antennas},
doi={10.1109/INFCOM.2003.1208937},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208938,
author={D. Dolev and O. Mokryn and Y. Shavitt},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On multicast trees: structure and size estimation},
year={2003},
volume={2},
number={},
pages={1011-1021 vol.2},
abstract={This work presents a thorough investigation of the structure of multicast trees cut from the Internet and power-law topologies. Based on both generated topologies and real Internet data, we characterize the structure of such trees and show that they obey the rank-degree power law; that most high degree tree nodes are concentrated in a low diameter neighborhood; and that the sub-tree size also obeys a power law. Our most surprising empirical finding suggests that there is a linear ratio between the number of high-degree network nodes, namely nodes whose tree degree is higher than some constant, and the number of leaf nodes in the multicast tree (clients). We also derive this ratio analytically. Based on this finding, we develop the fast algorithm, that estimates the number of clients, and show that it converges faster than one round trip delay from the root to a randomly selected client.},
keywords={Internet;multicast communication;network topology;parameter estimation;trees (mathematics);multicast trees structure;Internet topology;power-law topology;rank-degree power law;high degree tree nodes;sub-tree size;high degree network nodes;multicast tree leaf nodes;fast algorithm;client estimation;Internet;Network topology;Character generation;Multicast algorithms;Multicast protocols;IP networks;Feedback;Power generation;Delay estimation;Frequency estimation},
doi={10.1109/INFCOM.2003.1208938},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208939,
author={G. -. Kwon and J. W. Byers},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Smooth multirate multicast congestion control},
year={2003},
volume={2},
number={},
pages={1022-1032 vol.2},
abstract={A significant impediment to deployment of multicast services is the daunting technical complexity of developing, testing and validating congestion control protocols fit for wide-area deployment. Protocols such as pgmcc and TFMCC have recently made considerable progress on the single rate case, i.e. where one dynamic reception rate is maintained for all receivers in the session. However, these protocols have limited applicability, since scaling to session sizes beyond tens of participants necessitates the use of multiple rate protocols. Unfortunately, while existing multiple rate protocols exhibit better scalability, they are both less mature than single rate protocols and suffer from high complexity. We propose a new approach to multiple rate congestion control that leverages proven single rate congestion control methods by orchestrating an ensemble of independently controlled single rate sessions. We describe SMCC, a new multiple rate equation-based congestion control algorithm for layered multicast sessions that employs TFMCC as the primary underlying control mechanism for each layer. SMCC combines the benefits of TFMCC (smooth rate control, equation-based TCP friendliness) with the scalability and flexibility of multiple rates to provide a sound multiple rate multicast congestion control policy.},
keywords={multicast protocols;network topology;telecommunication congestion control;transport protocols;multicast services;multiple rate congestion control;independently controlled single rate sessions;pgmcc;SMCC;multiple rate equation;congestion control algorithm;layered multicast sessions;TFMCC;smooth multirate control;equation-based TCP friendliness;Multicast protocols;Testing;Scalability;Equations;Buildings;Centralized control;Computer science;Impedance;Multicast algorithms;Control design},
doi={10.1109/INFCOM.2003.1208939},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208940,
author={Y. Birk and D. Crupnicoff},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A multicast transmission schedule for scalable multirate distribution of bulk data using nonscalable erasure-correcting codes},
year={2003},
volume={2},
number={},
pages={1033-1043 vol.2},
abstract={This paper addresses the efficient multicast dissemination of bulk data from a single server to numerous clients. The challenge is complex: a client may commence reception at arbitrary times, should receive as little "extra" data as possible until it can reconstruct the entire content, and should have flexibility in choosing the data rate. From the network perspective, the data rate over any link should be as close as possible to the maximum single-downstream-client subscription rate. Also, the solution should scale to huge files and numerous subscribers, and should withstand changing network conditions and packet loss. Finally, it should be friendly to other traffic. For any base client-subscription rate and integer factors thereof, we jointly achieve all these goals in a near-optimal way while using standard ("any k of N") block erasure-correcting codes. Scalability in file size is attained by breaking the file into equisized groups of equisized blocks and separately encoding each group. The other properties are attained by a unique open-loop layered multicast transmission schedule. Each client merely subscribes to one or more standard multicast groups. The need to use special, nonstandard and possibly proprietary codes that scale well is thus obviated.},
keywords={block codes;error correction codes;Internet;multicast communication;packet switching;scheduling;bulk data multicast dissemination;single-downstream-client subscription rate;base client-subscription rate;block erasure-correcting codes;open-loop layered multicast transmission;scalable multirate distribution;nonscalable erasure-correcting codes;packet loss;file size scalability;Network servers;Streaming media;Scalability;Delay;Computer networks;Distributed computing;File servers;Paper technology;Subscriptions;Telecommunication traffic},
doi={10.1109/INFCOM.2003.1208940},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208941,
author={S. Ray and R. Ungrangsi and De Pellegrini and A. Trachtenberg and D. Starobinski},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Robust location detection in emergency sensor networks},
year={2003},
volume={2},
number={},
pages={1044-1053 vol.2},
abstract={We propose a new framework for providing robust location detection in emergency response systems, based on the theory of identifying codes. The key idea of this approach is to allow sensor coverage areas to overlap in such a way that each resolvable position is covered by a unique set of sensors. In this setting, determining a sensor-placement with a minimum number of sensors is equivalent to constructing an optimal identifying code, an NP-complete problem in general. We thus propose and analyze a new polynomial-time algorithm for generating irreducible codes for arbitrary topologies. We also generalize the concept of identifying codes to incorporate robustness properties that are critically needed in emergency networks and provide a polynomial-time algorithm to compute irreducible robust identifying codes. Through analysis and simulation, we show that our approach typically requires significantly fewer sensors than existing proximity-based schemes. Alternatively, for a fixed number of sensors, our scheme can provide robustness in the face of sensor failures or physical damage to the system.},
keywords={codes;indoor radio;optimisation;radio direction-finding;wireless sensor networks;robust location detection;emergency response systems;sensor coverage areas;sensor-placement determination;NP-complete problem;polynomial-time algorithm;irreducible codes generation;irreducible robust identifying codes;proximity-based schemes;emergency sensor networks;Robustness;Intelligent networks;Sensor systems;Face detection;Sensor phenomena and characterization;Network topology;Fires;Smoke detectors;Buildings;Personnel},
doi={10.1109/INFCOM.2003.1208941},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208942,
author={J. Chou and D. Petrovic and Kannan Ramachandran},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A distributed and adaptive signal processing approach to reducing energy consumption in sensor networks},
year={2003},
volume={2},
number={},
pages={1054-1062 vol.2},
abstract={We propose a novel approach to reducing energy consumption in sensor networks using a distributed adaptive signal processing framework and efficient algorithm. While the topic of energy-aware routing to alleviate energy consumption in sensor networks has received attention recently (C. Toh, 2001; R. Shah et al., 2002), in this paper, we propose an orthogonal approach to previous methods. Specifically, we propose a distributed way of continuously exploiting existing correlations in sensor data based on adaptive signal processing and distributed source coding principles. Our approach enables sensor nodes to blindly compress their readings with respect to one another without the need for explicit and energy-expensive intersensor communication to effect this compression. Furthermore, the distributed algorithm used by each sensor node is extremely low in complexity and easy to implement (i.e., one modulo operation), while an adaptive filtering framework is used at the data gathering unit to continuously learn the relevant correlation structures in the sensor data. Our simulations show the power of our proposed algorithms, revealing their potential to effect significant energy savings (from 10%-65%) for typical sensor data corresponding to a multitude of sensor modalities.},
keywords={adaptive filters;adaptive signal processing;data compression;distributed algorithms;source coding;wireless sensor networks;energy consumption reduction;sensor networks;distributed adaptive signal processing;distributed source coding principles;sensor nodes;energy-expensive intersensor communication avoidance;data gathering unit;sensor data correlation structures;sensor data energy savings;multitude sensor modalities;Adaptive signal processing;Energy consumption;Intelligent networks;Magnetic sensors;Temperature sensors;Sensor phenomena and characterization;Acoustic sensors;Signal processing algorithms;Routing;Wireless sensor networks},
doi={10.1109/INFCOM.2003.1208942},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208943,
author={C. Florens and R. McEliece},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Packets distribution algorithms for sensor networks},
year={2003},
volume={2},
number={},
pages={1063-1072 vol.2},
abstract={In this paper, we study, via simple discrete mathematical models, the problems of data distribution and data collection in wireless sensor networks. The work that follows continues the work presented by the authors in (C. Florens et al., 2002) where the focus was on sensor networks equipped with unidirectional antenna elements. Here we shift our interest to networks equipped with omnidirectional antenna elements. In particular we show how the data distribution and collection tasks can be performed optimally (with respect to time) on tree networks and give the corresponding time performances of those strategies. We also present a strategy for general graph networks that performs within a factor of 3 of the optimal performance. Finally we compare the performance of a network equipped with omnidirectional antenna elements with one equipped with unidirectional antenna elements. We show the latter outperforms the former by 33% at most in tree networks. To that purpose we included relevant results on directional antenna sensor networks, partly obtained in (C.Florens et al., 2002).},
keywords={antenna accessories;data communication;packet radio networks;wireless sensor networks;wireless sensor networks;unidirectional antenna elements;data distribution;tree networks;graph networks;omnidirectional antenna elements;directional antenna sensor networks;discrete mathematical models;data collection;packet distribution algorithms;Wireless sensor networks;Sensor systems;Tree graphs;Directional antennas;Very large scale integration;Monitoring;Ad hoc networks;Media Access Protocol;Signal processing algorithms;Mathematical model},
doi={10.1109/INFCOM.2003.1208943},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208944,
author={S. Shakkottai and R. Srikant and N. Shroff},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Unreliable sensor grids: coverage, connectivity and diameter},
year={2003},
volume={2},
number={},
pages={1073-1083 vol.2},
abstract={We consider an unreliable wireless sensor grid-network with n nodes placed in a square of unit area. We are interested in the coverage of the region and the connectivity of the network. We first show that the necessary and sufficient conditions for the random grid network to cover the unit square region as well as ensure that the active nodes are connected are of the form p(n)r2(n) ~ log(n)/n, where r(n) is the transmission radius of each node and p(n) is the probability that a node is "active" (not failed). This result indicates that, when n is large, even if each node is highly unreliable and the transmission power is small, we can still maintain connectivity with coverage. We also show that the diameter of the random grid (i.e., the maximum number of hops required to travel from any active node to another) is of the order √{n/log(n)}. Finally, we derive a sufficient condition for connectivity of the active nodes (without necessarily having coverage). If the node success probability p(n) is small enough, we show that connectivity does not imply coverage.},
keywords={stochastic processes;telecommunication network reliability;wireless sensor networks;wireless sensor grid-network;active nodes connectivity;transmission power;random grid diameter;node success probability;queueing theory;random grid network coverage;stochastic processes;Wireless sensor networks;Sufficient conditions;Intelligent sensors;Monitoring;Routing;Stochastic processes;Queueing analysis;Surges;Large-scale systems;Sensor systems},
doi={10.1109/INFCOM.2003.1208944},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208945,
author={X. Qin and R. Berry},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Exploiting multiuser diversity for medium access control in wireless networks},
year={2003},
volume={2},
number={},
pages={1084-1094 vol.2},
abstract={Multiuser diversity refers to a type of diversity present across different users in a fading environment. This diversity can be exploited by scheduling transmissions so that users transmit when their channel conditions are favorable. Using such an approach leads to a system capacity that increases with the number of users. However, such scheduling requires centralized control. In this paper, we consider a decentralized medium access control (MAC) protocol, where each user only has knowledge of its own channel gain. We consider a variation of the ALOHA protocol, channel-aware ALOHA; using this protocol we show that users can still exploit multiuser diversity gains. First we consider a backlogged model, where each user always has packets to send. In this case we show that the total system throughput increases at the same rate as in a system with a centralized scheduler. Asymptotically, the fraction of throughput lost due to the random access protocol is shown to be 1/e. We also consider a splitting algorithm, where the splitting sequence depends on the users' channel gains; this algorithm is shown to approach the throughput of an optimal centralized scheme. Next we consider a system with an infinite user population and random arrivals. In this case, it is proved that a variation of channel-aware ALOHA is stable for any total arrival rate in a memoryless channel, given that users can estimate the backlog. Extensions for channels with memory are also discussed.},
keywords={access protocols;decentralised control;diversity reception;Markov processes;packet radio networks;scheduling;multiuser diversity;decentralized medium access control protocol;channel gain;ALOHA protocol;channel-aware ALOHA;backlogged model;splitting algorithm;infinite user population;random arrivals;memoryless channel;Media Access Protocol;Intelligent networks;Wireless networks;Fading;Access protocols;Throughput;Centralized control;Diversity methods;Power control;Computer networks},
doi={10.1109/INFCOM.2003.1208945},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208946,
author={A. Fu and E. Modiano and J. Tsitsiklis},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal energy allocation for delay-constrained data transmission over a time-varying channel},
year={2003},
volume={2},
number={},
pages={1095-1105 vol.2},
abstract={We seek to maximize the data throughput of an energy and time constrained transmitter sending data over a fading channel. The transmitter has a fixed amount of energy and a limited amount of time to send data. Given that the channel fade state determines the throughput obtained per unit of energy expended, the goal is to obtain a policy for scheduling transmissions that maximizes the expected data throughput. We develop a dynamic programming formulation that leads to an optimal closed-form transmission schedule. We then extend our approach to the problem of minimizing the energy required to send a fixed amount of data over a fading channel given deadline constraints.},
keywords={data communication;dynamic programming;fading channels;mobile radio;scheduling;time-varying channels;transmitters;data throughput maximization;time constrained transmitter;fading channel;dynamic programming formulation;optimal closed-form transmission schedule;optimal energy allocation;delay-constrained data transmission;time-varying channel;Delay;Data communication;Time-varying channels;Throughput;Transmitters;Fading;Batteries;Energy efficiency;Bandwidth;Channel capacity},
doi={10.1109/INFCOM.2003.1208946},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208947,
author={Y. Liu and E. Knightly},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Opportunistic fair scheduling over multiple wireless channels},
year={2003},
volume={2},
number={},
pages={1106-1115 vol.2},
abstract={Emerging spread spectrum high-speed data networks utilize multiple channels via orthogonal codes or frequency-hopping patterns such that multiple users can transmit concurrently. In this paper, we develop a framework for opportunistic scheduling over multiple wireless channels. With a realistic channel model, any subset of users can be selected for data transmission at any time, albeit with different throughputs and system resource requirements. We first transform selection of the best users and rates from a complex general optimization problem into a decoupled and tractable formulation: a multiuser scheduling problem that maximizes total system throughput and a control-update problem that ensures long-term deterministic or probabilistic fairness constraints. We then design and evaluate practical schedulers that approximate these objectives.},
keywords={data communication;multi-access systems;radio networks;scheduling;spread spectrum communication;multiple wireless channels;spread spectrum high-speed data networks;orthogonal codes;frequency-hopping patterns;system resource requirements;complex general optimization problem;tractable formulation transformation;total system throughput;control-update problem;long-term deterministic fairness constraints;long-term probabilistic fairness constraints;practical schedulers design;weighted fair scheduling;multichannel scheduling;Throughput;Processor scheduling;Spread spectrum communication;Wireless networks;Time division multiple access;Multiaccess communication;Frequency;Data communication;Constraint optimization;Control systems},
doi={10.1109/INFCOM.2003.1208947},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208948,
author={M. Menth and M. Schmid and H. Heiss and T. Reim},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={MEDF - a simple scheduling algorithm for two real-time transport service classes with application in the UTRAN},
year={2003},
volume={2},
number={},
pages={1116-1122 vol.2},
abstract={In this paper, we consider real-time speech traffic, real-time circuit-switched data (CSD) and nonreal-time packet-switched data (PSD) in the UMTS terrestrial radio access network (UTRAN). The focus is on the single low-bandwidth link that interconnects the radio network controller (RNC) and the base station (node B). We show that all traffic on this link has real-time requirements. But we take advantage of the radio link control (RLC) layer protocol and formulate suitable quality of service (QoS) criteria that lead to two different transport service classes (TSC): A stringent TSC for speech traffic and CSD, and a tolerant TSC for PSD. The RNC transmits packets from both TSCs via a single low-bandwidth link to the node B. Since transmission capacity on this interface is a serious cost factor in the UTRAN, the link utilization should be optimized while respecting the QoS requirements of both TSCs. We propose a modified version (MEDF) of the earliest deadline first (EOF) algorithm for that task. In contrast to EDF, the MEDF is easy to implement in hardware and in contrast to algorithms like weighted fair queueing (WFQ), the knowledge of the traffic mix is not needed for a suitable parameter setting in the MEDF scheduler. The simulation results show its superiority over first-in-first-out (FIFO), static priority (SP), and weighted round robin (WRR) scheduling. The analysis of the waiting time distribution explains why MEDF performs better than the other scheduling strategies.},
keywords={3G mobile communication;circuit switching;data communication;packet radio networks;packet switching;quality of service;radio access networks;real-time systems;scheduling;telecommunication traffic;voice communication;MEDF scheduling algorithm;real-time transport service classes;real-time speech traffic;real-time circuit-switched data;nonreal-time PSD;packet-switched data network;UMTS terrestrial radio access network;single low-bandwidth link;radio network controller;base station node B;radio link control layer protocol;quality of service;QoS requirements;interface transmission capacity;link utilization optimization;earliest deadline first algorithm;weighted fair queueing;first-in-first-out;FIFO;static priority;weighted round robin scheduling;waiting time distribution analysis;Scheduling algorithm;Traffic control;Quality of service;Speech;Communication system traffic control;Radio control;Round robin;RLC circuits;3G mobile communication;Radio access networks},
doi={10.1109/INFCOM.2003.1208948},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208949,
author={J. R. Santos and Y. Turner and G. Janakiraman},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={End-to-end congestion control for infiniband},
year={2003},
volume={2},
number={},
pages={1123-1133 vol.2},
abstract={Infiniband system area networks (SANs) which use link-level flow control experience congestion spreading, where one bottleneck link causes traffic to block throughout the network. In this paper, we propose an end-to-end congestion control scheme that avoids congestion spreading, delivers high throughput, and prevents flow starvation. It couples a simple switch-based ECN packet marking mechanism appropriate for typical SAN switches with small input buffers, together with a source response mechanism that uses rate control combined with a window limit. The classic fairness convergence requirement for source response functions assumes network feedback is synchronous. We relax the classic requirement by exploiting the asynchronous behavior of packet marking. Our experimental results demonstrate that compared to conventional approaches, our proposed marking mechanism improves fairness. Moreover, rate increase functions possible under the relaxed requirement reclaim available bandwidth aggressively and improve throughput in both static and dynamic traffic scenarios.},
keywords={local area networks;packet switching;telecommunication congestion control;infiniband system area networks;link-level flow control;congestion spreading avoidance;end-to-end congestion control scheme;flow starvation prevention;switch-based ECN packet marking mechanism;classic fairness convergence requirement;source response functions;packet marking asynchronous behavior;static traffic scenarios;dynamic traffic scenarios;Switches;Packet switching;Delay;Throughput;Bandwidth;Telecommunication traffic;Laboratories;Milling machines;Control systems;Communication system traffic control},
doi={10.1109/INFCOM.2003.1208949},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208950,
author={S. Bohacek},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A stochastic model of TCP and fair video transmission},
year={2003},
volume={2},
number={},
pages={1134-1144 vol.2},
abstract={A stochastic model of TCP is developed. Unlike many other models, this model accounts for variations in latency and loss probability. A major strength of this model is that it easily produces the probability distribution of the congestion window. Thus, the mean as well as the median and percentiles can be found. It is shown that the mean congestion window can be far larger than the median. Other new insights include the effect of the rate of change of the latency on the performance of TCP. Specifically, this model predicts the well-known TCP-friendly formula only if the round-trip time rapidly varies. However, if the round-trip time does not vary quickly, then the TCP-friendly formula may not hold. Both rapidly and slowly varying round-trip times have been observed in real networks. As an application of the model, the question as to when a video can be fairly transmitted is addressed. If it is possible to transmit the video, the model yields the distribution of the size of the receiving buffer required to avoid underflow. Since the distribution can be found, it is possible to select a buffer size so that a specified percentage of users will view the video without interruption.},
keywords={stochastic processes;transport protocols;visual communication;TCP stochastic model;fair video transmission;loss probability variations;congestion window probability distribution;TCP-friendly formula;round-trip time variation;real networks;Stochastic processes;Video compression;Probability distribution;Streaming media;Delay;Predictive models;Traffic control;Differential equations;Unicast;Transform coding},
doi={10.1109/INFCOM.2003.1208950},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208951,
author={Puneet Mehra and A. Zakhor and C. De Vleeschouwer},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Receiver-driven bandwidth sharing for TCP},
year={2003},
volume={2},
number={},
pages={1145-1155 vol.2},
abstract={Applications using TCP, such as Web-browsers, ftp, and various P2P programs, dominate most of the Internet traffic today. In many cases the last-hop access links are bottlenecks due to their limited bandwidth capability with users running many simultaneous network applications. Standard TCP shares bottleneck link capacity according to connection round-trip time (RTT), and may result in a bandwidth partition which does not necessarily coincide with the user's desires. We present a receiver-based control system for allocating bandwidth among TCP flows according to user preferences. Our system does not require any changes to network infrastructure, and works with standard TCP senders. NS-2 simulations, as well as actual Internet experiments, show that our system achieves desired bandwidth allocation in a wide variety of scenarios including interfering cross-traffic. We also demonstrate the viability of our system in multimedia streaming applications over TCP.},
keywords={bandwidth allocation;Internet;multimedia communication;telecommunication congestion control;transport protocols;receiver-driven bandwidth sharing;Web-browsers;ftp applications;P2P programs;Internet traffic;last-hop access links;network applications;bottleneck link capacity;connection round-trip time;receiver-based control system;TCP flows;standard TCP senders;NS-2 simulations;Internet experiments;system bandwidth allocation;multimedia streaming applications;Bandwidth;Channel allocation;Internet;Streaming media;Peer to peer computing;Electronic mail;Application software;Telecommunication traffic;Control systems;Multimedia systems},
doi={10.1109/INFCOM.2003.1208951},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208952,
author={J. T. Wen and M. Arcak},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A unifying passivity framework for network flow control},
year={2003},
volume={2},
number={},
pages={1156-1166 vol.2},
abstract={Network flow control regulates the traffic between sources and links based on congestion, and plays a critical role in ensuring satisfactory performance. In recent studies, global stability has been shown for several flow control schemes. By using a passivity approach, this paper presents a unifying framework which encompasses these stability results as special cases. In addition, the new approach significantly expands the current classes of stable flow controllers by augmenting the source and link update laws with passive dynamic systems. This generality offers the possibility of optimizing the controllers, for example, to improve robustness and performance with respect to time delay, unmodeled flows, and capacity variation.},
keywords={optimisation;stability;telecommunication congestion control;unifying passivity framework;network flow control;congestion based-traffic regulation;stable flow controllers;source update laws;link update laws;passive dynamic systems;controller optimization;controller time delay;Robust stability;Routing;Aggregates;Constraint optimization;Control systems;Traffic control;Robust control;Delay effects;Steady-state;Lagrangian functions},
doi={10.1109/INFCOM.2003.1208952},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208953,
author={Ashwin Sridharan and R. Guerin and C. Diot},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Achieving near-optimal traffic engineering solutions for current OSPF/IS-IS networks},
year={2003},
volume={2},
number={},
pages={1167-1177 vol.2},
abstract={Traffic engineering is aimed at distributing traffic so as to "optimize" a given performance criterion. The ability to carry out such an optimal distribution depends on both the routing protocol and the forwarding mechanisms in use in the network. In IP networks running the OSPF or IS-IS protocols, routing is over shortest paths, and forwarding mechanisms are constrained to distributing traffic uniformly over equal cost shortest paths. These constraints often make achieving an optimal distribution of traffic impossible. In this paper, we propose and evaluate an approach, based on manipulating the set of next hops for routing prefixes, that is capable of realizing near optimal traffic distribution without any change to existing routing protocols and forwarding mechanisms. In addition, we explore the tradeoff that exists between performance and the overhead associated with the additional configuration steps that our solution requires. The paper's contributions are in formulating and evaluating an approach to traffic engineering for existing IP networks that achieves performance levels comparable to that offered when deploying other forwarding technologies such as MPLS.},
keywords={IP networks;routing protocols;telecommunication traffic;near-optimal traffic engineering solutions;OSPF/IS-IS networks;routing protocols;network forwarding mechanisms;IP networks;shortest path routing;optimal traffic distribution;MPLS technologies;traffic aggregation;Telecommunication traffic;Routing protocols;IP networks;Reliability engineering;Communication system traffic control;Costs;Multiprotocol label switching;Paper technology;Resource management;Web and internet services},
doi={10.1109/INFCOM.2003.1208953},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208954,
author={K. Papagiannaki and N. Taft and Z. -. Zhang and C. Diot},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Long-term forecasting of Internet backbone traffic: observations and initial models},
year={2003},
volume={2},
number={},
pages={1178-1188 vol.2},
abstract={We introduce a methodology to predict when and where link additions/upgrades have to take place in an IP backbone network. Using SNMP statistics, collected continuously since 1999, we compute aggregate demand between any two adjacent PoPs and look at its evolution at time scales larger than one hour. We show that IP backbone traffic exhibits visible long term trends, strong periodicities, and variability at multiple time scales. Our methodology relies on the wavelet multiresolution analysis and linear time series models. Using wavelet multiresolution analysis, we smooth the collected measurements until we identify the overall long-term trend. The fluctuations around the obtained trend are further analyzed at multiple time scales. We show that the largest amount of variability in the original signal is due to its fluctuations at the 12 hour time scale. We model inter-PoP aggregate demand as a multiple linear regression model, consisting of the two identified components. We show that this model accounts for 98% of the total energy in the original signal, while explaining 90% of its variance. Weekly approximations of those components can be accurately modeled with low-order autoregressive integrated moving average (ARIMA) models. We show that forecasting the long term trend and the fluctuations of the traffic at the 12 hour time scale yields accurate estimates for at least six months in the future.},
keywords={autoregressive moving average processes;computer network management;Internet;IP networks;telecommunication traffic;time series;IP backbone network;traffic long term forecasting;SNMP statistics;wavelet multiresolution analysis;linear time series models;fluctuations;inter-PoP aggregate demand;multiple linear regression model;low-order autoregressive integrated moving average;ARIMA models;98 percent;90 percent;Internet;Spine;Traffic control;Predictive models;Fluctuations;Telecommunication traffic;Aggregates;Wavelet analysis;Multiresolution analysis;Demand forecasting},
doi={10.1109/INFCOM.2003.1208954},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208955,
author={L. Li and M. Thottan and B. Yao and S. Paul},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Distributed network monitoring with bounded link utilization in IP networks},
year={2003},
volume={2},
number={},
pages={1189-1198 vol.2},
abstract={Designing optimal measurement infrastructure is a key step for network management. In this work we address the problem of optimizing a scalable distributed polling system. The goal of the optimization is to reduce the cost of deployment of the measurement infrastructure by identifying a minimum poller set subject to bandwidth constraints on the individual links. We show that this problem is NP-hard and propose three different heuristics to obtain a solution. We evaluate our heuristics on both hierarchical and flat topologies with different network sizes under different polling bandwidth constraints. We find that the heuristic of choosing the poller that can poll the maximum number of unpolled nodes is the best approach. Our simulation studies show that the results obtained by our best heuristic is close to the lower bound obtained using LP relaxation.},
keywords={computer network management;IP networks;optimisation;distributed network monitoring;bounded link utilization;IP networks;optimal measurement infrastructure design;network management;distributed polling system optimization;NP-hard problem;flat topologies heuristics evaluation;polling bandwidth constraints;LP relaxation;Monitoring;Intelligent networks;IP networks;Bandwidth;Quality of service;Resource management;Telecommunication traffic;Protocols;Hierarchical systems;Constraint optimization},
doi={10.1109/INFCOM.2003.1208955},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208956,
author={Sharad Jaiswal and G. Iannaccone and C. Diot and J. Kurose and D. Towsley},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Measurement and classification of out-of-sequence packets in a tier-1 IP backbone},
year={2003},
volume={2},
number={},
pages={1199-1209 vol.2},
abstract={We present a measurement study and classification methodology for out-of-sequence packets in TCP connections observed within the Sprint IP backbone. Such out-of-sequence packets can result from many causes including loss, looping, reordering, or duplication in the network. It is important to quantify and understand the causes of such out-of-sequence packets since they are one indication of the "health" of an end-end TCP connection. Our first contribution is methodological. Because we measure out-of-sequence packets at a single point in the backbone (rather than by sending and measuring end-end probe traffic at the sender or receiver), a new methodology is required to infer the causes of a connection's out-of-sequence packets based only on measurements taken in the "middle" of the connection. We thus describe techniques that classify the causes of observed out-of-sequence behavior based only on the previously- and subsequently-observed packets within a connection and knowledge of how TCP behaves. We show that using these simple techniques, it is possible to classify almost all out-of-sequence packets in our traces and that we can quantify the uncertainty in our classification. Our second contribution is the characterization of the out-of-sequence behavior itself. We analyze numerous several-hour packet-level traces from a set of OC-3 and OC-12 links for several million connections generated in nearly 4,300 unique ASs. Our measurements show a relatively consistent amount of out-of-sequence packets of approximately 5%. We find that few out-of-sequence packets result from pathological problems such as routing loops or in network duplication/reordering.},
keywords={IP networks;packet switching;transport protocols;out-of-sequence packets measurement;out-of-sequence packets classification;tier-1 IP backbone;end-end TCP connections;Sprint IP backbone;end-end probe traffic measurement;out-of-sequence behavior characterization;several-hour packet-level traces;OC-3 links set;OC-12 links set;routing loop problem;network duplication/reordering;Spine;TCPIP;Probes;Pathology;Routing;Internet;Instruments;Sampling methods},
doi={10.1109/INFCOM.2003.1208956},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208957,
author={M. Mandjes},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Pricing strategies under heterogeneous service requirements},
year={2003},
volume={2},
number={},
pages={1210-1220 vol.2},
abstract={This paper analyzes a communication network with heterogeneous customers. We investigate priority queueing as a way to differentiate between these users. Customers join the network as long as their utility (which is a function of the queueing delay) is larger than the price of the service. We focus on the specific situation in which two types of users play a role: one type is delay-sensitive ('voice'), whereas the other is delay-tolerant ('data'); these preferences are reflected in their utility curves. Two models are considered: in the first the network determines the priority class of the users, whereas the second model leaves this choice to the users. For both models we determine the prices that maximize the provider's profit. Importantly, these situations do not coincide. Our study uses elements from queueing theory, but also from microeconomics and game theory (e.g., the concept of a Nash equilibrium). We conclude the paper by considering a model in which throughput (rather than delay) is the main performance measure. Again the pricing strategy exploits the heterogeneity in required service and willingness-to-pay.},
keywords={customer satisfaction;game theory;integrated voice/data communication;Internet;packet switching;pricing;queueing theory;communication network;heterogeneous customers utility;priority class;queueing theory;delay-sensitive voice;delay-tolerant data;microeconomics;game theory;pricing strategy;differentiated services;Pricing;Delay;Microeconomics;Game theory;Internet;Telecommunication traffic;Traffic control;Communication networks;Queueing analysis;Nash equilibrium},
doi={10.1109/INFCOM.2003.1208957},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208958,
author={J. Shu and P. Varaiya},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Pricing network services},
year={2003},
volume={2},
number={},
pages={1221-1230 vol.2},
abstract={A game theoretic pricing mechanism for statistically guaranteed service in packet-switched networks is proposed. The mechanism provides congestion control, differentiated qualities of service, and efficient resource allocation. For users, the mechanism offers better quality and lower price. Service providers can base new service and revenue models within the mechanism. We apply this mechanism to the Internet.},
keywords={game theory;Internet;packet switching;pricing;quality of service;resource allocation;telecommunication congestion control;transport protocols;game theoretic pricing mechanism;packet-switched networks;congestion control;differentiated quality of service;resource allocation;service providers;Internet;transport protocols;Pricing;Quality of service;Game theory;Web and internet services;Costs;Delay;Industrial engineering;Operations research;Resource management;Bandwidth},
doi={10.1109/INFCOM.2003.1208958},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208959,
author={E. Campos-Nanez and S. D. Patek},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On-line tuning of prices for network services},
year={2003},
volume={2},
number={},
pages={1231-1241 vol.2},
abstract={Recent investigations into the pricing of multiclass loss networks have shown that static prices are optimal in the asymptotic regime of many small sources. These results suggest that nearly optimal prices for highly aggregated systems can be computed from the solution to a limiting deterministic optimization model. When the assumption of many small sources does not hold, static prices are still preferable (for practical reasons), but we are left with the difficult issue of computing an optimal solution when the stochastic nature of the process cannot be ignored. In this paper, we develop a computational procedure for optimizing static prices that operates by adjusting prices in response to actual customer arrivals and departures and is robust to parametric uncertainty about the underlying system. We provide initial arguments for the convergence properties of our optimization algorithm, and we illustrate its application in several numerical examples.},
keywords={Internet;optimisation;pricing;stochastic processes;multiclass loss networks;static prices;limiting deterministic optimization model;stochastic nature;computational procedure;actual customer arrivals;customer departures;convergence property;optimization algorithm;on-line tuning;small sources;Pricing;Systems engineering and theory;IP networks;Telecommunication traffic;Traffic control;Computer networks;Dynamic programming;Stochastic processes;Robustness;Uncertainty},
doi={10.1109/INFCOM.2003.1208959},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208960,
author={Y. Jin and G. Kesidis},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Nash equilibria of a generic networking game with applications to circuit-switched networks},
year={2003},
volume={2},
number={},
pages={1242-1249 vol.2},
abstract={A generic mechanism for end-user transmission rate control into a differentiated services Internet is formulated and basic results of corresponding Nash equilibria are proved. We consider specific examples of the mechanism including additive increase and multiplicative decrease inspired by present day TCP congestion control. For the example of users sharing access to a bandwidth resource via resizable provisioned label-switched paths (MPLS), we study the equilibria and the performance of the generic mechanism and give analytical results on convergence to equilibria. The fairness of the resulting equilibria when user demands exceed available network resources is also studied.},
keywords={circuit switching;convergence of numerical methods;game theory;Internet;multiprotocol label switching;telecommunication congestion control;transport protocols;generic networking game;end-user transmission rate control;differentiated services;Internet;Nash equilibria;TCP congestion control;bandwidth resource;resizable provisioned label-switched paths;network resources;multiprotocol label switching;convergence;Circuits;Bandwidth;Multiprotocol label switching;Convergence;Internet;Pricing;Access control;Application software;Computer science;IP networks},
doi={10.1109/INFCOM.2003.1208960},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208961,
author={Prasanna Ganesan and Q. Sun and H. Garcia-Molina},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={YAPPERS: a peer-to-peer lookup service over arbitrary topology},
year={2003},
volume={2},
number={},
pages={1250-1260 vol.2},
abstract={Existing peer-to-peer search networks generally fall into two categories: Gnutella-style systems that use arbitrary topology and rely on controlled flooding for search, and systems that explicitly build an underlying topology to efficiently support a distributed hash table (DHT). In this paper, we propose a hybrid scheme for building a peer-to-peer lookup service over arbitrary network topology. Specifically, for each node in the search network, we build a small DHT consisting of nearby nodes and then provide an intelligent search mechanism that can traverse all the small DHTs. Our hybrid approach can reduce the nodes contacted for a lookup by an order of magnitude compared to Gnutella, allows rapid searching of nearby nodes through quick fan-out, does not reorganize the underlying overlay, and isolates the effect of topology changes to small areas for better scalability and stability.},
keywords={information retrieval;Internet;network topology;search problems;peer-to-peer search network;Gnutella-style system;Yet Another Peer-to-Peer System;arbitrary network topology;controlled flooding;underlying topology;distributed hash table;peer-to-peer lookup service;intelligent search mechanism;YAPPERS;Internet;system design;Peer to peer computing;Network topology;Bandwidth;Control systems;Iterative algorithms;Floods;Sun;Computer science;Intelligent networks;Scalability},
doi={10.1109/INFCOM.2003.1208961},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208962,
author={E. Cohen and A. Fiat and H. Kaplan},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Associative search in peer to peer networks: harnessing latent semantics},
year={2003},
volume={2},
number={},
pages={1261-1271 vol.2},
abstract={The success of a P2P file-sharing network highly depends on the scalability and versatility of its search mechanism. Two particularly desirable search features are scope (ability to find infrequent items) and support for partial-match queries (queries that contain typos or include a subset of keywords). While centralized-index architectures (such as Napster) can support both these features, existing decentralized architectures seem to support at most one: prevailing unstructured P2P protocols (such as Gnutella and FastTrack) deploy a "blind" search mechanism where the set of peers probed is unrelated to the query; thus they support partial-match queries but have limited scope. On the other extreme, the recently-proposed distributed hash tables (DHTs) such as CAN and CHORD, couple index location with the item's hash value, and thus have good scope but can not effectively support partial-match queries. Another hurdle to DHTs deployment is their tight control of the overlay structure and the information (part of the index) each peer maintains, which makes them more sensitive to failures and frequent joins and disconnects. We develop a new class of decentralized P2P architectures. Our design is based on unstructured architectures such as gnutella and FastTrack, and retains many of their appealing properties including support for partial match queries, and relative resilience to peer failures. Yet, we obtain orders of magnitude improvement in the efficiency of locating rare items. Our approach exploits associations inherent in human selections to steer the search process to peers that are more likely to have an answer to the query. We demonstrate the potential of associative search using models, analysis, and simulations.},
keywords={file organisation;information retrieval;Internet;protocols;search problems;peer to peer file-sharing network;scalability;versatility;infrequent items;partial-match queries;centralized-index architectures;Napster;decentralized peer to peer architectures;peer to peer protocol;Gnutella;FastTrack;blind search mechanism;distributed hash tables;overlay structure;associative search;latent semantics;Intelligent networks;Peer to peer computing;Computer architecture;Scalability;Probes;Protocols;Resilience;Humans;Analytical models;IP networks},
doi={10.1109/INFCOM.2003.1208962},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208963,
author={S. Lee and R. Sherwood and Bobby Bhattacharjee},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Cooperative peer groups in NICE},
year={2003},
volume={2},
number={},
pages={1272-1282 vol.2},
abstract={A distributed scheme for trust inference in peer-to-peer networks is presented. Our work is in context of the NICE system, which is a platform for implementing cooperative applications over the Internet. We describe a technique for efficiently storing user reputation information in a completely decentralized manner, and show how this information can be used to efficiently identify noncooperative users in NICE. We present a simulation based study of our algorithms, in which we show our scheme scales to thousands of users using modest amounts of storage, processing, and bandwidth at any individual node. Lastly, we show that our scheme is robust and can form cooperative groups in systems where the vast majority of users are malicious.},
keywords={inference mechanisms;information retrieval;Internet;peer-to-peer networks;NICE system;platform;cooperative system;Internet;reputation information storage;decentralized manner;noncooperative users identification;individual node;distributed algorithm;malicious users;trust inference;Peer to peer computing;Internet;Cooperative systems;Inference algorithms;Bandwidth;Resource management;Streaming media;Intelligent networks;Computer science;Educational institutions},
doi={10.1109/INFCOM.2003.1208963},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208964,
author={D. A. Tran and K. A. Hua and T. Do},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={ZIGZAG: an efficient peer-to-peer scheme for media streaming},
year={2003},
volume={2},
number={},
pages={1283-1292 vol.2},
abstract={A peer-to-peer technique called ZIGZAG for single-source media streaming is designed . ZIGZAG allows the media server to distribute content to many clients by organizing them into an appropriate tree rooted at the server. This application-layer multicast tree has a height logarithmic with the number of clients and a node degree bounded by a constant. This helps reduce the number of processing hops on the delivery path to a client while avoiding network bottleneck. Consequently, the end-to-end delay is kept small. Although one could build a tree satisfying such properties easily, an efficient control protocol between the nodes must be in place to maintain the tree under the effects of network dynamics and unpredictable client behaviors. ZIGZAG handles such situations gracefully requiring a constant amortized control overhead. Especially, failure recovery can be done regionally with little impact on the existing clients and mostly no burden on the server.},
keywords={client-server systems;computer network reliability;Internet;multicast protocols;multimedia communication;trees (mathematics);peer-to-peer technique;zigzag;single-source media stream;media server;application-layer multicast tree;height logarithmic;node degree;processing hops reduction;network bottleneck;end-to-end delay;control protocol;network dynamics;unpredictable client behavior;Streaming media;Peer to peer computing;Delay;Computer science;Bandwidth;Network servers;Internet;Organizing;Protocols;Web server},
doi={10.1109/INFCOM.2003.1208964},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208965,
author={Y. Zou and Krishnendu Chakrabarty},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Sensor deployment and target localization based on virtual forces},
year={2003},
volume={2},
number={},
pages={1293-1303 vol.2},
abstract={The effectiveness of cluster-based distributed sensor networks depends to a large extent on the coverage provided by the sensor deployment. We propose a virtual force algorithm (VFA) as a sensor deployment strategy to enhance the coverage after an initial random placement of sensors. For a given number of sensors, the VFA algorithm attempts to maximize the sensor field coverage. A judicious combination of attractive and repulsive forces is used to determine virtual motion paths and the rate of movement for the randomly-placed sensors. Once the effective sensor positions are identified, a one-time movement with energy consideration incorporated is carried out, i.e., the sensors are redeployed to these positions. We also propose a novel probabilistic target localization algorithm that is executed by the cluster head. The localization results are used by the cluster head to query only a few sensors (out of those that report the presence of a target) for more detailed information. Simulation results are presented to demonstrate the effectiveness of the proposed approach.},
keywords={protocols;radio direction-finding;statistical analysis;wireless sensor networks;cluster-based distributed sensor networks;virtual force algorithm;sensor deployment strategy;sensor field coverage;attractive forces;repulsive forces;virtual motion paths;randomly-placed sensors;energy consideration;probabilistic target localization algorithm;sensor position identification;Clustering algorithms;Head;Force sensors;Surveillance;Object detection;Costs;Resource management;Robot sensing systems;Protocols;Event detection},
doi={10.1109/INFCOM.2003.1208965},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208966,
author={H. Zhou and L. M. Ni and M. W. Mutka},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Prophet address allocation for large scale MANETs},
year={2003},
volume={2},
number={},
pages={1304-1311 vol.2},
abstract={A mobile device in a MANET must be assigned a free IP address before it may participate in unicast communication. This is a fundamental and difficult problem in the practical use of any MANET. Several solutions have been proposed. However, these approaches have different drawbacks. A new IP address allocation algorithm, namely prophet allocation, is proposed in the paper. The proposed scheme may be applied to large scale MANETs with low complexity, low communication overhead, even address distribution, and low latency. Both theoretical analysis and simulation experiments are conducted to demonstrate the superiority of the proposed algorithm over other known algorithms. Moreover, the proposed prophet allocation is able to solve the problem of network partition and merger efficiently.},
keywords={ad hoc networks;IP networks;mobile radio;prophet address allocation;large scale mobile ad-hoc network;mobile device;unicast communication;mobile ad-hoc networks;MANET;IP address allocation algorithm;communication overhead;even address distribution;simulation experiment;network partition problem solving;autoconfiguration algorithm;network merger problem solving;Large-scale systems;Mobile ad hoc networks;Mobile communication;Computer science;Unicast;Partitioning algorithms;Mobile computing;Delay;Algorithm design and analysis;Analytical models},
doi={10.1109/INFCOM.2003.1208966},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208967,
author={J. Yoon and M. Liu and B. Noble},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Random waypoint considered harmful},
year={2003},
volume={2},
number={},
pages={1312-1321 vol.2},
abstract={This study examines the random waypoint model widely used in the simulation studies of mobile ad hoc networks. Our findings show that this model fails to provide a steady state in that the average nodal speed consistently decreases over time, and therefore should not be directly used for simulation. We show how unreliable results can be obtained by using this model. In particular, certain ad hoc routing metrics can drop by as much as 40% over the course of a 900-second simulation using the random waypoint model. We give both an intuitive and a formal explanation for this phenomenon. We also propose a simple fix of the problem and discuss a few alternatives. Our modified random waypoint model is able to reach a steady state and simulation results are presented.},
keywords={ad hoc networks;mobile radio;telecommunication network routing;mobile ad hoc network;ad hoc routing metric;modified random waypoint model;average nodal speed;Steady-state;Computational modeling;Routing;Protocols;Mobile computing;Predictive models;Computer simulation;Mobile ad hoc networks;Analytical models;Stability},
doi={10.1109/INFCOM.2003.1208967},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208968,
author={J. -. Lapeyrie and T. Turletti},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={FPQ: a fair and efficient polling algorithm with QoS support for Bluetooth Piconet},
year={2003},
volume={2},
number={},
pages={1322-1332 vol.2},
abstract={Bluetooth is an emerging standard for short range, low cost, low power wireless access technology. The Bluetooth technology is just starting to appear on the market and there is an urgent need to enable new applications with real time constraints to run on top of Bluetooth devices. The Bluetooth Specification proposes a Round Robin scheduler as possible solution for scheduling the transmissions in a Bluetooth Piconet. However, this basic scheme performs badly under asymmetric traffic conditions. Recently, several polling schemes have been proposed to improve performance on asymmetric transmissions and to support bandwidth guarantee. However, there is no solution available to support both delay and bandwidth guarantees required by real time applications. In this paper, we present FPQ, a new polling algorithm for Bluetooth Piconet that supports both delay and bandwidth guarantees and aims to remain fair and efficient with asymmetric flow rates. We present an extensive set of simulations and provide performance comparisons with other polling algorithms. Our performance study indicates that FPQ, while supporting flow rate and maximum delay QoS requests, outperforms Deficit Round Robin in term of delays by at least 10% in all cases, sometimes by more than 30% to 50%. Moreover, FPQ was designed to take the specifics of Bluetooth into consideration, in particular the low complexity required for cheap implementation.},
keywords={Bluetooth;quality of service;radio access networks;scheduling;fair polling algorithm;efficient polling algorithm;Bluetooth Piconet;short range wireless access technology;low power wireless access technology;Bluetooth technology;Bluetooth device;asymmetric transmission;bandwidth guarantee;asymmetric flow rate;maximum delay QoS request;Bluetooth;Personal area networks;Master-slave;Baseband;Bandwidth;Delay;Round robin;Access protocols;Costs;Job shop scheduling},
doi={10.1109/INFCOM.2003.1208968},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208969,
author={Swarup Acharya and Bhawna Gupta and Pankaj Risbood and Anurag Srivastava},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={IP-subnet aware routing in WDM mesh networks},
year={2003},
volume={2},
number={},
pages={1333-1343 vol.2},
abstract={The problem of routing bandwidth guaranteed paths in wavelength-routed, WDM optical mesh networks is explored. A WDM mesh network offers great flexibility in dynamically reconfiguring the optical core to match the IP layer demands. In this paper, we argue that IP subnets can limit the reconfigurability potential of the WDM mesh network. We show that finding the shortest IP-hop path, normally admitting a straightforward polynomial solution on the WDM mesh, is NP-hard in the presence of subnets. We propose a new algorithm called MobiTwist that finds the optimal shortest path when accounting for subnets. We also observe that subnets impose a routing penalty by forcing longer paths for bandwidth demands. Consequently, they create a trade-off between lower network efficiency if subnets are honored (due to longer paths) or, an upfront overhead of dynamically changing subnets to derive shorter paths. We propose the MobiFlex algorithm that attempts to achieve a balance by finding the shortest path given an upper limit on the number of subnet violations acceptable. The inherent hardness of the routing problem due to subnets precludes a solution with low worst-case complexity. However, we present performance results that show that both the algorithms proposed are extremely efficient in routing demands, and in practice, do so in polynomial time.},
keywords={IP networks;optical communication;optimisation;telecommunication network routing;wavelength division multiplexing;IP-subnet aware routing;routing bandwidth guaranteed path;wavelength-routed optical mesh network;WDM optical mesh network;optical core dynamical reconfiguration;IP layer demand;NP-hard;MobiTwist algorithm;optimal shortest path;routing penalty;bandwidth demand;lower network efficiency;dynamically changing subnet upfront overhead;shortest IP-hop path;MobiFlex algorithm;acceptable subnet violations;low worst-case complexity solution;routing demand;polynomial time;IP networks;Routing;Intelligent networks;Wavelength division multiplexing;WDM networks;Mesh networks;High speed optical techniques;Multiprotocol label switching;Optical fiber networks;Bandwidth;Optical interconnections},
doi={10.1109/INFCOM.2003.1208969},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208970,
author={R. Izmailov and Samrat Ganguly and V. Kleptsyn and A. C. Varsou},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Nonuniform waveband hierarchy in hybrid optical networks},
year={2003},
volume={2},
number={},
pages={1344-1354 vol.2},
abstract={Aggregation of individual wavelengths into wavebands for their subsequent switching and routing as a single group is an attractive way for scalable and cost-efficient optical networks. We analyze the implications of this waveband hierarchy for a single optical node by analyzing two issues: the proper selection of waveband sizes and the assignment of wavebands for a limited set of input-output patterns of traffic. We formulate a general model and propose optimal algorithmic solutions for both problems. The performance of resulting sets of nonuniform wavebands is studied for several representative cases (a single node, an optical ring network, an optical mesh network). The results demonstrate improved optical throughput and reduced cost of switching and routing when using nonuniform waveband hierarchy.},
keywords={optical fibre networks;telecommunication network routing;telecommunication switching;telecommunication traffic;hybrid cost-efficient optical network;nonuniform waveband hierarchy;individual wavelength aggregation;scalable optical network;single optical node;waveband size selection;waveband assignment;input-output traffic pattern;optimal algorithmic solution;optical ring network;optical mesh network;improved optical throughput;switching cost reduction;routing cost reduction;Intelligent networks;Optical fiber networks;Optical network units;Telecommunication traffic;Wavelength routing;Costs;Wavelength division multiplexing;Pattern analysis;Traffic control;Mesh networks},
doi={10.1109/INFCOM.2003.1208970},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208971,
author={C. Nomikos and A. Pagourtzis and S. Zachos},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Minimizing request blocking in all-optical rings},
year={2003},
volume={2},
number={},
pages={1355-1361 vol.2},
abstract={In all-optical networks that use WDM technology it is often the case that several communication requests have to be blocked, due to bandwidth and technology limitations. Minimizing request blocking is therefore an important task calling for algorithmic techniques for efficient routing and wavelength assignment. Here we study the problem for rings under both the undirected and the directed settings, corresponding to symmetric and one-way communication respectively. The problem in graph-theoretic terms can be formulated as the maximum routing and path coloring problem. We present a chain-and-matching technique for routing requests and coloring the corresponding paths which gives constant approximations for both the undirected and the directed cases. For the undirected problem we obtain a 2/3-approximation algorithm; this corresponds to a considerable increase in the number of satisfied requests compared to the best known algorithm so far, due to Wan and Liu (1998), that achieves a 1 - 1/e ratio using iteratively a maximum edge-disjoint paths algorithm. For the directed case, we also introduce a balanced matching method which, combined with the chain-and-matching technique, gives a 7/11-approximation algorithm. This algorithm also improves upon the (1 $1/e)-approximation algorithm that can be obtained by extending the iterative method of Wan and Liu.},
keywords={graph colouring;optical fibre networks;telecommunication network routing;wavelength division multiplexing;all-optical ring network;WDM technology;communication request blocking minimization;bandwidth limitation;routing assignment;wavelength assignment;undirected communication;directed communication;symmetric communication;one-way communication;graph-theoretic term;maximum routing and path coloring problem;chain-and-matching technique;routing request;2/3-approximation algorithm;balanced matching method;7/11-approximation algorithm;Iterative algorithms;Routing;Computer science;Wavelength division multiplexing;Approximation algorithms;All-optical networks;Iterative methods;Optical fiber networks;Mathematics;Computational Intelligence Society},
doi={10.1109/INFCOM.2003.1208971},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208972,
author={G. Liu and C. Ji and V. Chan},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Network management information for light-path assessment: trade-off between performance and complexity},
year={2003},
volume={2},
number={},
pages={1362-1372 vol.2},
abstract={Network management information for light-path assessment to dynamically set up end-to-end lightpaths across administrative domains is investigated. Our focus is on investigating what performance can be possibly achieved given partial management information, and whether a small loss in performance can trade off with a large saving in management information. The partial information we consider includes aggregated characterization of subnetworks, and local states from wavelength converters. We cast the light-path assessment as a decision problem, and define the performance as the probability of an erroneous decision. We apply the decision theory to show that the optimal performance using the partial information is the Bayes probability of error. We derive an upper bound of the Bayes error in terms of the blocking probability. We evaluate the upper bound using both independent and dependent models of wavelength usage. Our study shows that there exits a "threshold effect": the Bayes error decreases exponentially to 0 with respect to the load when the load is either below or above a threshold value; and is nonnegligible when the load is in a small duration around the threshold. This suggests that a small percentage of error decisions can trade off with a large saving in management information.},
keywords={Bayes methods;decision theory;error statistics;optical fibre networks;telecommunication network management;network management information;light-path assessment;end-to-end lightpath;administrative domain;partial management information;performance loss;subnetwork aggregated characterization;wavelength converter local state;decision problem;erroneous decision probability;decision theory;optimal performance;Bayes error probability;Bayes error upper bound evaluation;optical fiber networks;blocking probability;wavelength usage independent model;wavelength usage dependent model;threshold effect;threshold value;error decision percentage;Bayes rule;Information management;Optical wavelength conversion;Computer network management;Cloud computing;Computer networks;Decision theory;Optical fiber networks;Protection;Wavelength measurement;Network topology},
doi={10.1109/INFCOM.2003.1208972},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208973,
author={S. Sarkar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimum scheduling and memory management in input queued switches with finite buffer space},
year={2003},
volume={2},
number={},
pages={1373-1383 vol.2},
abstract={This paper addresses scheduling and memory management in input queued switches with finite input buffers, with the objective of minimizing packet loss. The framework and algorithms proposed here apply to buffer constrained wireless networks as well. The scheduling problem has been extensively addressed under the assumption of infinite input buffers. We study the finite buffer case here which arises in practice. The introduction of memory constraint significantly complicates the problem. The optimal strategies for infinite buffer case no longer apply and become strictly suboptimal in presence of memory limitations. We present closed form optimal strategies which minimize packet loss in 2 × 2 switches with equal arrival rates for all streams. We identify certain characteristics of the optimal strategy for arbitrary arrival rates, and use these properties to design a near optimal heuristic. We use the insight obtained from the investigation for 2 × 2 switches to propose a heuristic for N × N switches, arbitrary N and show numerically that this strategy performs close to optimal. The policies presented here reduce packet loss by about 25% as compared to the optimal strategy for the infinite buffer case.},
keywords={buffer storage;packet switching;queueing theory;scheduling;optimum scheduling;memory management;input queued switch;finite input buffer space;packet loss minimization;buffer constrained wireless network;closed form optimal strategy;2 × 2 switch;equal packet arrival rate;arbitrary packet arrival rate;N × N switch;Memory management;Switches;Packet switching;Resource management;Indium phosphide;Processor scheduling;Throughput;Performance loss;Scheduling algorithm;Wireless networks},
doi={10.1109/INFCOM.2003.1208973},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208974,
author={I. Keslassy and Murali Kodialam and T. V. Lakshman and D. Stiliadis},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On guaranteed smooth scheduling for input-queued switches},
year={2003},
volume={2},
number={},
pages={1384-1394 vol.2},
abstract={Input-queued switches are used extensively in the design of high-speed routers. As switch speeds and sizes increase, the design of the switch scheduler becomes a primary challenge, because the time interval for the matching computations needed for determining switch configurations becomes very small. Possible alternatives in scheduler design include increasing the scheduling interval by using envelopes, and using a frame-based scheduler that guarantees fixed rates between input-output pairs. However, both these alternatives have significant jitter drawbacks: the jitter increases with the envelope size in the first alternative, and previously-known methods do not guarantee tight jitter bounds in the second. In this paper, we propose a hybrid approach to switch scheduling. Traffic with tight jitter constraints is first scheduled using a frame-based scheduler that achieves low jitter bounds. Jitter-insensitive traffic is later scheduled using an envelope-based scheduler. The main contribution of this paper is a scheduler design for generating low-jitter schedules. The scheduler uses a rate matrix decomposition designed for low jitter and different from the minimum-bandwidth Birkhoff-Von Neumann (BV) decomposition. In addition to generating low-jitter schedules, this decomposition yields fewer switch configuration matrices (O(n)) than the BV decomposition (O(n<sup>2</sup>)), and so uses far less high-speed switch memory. We develop an efficient algorithm for decomposing the rate matrix and for scheduling the permutation matrices. We prove that our low-jitter algorithm has an O(log n) factor bound on its bandwidth consumption in comparison to the minimum-bandwidth BV decomposition. Experimentally, we find that the bandwidth increase in practice is much lower than the theoretical bound. We also prove several related performance bounds for our scheduler. Finally, we propose a practical bandwidth-guaranteed algorithm, and show how our findings could even be extended to systems with large tuning time.},
keywords={jitter;matrix decomposition;queueing theory;scheduling;telecommunication switching;input-queued switch;guaranteed smooth scheduling;high-speed router;switch speed;switch size;switch scheduler design;matching computation time interval;switch configuration matrix;frame-based scheduler;switch scheduling;tight jitter constraint traffic;low jitter bound;jitter-insensitive traffic;envelope-based scheduler;low-jitter schedule generation;rate matrix decomposition;high-speed switch memory;permutation matrix scheduling;low-jitter algorithm;bandwidth consumption;bandwidth increase;bandwidth-guaranteed algorithm;large tuning time system;Switches;Processor scheduling;Jitter;Matrix decomposition;Scheduling algorithm;Bandwidth;Traffic control;Fabrics;Circuits;Laboratories},
doi={10.1109/INFCOM.2003.1208974},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208975,
author={M. A. Marsan and P. Giaccone and E. Leonardi and F. Neri},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Local scheduling policies in networks of packet switches with input queues},
year={2003},
volume={2},
number={},
pages={1395-1405 vol.2},
abstract={A significant research effort has been devoted in recent years to the design of simple and efficient scheduling policies for input queued (IQ) and combined input output queued (CIOQ) packet switches. As a result, a number of switch control algorithms have been proposed. Among these, scheduling policies based on maximum weight matching (MWM) were identified as optimal, in the sense that they were proved to achieve 100% throughput under any admissible arrival process satisfying the strong law of large number. On the contrary, it has been recently shown that the usual MWM policies fail to guarantee 100% throughput in networks of interconnected IQ/CIOQ switches. Hence, new policies suited for networks of interconnected switches were proposed and proved to achieve 100% throughput. All of these new policies require coordination and cooperation among different switches. In this paper we address the open problem of the existence of local scheduling policies that guarantee 100% throughput in a network of IQ/CIOQ switches, providing a positive answer to such question. The only assumptions on the input traffic are that it satisfies the strong law of large numbers and that it does not oversubscribe any link in the network.},
keywords={packet switching;queueing theory;scheduling;switching networks;local scheduling policy;packet switch network;input queue;combined input output queued packet switch;switch control algorithm;maximum weight matching policy;network throughput;interconnected queue switch;switch coordination;network input traffic;Intelligent networks;Packet switching;Switches;Throughput;Scheduling algorithm;Traffic control;Fabrics;Computational complexity;Telecommunication traffic;Asynchronous transfer mode},
doi={10.1109/INFCOM.2003.1208975},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208976,
author={V. Tabatabaee and L. Tassiulas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={MNCM a new class of efficient scheduling algorithms for input-buffered switches with no speedup},
year={2003},
volume={2},
number={},
pages={1406-1413 vol.2},
abstract={In this paper, we use fluid model techniques to establish some new results for the throughput of input-buffered switches. In particular, we introduce a new class of deterministic maximal size matching algorithms that achieves 100% throughput. Dai and Prabhakar (2000) has shown that any maximal size matching algorithm with speedup of 2 achieves 100% throughput. We introduce a class of maximal size matching algorithms that we call them maximum node containing matching (MNCM) algorithms, and prove that they have 100% throughput with no speedup. We also introduce a new weighted matching algorithm, maximum first matching (MFM) with complexity O(N<sup>2.5</sup>) that belongs to MNCM. MFM, to the best of our knowledge, is the lowest complexity deterministic algorithm that delivers 100% throughput. The only assumption on the input traffic is that it satisfies the strong law of large numbers. Besides throughput, average delay is the other key performance metric for the input-buffered schedulers. We use simulation results to compare and study the delay performance of MFM. The simulation results demonstrate promising delay performance for MFM.},
keywords={buffer storage;delays;packet switching;queueing theory;scheduling;telecommunication traffic;maximum node containing matching algorithm;efficient scheduling algorithm;input-buffered switch throughput;fluid model technique;deterministic maximal size matching algorithm;weighted matching algorithm;maximum first matching;complexity deterministic algorithm;input traffic;input-buffer average delay;input-buffered scheduler;Scheduling algorithm;Throughput;Delay;Magnetic force microscopy;Fabrics;Optical switches;Educational institutions;Traffic control;Internet;Stability},
doi={10.1109/INFCOM.2003.1208976},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208977,
author={Yong Cui and Ke Xu and Jianping Wu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Precomputation for multiconstrained QoS routing in high-speed networks},
year={2003},
volume={2},
number={},
pages={1414-1424 vol.2},
abstract={As one of the most challenging problems of the next-generation high-speed networks, quality-of- service routing (QoSR) with multiple (k) constraints is an NP-complete problem. In this paper, we propose a multiconstrained energy function-based precomputation algorithm, MEFPA. It cares each QoS weight to b degrees, and computes a number (B= C<sub>b+k-2</sub><sup>k-1</sup>) of coefficient vectors uniformly distributed in the k-dimensional QoS metric space to construct B linear energy functions. Using each LEF, it then converts k QoS constraints to a single energy value. At last, it uses Dijkstra's algorithm to create B least energy trees, based on which the QoS routing table is created. We first analyze the performance of energy functions with k constraints, and give the method to determine the feasible and unfeasible areas for QoS requests in the k-dimensional QoS metric space. We then introduce our MEFPA for k-constrained routing with the computation complexity of O(B(m+n+nlogn)). Extensive simulations show that, with few coefficient vectors, this algorithm performs well in both absolute performance and competitive performance. In conclusion, for its high scalability, high performance and simplicity, MEFPA is a promising QoSR algorithm in the next-generation high-speed networks.},
keywords={computational complexity;internetworking;network routing;performance evaluation;quality of service;multiconstrained QoS routing precomputation;high-speed network;quality-of- service routing algorithm;NP-complete problem;multiconstrained energy function-based precomputation algorithm;b degree QoS;vector coefficient;k-dimensional QoS metric space;B linear energy function;k QoS constraint;single energy value;Dijkstra algorithm;B least energy tree;QoS routing table;QoS request;computation complexity;high routing scalability;high routing performance evaluation;Routing;High-speed networks;Next generation networking;Extraterrestrial measurements;NP-complete problem;Distributed computing;Vectors;Performance analysis;Computational modeling;Scalability},
doi={10.1109/INFCOM.2003.1208977},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208978,
author={F. A. Kuipers and P. Van Mieghem},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={The impact of correlated link weights on QoS routing},
year={2003},
volume={2},
number={},
pages={1425-1434 vol.2},
abstract={Finding a path in a network based on multiple constraints (the MCP problem) is often referred to as QoS routing. QoS routing with constraints on multiple additive metrics has been proven to be NP-complete. This proof has dramatically influenced the research community, resulting in the common belief that exact QoS routing is intractable in practice. Hence, many heuristics for this problem were proposed, while hardly any exact algorithms. However, to our best knowledge, no one has ever examined which "worst-cases" cause NP-complete behavior. In fact, the MCP problem is not strong NP-complete, suggesting that in practice an exact QoS algorithm may work in polynomial time, making guaranteed QoS routing possible. The goal of this paper is to provide some properties and simulation results that indicate that NP-complete behavior hinges on a specific correlation structure between the link weights, which will be hardly ever encountered in practice.},
keywords={computational complexity;quality of service;telecommunication network routing;correlated link weight;QoS routing;network path finding;multiconstrained path problem;multiple additive metric;NP-complete problem;QoS algorithm;polynomial time;Quality of service;Routing protocols;Additives;Internet;Bandwidth;Delay;Jitter;Network topology;Loss measurement;Maximum likelihood detection},
doi={10.1109/INFCOM.2003.1208978},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208979,
author={Y. Bejerano and Y. Breitbart and A. Orda and Rajeev Rastogi and A. Sprintson},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Algorithms for computing QoS paths with restoration},
year={2003},
volume={2},
number={},
pages={1435-1445 vol.2},
abstract={There is a growing interest among service providers to offer new services with quality of service (QoS) guaranties that are also resilient to failures. Supporting QoS connections requires the existence of a routing mechanism, that computes the QoS paths, i.e., paths that satisfy QoS constraints (e.g., delay or bandwidth). Resilience to failures, on the other hand, is achieved by providing, for each primary QoS path, a set of alternative QoS paths used upon a failure of either a link or a node. The above objectives, coupled with the need to minimize the global use of network resources, imply that the cost of both the primary path and the restoration topology should be a major consideration of the routing process. We undertake a comprehensive study of problems related to finding suitable restoration topologies for QoS paths. We consider both bottleneck QoS constraints, such as bandwidth, and additive QoS constraints, such as delay and jitter. This is the first study to provide a rigorous solution, with proven guarantees, to the combined problem of computing QoS paths with restoration. It turns out that the widely used approach of disjoint primary and restoration paths is not an optimal strategy. Hence, the proposed algorithms construct a restoration topology, i.e., a set of bridges, each bridge protecting a portion of the primary QoS path. This approach guaranties to find a restoration topology with low cost when one exists. In addition to analysis, we test our approach also by way of simulations. The simulation results demonstrate that our proposed approximation algorithms identify QoS restoration paths whose cost is significantly smaller than those provided by alternative approaches.},
keywords={computational complexity;network topology;quality of service;telecommunication network reliability;telecommunication network routing;QoS path computing algorithm;QoS restoration path;service provider;quality of service;QoS connection;routing mechanism;bottleneck QoS constraint;QoS bridge;primary QoS path;path link failure;path node failure;network resource;restoration topology;Qos routing process;additive QoS constraint;restricted shortest path;approximation algorithm;Quality of service;Costs;Routing;Delay;Bandwidth;Network topology;Bridges;Resilience;Jitter;Protection},
doi={10.1109/INFCOM.2003.1208979},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208980,
author={S. L. Spitler and D. C. Lee},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Integrating effective-bandwidth-based QoS routing and best effort routing},
year={2003},
volume={2},
number={},
pages={1446-1455 vol.2},
abstract={A methodology is presented for integrating effective-bandwidth-based routing for QoS-sensitive traffic and datagram routing of the best-effort traffic. To prevent excessive delays of best-effort traffic in a network domain, we develop (1) a constraint, stated in the form of a residual link bandwidth, and (2) a cost function for application to routing of QoS connections. Link-based and path-based problem formulations and algorithms are presented. For the case that a cost quantization condition holds, we develop an efficient implementation of a link-based routing strategy that first minimizes a QoS cost, then secondarily minimizes a best-effort cost. The performance of this approach is further enhanced by explicitly accounting for the difference between the effective bandwidth and the average bandwidth of traffic. Simulation results illustrate the application of our BE-friendly method to an algorithm for path routing with restoration.},
keywords={IP networks;multiprotocol label switching;quality of service;telecommunication network routing;telecommunication traffic;effective-bandwidth-based QoS routing integrating;best effort routing;QoS-sensitive traffic;datagram routing;residual link bandwidth;QoS connection;link-based problem formulation;path-based problem formulation;cost quantization condition;link-based routing strategy;QoS cost function;best-effort cost;best effort-friendly method application;path routing;quality of service;path restoration;dynamic routing;constraint-based routing;MPLS;best-effort traffic;Routing;Quality of service;Telecommunication traffic;Bandwidth;Multiprotocol label switching;Traffic control;Delay;Cost function;Quantization;Web and internet services},
doi={10.1109/INFCOM.2003.1208980},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208981,
author={T. Ho and M. Medard and R. Koetter},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={An information theoretic view of network management},
year={2003},
volume={2},
number={},
pages={1456-1466 vol.2},
abstract={We present an information theoretic framework for network management for recovery from nonergodic link failures. Building on recent work in the field of network coding, we describe the input-output relations of network nodes in terms of network codes. This very general concept of network behavior as a code provides a fundamental way to quantify essential management information as that needed to switch among different codes (behaviors) for different failure scenarios. We give bounds on the network management information needed for link failure recovery in various network connection problems, in terms of basic parameters such as the number of source processes and the number of links in a minimum source-receiver cut. This is the first paper to our knowledge that looks at network management for general connections.},
keywords={codes;telecommunication links;telecommunication network management;telecommunication network reliability;information theoretic view framework;network management;nonergodic link failure;network coding field;network input-output relation;network node;link failure recovery;network connection problem;source process;minimum source-receiver links;Network coding;Switches;Information management;Robustness;Switching circuits;Packet switching;Knowledge management;Spine;Protection;Routing},
doi={10.1109/INFCOM.2003.1208981},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208982,
author={R. Bush and T. G. Griffin},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Integrity for virtual private routed networks},
year={2003},
volume={2},
number={},
pages={1467-1476 vol.2},
abstract={The term virtual private network (VPN) encompasses a wide array of diverse technologies and network architectures. All VPNs should provide users with the isolation and security associated with private networks, but at lower costs made possible by implementing these networks over some type of shared infrastructure. Provider provisioned VPN allow enterprises to outsource their private backbone networks to service providers. For this reason, we will also refer to them as virtual private routed networks (VPRNs). This contrasts with other VPN technologies that require customers to manage their own point-to-point connections (leased lines or tunnels) and associated network administration. One type of VPRN currently being deployed is described in RFC 2547, which uses BGP to propagate routing information for all VPNs implemented within a provider's backbone, and a tunneling technology, such as MPLS, to isolate traffic. This technology requires fairly complex configurations within the backbone, and so poses challenges to providers supporting a large number of VPN customers. We present a formal analysis of several configuration and implementation concerns for VPRNs of the RFC 2547 variety. In particular, we focus on integrity constraints that must be maintained by providers in order to ensure that intraVPRN connectivity is achieved, and that disjoint VPRNs are isolated from each other.},
keywords={Internet;telecommunication network routing;telecommunication security;virtual private networks;virtual private routed network integrity;network diverse technology;network architecture;virtual private network;private network isolation;private network security;network shared infrastructure;provider provisioned VPN;VPN enterprise;private backbone network outsource;service provider;VPN technology;point-to-point connection;leased line connection;associated network administration;RFC 2547 variety;BGP;routing information;tunneling technology;MPLS;traffic isolation;VPN customer;integrity constraint;intravirtual private routed network connectivity;Virtual private networks;Spine;Isolation technology;IP networks;Multiprotocol label switching;Circuits;Extranets;Internet;Costs;Technology management},
doi={10.1109/INFCOM.2003.1208982},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208983,
author={Bhaskaran Raman and R. H. Katz},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Load balancing and stability issues in algorithms for service composition},
year={2003},
volume={2},
number={},
pages={1477-1487 vol.2},
abstract={Service composition enables flexible creation of new services by assembling independent service components. We are focused on the scenario where such composition takes place across the wide-area Internet. We envision independent providers deploying and managing service instances and portal providers composing them to quickly enable new applications in next-generation networks. One of the important goals in such service composition is load balancing across service instances. While load balancing has been studied extensively for web-server selection, the presence of composition presents new challenges. First, each client session involving composition requires a set of service instances and not just one server. Second, unlike web-mirror selection, we also concern ourselves with load balancing in the presence of failure recovery during a client session. We introduce (a) a metric to choose the set of service instances for composed client sessions: the least-inverse-available-capacity (LIAC) metric, as well as (b) a piggybacking mechanism to give quick feedback about server load. We then introduce an additional factor in the load balancing metric to avoid choosing far away service instances. Our experiments, based on an emulation testbed, show that our load balancing mechanism works well under a variety of scenarios including network path failures.},
keywords={computer network reliability;Internet;resource allocation;telecommunication services;load balancing mechanism;stability issue algorithm;service composition;service creation;service component assembling;wide-area Internet;service provider;service instance managing;portal provider;web-server selection;client session;failure recovery;least-inverse-available-capacity metric;piggybacking mechanism;server load feedback;emulation testbed;network path failure;Load management;Stability;Network servers;Assembly;Internet;Portals;Next generation networking;Feedback;Emulation;Testing},
doi={10.1109/INFCOM.2003.1208983},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208984,
author={X. He and C. Papadopoulos and P. Radoslavov},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A framework for incremental deployment strategies for router-assisted services},
year={2003},
volume={2},
number={},
pages={1488-1498 vol.2},
abstract={Incremental deployment of a new network service or protocol is typically a hard problem, especially when it has to be deployed in the routers. First, an incrementally deployable protocol is needed. Second, a study of the performance impact of incremental deployment should be carried out to evaluate deployment strategies. Choosing the wrong strategy can be disastrous, as it may inhibit reaping the benefits of an otherwise robust service, and prevent widespread adoption. Unfortunately, to date there has been no systematic evaluation of incremental deployment for such services. Our research work is focused on the second aspect, namely the performance impact of incremental deployment of router-assisted services. We take the first step to define a framework for evaluating incrementally deployable services, which consists of three parts: (a) selection and classification of deployment strategies; (b) definition of performance metrics; and (c) systematic evaluation of deployment strategies. As a case study for our framework, we evaluate the performance of router-assisted reliable multicast protocols. Although our framework is still evolving, our results clearly demonstrate that the choice of a strategy has a substantial impact on performance, and thus affirms the need for systematic evaluation of incremental deployment. Our case study includes two router-assisted reliable multicast protocols, namely PGM and LMS. We make several interesting observations: (a) the performance of different deployment strategies varies widely; for example, with some strategies, both PGM and LMS approach full deployment performance with as little as 5% of the routers deployed, but with other strategies up to 80% deployment may be needed to approach the same level; (b) our sensitivity analysis reveals relatively small variation in the results in most cases; and (c) the penalty associated with partial deployment is different for each of these protocols; PGM tends to impact the network, whereas LMS impacts the endpoints.},
keywords={Internet;multicast protocols;routing protocols;incremental deployment strategies;router-assisted service;Internet;protocol;robust service;performance metrics;systematic evaluation;reliable multicast protocols;LMS;sensitivity analysis;Computer science;Least squares approximation;Measurement;Multicast protocols;Web and internet services;Large-scale systems;Topology;Helium;Robustness;Sensitivity analysis},
doi={10.1109/INFCOM.2003.1208984},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208985,
author={Z. Xu and M. Mahalingam and M. Karlsson},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Turning heterogeneity into an advantage in overlay routing},
year={2003},
volume={2},
number={},
pages={1499-1509 vol.2},
abstract={Distributed hash table (DHT)-based overlay networks, represented by Pastry, CAN, and Chord, offer an administration-free and fault-tolerant application-level overlay network. While elegant from a theoretical perspective, these systems have some disadvantages. First, they rely on application-level routing, which may be inefficient with respect to network delays and bandwidth consumption. Second, they typically construct a homogeneously structured overlay even though nodes in these networks usually have varying physical connectivity and packet-forwarding capacities. In this paper, we propose two approaches for constructing an auxiliary expressway network to take advantage of the different connectivity, forwarding capacities, and availabilities of the nodes. As a result, we are able to reconcile the conflict of presenting the applications with a homogeneous structured overlay to simplify management, while at the same time taking advantage of the inherent heterogeneity of the underlying physical network to speed up routing. Our simulation results show that our expressway can achieve close to optimal routing performance (on average, 1.07 and 1.41 times optimal routing for an Internet-like topology and a large synthesized transit-stub graph, respectively) in overlay networks.},
keywords={Internet;network topology;telecommunication network routing;distributed hash table;DHT;application-level routing;network delays;bandwidth consumption;auxiliary expressway network;forwarding capacities;nodes availability;overlay routing;inherent heterogeneity;physical network;simulation results;optimal routing performance;Internet-like topology;Turning;Routing;Peer to peer computing;Network topology;Laboratories;Milling machines;Streaming media;Fault tolerance;Bandwidth;IP networks},
doi={10.1109/INFCOM.2003.1208985},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208986,
author={M. Castro and M. B. Jones and A. -. Kermarrec and A. Rowstron and M. Theimer and H. Wang and A. Wolman},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={An evaluation of scalable application-level multicast built using peer-to-peer overlays},
year={2003},
volume={2},
number={},
pages={1510-1520 vol.2},
abstract={Structured peer-to-peer overlay networks such as CAN, Chord, Pastry, and Tapestry can be used to implement Internet-scale application-level multicast. There are two general approaches to accomplishing this: tree building and flooding. This paper evaluates these two approaches using two different types of structured overlay: 1) overlays which use a form of generalized hypercube routing, e.g., Chord, Pastry and Tapestry, and 2) overlays which use a numerical distance metric to route through a Cartesian hyperspace, e.g., CAN. Pastry and CAN are chosen as the representatives of each type of overlay. To the best of our knowledge, this paper reports the first head-to-head comparison of CAN-style versus Pastry-style overlay networks, using multicast communication workloads running on an identical simulation infrastructure. The two approaches to multicast are independent of overlay network choice, and we provide a comparison of flooding versus tree-based multicast on both overlays. Results show that the tree-based approach consistently outperforms the flooding approach. Finally, for tree-based multicast, we show that Pastry provides better performance than CAN.},
keywords={multicast communication;simulation;peer-to-peer overlay networks;CAN;Chord;Pastry;Tapestry;tree building;flooding;hypercube routing;numerical distance metric;Cartesian hyperspace;CAN-style;Pastry-style overlay networks;multicast communication;simulation infrastructure;tree-based approach;flooding approach;tree-based multicast;Peer to peer computing;Routing;Floods;Hypercubes;Multicast algorithms;IP networks;Broadcasting;Scalability;Delay;Costs},
doi={10.1109/INFCOM.2003.1208986},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208987,
author={S. Banerjee and C. Kommareddy and K. Kar and B. Bhattacharjee and S. Khuller},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Construction of an efficient overlay multicast infrastructure for real-time applications},
year={2003},
volume={2},
number={},
pages={1521-1531 vol.2},
abstract={This paper presents an overlay architecture where service providers deploy a set of service nodes (called MSNs) in the network to efficiently implement media-streaming applications. These MSNs are organized into an overlay and act as application-layer multicast forwarding entities for a set of clients. We present a decentralized scheme that organizes the MSNs into an appropriate overlay structure that is particularly beneficial for real-time applications. We formulate our optimization criterion as a "degree-constrained minimum average-latency problem" which is known to be NP-hard. A key feature of this formulation is that it gives a dynamic priority to different MSNs based on the size of its service set. Our proposed approach iteratively modifies the overlay tree using localized transformations to adapt with changing distribution of MSNs, clients, as well as network conditions. We show that a centralized greedy approach to this problem does not perform quite as well, while our distributed iterative scheme efficiently converges to near-optimal solutions.},
keywords={Internet;iterative methods;multicast communication;real-time systems;overlay multicast infrastructure;real time applications;media-streaming applications;application-layer;multicast forwarding entities;decentralized scheme;optimization criterion;distributed iterative scheme;NP-hard;multicast service nodes;MSN;Application software;Spine;Streaming media;Large-scale systems;Internet;Multicast protocols;Jitter;Delay;Real time systems;Computer science},
doi={10.1109/INFCOM.2003.1208987},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208988,
author={P. Rajvaidya and K. C. Almeroth},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Analysis of routing characteristics in the multicast infrastructure},
year={2003},
volume={2},
number={},
pages={1532-1542 vol.2},
abstract={As the multicast-capable part of the Internet continues to evolve, important questions to ask are whether the protocols are operating correctly, the topology is well connected, and the routes are stable. A critical step in being able to answer these questions is to monitor the traffic and network operation. In this paper, we analyze characteristics of the multicast infrastructure over the last three years using monitoring data collected from several key routers. Specifically, we focus on analyzing two characteristics of the infrastructure: size and stability. The size analysis focuses on counting the number of connected hosts and networks, and analyzing how the size of the infrastructure has changed over past three years. Second, the stability analysis focuses on examining persistence, prevalence, and visibility of routes across the topology. From our analyses, we identify a number of problems with multicast routing and their effect on the connectivity of certain multicast networks. Moreover, we offer insight into the evolution and future of multicast in the Internet.},
keywords={Internet;multicast protocols;network topology;telecommunication network routing;routing characteristics;multicast infrastructure;Internet;protocols;topology;traffic monitoring;network operation;monitoring data;size analysis;connected hosts;stability analysis;multicast routing;multicast networks;Multicast protocols;Monitoring;Routing protocols;Network topology;Stability analysis;Web and internet services;Robust stability;Computer science;Telecommunication traffic;Scalability},
doi={10.1109/INFCOM.2003.1208988},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208989,
author={B. Liu and Z. Liu and D. Towsley},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On the capacity of hybrid wireless networks},
year={2003},
volume={2},
number={},
pages={1543-1552 vol.2},
abstract={This paper involves the study of the throughput capacity of hybrid wireless networks. A hybrid network is formed by placing a sparse network of base stations in an ad hoc network. These base stations are assumed to be connected by a high-bandwidth wired network and act as relays for wireless nodes. They are not data sources nor data receivers. Hybrid networks present a tradeoff between traditional cellular networks and pure ad hoc networks in that data may be forwarded in a multihop fashion or through the infrastructure. It has been shown that the capacity of a random ad hoc network does not scale well with the number of nodes in the system. In this work, we consider two different routing strategies and study the scaling behavior of the throughput capacity of a hybrid network. Analytical expressions of the throughput capacity are obtained. For a hybrid network of n nodes and m base stations, the results show that if m grows asymptotically slower than √n, the benefit of adding base stations on capacity is insignificant. However, if m grows faster than √n, the throughput capacity increases linearly with the number of base stations, providing an effective improvement over a pure ad hoc network. Therefore, in order to achieve nonnegligible capacity gain, the investment in the wired infrastructure should be high enough.},
keywords={ad hoc networks;cellular radio;telecommunication network routing;hybrid wireless networks;sparse network;ad hoc network;high-bandwidth wired network;wireless nodes;traditional cellular networks;multihop fashion;base stations;nonnegligible capacity gain;wired infrastructure;throughput capacity;Wireless networks;Ad hoc networks;Throughput;Base stations;Land mobile radio cellular systems;Spread spectrum communication;Wireless LAN;Femtocell networks;Routing;Mobile ad hoc networks},
doi={10.1109/INFCOM.2003.1208989},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208990,
author={N. Bansal and Z. Liu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Capacity, delay and mobility in wireless ad-hoc networks},
year={2003},
volume={2},
number={},
pages={1553-1563 vol.2},
abstract={Network throughput and packet delay are two important parameters in the design and the evaluation of routing protocols for ad-hoc networks. While mobility has been shown to increase the capacity of a network, it is not clear whether the delay can be kept low without trading off the throughput. We consider a theoretical framework and propose a routing algorithm which exploits the patterns in the mobility of nodes to provide guarantees on the delay. Moreover, the throughput achieved by the algorithm is only a poly-logarithmic factor off from the optimal. The algorithm itself is fairly simple. In order to analyze its feasibility and the performance guarantee, we used various techniques of probabilistic analysis of algorithms. The approach taken in this paper could be applied to the analyses of some other routing algorithms for mobile ad hoc networks proposed in the literature.},
keywords={ad hoc networks;delays;routing protocols;network throughput;packet delay;routing protocols;ad-hoc networks;routing algorithm;nodes mobility;poly-logarithmic factor;probabilistic analysis;wireless communication;network capacity;Intelligent networks;Ad hoc networks;Throughput;Routing protocols;Algorithm design and analysis;Relays;Performance analysis;Mobile ad hoc networks;Wireless networks;Network topology},
doi={10.1109/INFCOM.2003.1208990},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208991,
author={R. M. D'Souza and S. Ramanathan and D. T. Lang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Measuring performance of ad hoc networks using timescales for information flow},
year={2003},
volume={2},
number={},
pages={1564-1574 vol.2},
abstract={This paper defines the metrics to characterize the performance of ad hoc networks based on timescales for information flow, power consumption and interference. The statistical distribution of timescales has not been previously considered. Yet, it is important for understanding the feasibility of communicating over such networks, for comparing different algorithms for building up network topology and for distinguishing regimes of routing. We quantify the longest timescale for information flow and estimate its distribution. We also introduce a decentralized adaptive power algorithm, that uses only information local to each device, for building ad hoc networks. This algorithm is shown to perform significantly better by all our metrics when compared with a standard, constant power, algorithm.},
keywords={ad hoc networks;mobile radio;network topology;radiofrequency interference;statistical distributions;telecommunication network routing;ad hoc networks measuring performance;information flow;power consumption;interference;timescale statistical distribution;network topology;routing;decentralized adaptive power algorithm;standard constant power algorithm;Fluid flow measurement;Ad hoc networks;Routing;Network topology;Statistical distributions;Interference;Power measurement;Energy consumption;Mobile communication;Communication networks},
doi={10.1109/INFCOM.2003.1208991},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208992,
author={E. Perevalov and R. Blum},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Delay limited capacity of ad hoc networks: asymptotically optimal transmission and relaying strategy},
year={2003},
volume={2},
number={},
pages={1575-1582 vol.2},
abstract={The delay limited capacity of an ad hoc wireless network confined to a finite region is investigated. A transmission and relaying strategy making use of the nodes' motion to maximize the throughput is constructed. An approximate expression for the capacity as a function of the maximum allowable delay is obtained. It is found that there exists a critical value of the delay such that: (1) for values of the delay d below critical, the capacity does not benefit appreciably from the motion, (2) for moderate values of the delay d above critical, the capacity that can be achieved by taking advantage of the motion increases as d<sup>2/3</sup>, (3) the dependence of the critical delay on the number of nodes is a very slowly increasing function (n<sup>1/14</sup>). Finally, asymptotic optimality of the proposed strategy in a certain class is shown.},
keywords={ad hoc networks;delays;probability;delay limited capacity;ad hoc wireless network;optimal transmission;relaying strategy;critical delay;asymptotic optimality;Ad hoc networks;Relays;Delay;Wireless networks;Upper bound;Routing;Throughput;Communications technology;Mobile communication;Collaboration},
doi={10.1109/INFCOM.2003.1208992},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208653,
author={F. Giroire and A. Nucci and N. Taft and C. Diot},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Increasing the robustness of IP backbones in the absence of optical level protection},
year={2003},
volume={1},
number={},
pages={1-11 vol.1},
abstract={There are two fundamental technology issues that challenge the robustness of IP backbones. First, SONET protection is gradually being removed because of its high cost (while SONET framing is kept for failure detection purposes). Protection and restoration are provided by the IP layer that operates directly over a DWDM infrastructure. Second, ISPs are systematically forced to use the shortest distance path between two points of presence in order to meet their promised SLAs. In this context, IP backbones are extremely vulnerable to fiber cuts that can bring down a significant fraction of the IP routes. We propose two solutions (an ILP model and a heuristic algorithm) to optimally map a given IP topology onto a fiber infrastructure. The version of the mapping problem that we address incorporates a number of real constraints and requirements faced by carriers today. The optimal mapping maximizes the robustness of the network while maintaining the ISP's SLA delay requirements. In addition, our heuristic takes into consideration constraints such as a shortage of wavelengths and priorities among POPs and routes. The heuristic is evaluated on the Sprint backbone network. We illustrate the tradeoffs between the many requirements.},
keywords={IP networks;wavelength division multiplexing;integer programming;linear programming;network topology;optical fibre networks;computer network reliability;Internet Protocol;IP backbone robustness;IP route;optical level protection absence;synchronous optical network;SONET framing;failure detection purpose;dense wavelength division multiplexing;DWDM infrastructure;shortest distance path;service level agreement;SLA delay requirement;integer linear program model;heuristic algorithm;IP topology;mapping problem;wavelength shortage;point of presence;POP;Sprint backbone network;Internet service provider;ISP;network robustness;Robustness;Spine;Protection;Optical fiber devices;Wavelength division multiplexing;SONET;Network topology;IP networks;Costs;Optical wavelength conversion},
doi={10.1109/INFCOM.2003.1208653},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208654,
author={Sunil Gowda and K. M. Sivalingam},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Protection mechanisms for optical WDM networks based on wavelength converter multiplexing and backup path relocation techniques},
year={2003},
volume={1},
number={},
pages={12-21 vol.1},
abstract={This paper studies the problem of designing survivable optical wavelength division multiplexed (WDM) networks. A wavelength-routed wide area backbone network supporting circuit-switched traffic is considered. This paper also considers the use of optical wavelength conversion technology which has been shown to help improve network performance. However, wavelength conversion is still an expensive technology and using optical conversion could potentially result in signal quality degradation. In survivable networks, protection against failures is provided using backup paths that are determined when a session is established. In this paper, we present three primary and backup route computation mechanisms that attempt to improve overall network performance compared to existing solutions. One of the key design goals is to reduce the number of required converters per node. First, we present a routing algorithm, termed conversion free primary routing (CFPR) that computes primary paths without wavelength conversion, as far as possible. Next, we present a converter multiplexing technique that is used to share wavelength converters among multiple backup paths. This significantly reduces the number of connections blocked due to wavelength converter unavailability and reduces the number of wavelength converters required at each node, thus reducing system cost. Finally, we propose a backup path relocation scheme that migrates existing backup paths, whenever needed, to accommodate more primary paths and also to obtain primary routes with fewer hops. This is done to improve network utilization and reduce blocking probability. The proposed techniques are analyzed in detail using a discrete-event simulation model. The results show that significant reduction in blocking probability is possible with the proposed mechanisms. The number of converters required at each node to achieve a given blocking probability is also seen to be four times lower, compared to existing architectures based on static shortest path routing.},
keywords={wavelength division multiplexing;optical fibre networks;optical wavelength conversion;circuit switching;discrete event systems;discrete event simulation;telecommunication network reliability;wavelength division multiplexing;optical WDM network protection mechanism;wavelength converter multiplexing;backup path relocation technique;circuit-switched traffic;network performance improvement;optical wavelength conversion technology;signal quality degradation;survivable network;backup route computation mechanism;routing algorithm;conversion free primary routing;CFPR;blocking probability reduction;discrete-event simulation model;static shortest path routing;wide area backbone network;network utilization;WDM networks;Protection;Optical fiber networks;Optical wavelength conversion;Wavelength division multiplexing;Wavelength conversion;Wavelength routing;Optical design;Spine;Circuits},
doi={10.1109/INFCOM.2003.1208654},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208655,
author={M. Ma and Y. Zhu and T. H. Cheng},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A bandwidth guaranteed polling MAC protocol for Ethernet passive optical networks},
year={2003},
volume={1},
number={},
pages={22-31 vol.1},
abstract={While the backbone networks have experienced substantial changes in the last decade; the access networks have not changed much. Recently, passive optical networks (PONs) seem to be ready for commercial deployment in access networks due to the maturity of a number of enabling technologies, long distance and reduced maintenance. Among PON technologies, the Ethernet PON (EPON) presently being standardized by the IEEE 802.3ah Ethernet in the first miles (EFM) task force is most attractive because of its high speed, low cost, familiarity, interoperability and low overhead. In this paper, we propose a novel bandwidth guarantee polling (BGP) scheme that will allow the upstream bandwidth to be shared based on the service level agreement (SLA) between each subscriber and the operator. It is able to provide bandwidth guarantee for premium subscribers according to the SLAs while providing best-effort service to other subscribers. The analytical and simulation results prove that the proposed scheme does best in what it is designed to do compared to another well-known scheme that has not considered providing differentiated services. With business customers preferring premium services with guaranteed bandwidth and residential users preferring low-cost best effort services, our scheme could benefit both groups of subscribers as well as the operators.},
keywords={access protocols;local area networks;optical fibre subscriber loops;bandwidth allocation;media access control;bandwidth guaranteed polling MAC protocol;passive optical network;Ethernet PON;access network;IEEE 802.3ah;Ethernet in the first miles task force;service level agreement;differentiated service;residential user;upstream bandwidth;Bandwidth;Media Access Protocol;Passive optical networks;Ethernet networks;Access protocols;Spine;EPON;Costs;Analytical models;Business},
doi={10.1109/INFCOM.2003.1208655},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208656,
author={D. -. Yang and W. Liao},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Design of light-tree based logical topologies for multicast streams in wavelength routed optical networks},
year={2003},
volume={1},
number={},
pages={32-41 vol.1},
abstract={In this paper, we formulate an optimization problem for the design of light-tree based logical topology in wavelength division multiplexing (WDM) networks. The problem is comprised of two parts: (1) multicast routing and wavelength assignment of light-trees, and (2) the design of light-tree based logical topology for multicast streams. In the first part, we use mixed integer linear programming (MILP) to solve the optimal routing and wavelength assignment problem of light-trees with an end-to-end delay bound, and obtain the optimal placement of power splitters and wavelength converters. The numerical results show that networks with just a few power splitters and wavelength converters can efficiently carry multicast data. In the second part, we extend the above formulation to design the logical topology based on light-trees for multicast streams. In our approach, a light-tree can carry data of multiple multicast streams, and data of a multicast stream may traverse multiple light-trees to reach a receiver. The numerical results show that our approach use network resources more efficiently, as compared to the approach with a separate light-tree for a multicast stream and to the approach of transporting multicast streams over lightpath based logical networks.},
keywords={wavelength division multiplexing;multicast communication;optical fibre networks;integer programming;linear programming;telecommunication network routing;network topology;light-tree based logical topology design;multicast stream;wavelength routed optical network;optimization problem;wavelength division multiplexing networks;WDM;light-tree wavelength assignment;end-to-end delay bound;power splitter optimal placement;wavelength converter;mixed integer linear programming;network resource;optimal routing;Optical design;Network topology;Wavelength routing;Optical fiber networks;Wavelength division multiplexing;Wavelength assignment;Optical wavelength conversion;Design optimization;WDM networks;Mixed integer linear programming},
doi={10.1109/INFCOM.2003.1208656},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208657,
author={F. Zane and Girija Narlikar and A. Basu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Coolcams: power-efficient TCAMs for forwarding engines},
year={2003},
volume={1},
number={},
pages={42-52 vol.1},
abstract={Ternary content-addressable memories (TCAMs) are becoming very popular for designing high-throughput forwarding engines on routers: they are fast, cost-effective and simple to manage. However, a major drawback of TCAMs is their high power consumption. This paper presents architectures and algorithms for making TCAM-based routing tables more power efficient. The proposed architectures and algorithms are simple to implement, use commodity TCAMs, and provide worst-case power consumption guarantees (independent of routing table contents).},
keywords={content-addressable storage;telecommunication network routing;telecommunication equipment;coolcam;ternary content-addressable memory;high-throughput forwarding engine design;power consumption guarantee;routing table;router;Engines;Energy consumption;Routing;Costs;Associative memory;Cooling;Hardware;Memory management;Content management;Technology management},
doi={10.1109/INFCOM.2003.1208657},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208658,
author={F. Baboescu and Sumeet Singh and G. Varghese},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Packet classification for core routers: is there an alternative to CAMs?},
year={2003},
volume={1},
number={},
pages={53-63 vol.1},
abstract={A classifier consists of a set of rules for classifying packets based on header fields. Because core routers can have fairly large (e.g., 2000 rule) database and must use limited SRAM to meet OC-768 speeds, the best existing classification algorithms (RFC, HiCuts, ABV) are precluded because of the large amount of memory they need. Thus the general belief is that hardware solutions like CAMs are needed, despite the amount of board area and power they consume. In this paper, we provide an alternative to CAMs via an extended grid-of-tries with path compression (EGT-PC) algorithm whose worst-case speed scales well with database size while using a minimal amount of memory. Our evaluation is based on real databases used by tier 1 ISPs, and synthetic databases. EGT-PC is based on a observation that we found holds for all the tier 1 databases we studied: regardless of database size, any packet matches only a small number of distinct source-destination prefix pairs. The code we wrote for EGT-PC, RFC, HiCuts, and ABV is publicly available (Ref.1), providing the first publicly available code to encourage experimentation with classification algorithms.},
keywords={very large databases;telecommunication network routing;packet switching;Internet;decision trees;packet classification;core router;CAM;header field;SRAM;OC-768 speed;RFC;HiCuts;ABV;hardware solution;extended grid-of-tries with path compression algorithm;tier 1 ISP;synthetic database;classification algorithm;board area;Cams;Databases;Telecommunication traffic;Classification algorithms;Traffic control;Network address translation;Diffserv networks;Random access memory;Hardware;IP networks},
doi={10.1109/INFCOM.2003.1208658},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208659,
author={A. Basu and Girija Narlikar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Fast incremental updates for pipelined forwarding engines},
year={2003},
volume={1},
number={},
pages={64-74 vol.1},
abstract={Pipelined ASIC architectures are increasingly being used in forwarding engines for high speed IP routers. We explore optimization issues in the design of memory-efficient data structures that support fast incremental updates in such forwarding engines. Our solution aims to balance the memory utilization across the multiple pipeline stages. We also propose a series of optimizations that minimize the disruption to the forwarding process caused by route updates. These optimizations reduce the update overheads by a factor of 2-5 for a variety of different core routing tables and update traces.},
keywords={application specific integrated circuits;telecommunication equipment;pipeline processing;IP networks;telecommunication network routing;data structures;minimisation;fast incremental update;pipelined forwarding engine;application-specific integrated circuit;pipelined ASIC architecture;high speed IP router;optimization issues;memory-efficient data structure design;memory utilization balances;disruption minimization;core routing table;multiple pipeline stage;update overhead reduction;Engines;Routing;Pipeline processing;Application specific integrated circuits;Hardware;Random access memory;Data structures;Filtering;Costs;Design optimization},
doi={10.1109/INFCOM.2003.1208659},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208660,
author={I. Ioannidis and Ananth Grama and M. Atallah},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Adaptive data structures for IP lookups},
year={2003},
volume={1},
number={},
pages={75-84 vol.1},
abstract={The problem of efficient data structures for IP lookups has been well studied in literature. Techniques such as LC tries and extensible hashing are commonly used. In this paper, we address the problem of generalizing LC tries and extensible hashing, based on traces of past lookups, to provide performance guarantees for memory sub-optimal structures. As a specific example, if a memory-optimal (LC) trie takes 6 MB and the total memory at the router is 8 MB, how should the trie be modified to make best use of the 2 MB of excess memory? We present a greedy algorithm for this problem and prove that, if for the optimal data structure there are b fewer memory accesses on average for each lookup compared with the original trie, the solution produced by the greedy algorithm will have 9/spl times/b/22 fewer memory accesses on average (compared to the original trie). An efficient implementation of this algorithm presents significant additional challenges. We describe an implementation with a time complexity of O(/spl xi/(d)n /spl times/ log n) and a space complexity of O(n), where n is the number of nodes of the trie and d its depth. The depth of a trie is fixed for a given version of the Internet protocol and is typically O(log n). In this case, /spl xi/(d) = O(log/sup 2/ n). We demonstrate experimentally the performance and scalability of the algorithm on actual routing data. We also show that our algorithm significantly outperforms extensible hashing for the same amount of memory.},
keywords={data structures;trees (mathematics);computational complexity;IP networks;adaptive data structure;IP lookup;LC tries technique;extensible hashing;memory sub-optimal structure;greedy algorithm;optimal data structure;memory access;space complexity;Internet protocol;routing data;time complexity;Data structures;Greedy algorithms;Internet;Protocols;Scalability;Routing;Table lookup;Turning;Probability distribution;Memory management},
doi={10.1109/INFCOM.2003.1208660},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208661,
author={C. V. Hollot and Y. Liu and Vishal Misra and D. Towsley},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Unresponsive flows and AQM performance},
year={2003},
volume={1},
number={},
pages={85-95 vol.1},
abstract={Routers handle data packets from sources unresponsive to TCP's congestion avoidance feedback. We are interested in the impact these sources have on active queue management (AQM) control of long-lived TCP traffic. In this paper, we combine models of TCP/AQM dynamics with models of unresponsive traffic to analyze the effects on AQM performance.},
keywords={telecommunication congestion control;telecommunication traffic;packet switching;telecommunication network routing;telecommunication network management;transport protocols;queueing theory;unresponsive traffic model;active queue management performance;router;data packet;transport control protocol;TCP congestion avoidance feedback;TCP/AQM dynamics;Traffic control;Feedback;Performance analysis;Computer science;Fluid dynamics;Internet;Transient response;Computer networks;Contracts;US Department of Defense},
doi={10.1109/INFCOM.2003.1208661},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208662,
author={F. Paganini and Z. Wang and S. H. Low and J. C. Doyle},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A new TCP/AQM for stable operation in fast networks},
year={2003},
volume={1},
number={},
pages={96-105 vol.1},
abstract={This paper is aimed at designing a congestion control system that scales gracefully with network capacity, providing high utilization, low queueing delay, dynamic stability, and fairness among users. In earlier work we had developed fluid-level control laws that achieve the first three objectives for arbitrary networks and delays, but were forced to constrain the resource allocation policy. In this paper we extend the theory to include dynamics at TCP sources, preserving the earlier features at fast time-scales, but permitting sources to match their steady-state preferences, provided a bound on round-trip-times is known. We develop two packet-level implementations of this protocol, using (i) ECN marking, and (ii) queueing delay, as means of communicating the congestion measure from links to sources. We discuss parameter choices and demonstrate using ns-2 simulations the stability of the protocol and its equilibrium features in terms of utilization, queueing and fairness. We also demonstrate the scalability of these features to increases in capacity, delay, and load, in comparison with other deployed and proposed protocols.},
keywords={transport protocols;telecommunication congestion control;queueing theory;stability;resource allocation;TCP/AQM;congestion control system design;network capacity;high utilization;queueing delay;dynamic stability;arbitrary networks;resource allocation policy;time-scales;round-trip-times;packet-level implementations;explicit congestion notification marking;ns-2 simulations;active queue management;Intelligent networks;Protocols;Stability;Delay;Resource management;Fluid dynamics;Control systems;Force control;Steady-state;Scalability},
doi={10.1109/INFCOM.2003.1208662},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208663,
author={D. Dutta and A. Goel and J. Heidemann},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Oblivious AQM and Nash equilibria},
year={2003},
volume={1},
number={},
pages={106-113 vol.1},
abstract={An oblivious active queue management scheme is one which does not differentiate between packets belonging to different flows. In this paper, we study the existence and the quality of Nash equilibria imposed by oblivious AQM schemes on selfish agents. Oblivious AQM schemes are of obvious importance because of the ease of implementation and deployment, and Nash equilibrium offers valuable clues into network performance under noncooperative user behavior. Specifically, we ask the following three questions: 1) do there exist oblivious AQM schemes that impose Nash equilibria on selfish agents? 2) Are the imposed equilibria, if they exist, efficient in terms of the goodput obtained and the drop probability experienced at the equilibrium? 3) How easy is it for selfish users to reach the Nash equilibrium state? We assume that the traffic sources are Poisson but the users can control the average rate. We show that drop-tail and RED do not impose Nash equilibria. We modify RED slightly to obtain an oblivious scheme, VLRED, that imposes a Nash equilibrium, but is not efficient. We then present another AQM policy, EN-AQM, that can impose an efficient Nash equilibrium. Finally, we show that for any oblivious AQM, the Nash equilibrium imposed on selfish agents is highly sensitive as the number of agents increases, thus making it hard for the users to converge to the Nash equilibrium, and motivating the need for equilibria-aware protocols.},
keywords={probability;telecommunication network management;packet switching;queueing theory;Internet;Markov processes;oblivious active queue management scheme;selfish agents;network performance;noncooperative user behavior;drop probability;Poisson processes;random early detection;virtual load RED;efficient Nash equilibrium;equilibria-aware protocols;Markov processes;Nash equilibrium;Traffic control;Intersymbol interference;Internet;Robustness;Transport protocols;Game theory;Computer science},
doi={10.1109/INFCOM.2003.1208663},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208664,
author={A. Tang and J. Wang and S. H. Low},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Understanding CHOKe},
year={2003},
volume={1},
number={},
pages={114-124 vol.1},
abstract={A recently proposed active queue management, CHOKe, is stateless, simple to implement, yet surprisingly effective in protecting TCP from UDP flows. As UDP rate increases, even though the number of UDP packets in the queue rises, its bandwidth share eventually drops to zero, in stark contrast to the behavior of a regular FIFO buffer. We derive a detailed model of CHOKe that accurately predicts this, and other behaviors of CHOKe, and validate the model with simulations. Its key features are the incorporation of the feedback equilibrium of TCP with dropping probability and the spatial characteristics of the queueing process. CHOKe produces a "leaky buffer" where packets can be dropped as they move toward the head of the queue. This leads to a spatially nonuniform distribution of packets and their velocity, and makes it possible for a flow to simultaneously maintain a large number of packets in the queue and receive a vanishingly small bandwidth share. This is the main mechanism through which CHOKe protects TCP from UDP flows.},
keywords={queueing theory;telecommunication network management;packet switching;transport protocols;probability;buffer storage;Internet;active queue management;CHOKe;TCP packet;transport control protocol;UDP flows;user datagram protocol;dropping probability;leaky buffer;nonuniform packet distribution;Internet;first in first out buffer;FIFO;Inductors;Bandwidth;Predictive models;Protection;Feedback;Internet;Technology management;Current measurement;Communication system traffic control;Traffic control},
doi={10.1109/INFCOM.2003.1208664},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208665,
author={M. Aida and N. Miyoshi and K. Ishibashi},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A scalable and lightweight QoS monitoring technique combining passive and active approaches},
year={2003},
volume={1},
number={},
pages={125-133 vol.1},
abstract={To make a scalable and lightweight QoS monitoring system, we have proposed a new QoS monitoring technique, change-of-measure based passive/active monitoring (CoMPACT monitor), which is based on change-of-measure framework and is an active measurement transformed by using passively monitored data. This technique enables us to measure detailed QoS information for individual users, applications, and organizations, in a scalable and lightweight manner. In this paper, we present the mathematical foundation of CoMPACT monitor. In addition, we show its characteristics through simulations in terms of typical implementation issues for inferring the delay distributions. The results show that CoMPACT monitor gives accurate QoS estimations with only a small amount of extra traffic for active measurement.},
keywords={monitoring;quality of service;Internet;scalable QoS monitoring system;compact monitor;change-of-measure framework;active measurement;passively monitored data;delay distributions;Monitoring;Quality of service;Probes;Telecommunication traffic;Traffic control;Internet;Performance loss;Volume measurement;Delay estimation;Time measurement},
doi={10.1109/INFCOM.2003.1208665},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208666,
author={Y. Bejerano and Rajeev Rastogi},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Robust monitoring of link delays and faults in IP networks},
year={2003},
volume={1},
number={},
pages={134-144 vol.1},
abstract={In this paper, we develop failure-resilient techniques for monitoring link delays and faults in a service provider or enterprise IP network. Our two-phased approach attempts to minimize both the monitoring infrastructure costs as well as the additional traffic due to probe messages. In the first phase of our approach, we compute the locations of a minimal set of monitoring stations such that all network links are covered, even in the presence of several link failures. Subsequently, in the second phase, we compute a minimal set of probe messages that are transmitted by the stations to measure link delays and isolate network faults. We show that both the station selection problem as well as the probe assignment problem are NP-hard. We then propose greedy approximation algorithms that achieve a logarithmic approximation factor for the station selection problem and a constant factor for the probe assignment problem. These approximation ratios are provably very close to the best possible bounds for any algorithm.},
keywords={IP networks;monitoring;minimisation;delays;computer network reliability;failure-resilient techniques;service provider;enterprise IP network;two-phased approach;probe messages;network links failures;station selection problem;probe assignment problem;NP-hard problem;greedy approximation algorithms;logarithmic approximation factor;fault monitoring;set cover problem;Robustness;Intelligent networks;IP networks;Condition monitoring;Probes;Delay;Costs;Approximation algorithms;Quality of service;Telecommunication traffic},
doi={10.1109/INFCOM.2003.1208666},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208667,
author={V. N. Padmanabhan and L. Qiu and H. J. Wang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Server-based inference of Internet link lossiness},
year={2003},
volume={1},
number={},
pages={145-155 vol.1},
abstract={The problem of inferring the packet loss characteristics of Internet links using server-based measurements is investigated. Unlike much of existing work on network tomography that is based on active probing, we make inferences based on passive observation of end-to-end client-server traffic. Our work on passive network tomography focuses on identifying lossy links (i.e., the trouble spots in the network). We have developed three techniques for this purpose based on random sampling, linear optimization, and Bayesian inference using Gibbs sampling, respectively. We evaluate the accuracy of these techniques using both simulations and Internet packet traces. We find that these techniques can identify most of the lossy links in the network with a manageable false positive rate. For instance, simulation results indicate that the Gibbs sampling technique has over 80% coverage with a false positive rate under 5%. Furthermore, this technique provides a confidence indicator on its inference. We also perform inference based on Internet traces gathered at the busy microsoft.com Web site. However, validating these inferences is a challenging problem. We present a method for indirect validation that suggests that the false positive rate is manageable.},
keywords={sampling methods;client-server systems;telecommunication traffic;Internet;linear programming;packet switching;belief networks;server-based inference;Internet link lossiness;packet loss characteristics;network tomography;active probing;end-to-end client-server traffic;random sampling;linear optimisation;Bayesian inference;Gibbs sampling;Internet packet traces;false positive rate;microsoft.com Web site;Internet;Network servers;Tomography;Web server;Telecommunication traffic;Sampling methods;IP networks;Throughput;Passive networks;Bayesian methods},
doi={10.1109/INFCOM.2003.1208667},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208668,
author={G. Di Battista and M. Patrignani and M. Pizzonia},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Computing the types of the relationships between autonomous systems},
year={2003},
volume={1},
number={},
pages={156-165 vol.1},
abstract={The problem of computing the types of the relationships between Internet autonomous systems is investigated. We refer to the model introduced in (ref.1), (ref.2) that bases the discovery of such relationships on the analysis of the AS paths extracted from the BGP routing tables. We characterize the time complexity of the above problem, showing both NP-completeness results and efficient algorithms for solving specific cases. Motivated by the hardness of the general problem, we propose heuristics based on a novel paradigm and show their effectiveness against publicly available data sets. The experiments put in evidence that our heuristics performs significantly better than state of the art heuristics.},
keywords={Internet;routing protocols;optimisation;computing problem;Internet;autonomous systems;border gateway protocol routing tables;time complexity;NP-completeness results;efficient algorithms;publicly available data sets;Internet;Data mining;Routing protocols;Peer to peer computing;Topology;FETs;IP networks;Adaptive systems;Information systems;IEEE news},
doi={10.1109/INFCOM.2003.1208668},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208669,
author={P. Dube and E. Altman},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Goodput analysis of a fluid queue with selective discarding and a responsive bursty source},
year={2003},
volume={1},
number={},
pages={166-176 vol.1},
abstract={In this paper we analyse a feedback system consisting of a finite buffer fluid queue and a responsive source. The source alternates between silence periods and active periods. At random epochs of times the source becomes ready to send a burst of fluid. The length of the bursts (length of the active periods) are independent and identically distributed with some general distribution. The queue employs a threshold discarding policy in the sense that only those bursts at whose commencement epoch (the instant at which the source is ready to send), the workload (i.e., the amount of fluid in the buffer) is less than some preset threshold are accepted. If the burst is rejected then the source backs off from sending. Using techniques from Volterra integral equations we obtain an explicit characterization of the queue length distribution at commencement epochs of bursts from which we obtain an explicit characterization of the goodput ratio associated with such a feedback system. For the particular case of exponential distribution of on-periods we are able to obtain explicit closed form expression for the goodput ratio. Our explicit characterizations shall be quite helpful in studying the sensitivity of goodput ratio to different parameters, in selecting optimal discarding threshold etc. which will further provide useful "engineering" guidelines for better network designing.},
keywords={Volterra equations;exponential distribution;queueing theory;feedback;buffer storage;feedback system;finite buffer fluid queue;responsive source;silence periods;active periods;threshold discarding policy;commencement epoch;Volterra integral equations;queue length distribution;explicit characterization;goodput ratio;exponential distribution;optimal discarding threshold;network design;on-off fluid;level-crossing arguments;workload distribution;Queueing analysis;Feedback;Asynchronous transfer mode;Integral equations;Guidelines;Exponential distribution;Performance analysis;Switches;Bit rate},
doi={10.1109/INFCOM.2003.1208669},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208670,
author={M. F. Neuts and J. Guo and M. Zukerman and Hai Le Vu},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={The waiting time distribution for a TDMA model with a finite buffer},
year={2003},
volume={1},
number={},
pages={177-185 vol.1},
abstract={Detailed analytic formulas for the density and probability distribution of the waiting time in a TDMA model with a finite buffer is obtained. On successive intervals of length equal to the duration of a slot, the density is expressed as (infinite) linear combinations of beta densities with positive coefficients. A recursive scheme, obtained by a matrix-analytic derivation, allows for the highly efficient computations of the coefficient sequences.},
keywords={time division multiple access;probability;matrix algebra;delay estimation;buffer storage;probability distribution;waiting time;TDMA model;time division multiple access;finite buffer;length intervals;linear combinations;beta densities;positive coefficients;recursive scheme;matrix-analytic derivation;coefficient sequences;Time division multiple access;Industrial electronics;Probability distribution;Telecommunication computing;GSM;Queueing analysis;Delay effects;Computational modeling;Density functional theory},
doi={10.1109/INFCOM.2003.1208670},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208671,
author={J. Boyer and F. Guillemin and P. Robert and B. Zwart},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Heavy tailed M/G/1-PS queues with impatience and admission control in packet networks},
year={2003},
volume={1},
number={},
pages={186-195 vol.1},
abstract={In this paper we analyze the M/G/1 processor sharing queue with heavy tailed services and with impatient customers. It is assumed that impatience depends on the value of the service required. We prove that a reduced service rate (RSR) approximation holds for estimating the sojourn time of a customer in the system, when the queue capacity is finite or infinite. This allows us to evaluate the reneging probability of customers with very large service times. We then use these results to investigate the impact of admission control on a link of a packet network. Admission control simply consists of limiting the number of simultaneous connections. It turns out that there is a real benefit for the efficiency of the system to perform admission control: It globally increases the fraction of customers, who complete their service (i.e. without being impatient). Finally, we investigate the fairness of the system and propose a criterion to assess the capacity of the system so as to allow the completion of very large service times.},
keywords={queueing theory;probability;computer networks;telecommunication congestion control;packet switching;M/G/1 processor sharing queue;heavy tailed services;reduced service rate approximation;sojourn time estimation;customer probability;large service times;admission control;packet network links;elastic traffic;Admission control;Intelligent networks;Communication system traffic control;Quality of service;Queueing analysis;Traffic control;Spine;IP networks;Electronic mail;Contracts},
doi={10.1109/INFCOM.2003.1208671},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208672,
author={I. C. Paschalidis and C. Su and M. C. Caramanis},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Target-pursuing policies for open multiclass queueing networks},
year={2003},
volume={1},
number={},
pages={196-206 vol.1},
abstract={A new parametric class of scheduling and routing policies for open multiclass queueing networks is proposed. We establish their stability and show they are amenable to distributed implementation using localized state information. We exploit our earlier work in (Ref.1) to select appropriate parameter values and outline how optimal parameter values can be computed. We report numerical results indicating that we obtain near-optimal policies (when the optimal can be computed) and significantly outperform heuristic alternatives.},
keywords={scheduling;telecommunication network routing;queueing theory;target-pursuing policies;open multiclass queueing networks;scheduling parametric class;routing policies;distributed implementation;localized state information;optimal parameter values;near-optimal policies;heuristic alternatives;fluid models;Network servers;Job shop scheduling;Routing;Stability;Processor scheduling;Manufacturing;Application specific processors;Databases;Web server;Systems engineering and theory},
doi={10.1109/INFCOM.2003.1208672},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208673,
author={P. Karbhari and E. Zegura and M. Ammar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Multipoint-to-point session fairness in the Internet},
year={2003},
volume={1},
number={},
pages={207-217 vol.1},
abstract={In the current Internet, many applications start sessions with multiple connections to multiple servers in order to expedite the reception of data. One may argue that such aggressive behavior leads to unfair sharing of bandwidth using the current per-connection rate allocation methods. Sessions with more connections get a higher total rate than competing sessions with fewer connections. In this paper, we explore the issue of fairness of rate allocation from a session point of view. We define a multipoint-to-point session as a set of point-to-point connections started from multiple servers to a client in order to transfer an application-level object. We present session fairness definitions, propose algorithms to achieve these definitions, and compare the resulting allocations with the traditional connection fair algorithm. It is clear from our evaluations that the session fair algorithms proposed achieve a more fair distribution of session rates than the connection fair algorithm, by redistributing the rates claimed by sessions with more connections. We present some initial thoughts on the challenges involved in implementing the session fair algorithms proposed.},
keywords={Internet;data communication;client-server systems;multipoint-to-point session fairness;Internet;multiple connections;multiple servers;data reception;aggressive behavior;bandwidth unfair sharing;current per-connection rate allocation methods;point-to-point connections;application-level object transfer;session fairness definitions;traditional connection fair algorithm;session fair algorithms;session rates;Internet;Network servers;Web server;Bandwidth;Peer to peer computing;Intelligent networks;Educational institutions;Computer networks;Telecommunication computing;IP networks},
doi={10.1109/INFCOM.2003.1208673},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208674,
author={W. C. Cheng and C. -. Chou and L. Golubchik and S. Khuller and Y. -. Wan},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Large-scale data collection: a coordinated approach},
year={2003},
volume={1},
number={},
pages={218-228 vol.1},
abstract={In this paper we consider the problem of collecting a large amount of data from several different hosts to a single destination in a wide-area network. Often, due to congestion conditions, the paths chosen by the network may have poor throughput. By choosing an alternate route at the application level, we may be able to obtain substantially faster completion time. This data collection problem is a nontrivial one because the issue is not only to avoid congested link(s), but to devise a coordinated transfer schedule which would afford maximum possible utilization of available network resources. In this paper we present an approach for computing coordinated data collection schedules, which can result in significant performance improvements. We make no assumptions about knowledge of the topology of the network or the capacity available on individual links of the network, i.e., we only use end-to-end information. Finally, we also study the shortcomings of this approach in terms of the gap between the theoretical formulation and the resulting data transfers in wide-area networks. In general, our approach can be used for solving arbitrary data movement problems over the Internet. We use the Bistro platform to illustrate one application of our techniques.},
keywords={Internet;network topology;graph theory;telecommunication network routing;large-scale data collection;hosts;wide-area network;congestion conditions;network paths;application level;completion time;coordinated transfer schedule;network resources;coordinated data collection schedules;network topology;network links capacity;end-to-end information;theoretical formulation;data transfers;arbitrary data movement problems;Internet;Bistro platform;system design;simulations;graph theory;Large-scale systems;Computer science;Internet;Educational institutions;Job shop scheduling;Processor scheduling;Data engineering;Intersymbol interference;Throughput;Network topology},
doi={10.1109/INFCOM.2003.1208674},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208675,
author={Mukesh Agrawal and A. Manjhi and N. Bansal and Srinivasan Seshan},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Improving Web performance in broadcast-unicast networks},
year={2003},
volume={1},
number={},
pages={229-239 vol.1},
abstract={Satellite operators have recently begun offering Internet access over their networks. Typically, users connect to the network using a modem for uplink, and a satellite dish for downlink. We investigate how the performance of these networks might be improved by two simple techniques: caching and use of the return path on the modem link. We examine the problem from a theoretical perspective and via simulation. We show that the general problem is NP-hard, as are several special cases, and we give approximation algorithms for them. We then use insights from these cases to design practical heuristic schedulers which leverage caching and the modem downlinks. Via simulation, we show that caching alone can simultaneously reduce bandwidth requirements by 33% and improve response times by 62%. We further show that the proposed schedulers, combined with caching, yield a system that performs far better under high loads than existing systems.},
keywords={satellite communication;broadcasting;cache storage;optimisation;Internet;scheduling;Web performance;broadcast-unicast networks;satellite operators;uplink modem;downlink satellite dish;return path caching;simulation;NP-hard problem;approximation algorithms;heuristic schedulers design;modem downlinks;channel bandwidth;response times;Intelligent networks;Satellite broadcasting;Modems;Downlink;Bandwidth;Web pages;Network-on-a-chip;Web and internet services;Web server;Aggregates},
doi={10.1109/INFCOM.2003.1208675},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208676,
author={A. Armon and H. Levy},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Cache satellite distribution systems: modeling and analysis},
year={2003},
volume={1},
number={},
pages={240-250 vol.1},
abstract={Web caches have become an integral component contributing to the improvement of the performance observed by Web clients. Content Distribution Networks (CDN) and Cache Satellite Distribution Systems (CSDS) have emerged as technologies for feeding the caches with the information clients are expected to request, ahead of time. In a Cache Satellite Distribution System (CSDS), the proxies participating in the CSDS periodically report to a central station about the requests they are receiving from their clients. The central station processes this information and selects a collection of Web documents (or "Web pages"), which it then "pushes" via a satellite broadcast to all, or some, of the participating proxies, hoping most of them will request most documents in the near future. The result is that upon such request, the documents will reside in the local cache, and will not need to be fetched. In this paper we aim at addressing the issues of how to operate the CSDS, how to design it, and how to estimate its effect. Questions of interest are 1) what classes of Web documents should be transmitted by the central station, and how they are characterized, and 2) what is the benefit of adding a particular proxy into a CSDS. We offer a model of this system that accounts for the request streams addressed to the proxies and which captures the intricate interaction between the proxy caches. Unlike models that are based only on the access frequency of the various documents, this model captures both their frequency and their locality of reference. We provide an analysis of this system that is based on the stochastic properties of the traffic streams that can be derived from HTTP logs. The model and analysis can serve as a basis for the design and efficient operation of the system.},
keywords={cache storage;stochastic processes;Internet;satellite communication;telecommunication traffic;Web caches;integral component;Web clients;content distribution networks;cache satellite distribution systems;central station;Web documents;satellite network;proxy caches;documents access frequency;stochastic properties;traffic stream;HTTP logs;performance analysis;system design;simulation;performance evaluation;Satellite broadcasting;Performance analysis;Frequency;Costs;Computer science;Stochastic systems;Telecommunication traffic;Traffic control;Design methodology;Process design},
doi={10.1109/INFCOM.2003.1208676},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208677,
author={P. P. Pham and S. Perreau},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Performance analysis of reactive shortest path and multipath routing mechanism with load balance},
year={2003},
volume={1},
number={},
pages={251-259 vol.1},
abstract={Research on multipath routing protocols to provide improved throughput and route resilience as compared with single-path routing has been explored in details in the context of wired networks. However, multipath routing mechanism has not been explored thoroughly in the domain of ad hoc networks. In this paper, we analyze and compare reactive single-path and multipath routing with load balance mechanisms in ad hoc networks, in terms of overhead, traffic distribution and connection throughput. The results reveals that in comparison with general single-path routing protocol, multipath routing mechanism creates more overheads but provides better performance in congestion and capacity provided that the route length is within a certain upper bound which is derivable. The analytical results are further confirmed by simulation.},
keywords={routing protocols;ad hoc networks;telecommunication traffic;simulation;performance analysis;reactive shortest path;multipath routing protocols;load balance mechanism;route resilience;single-path routing protocol;wired networks;ad hoc networks;overhead;traffic distribution;connection throughput;congestion performance;route length;simulation;Performance analysis;Routing protocols;Throughput;Analytical models;Ad hoc networks;Traffic control;Telecommunication traffic;Wireless networks;Lakes;Australia},
doi={10.1109/INFCOM.2003.1208677},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208678,
author={A. Valera and W. K. G. Seah and S. V. Rao},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Cooperative packet caching and shortest multipath routing in mobile ad hoc networks},
year={2003},
volume={1},
number={},
pages={260-269 vol.1},
abstract={A mobile ad hoc network is an autonomous system of infrastructureless, multihop wireless mobile nodes. Reactive routing protocols perform well in such an environment due to their ability to cope quickly against topological changes. In this paper, we propose a new routing protocol called Caching and Multipath (CHAMP) Routing Protocol. CHAMP uses cooperative packet caching and shortest multipath routing to reduce packet loss due to frequent route breakdowns. Simulation results reveal that by using a five-packet data cache, CHAMP exhibits excellent improvement in packet delivery, outperforming AODV and DSR by at most 30% in stressful scenarios. Furthermore, end-to-end delay is significantly reduced while routing overhead is lower at high mobility rates.},
keywords={ad hoc networks;mobile radio;routing protocols;network topology;cache storage;cooperative packet caching;shortest multipath routing;mobile ad hoc networks;multihop wireless mobile nodes;reactive routing protocols;network topological changes;caching and multipath routing protocol;packet loss;route breakdowns;simulation;five-packet data cache;packet delivery;AODV;DSR;end-to-end delay;routing overhead;mobility rates;Intelligent networks;Mobile ad hoc networks;Routing protocols;Spread spectrum communication;Delay;Network topology;Computer science;Computer networks;Mobile communication;Electronic mail},
doi={10.1109/INFCOM.2003.1208678},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208679,
author={Z. Ye and S. V. Krishnamurthy and S. K. Tripathi},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A framework for reliable routing in mobile ad hoc networks},
year={2003},
volume={1},
number={},
pages={270-280 vol.1},
abstract={Mobile ad hoc networks consist of nodes that are often vulnerable to failure. As such, it is important to provide redundancy in terms of providing multiple node-disjoint paths from a source to a destination. We first propose a modified version of the popular AODV protocol that allows us to discover multiple node-disjoint paths from a source to a destination. We find that very few of such paths can be found. Furthermore, as distances between sources and destinations increase, bottlenecks inevitably occur and thus, the possibility of finding multiple paths is considerably reduced. We conclude that it is necessary to place what we call reliable nodes (in terms of both being robust to failure and being secure) in the network for efficient operations. We propose a deployment strategy that determines the positions and the trajectories of these reliable nodes such that we can achieve a framework for reliably routing information. We define a notion of a reliable path which is made up of multiple segments, each of which either entirely consists of reliable nodes, or contains a preset number of multiple paths between the end points of the segment. We show that the probability of establishing a reliable path between a random source and destination pair increases considerably even with a low percentage of reliable nodes when we control their positions and trajectories in accordance with our algorithm.},
keywords={telecommunication network routing;mobile radio;ad hoc networks;telecommunication network reliability;protocols;reliable routing framework;mobile ad hoc networks;multiple node-disjoint paths;ad hoc distance vector routing protocol;reliable nodes trajectory;deployment strategy;segment end points;reliable path;random source;destination pair;performance evaluation;Routing;Intelligent networks;Mobile ad hoc networks;Ad hoc networks;Robustness;Batteries;Fading;Redundancy;Protocols;Telecommunication network reliability},
doi={10.1109/INFCOM.2003.1208679},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208680,
author={B. Liang and Z. J. Haas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimizing route-cache lifetime in ad hoc networks},
year={2003},
volume={1},
number={},
pages={281-291 vol.1},
abstract={On-demand routing reduces the control overhead in mobile ad hoc networks, but it has the major drawback of introducing latency between route-request arrival and the determination of a valid route. This paper addresses the issue of minimizing the delay in on-demand routing protocols through optimizing the Time-to-Live (TTL) interval for route caching. An analytical framework is introduced to compute the expected routing delay when a source node or an intermediate node has a cached route with any given TTL value. Furthermore, numerical methods are proposed to determine the optimal TTL of a newly cached route. We present simulation results that support the validity of our analysis. Using the proposed analytical framework, we study how the routing delay is affected by route length, route-request frequency, and the frequency of topology variation. We show that the proposed optimal route-cache TTL strategy can significantly reduce the routing delay over systems that either does not use route-cache or keeps route-cache indefinitely long. We further show that the performance gain of optimizing the route-cache TTL increases with increasing traffic pattern localization.},
keywords={cache storage;mobile radio;ad hoc networks;routing protocols;minimisation;delays;route-cache lifetime;mobile ad hoc networks;on-demand routing protocols;control overhead;optimal time-to-live interval;analytical framework;routing delay;source node;simulation;route length;route-request frequency;topology variation frequency;performance gain;traffic pattern localization;optimisation;Intelligent networks;Ad hoc networks;Routing protocols;Delay;Frequency;Computer networks;Mobile ad hoc networks;Computational modeling;Analytical models;Topology},
doi={10.1109/INFCOM.2003.1208680},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208681,
author={Krishnan Kumaran and L. Qian},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Uplink scheduling in CDMA packet-data systems},
year={2003},
volume={1},
number={},
pages={292-300 vol.1},
abstract={Uplink scheduling in wireless systems is gaining importance due to arising uplink intensive data services (ftp, image uploads etc.), which could be hampered by the currently in-built asymmetry in favor of the downlink. In this work, we propose and study algorithms for efficient uplink packet-data scheduling in a CDMA cell. The algorithms attempt to maximize system throughput under transmit power limitations on the mobiles assuming instantaneous knowledge of user queues and channels. However no channel statistics or traffic characterization is necessary. Apart from increasing throughput, the algorithms also improve fairness of service among users, hence reducing chances of buffer overflows for poorly located users. The major observation arising from our analysis is that it is advantageous on the uplink to schedule "strong" users one-at-a-time, and "weak" users in larger groups. This contrasts with the downlink where one-at-a-time transmission for all users has shown to be the preferred mode in much previous work. Based on the optimal schedules, we propose less complex and more practical approximate methods, both of which offer significant performance improvement compared to one-at-a-time transmission, and the widely acclaimed Proportional Fair (PF) algorithm, in simulations. When queue content cannot be fed back, we propose a simple modification of PF, Uplink PF (UPF), that offers similar improvement.},
keywords={scheduling;packet radio networks;code division multiple access;mobile radio;queueing theory;uplink scheduling;CDMA packet-data systems;wireless systems;uplink intensive data services;system throughput;transmit power limitations;user queues;user service fairness;buffer overflows;one-at-a-time transmission;optimal schedules;uplink proportional fair;simulations;reverse uplink;Multiaccess communication;Optimal scheduling;Downlink;Traffic control;Throughput;Scheduling algorithm;Statistics;Feedback;Processor scheduling;Interference},
doi={10.1109/INFCOM.2003.1208681},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208682,
author={V. Tsibonis and L. Georgiadis and L. Tassiulas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Exploiting wireless channel state information for throughput maximization},
year={2003},
volume={1},
number={},
pages={301-310 vol.1},
abstract={The problem of scheduling packets over a number of channels with time varying connectivity is considered. Policies proposed for this problem either stabilize the system when the arrival rates are within the stability region, or optimize an objective function under the assumption that all channel queues are saturated. We address the realistic situation where it is not known a priori whether the channel queues are saturated or not, and provide a scheduling policy that maximizes the weighted sum of channel throughputs. We employ a burstiness-constrained channel model that allows us to dispense of statistical assumptions and simplifies the proofs.},
keywords={packet radio networks;scheduling;queueing theory;quality of service;time-varying channels;optimisation;wireless channel state information;packet scheduling policy;time varying connectivity;system stabilization;arrival rate;stability region;channel queue;channel throughput weighted sum maximization;burstiness-constrained channel model;QoS;wireless network;deterministic network calculus;Channel state information;Throughput;Optimal scheduling;Stability;Hidden Markov models;Network topology;Calculus;Wireless networks;Delay;Telecommunication traffic},
doi={10.1109/INFCOM.2003.1208682},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208683,
author={Munish Goyal and Anurag Kumar and Vinod Sharma},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Power constrained and delay optimal policies for scheduling transmission over a fading channel},
year={2003},
volume={1},
number={},
pages={311-320 vol.1},
abstract={An optimal power and rate scheduling problem for a single user transmitting to a base station on a fading wireless link with the objective of minimizing the mean delay subject to an average power constraint is considered. The base station acts as a controller which, depending upon the transmitter buffer lengths and the signal power to interference ratio (SIR) on the uplink pilot channel, allocates transmission rate and power to the user. We provide structural results for an average cost optimal stationary policy under a long run average transmitter power constraint. We obtain a closed form expression relating the optimal policy when the SIR is the best, to the optimal policy for any other SIR value. We also obtain lower and upper bounds for the optimal policy.},
keywords={fading channels;radio links;quality of service;scheduling;power control;buffer storage;radiofrequency interference;scheduling transmission;fading channel;delay optimal policy;rate scheduling problem;base station;fading wireless link;mean delay minimization;average power constraint;transmitter buffer length;signal power to interference ratio;SIR value;uplink pilot channel;transmission rate allocation;optimal power allocation;average cost optimal stationary policy;long run average transmitter power constraint;closed form expression;optimal policy lower bound;optimal policy upper bound;wireless network;quality of service;power control;Delay;Fading;Transmitters;Resource management;Quality of service;Base stations;Interference constraints;Communication system control;Wireless networks;Physical layer},
doi={10.1109/INFCOM.2003.1208683},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208684,
author={S. Borst},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={User-level performance of channel-aware scheduling algorithms in wireless data networks},
year={2003},
volume={1},
number={},
pages={321-331 vol.1},
abstract={Channel-aware scheduling strategies, such as the Proportional Fair algorithm for the CDMA 1xEV-DO system, provide an effective mechanism for improving throughput performance in wireless data networks by exploiting channel fluctuations. The performance of channel-aware scheduling algorithms has mostly been explored at the packet level for a static user population, often assuming infinite backlogs. In the present paper, we focus on the performance at the flow level in a dynamic setting with random finite-size service demands. We show that in certain cases the user-level performance may be evaluated by means of a multiclass Processor-Sharing model where the total service rate varies with the total number of users. The latter model provides explicit formulas for the distribution of the number of active users of the various classes, the mean response times, the blocking probabilities, and the mean throughput. In addition we show that, in the presence of channel variations, greedy, myopic strategies which maximize throughput in a static scenario, may result in sub-optimal throughput performance for a dynamic user configuration and cause potential instability effects.},
keywords={radio networks;telecommunication channels;telecommunication traffic;code division multiple access;scheduling;data communication;optimisation;user-level performance;channel-aware scheduling algorithm;wireless data network;proportional fair scheduling algorithm;CDMA 1xEV-DO system;channel fluctuation exploitation;random finite-size service demand;multiclass processor-sharing model;service rate;active user;mean response time;blocking probability;mean throughput;channel variation;throughput maximization;sub-optimal throughput performance;dynamic user configuration;potential instability effect;elastic traffic;throughput optimization;Scheduling algorithm;Intelligent networks;Throughput;Delay;Processor scheduling;Multiaccess communication;Telecommunication traffic;Laboratories;Mathematics;Computer science},
doi={10.1109/INFCOM.2003.1208684},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208685,
author={A. Lakhina and J. W. Byers and M. Crovella and P. Xie},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Sampling biases in IP topology measurements},
year={2003},
volume={1},
number={},
pages={332-341 vol.1},
abstract={Considerable attention has been focused on the properties of graphs derived from Internet measurements. Router-level topologies collected via traceroute-like methods have led some to conclude that the router graph of the Internet is well modeled as a power-law random graph. In such a graph, the degree distribution of nodes follows a distribution with a power-law tail. We argue that the evidence to date for this conclusion is at best insufficient We show that when graphs are sampled using traceroute-like methods, the resulting degree distribution can differ sharply from that of the underlying graph. For example, given a sparse Erdos-Renyi random graph, the subgraph formed by a collection of shortest paths from a small set of random sources to a larger set of random destinations can exhibit a degree distribution remarkably like a power-law. We explore the reasons for how this effect arises, and show that in such a setting, edges are sampled in a highly biased manner. This insight allows us to formulate tests for determining when sampling bias is present. When we apply these tests to a number of well-known datasets, we find strong evidence for sampling bias.},
keywords={IP networks;Internet;network topology;graph theory;telecommunication network routing;sampling methods;IP topology measurement;sampling bias;graph property;Internet measurement;router-level topology;Internet router graph;node degree distribution;power-law;sampled graph;traceroute-like method;sparse Erdos-Renyi random graph;shortest path collection subgraph;small set random source;larger set random destination;highly biased edge sampling;Sampling methods;Internet;Testing;Network topology;Frequency;Optical reflection;Computer science;Probability distribution;Assembly;Probes},
doi={10.1109/INFCOM.2003.1208685},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208686,
author={Y. Bejerano and Y. Breitbart and M. Garofalakis and Rajeev Rastogi},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Physical topology discovery for large multisubnet networks},
year={2003},
volume={1},
number={},
pages={342-352 vol.1},
abstract={Knowledge of the up-to-date physical (i.e., layer-2) topology of an Ethernet network is crucial to a number of critical network management tasks, including reactive and proactive resource management, event correlation, and root-cause analysis. Given the dynamic nature of today's IP networks, keeping track of topology information manually is a daunting (if not impossible) task. Thus, effective algorithms for automatically discovering physical network topology are necessary. In this paper, we propose the first complete algorithmic solution for discovering the physical topology of a large, heterogeneous Ethernet network comprising multiple subnets as well as (possibly) dumb or uncooperative network elements. Our algorithms rely on standard SNMP MIB information that is widely supported in modern IP networks and require no modifications to the operating system software running on elements or hosts. Furthermore, we formally demonstrate that our solution is complete for the given MIB data; that is, if the MIB information is sufficient to uniquely identify the network topology then our algorithm is guaranteed to recover it. To the best of our knowledge, ours is the first solution to provide such a strong completeness guarantee.},
keywords={local area networks;IP networks;network topology;computer network management;graph theory;large multisubnet network;up-to-date physical network topology discovery;heterogeneous Ethernet network;critical network management task;reactive resource management;proactive resource management;event correlation;root-cause analysis;IP network dynamic nature;topology information;dumb network element;uncooperative network element;simple network management protocol;management information base;standard SNMP MIB information;operating system software running;Ethernet LAN;hub;Network topology;Ethernet networks;IP networks;Switches;Resource management;LAN interconnection;Bridges;Hardware;Local area networks;Protocols},
doi={10.1109/INFCOM.2003.1208686},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208687,
author={B. Yao and Ramesh Viswanathan and F. Chang and D. Waddington},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Topology inference in the presence of anonymous routers},
year={2003},
volume={1},
number={},
pages={353-363 vol.1},
abstract={Many topology discovery systems rely on traceroute to discover path information in public networks. However, for some routers, traceroute detects their existence but not their address; we term such routers anonymous routers. This paper considers the problem of inferring the network topology in the presence of anonymous routers. We illustrate how obvious approaches to handle anonymous routers lead to incomplete, inflated, or inaccurate topologies. We formalize the topology inference problem and show that producing both exact and approximate solutions is intractable. Two heuristics are proposed and evaluated through simulation. These heuristics have been used to infer the topology of the 6Bone, and could be incorporated into existing tools to infer more comprehensive and accurate topologies.},
keywords={network topology;telecommunication network routing;network topology inference;topology discovery system;traceroute;path information discovery;public network;anonymous router;6Bone topology;Network topology;Probes;Intelligent networks;Protocols;Optimization;Large-scale systems;Internet;Privacy},
doi={10.1109/INFCOM.2003.1208687},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208688,
author={C. Gkantsidis and M. Mihail and E. Zegura},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Spectral analysis of Internet topologies},
year={2003},
volume={1},
number={},
pages={364-374 vol.1},
abstract={Spectral analysis of the Internet topology at the autonomous system (AS) level, by adapting the standard spectral filtering method of examining the eigenvectors corresponding to the largest eigenvalues of matrices related to the adjacency matrix of the topology is performed. We observe that the method suggests clusters of ASs with natural semantic proximity, such as geography or business interests. We examine how these clustering properties vary in the core and in the edge of the network, as well as across geographic areas, over time, and between real and synthetic data. We observe that these clustering properties may be suggestive of traffic patterns and thus have direct impact on the link stress of the network. Finally, we use the weights of the eigenvector corresponding to the first eigenvalue to obtain an alternative hierarchical ranking of the ASs.},
keywords={spectral analysis;Internet;network topology;telecommunication traffic;eigenvalues and eigenfunctions;telecommunication links;spectral analysis;Internet topology;AS level topology;standard spectral filtering method;eigenvector examination;matrix eigenvalue;adjacency matrix;AS cluster;natural semantic proximity;geographic area;clustering property;network core;network edge;synthetic data;traffic pattern;network link stress;eigenvector weight;Spectral analysis;Internet;Network topology;Eigenvalues and eigenfunctions;Geography;Information filtering;Information filters;Protocols;Information retrieval;Educational institutions},
doi={10.1109/INFCOM.2003.1208688},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208689,
author={C. Fraleigh and F. Tobagi and C. Diot},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Provisioning IP backbone networks to support latency sensitive traffic},
year={2003},
volume={1},
number={},
pages={375-385 vol.1},
abstract={To support latency sensitive traffic such as voice, network providers can either use service differentiation to prioritize such traffic or provision their network with enough bandwidth so that all traffic meets the most stringent delay requirements. In the context of wide-area Internet backbones, two factors make overprovisioning an attractive approach. First, the high link speeds and large volumes of traffic make service differentiation complex and potentially costly to deploy. Second, given the degree of aggregation and resulting traffic characteristics, the amount of overprovisioning necessary may not be very large. This study develops a methodology to compute the amount of overprovisioning required to support a given delay requirement. We first develop a model for backbone traffic which is needed to compute the end-to-end delay through the network. The model is validated using 331 one-hour traffic measurements collected from the Sprint IP network. We then develop a procedure which uses this model to find the amount of bandwidth needed on each link in the network so that an end-to-end delay requirement is satisfied. Applying this procedure to the Sprint network, we find that satisfying end-to-end delay requirements as low as 3 ms requires only 15% extra bandwidth above the average data rate of the traffic.},
keywords={IP networks;telecommunication traffic;telecommunication links;Internet;IP backbone network;latency sensitive traffic;network provider;service differentiation;traffic prioritization;wide-area Internet backbone;high link speed;large traffic volume;aggregation degree;traffic characteristics;backbone traffic model;end-to-end delay computation;one-hour traffic measurement;Sprint IP network;average traffic data rate;bandwidth provisioning;Spine;Delay;Telecommunication traffic;Traffic control;Bandwidth;IP networks;Costs;Internet;Computer networks;Electronic mail},
doi={10.1109/INFCOM.2003.1208689},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208690,
author={A. Juttner and I. Szabo and A. Szentesi},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On bandwidth efficiency of the hose resource management model in virtual private networks},
year={2003},
volume={1},
number={},
pages={386-395 vol.1},
abstract={The hose resource provisioning model promises to provide an easy-to-use characterization framework for virtual private network service offerings. Significant research effort has recently been spent on proposing new algorithms for provisioning cost-optimal networks specified according to this new model. However, a detailed comparison of the bandwidth requirement for networks designed based on the hose model and networks designed based on the traditional pipe model has not been performed. The first contribution of this paper is a detailed comparison of the bandwidth needs of the two models assuming a range of network sizes and network topologies. This numerical evaluation required efficient calculation methods for determining resource allocation based on the hose model parameters, therefore, a linear programming based formulation is also presented for this purpose. The second contribution is the calculation of a lower bound for the hose based realization. This lower bound is very useful in evaluating the two models given that the problem of provisioning a minimal cost network based on the hose model specification can only approximately be solved in polynomial time.},
keywords={virtual private networks;network topology;linear programming;resource allocation;bandwidth efficiency;hose resource management model;virtual private network service offering;hose resource provisioning model;easy-to-use characterization framework;cost-optimal network;network bandwidth requirement;traditional pipe model;network size;network topology;resource allocation determination;hose model parameter;linear programming based formulation;hose based realization lower bound;minimal cost network provisioning;hose model specification;polynomial time;Bandwidth;Hoses;Resource management;Intelligent networks;Virtual private networks;Telecommunication traffic;Traffic control;Protocols;Laboratories;Electronic mail},
doi={10.1109/INFCOM.2003.1208690},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208691,
author={D. Mitra and Q. Wang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Stochastic traffic engineering, with applications to network revenue management},
year={2003},
volume={1},
number={},
pages={396-405 vol.1},
abstract={A stochastic traffic engineering framework for optimizing bandwidth provisioning and path selection in networks is presented. The objective is to maximize revenue from serving demands, which are uncertain and specified by probability distributions. We consider a two-tier market structure, where demands in the two markets are associated with different unit revenues and uncertainties. Based on mean-risk analysis, the optimization model enables a carrier to maximize mean revenue and contain the risk that the revenue falls below an acceptable level. Our framework is intended for off-line traffic engineering design, which takes a centralized view of network topology, link capacity, and demand. We obtain conditions under which the optimization problem is an instance of convex programming and therefore efficiently solvable. We derive properties of the optimal solution for the special case of Gaussian distributions of demands. We focus on the impact of demand variability on various aspects of traffic engineering, such as link utilization, routing, capacity provisioning, and total revenue.},
keywords={telecommunication traffic;stochastic processes;telecommunication network management;telecommunication links;mathematical programming;Gaussian distribution;telecommunication network routing;convex programming;network topology;stochastic traffic engineering framework;network revenue management;bandwidth provisioning optimization;network path selection;mean revenue maximization;probability distribution;two-tier market structure;different unit revenue;mean-risk analysis;optimization model;off-line traffic engineering design;network topology;link capacity;convex programming;Gaussian distribution;demand variability impact;link utilization;routing;capacity provisioning;mathematical programming;serving demand uncertainty;Stochastic processes;Telecommunication traffic;Engineering management;Bandwidth;Probability distribution;Uncertainty;Risk analysis;Traffic control;Design engineering;Network topology},
doi={10.1109/INFCOM.2003.1208691},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208692,
author={Sundar Iyer and Supratik Bhattacharyya and N. Taft and C. Diot},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={An approach to alleviate link overload as observed on an IP backbone},
year={2003},
volume={1},
number={},
pages={406-416 vol.1},
abstract={Shortest path routing protocols may suffer from congestion due to the use of a single shortest path between a source and a destination. The goal of our work is to first understand how links become overloaded in an IP backbone, and then to explore if the routing protocol, -either in its existing form, or in some enhanced form could be made to respond immediately to overload and reduce the likelihood of its occurrence. Our method is to use extensive measurements of Sprint's backbone network, measuring 138 links between September 2000 and June 2001. We find that since the backbone is designed to be overprovisioned, link overload is rare, and when it occurs, 80% of the time it is caused due to link failures. Furthermore, we find that when a link is overloaded, few (if any) other links in the network are also overloaded. This suggests that deflecting packets to less utilized alternate paths could be an effective method for tackling overload. We analytically derive the condition that a network, which has multiple equal length shortest paths between every pair of nodes (as is common in the highly meshed backbone networks) can provide for loop-free deflection paths if all the link weights are within a ratio 1 + 1/(d- I) of each other; where d is the diameter of the network. Based on our measurements, the nature of the backbone topology and the careful use of link weights, we propose a deflection routing algorithm to tackle link overload where each node makes local decisions. Simulations suggest that this can be a simple and efficient way to overcome link overload, without requiring any changes to the routing protocol.},
keywords={routing protocols;transport protocols;telecommunication links;telecommunication congestion control;shortest path routing protocols;IP backbone topology;Sprint backbone network;loop-free deflection paths;deflection routing algorithm;link overload;network measurements;link failure;link weights;Spine;Routing protocols;Telecommunication traffic;Costs;Load management;Network topology;Traffic control;Availability;Resilience;Throughput},
doi={10.1109/INFCOM.2003.1208692},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208693,
author={J. Jung and A. W. Berger and Hari Balakrishnan},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Modeling TTL-based Internet caches},
year={2003},
volume={1},
number={},
pages={417-426 vol.1},
abstract={This paper presents a way of modeling the hit rates of caches that use a time-to-live (TTL)-based consistency policy. TTL-based consistency, as exemplified by DNS and Web caches, is a policy in which a data item, once retrieved, remains valid for a period known as the "time-to-live". Cache systems using large TTL periods are known to have high hit rates and scale well, but the effects of using shorter TTL periods are not well understood. We model hit rate as a function of request arrival times and the choice of TTL, enabling us to better understand cache behavior for shorter TTL periods. Our formula for the hit rate is closed form and relies upon a simplifying assumption about the interarrival times of requests for the data item in question: that these requests can be modeled as a sequence of independent and identically distributed random variables. Analyzing extensive DNS traces, we find that the results of the formula match observed statistics surprisingly well; in particular, the analysis is able to adequately explain the somewhat counterintuitive empirical finding of Jung et al. that the cache hit rate for DNS accesses rapidly increases as a function of TTL, exceeding 80% for a TTL of 15 minutes.},
keywords={cache storage;Internet;cache hit rates modeling;time-to-live based consistency policy;DNS;Web caches;request arrival times;shorter time-to-live periods;identically distributed random variables;Internet caches;Internet;Laboratories;Computer science;Information retrieval;Random variables;Statistical analysis;Statistical distributions;Delay;Bandwidth;Domain Name System},
doi={10.1109/INFCOM.2003.1208693},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208694,
author={O. Bahat and A. M. Makowski},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal replacement policies for nonuniform cache objects with optional eviction},
year={2003},
volume={1},
number={},
pages={427-437 vol.1},
abstract={Replacement policies for general caching applications and Web caching in particular have been discussed extensively in the literature. Many ad-hoc policies have been proposed that attempt to take adavantage of the retrieval latency of documents, their size, the popularity of references and temporal locality of requested documents. However, the problem of finding optimal replacement policies under these factors has not been pursued in any systematic manner. In this paper, we take a step in that direction: we first show, still under the independent reference model, that a simple Markov stationary replacement policy, called the policy C*/sub 0/, minimizes the long-run average metric induced by nonuniform document costs when document eviction is optional. We then propose a framework for operating caching systems with multiple performance metrics. We do so by solving a constrained caching problem with a single constraint. The resulting constrained optimal replacement policy is obtained by simple randomization between two Markov stationary optimal replacement policies C*/sub 0/ but induced by different costs.},
keywords={optimisation;cache storage;Internet;caching applications;Web caching;ad-hoc policies;independent reference model;Markov stationary replacement policy;C*/sub 0/ policy;long-run average metric;caching systems operating framework;multiple performance metrics;constrained caching problem;constrained optimal replacement policy;Markov stationary optimal replacement policies;nonuniform cache objects;replacement policy randomization;Educational institutions;Delay;Telecommunication traffic;Cache storage;Frequency estimation;Application software;Measurement;Cost function;Network servers;Content based retrieval},
doi={10.1109/INFCOM.2003.1208694},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208695,
author={P. Jelenkovic and A. Radovanovic},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Asymptotic insensitivity of least-recently-used caching to statistical dependency},
year={2003},
volume={1},
number={},
pages={438-447 vol.1},
abstract={We investigate a widely popular least-recently-used (LRU) cache replacement algorithm with semiMarkov modulated requests. SemiMarkov processes provide the flexibility for modeling strong statistical correlation, including the broadly reported long-range dependence in the World Wide Web page request patterns. When the frequency of requesting a page n is equal to the generalized Zipf's law c/n/sup /spl alpha//, /spl alpha/ > 1, our main result shows that the cache fault probability is asymptotically, for large cache sizes, the same as in the corresponding LRU system with i.i.d. requests. This appears to be the first explicit average case analysis of LRU caching with statistically dependent request sequences. The surprising insensitivity of LRU caching performance demonstrates its robustness to changes in document popularity. Furthermore, we show that the derived asymptotic result and simulation experiments are in excellent agreement, even for relatively small cache sizes. The potential of using our results in predicting the behavior of Web caches is tested using actual, strongly correlated, proxy server access traces.},
keywords={Markov processes;Internet;cache storage;least-recently-used cache replacement algorithm;semiMarkov modulated requests;statistical correlation modeling;World Wide Web page request patterns;generalized Zipf law;cache fault probability;statistically dependent request sequences;Web caches;proxy server access traces;Probability;Testing;Web sites;Frequency;Robustness;Application software;Internet;Heuristic algorithms;Algorithm design and analysis;Performance analysis},
doi={10.1109/INFCOM.2003.1208695},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208696,
author={R. Fonseca and V. Almeida and M. Crovella and B. Abrahao},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On the intrinsic locality properties of Web reference streams},
year={2003},
volume={1},
number={},
pages={448-458 vol.1},
abstract={There has been considerable work done in the study of Web reference streams: sequences of requests for Web objects. In particular, many studies have looked at the locality properties of such streams, because of the impact of locality on the design and performance of caching and prefetching systems. However, a general framework for understanding why reference streams exhibit given locality properties has not yet emerged. In this paper we take a first step in this direction. We propose a framework for describing how reference streams are transformed as they pass through the Internet, based on three operations: aggregation, disaggregation, and filtering. We also propose metrics to capture the temporal locality of reference streams in this framework. We argue that these metrics (marginal entropy and interreference coefficient of variation) are more natural and more useful than previously proposed metrics for temporal locality; and we show that these metrics provide insight into the nature of reference stream transformations in the Web.},
keywords={cache storage;entropy;Internet;Web reference streams;Web objects;caching system;prefetching systems;Internet;aggregation operation;disaggregation operation;filtering operation;reference stream temporal locality;entropy;interreference variation coefficient;reference stream transformations;Information filtering;Information filters;Computer science;Prefetching;Internet;Entropy;Protocols;Cache storage;Merging;Character generation},
doi={10.1109/INFCOM.2003.1208696},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208697,
author={Vikas Kawadia and P. R. Kumar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Power control and clustering in ad hoc networks},
year={2003},
volume={1},
number={},
pages={459-469 vol.1},
abstract={In this paper, we consider the problem of power control when nodes are nonhomogeneously dispersed in space. In such situations, one seeks to employ per packet power control depending on the source and destination of the packet. This gives rise to a joint problem which involves not only power control but also clustering. We provide three solutions for joint clustering and power control. The first protocol, CLUSTERPOW, aims to increase the network capacity by increasing spatial reuse. We provide a simple and modular architecture to implement CLUSTERPOW at the network layer. The second, Tunnelled CLUSTERPOW, allows a finer optimization by using encapsulation, but we do not know of an efficient way to implement it. The last, MINPOW, whose basic idea is not new, provides an optimal routing solution with respect to the total power consumed in communication. Our contribution includes a clean implementation of MINPOW at the network layer without any physical layer support. We establish that all three protocols ensure that packets ultimately reach their intended destinations. We provide a software architectural framework for our implementation as a network layer protocol. The architecture works with any routing protocol, and can also be used to implement other power control schemes. Details of the implementation in Linux are provided.},
keywords={ad hoc networks;telecommunication control;routing protocols;power control;nonhomogeneously dispersed nodes;packet power control;ad hoc network clustering;CLUSTERPOW protocol;network capacity;tunnelled CLUSTERPOW protocol;MINPOW protocol;software architectural framework;network layer protocol;Linux implementation;routing protocol;Power control;Intelligent networks;Ad hoc networks;Protocols;Contracts;Delay;Routing;Computer architecture;Linux;Batteries},
doi={10.1109/INFCOM.2003.1208697},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208698,
author={A. Muqattash and M. Krunz},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Power controlled dual channel (PCDC) medium access protocol for wireless ad hoc networks},
year={2003},
volume={1},
number={},
pages={470-480 vol.1},
abstract={In this paper, we propose a comprehensive solution for power control in mobile ad hoc networks (MANETs). Our solution emphasizes the interplay between the MAC and network layers, whereby the MAC layer indirectly influences the selection of the next-hop by properly adjusting the power of route request packets. This is done while maintaining network connectivity. Directional and channel-gain information obtained mainly from overheard RTS and CTS packets is used to dynamically construct the network topology. By properly estimating the required transmission power for data packets, our protocol allows for interference-limited simultaneous transmissions to take place in the neighborhood of a receiving node. Simulation results indicate that compared to the IEEE 802.11 approach, the proposed protocol achieves a significant increase in the channel utilization and end-to-end network throughput, and a significant decrease in the total energy consumption.},
keywords={channel allocation;ad hoc networks;mobile radio;telecommunication network routing;network topology;access protocols;power control;telecommunication control;power control;mobile ad hoc networks;MAC layer;network layers;route request packets;network connectivity;directional information;channel-gain information;request-to-send packets;clear-to-send packets;network topology;data packets transmission power;interference-limited simultaneous transmissions;IEEE 802.11;channel utilization;end-to-end network throughput;dual channel medium access protocol;Access protocols;Ad hoc networks;Power control;Mobile ad hoc networks;Energy consumption;Network topology;Interference;Throughput;Spread spectrum communication;Routing},
doi={10.1109/INFCOM.2003.1208698},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208699,
author={R. Zheng and R. Kravets},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={On-demand power management for ad hoc networks},
year={2003},
volume={1},
number={},
pages={481-491 vol.1},
abstract={Battery power is an important resource in ad hoc networks. It has been observed that in ad hoc networks, energy consumption does not reflect the communication activities in the network. Many existing energy conservation protocols based on electing a routing backbone for global connectivity are oblivious to traffic characteristics. In this paper, we propose an extensible on-demand power management framework for ad hoc networks that adapts to traffic load. Nodes maintain soft-state timers that determine power management transitions. By monitoring routing control messages and data transmission, these timers are set and refreshed on-demand. Nodes that are not involved in data delivery may go to sleep as supported by the MAC protocol. This soft state is aggregated across multiple flows and its maintenance requires no additional out-of-band messages. We implement a prototype of our framework in the ns-2 simulator that uses the IEEE 802.11 MAC protocol. Simulation studies using our scheme with the dynamic source routing protocol show a reduction in energy consumption near 50% when compared to a network without power management under both long-lived CBR traffic and on-off traffic loads, with comparable throughput and latency. Preliminary results also show that it outperforms existing routing backbone election approaches.},
keywords={ad hoc networks;routing protocols;access protocols;power control;telecommunication control;telecommunication network management;wireless LAN;ad hoc networks;on-demand power management framework;power management transitions;MAC protocol;ns-2 simulator;IEEE 802.11 MAC protocol;dynamic source routing protocol;CBR traffic;soft-state timers;data transmission monitoring;energy consumption reduction;Energy management;Ad hoc networks;Telecommunication traffic;Energy consumption;Routing protocols;Spine;Media Access Protocol;Batteries;Energy conservation;Communication system traffic control},
doi={10.1109/INFCOM.2003.1208699},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208700,
author={Y. E. Sagduyu and A. Ephremides},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Energy-efficient collision resolution in wireless ad-hoc networks},
year={2003},
volume={1},
number={},
pages={492-502 vol.1},
abstract={In this paper, we address the collision resolution (CR) problem from an energy-efficiency point of view and develop a residual-energy-based collision resolution algorithm (CRA) for energy-limited terminals. In this algorithm, which is based on tree-splitting, packets involved in a collision are partitioned into subsets according to the amount of residual battery energy left at the corresponding terminals, and retransmissions are scheduled according to a tree structure. We extend the proposed energy-based CR approach to cases without hard energy constraints but, rather, with energy-efficiency objectives. The algorithm then utilizes the distance from the receiver as the criterion. We evaluate the proposed algorithm via simulation for communication systems ranging from simple single-cell classical collision channel models to general multihop wireless ad-hoc networks.},
keywords={telecommunication congestion control;ad hoc networks;radio access networks;collision resolution algorithm;energy-limited terminals;tree-splitting;residual battery energy;simulation;communication systems;single-cell classical collision channel models;multihop wireless ad-hoc networks;packet retransmissions;packet subsets;Energy efficiency;Energy resolution;Intelligent networks;Ad hoc networks;Partitioning algorithms;Batteries;Spread spectrum communication;Throughput;Chromium;Collaborative work},
doi={10.1109/INFCOM.2003.1208700},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208701,
author={M. Buddhikot and G. Chandranmenon and S. Han and Y. W. Lee and S. Miller and L. Salgarelli},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Integration of 802.11 and third-generation wireless data networks},
year={2003},
volume={1},
number={},
pages={503-512 vol.1},
abstract={The third-generation (3G) wide area wireless networks and 802.11 local area wireless networks possess complementary characteristics. 3G networks promise to offer always-on, ubiquitous connectivity with relatively low data rates. 802.11 offers much higher data rates, comparable to wired networks, but can cover only smaller areas, suitable for hot-spot applications in hotels and airports. The performance and flexibility of wireless data services would be dramatically improved if users could seamlessly roam across the two networks. In this paper, we address the problem of integration of these two classes of networks to offer such seamless connectivity. Specifically, we describe two possible integration approaches - namely tight integration and loose integration and advocate the latter as the preferred approach. Our realization of the loose integration approach consists of two components: a new network element called IOTA gateway deployed in 802.11 networks, and a new client software. The IOTA gateway is composed of several software modules, and with cooperation from the client software offers integrated 802.11/3G wireless data services that support seamless intertechnology mobility, Quality of Service (QoS) guarantees and multiprovider roaming agreements. We describe the design and implementation of the IOTA gateway and the client software in detail and present experimental performance results that validate our architectural approach.},
keywords={wireless LAN;data communication;quality of service;3G mobile communication;third-generation wide area wireless networks;802.11 local area wireless networks;hot-spot applications;seamless connectivity;tight integration approach;loose integration approach;network element;IOTA gateway;client software;software modules;integrated 802.11/3G wireless data services;seamless intertechnology mobility;QoS guarantees;multiprovider roaming agreements;Wireless networks;Airports;Software quality;Quality of service;Roaming;3G mobile communication;Wireless LAN;Investments;Switches;USA Councils},
doi={10.1109/INFCOM.2003.1208701},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208702,
author={A. Kopke and A. Willig and H. Karl},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Chaotic maps as parsimonious bit error models of wireless channels},
year={2003},
volume={1},
number={},
pages={513-523 vol.1},
abstract={The error patterns of a wireless digital communication channel can be described by looking at consecutively correct or erroneous bits (runs and bursts) and at the distribution function of these run and burst lengths. A number of stochastic models exist that can be used to describe these distributions for wireless channels, e.g., the Gilbert-Elliot model. When attempting to apply these models to actually measured error sequences, they fail: measured data gives raise to two essentially different types of error patterns which can not be described using simple error models like Gilbert-Elliot. These two types are distinguished by their run length distribution; one type in particular is characterized by a heavy-tailed run length distribution. This paper shows how the chaotic map model can be used to describe these error types and how to parameterize this model on the basis of measurement data. We show that the chaotic map model is a superior stochastic bit error model for such channels by comparing it with both simple and complex error models. Chaotic maps achieve a modeling accuracy that is far superior to that of simple models and competitive with that of much more complex models, despite needing only six parameters. Furthermore, these parameters have a clear intuitive meaning and are amenable to direct manipulation. In addition, we show how the second type of channels can be well described by a semiMarkov model using a quantized lognormal state holding time distribution.},
keywords={wireless LAN;chaotic communication;error statistics;digital radio;wireless digital communication channel;parsimonious bit error models;chaotic maps;error patterns;heavy-tailed run length distribution;burst length distribution function;stochastic bit error model;Gilbert-Elliot model;semiMarkov model;quantized lognormal time distribution;state holding time distribution;IEEE 802.11 sources;Chaos;Chaotic communication;Wireless communication;Stochastic processes;Stochastic resonance;Error correction;Digital communication;Wireless application protocol;Access protocols;Distribution functions},
doi={10.1109/INFCOM.2003.1208702},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208703,
author={B. Hajek and K. Mitzel and S. Yang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Paging and registration in cellular networks: jointly optimal policies and an iterative algorithm},
year={2003},
volume={1},
number={},
pages={524-532 vol.1},
abstract={This paper explores optimization of paging and registration policies in cellular networks. Motion is modeled as a discrete-time Markov process, and minimization of the discounted, infinite-horizon average cost is addressed. The structure of jointly optimal paging and registration policies is investigated through the use of dynamic programming for partially observed processes. It is shown that there exist policies with a certain simple structure that are jointly optimal, though the dynamic programming approach does not directly provide an efficient method to find the policies. An iterative algorithm for policies with the simple form is proposed and investigated. The algorithm alternates between paging policy optimization and registration policy optimization. It finds a pair of individually optimal policies, but an example is given showing that the policies need not be jointly optimal.},
keywords={dynamic programming;paging communication;cellular radio;iterative methods;Markov processes;cellular networks;paging policies optimization;registration policies optimization;policy iterative algorithm;jointly optimal policies;discrete-time Markov process;infinite-horizon average cost minimization;dynamic programming approach;Intelligent networks;Land mobile radio cellular systems;Iterative algorithms;Costs;Dynamic programming;Delay;Satellite broadcasting;Markov processes;Personal communication networks;Wireless communication},
doi={10.1109/INFCOM.2003.1208703},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208704,
author={I. Koutsopoulos and T. Ren and L. Tassiulas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={The impact of space division multiplexing on resource allocation: a unified approach},
year={2003},
volume={1},
number={},
pages={533-543 vol.1},
abstract={Recent advances in the area of wireless communications have revealed the emerging need for efficient wireless access in personal, local and wide area networks. Space division multiple access (SDMA) with smart antennas at the base station is recognized as a promising means of increasing system capacity and supporting rate-demanding services. However, the existence of SDMA at the physical layer raises significant issues at higher layers. In this paper, we attempt to capture the impact of SDMA on channel allocation at the media access control (MAC) layer. This impact obtains different forms in TDMA, CDMA and OFDMA access schemes, due to the different cochannel and interchannel interference instances, as well as the different effect of corresponding channels (time slots, codes or subcarrier frequencies) on user channel characteristics. We follow a unified approach for these multiple access schemes and propose heuristic algorithms to allocate channels to users and adjust down-link beamforming vectors and transmission powers, with the objective to increase achievable system rate and provide QoS to users in the form of minimum rate guarantees. We consider the class of greedy algorithms, based on criteria such as minimum induced or received interference and minimum signal-to-interference ratio (SIR), as well as the class of SIR balancing algorithms. Our results indicate that this cross-layer approach yields significant performance benefits and that SIR balancing algorithms achieves the best performance.},
keywords={space division multiple access;channel allocation;quality of service;access protocols;radiofrequency interference;cellular radio;wireless communications;resource allocation;personal area networks;local area networks;wide area networks;space division multiple access;rate-demanding services;SDMA access scheme;media access control;MAC layer;TDMA access scheme;CDMA access scheme;OFDMA access scheme;cochannel interference;interchannel interference;user channel characteristics;down-link beamforming vectors;down-link transmission powers;QoS guarantees;greedy algorithm class;signal-to-interference ratio;SIR balancing algorithms;Resource management;Multiaccess communication;Wireless communication;Wide area networks;Space stations;Base stations;Physical layer;Channel allocation;Media Access Protocol;Time division multiple access},
doi={10.1109/INFCOM.2003.1208704},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208705,
author={Anupam Gupta and Amit Kumar and Rajeev Rastogi},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Exploring the trade-off between label size and stack depth in MPLS routing},
year={2003},
volume={1},
number={},
pages={544-554 vol.1},
abstract={Multiprotocol label switching or MPLS technology is being increasingly deployed by several of the largest Internet service providers to solve problems such as traffic engineering and to offer IP services like virtual private networks (VPNs). In MPLS, the analysis of the packet (network layer) header is performed just once, and each packet is assigned a stack of labels, which is examined by subsequent routers when making forwarding decisions. Despite the fact that MPLS is becoming widespread on the Internet, we know essentially very little about the performance one can achieve with it, and about the intrinsic trade-offs in its use of resources. In this paper, we undertake a comprehensive study of the label size versus stack depth trade-off for MPLS routing protocols on lines and trees. We show that in addition to LSP tunneling, label stacks can also be used to dramatically reduce the number of labels required for setting up MPLS LSPs in a network. Based on this observation, we develop routing algorithms and prove lower bounds for two basic problems: (1) fixed label routing: given a fixed number of labels, we want to minimize the stack depth, and (2) fixed stack routing: given a bound on the stack depth, we want to minimize the number of labels used. Our simulation results validate our approach, demonstrating that our novel protocols enable MPLS routing on large trees with few labels and small stack sizes. Thus, our MPLS routing algorithms are applicable to a number of practical scenarios involving the provisioning of VPNs and multicast trees.},
keywords={multiprotocol label switching;routing protocols;Internet;telecommunication traffic;virtual private networks;MPLS routing protocols;Internet service providers;traffic engineering problem;IP services;virtual private networks;VPN service;network layer packet header analysis;label size/stack depth trade-off;LSP tunneling;routing algorithms;fixed label routing problem;fixed stack routing problem;multicast trees provisioning;Multiprotocol label switching;Virtual private networks;Routing protocols;Performance analysis;Computer science;Web and internet services;Telecommunication traffic;Tunneling;Multicast algorithms;Data mining},
doi={10.1109/INFCOM.2003.1208705},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208706,
author={D. Applegate and M. Thorup},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Load optimal MPLS routing with N + M labels},
year={2003},
volume={1},
number={},
pages={555-565 vol.1},
abstract={MPLS is becoming an important protocol for intradomain routing. MPLS routers are offered by the major vendors and many ISPs are deploying MPLS in their IP backbones, as well as in ATM and frame relay networks. For this period of possible transition to MPLS, it is urgent to increase our understanding of the power and limitation of MPLS. An attraction to MPLS is the flexibility it offers in engineering the routing of traffic in a network, e.g., to support higher demands without overloading any links. Mitra and Ramakrishnan [GLOBECOM'99] showed that optimal routing solutions may be found for a diverse set of traffic engineering goals. However, for a network with N nodes (routers) and M edges (links), their MPLS implementation may use /spl Omega/(N /spl times/ M) different labels. This is prohibitive since the number of labels is the number of entries needed in the router tables. We present an algorithm reducing the number of MPLS labels to N + M without increasing any link load. Our explicit N + M bound makes it easy to limit the table size requirement for a planned network, and the linearity allows for tables implemented in fast memory. For differentiated services with K traffic classes with different load constraints, our bound increases to K(N + M). Our stack-depth is only one, justifying implementations of MPLS with limited stack-depth.},
keywords={multiprotocol label switching;telecommunication traffic;IP networks;routing protocols;load optimal MPLS routing;intradomain routing protocol;ISPs deployment;IP backbones;ATM networks;frame relay networks;optimal routing solutions;traffic engineering goals;MPLS labels;limited stack-depth MPLS implementation;router tables;network link load;network table size requirement;Multiprotocol label switching;Telecommunication traffic;Power engineering and energy;Communication system traffic control;Routing protocols;Laboratories;Electronic mail;Spine;Asynchronous transfer mode;Frame relay},
doi={10.1109/INFCOM.2003.1208706},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208707,
author={Indra Widjaja and A. I. Elwalid},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Exploiting parallelism to boost data-path rate in high-speed IP/MPLS networking},
year={2003},
volume={1},
number={},
pages={566-575 vol.1},
abstract={Link bundling is a way to increase routing scalability whenever a pair of label switching routers in MPLS are connected by multiple parallel links. However, link bundling can be inefficient as a label switched path (LSP) has to be associated with a particular link. In this paper, we show that the efficiency of link bundling can be significantly improved if traffic can be effectively distributed across the parallel links. We propose an IP switch architecture that is capable of distributing flows both inside the switch and among the parallel links based on operations that are relatively simple to implement. The switch requires no speedup, guarantees in-sequence packet delivery for a given flow, avoids complex coordination algorithms, and can achieve LSP throughput higher than the line rate. By means of simulation using IP traces, we investigate the performance of the proposed switch, and show that the switch achieves good load-balancing performance. We describe extensions to the basic architecture which allows for very large bundle size, handles incremental upgrade strategy, improves reliability, and accommodates nonIP traffic.},
keywords={IP networks;routing protocols;multiprotocol label switching;telecommunication traffic;telecommunication links;IP/MPLS networking;data-path rate;link bundling;label switching routers;multiple parallel links;label switched path throughput;IP switch architecture;complex coordination algorithms;in-sequence packet delivery;load-balancing performance;incremental upgrade strategy;nonIP traffic;link hashing;Intelligent networks;Multiprotocol label switching;Switches;Telecommunication traffic;Spine;Packet switching;Protocols;Routing;Scalability;Throughput},
doi={10.1109/INFCOM.2003.1208707},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208708,
author={L. Gouveia and P. Patricio and A. F. de Sousa and R. Valadas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={MPLS over WDM network design with packet level QoS constraints based on ILP models},
year={2003},
volume={1},
number={},
pages={576-586 vol.1},
abstract={MPLS (multiprotocol label switching) over WDM (wavelength division multiplexing) networks are gaining significant attention due to the efficiency in resource utilization that can be achieved by jointly considering the two network layers. This paper addresses the design of MPLS over WDM networks, where some of the WDM nodes may not have packet switching capabilities. Given the WDM network topology and the offered traffic matrix, which includes the location of the edge LSRs (label switched routers), we jointly determine the location of the core LSRs (i.e. the core WDM nodes that also need to include packet switching capabilities) and the lightpath routes (which are terminated on the LSRs) that minimize the total network cost. We consider constraints both at the optical and packet layers: an MPLS hop constraint on the maximum number of LSRs traversed by each LSP (label switched path), which guarantees a given packet level QoS, and a WDM path constraint on the maximum length of lightpaths, which accommodates the optical transmission impairments. A novel integer linear programming (ILP) formulation based on an hop-indexed approach, which we call the HOP model, is proposed. A two-phase heuristic, derived from a decomposition of the HOP model in two simpler ILP models that are solved sequentially, is also developed. The computational results show that the heuristic is efficient and produces good quality solutions, as assessed by the lower bounds computed from the HOP model. In some cases, the optimal solution is obtained with the branch-and-bound method.},
keywords={multiprotocol label switching;wavelength division multiplexing;quality of service;integer programming;packet level QoS constraints;multiprotocol label switching networks;wavelength division multiplexing networks;packet switching capabilities;label switched routers;core WDM nodes;optical layer constraints;label switched path;optical transmission impairments;integer linear programming formulation;hop-indexed approach;HOP model;branch-and-bound method;network design;network planning;Multiprotocol label switching;WDM networks;Wavelength division multiplexing;Optical packet switching;Packet switching;Resource management;Network topology;Telecommunication traffic;Costs;Integer linear programming},
doi={10.1109/INFCOM.2003.1208708},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208709,
author={M. Zukerman and T. D. Neame and R. G. Addie},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Internet traffic modeling and future technology implications},
year={2003},
volume={1},
number={},
pages={587-596 vol.1},
abstract={This paper presents the Poisson Pareto burst process (PPBP) as a simple but accurate model for Internet traffic. It presents formulae relating the parameters of the PPBP to measurable traffic statistics, and describes a technique for fitting the PPBP to a given traffic stream. The PPBP is shown to accurately predict the queueing performance of a sample trace of aggregated Internet traffic. We predict that in few years, natural growth and statistical multiplexing will lead to an efficient optical Internet.},
keywords={Internet;Pareto distribution;queueing theory;telecommunication traffic;stochastic processes;Internet traffic modeling;Poisson Pareto burst process;traffic statistics;sample trace queueing performance;statistical multiplexing;optical Internet;Internet;Traffic control;Statistics;Predictive models;Telecommunication traffic;Stochastic processes;Queueing analysis;Optical packet switching;Performance analysis;Analytical models},
doi={10.1109/INFCOM.2003.1208709},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208710,
author={D. Y. Eun and N. B. Shroff},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Simplification of network analysis in large-bandwidth systems},
year={2003},
volume={1},
number={},
pages={597-607 vol.1},
abstract={In this paper, we show that significant simplicities can arise in the analysis of a network when link capacities are large enough to carry many flows. In particular, we prove that, when an upstream queue serves a large number of regulated traffic sources, the queue-length of the downstream queue converges almost surely to the queue-length of a simplified queueing system (single queue) obtained by removing the upstream queue. We provide similar results (convergence of the queue-length in distribution) for general (including nonregulated) traffic arrivals. In both cases, the convergence of the overflow probability is uniform and at least exponentially fast. Through an extensive numerical investigation, we demonstrate several aspects and implications of our results in simplifying network analysis.},
keywords={Internet;queueing theory;telecommunication traffic;convergence;network analysis simplification;large-bandwidth systems;upstream queue;regulated traffic sources;downstream queue-length;queueing system;distribution queue-length convergence;nonregulated traffic arrivals;overflow probability convergence;Intelligent networks;Traffic control;Queueing analysis;Telecommunication traffic;Helium;IP networks;Quality of service;Next generation networking;Stochastic processes;Communication system traffic control},
doi={10.1109/INFCOM.2003.1208710},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208711,
author={P. Key and L. Massoulie},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Probing strategies for distributed admission control in large and small scale systems},
year={2003},
volume={1},
number={},
pages={608-618 vol.1},
abstract={The aim of this article is to propose and analyse measurement-based admission control schemes. We distinguish between large-scale and small-scale systems, where scale is measured in the number of concurrent applications that can run simultaneously. For large scale systems, we show that simple end-user probing strategies, based on ECN-type feedback provided by the network, achieve a good utilisation/quality trade-off. We explicitly take account of feedback delay, and use limiting results for assessing performance. We illustrate the benefits of using ECN-type feedback rather than relying on loss. For small-scale systems, the previous strategies are no longer adequate and we propose alternative, more gradual probing strategies.},
keywords={stochastic processes;telecommunication traffic;queueing theory;distributed control;telecommunication congestion control;distributed admission control;small scale systems;measurement-based admission control schemes;large-scale systems;concurrent applications;end-user probing strategies;ECN-type feedback;explicit congestion notification;quality trade-off;feedback delay;stochastic processes;queuing theory;control theory;system design;Admission control;Feedback;Delay;Traffic control;Quality of service;Bandwidth;Large-scale systems;Probes;Control system analysis;Stochastic processes},
doi={10.1109/INFCOM.2003.1208711},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208712,
author={Mahadevan Iyer and W. K. Tsai},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Time-optimal network queue control: the case of a single congested node},
year={2003},
volume={1},
number={},
pages={619-629 vol.1},
abstract={The problem of time-optimal network queue control is solved: what are the input data rates that make network queue sizes converge to their ideal size in the least possible time after a disturbance while still maintaining maximum link utilization at all times, even in the transient? The problem is nontrivial especially because of the vast possible heterogeneity in packet propagation delays in the network. In this paper, we derive the time-optimal queue control for a single congested network node with a single finite queue shared by flows with arbitrary network delays. We neatly separate the derivation of the optimal arrival rate sequence from that of the feedback control protocol to achieve it. The time-optimal control is robust to bandwidth and queue size estimation errors. Its complexity is only a function of the size of the network delays and no per-flow computation is needed. The time-optimality and robustness properties are proven to hold under all queue operating regimes with no need for linearizing approximations.},
keywords={asynchronous transfer mode;telecommunication congestion control;time optimal control;queueing theory;telecommunication links;protocols;packet switching;time-optimal network queue control;single congested node;link utilization;packet propagation delays;arbitrary network delays;optimal arrival rate sequence;feedback control protocol;queue size estimation errors;per-flow computation;linearizing approximations;ATM;ABR;available bit rate;asynchronous transfer mode;Size control;Propagation delay;Feedback control;Protocols;Robust control;Bandwidth;Estimation error;Computer networks;Robustness;Linear approximation},
doi={10.1109/INFCOM.2003.1208712},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208713,
author={Jiangchuan Liu and Bo Li and Y. T. Hou and I. Chlamtac},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Dynamic layering and bandwidth allocation for multisession video broadcasting with general utility functions},
year={2003},
volume={1},
number={},
pages={630-640 vol.1},
abstract={For video broadcasting applications in a wireless environment, layered transmission is an effective approach to support heterogeneous receivers with varying bandwidth requirements. There are several important issues that need to be addressed for such layered video broadcasting systems. At the session level, it is not clear how to allocate bandwidth resources among competing video sessions. For a session with a given bandwidth, questions such as how to set up the video layering structure (i.e., number of layers) and how much bandwidth should be allocated to each layer remain to be answered. The solutions to these questions are further complicated by practical issues such as uneven popularity among video sessions and video layering overhead. This paper presents a systematic study to address these issues for a layered video broadcasting system in a wireless environment. Our approach is to employ a generic utility function for each receiver under each video session. We cast the joint problem of layering and bandwidth allocation (among sessions and layers) into an optimization problem of total system utility among all the receivers. By using a simple 2-step decomposition of inter-session and intra-session optimization, we derive efficient algorithms to solve the optimal layering and bandwidth allocation problem. Practical issues for deploying the optimal algorithm in wireless networks are also discussed. Simulation results show that the optimal layering and bandwidth allocation improves the total system utility.},
keywords={digital video broadcasting;receivers;bandwidth allocation;optimisation;dynamic layering;bandwidth allocation;multisession video broadcasting applications;layered transmission;heterogeneous receivers;video sessions;generic utility function;joint problem;2-step decomposition;inter-session optimization;intra-session optimisation;wireless networks;Channel allocation;Multimedia communication;Broadcasting;Bandwidth;Video compression;Video sharing;Streaming media;Broadcast technology;Computer science;Resource management},
doi={10.1109/INFCOM.2003.1208713},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208714,
author={T. Kim and M. H. Ammar},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal quality adaptation for MPEG-4 fine-grained scalable video},
year={2003},
volume={1},
number={},
pages={641-651 vol.1},
abstract={Dynamic behavior of the Internet's transmission resources makes it difficult to provide perceptually good quality of streaming video. MPEG-4 Fine-Grained Scalable coding is proposed to deal with this problem by distributing the data in enhancement layers over a wide range of bit rates. However, encoded video also exhibits significant data rate variability to provide a consistent quality video. We are, therefore, faced with the problem of trying to accommodate the mismatch between the available bandwidth variability and the encoded video variability. In this paper, we investigate quality adaptation of the layered VBR video generated by MPEG-4 FGS. Our goal is to develop a quality adaptation scheme that maximizes perceptual video quality through minimizing quality variation while at the same time increasing the usage of available bandwidth. We develop an optimal adaptation scheme and an online heuristic based on whether the network conditions are known a priori. Experimental results show that the online heuristic as well as the optimal adaptation algorithm provide consistent video quality when used over both TFRC and TCP.},
keywords={video coding;Internet;variable rate codes;transport protocols;MPEG-4 fine-grained scalable video;dynamic behavior;Internet;transmission resources;scalable coding;encoded video;layered VBR video;variable bit rate;quality adaptation scheme;online heuristic;optimal adaptation algorithm;TFRC;TCP;transport protocols;MPEG 4 Standard;Bandwidth;Internet;Streaming media;Encoding;Bit rate;Decoding;Fluctuations;Video compression;Propagation losses},
doi={10.1109/INFCOM.2003.1208714},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208715,
author={C. Boutremans and J. -. Le Boudec},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Adaptive joint playout buffer and FEC adjustment for Internet telephony},
year={2003},
volume={1},
number={},
pages={652-662 vol.1},
abstract={A joint playout buffer and forward error correction (FEC) adjustment scheme are developed for Internet telephony, which incorporates the impact of end-to-end delay on the perceived audio quality. We show that it provides better quality than the adjustment schemes for playout buffer and FEC that were previously published. This is important because of a threshold effect when the end-to-end delay of interactive audio is around 150 ms. We represent the perceived audio quality as a function of both the end-to-end delay and the distortion of the voice signal. We develop a joint rate/error/playout delay control algorithm that optimizes this measure of quality and is TCP-friendly. It uses a channel model for both loss and delay. We validate our approach by simulation and show that (1) our scheme allows a source to increase its utility by avoiding an increase of the playout delay when it is not really necessary, (2) it performs better than direct combinations of existing algorithms in the cases where end-to-end delay is important and (3) adaptive delay aware FEC adjustment brings significant improvements only if it is coupled with an adaptive playout adjustment.},
keywords={forward error correction;buffer storage;interactive systems;delays;Internet telephony;transport protocols;optimisation;adaptive joint playout buffer;forward error correction;FEC adjustment scheme;Internet telephony;end-to-end delay;audio quality;threshold effect;voice signal distortion;joint rate/error/playout delay control algorithm;channel model;TCP-friendly delay control algorithm;quality measure optimization;Internet telephony;Forward error correction;Error correction;Added delay;Delay effects;Programmable control;Adaptive control;Distortion measurement;IP networks;Bit rate},
doi={10.1109/INFCOM.2003.1208715},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208716,
author={T. Nguyen and A. Zakhor},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Path diversity with forward error correction (PDF) system for packet switched networks},
year={2003},
volume={1},
number={},
pages={663-672 vol.1},
abstract={Packet loss and end-to-end delay limit delay sensitive applications over the best effort packet switched networks such as the Internet. In our previous work, we have shown that substantial reduction in packet loss can be achieved by sending packets at appropriate sending rates to a receiver from multiple senders, using disjoint paths, and by protecting packets with forward error correction. In this paper, we propose a path diversity with forward error correction (PDF) system for delay sensitive applications over the Internet in which, disjoint paths from a sender to a receiver are created using a collection of relay nodes. We propose a scalable, heuristic scheme for selecting a redundant path between a sender and a receiver, and show that substantial reduction in packet loss can be achieved by dividing packets between the default path and the redundant path. NS simulations are used to verify the effectiveness of PDF system.},
keywords={forward error correction;packet switching;Internet;path diversity with forward error correction system;packet switched network;packet loss reduction;end-to-end delay limit;delay sensitive application;Internet;disjoint path;relay node collection;scalable heuristic scheme;redundant path;NS simulation;Forward error correction;Packet switching;Internet;Streaming media;Bandwidth;IP networks;Delay systems;Bit rate;Video codecs;Protocols},
doi={10.1109/INFCOM.2003.1208716},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208717,
author={K. Kar and Murali Kodialam and T. V. Lakshman and L. Tassiulas},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Routing for network capacity maximization in energy-constrained ad-hoc networks},
year={2003},
volume={1},
number={},
pages={673-681 vol.1},
abstract={A new algorithm for routing of messages in ad-hoc networks where the nodes are energy-constrained is presented. The routing objective is to maximize the total number of messages that can be successfully sent over the network without knowing any information regarding future message arrivals or message generation rates. From a theoretical perspective, we show that if admission control of messages is permitted, then the worst-case performance of our algorithm is within a factor of O(log(network size)) of the best achievable solution. In other words, our algorithm achieves a logarithmic competitive ratio. Our approach provides sound theoretical backing for several observations that have been made by previous researchers. From a practical perspective, we show by extensive simulations that the performance of the algorithm is very good even in the absence of admission control (the admission control being necessary only to prove the competitive ratio result), and that it also performs better than previously proposed algorithms for other suggested metrics such as network lifetime maximization. Our algorithm uses a single shortest path computation, and is amenable to efficient implementation. We also evaluate by simulations the performance impact of inexact knowledge of residual battery energy, and the impact of energy drain due to dissemination of residual energy information.},
keywords={telecommunication network routing;ad hoc networks;telecommunication congestion control;optimisation;network capacity maximization routing;energy-constrained ad-hoc network;message generation rate;message admission control;logarithmic competitive ratio;shortest path computation;residual battery energy;energy drain impact;residual energy information dissemination;future message arrival;Routing;Intelligent networks;Ad hoc networks;Admission control;Batteries;Costs;Wireless sensor networks;Energy consumption;Educational institutions;Computational modeling},
doi={10.1109/INFCOM.2003.1208717},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208718,
author={G. Zussman and A. Segall},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Energy efficient routing in ad hoc disaster recovery networks},
year={2003},
volume={1},
number={},
pages={682-691 vol.1},
abstract={The terrorist attacks on September 11, 2001 have drawn attention to the use of wireless technology in order to locate survivors of structural collapse. We propose to construct an ad hoc network of wireless smart badges in order to acquire information from trapped survivors. We investigate the energy efficient routing problem that arises in such a network and show that since smart badges have very limited power sources and very low data rates, which may be inadequate in an emergency situation, the solution of the routing problem requires new protocols. The problem is formulated as an anycast routing problem in which the objective is to maximize the time until the first battery drains-out. We present iterative algorithms for obtaining the optimal solution of the problem. Then, we derive an upper bound on the network lifetime for specific topologies. Finally, a polynomial algorithm for obtaining the optimal solution in such topologies is described.},
keywords={ad hoc networks;telecommunication network routing;disasters;iterative methods;protocols;network topology;energy efficient routing;ad hoc disaster recovery network;wireless technology;wireless smart badge;energy efficient routing problem;power source;data rate;protocol;time maximization;iterative algorithm;network lifetime;polynomial algorithm;topology;IEEE 802.15;Energy efficiency;Routing;Intelligent networks;Terrorism;Ad hoc networks;Wireless sensor networks;Batteries;Iterative algorithms;Network topology;Mobile ad hoc networks},
doi={10.1109/INFCOM.2003.1208718},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208719,
author={Rajgopal Kannan and Sudipta Sarangi and S. S. Iyengar and Lydia Ray},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Sensor-centric quality of routing in sensor networks},
year={2003},
volume={1},
number={},
pages={692-701 vol.1},
abstract={Standard embedded sensor network models emphasize energy efficiency and distributed decision-making by considering untethered and unattended sensors. To this we add two constraints - the possibility of sensor failure and the fact that each sensor must tradeoff its own resource consumption with overall network objectives. In this paper, we develop an analytical model of data-centric information routing in sensor networks under all the above constraints. Unlike existing techniques, we use game theory to model intelligent sensors thereby making our approach sensor-centric. Sensors behave as rational players in an N-player routing game, where they tradeoff individual communication and other costs with network wide benefits. The outcome of the sensor behavior is a sequence of communication link establishments, resulting in routing paths from reporting to querying sensors. We show that the optimal routing architecture is the Nash equilibrium of the N-player routing game and that computing the optimal paths (which maximizes payoffs of the individual sensors) is NP-hard with and without data-aggregation. We develop a game-theoretic metric called path weakness to measure the qualitative performance of different routing mechanisms. This sensor-centric concept which is based on the contribution of individual sensors to the overall routing objective is used to define the quality of routing (QoR) paths. Simulation results are used to compare the QoR of different routing paths derived using various energy-constrained routing algorithms.},
keywords={distributed decision making;wireless sensor networks;game theory;intelligent sensors;telecommunication network routing;sensor-centric;quality of routing path;embedded sensor network model;energy efficiency;distributed decision-making;untethered sensor;unattended sensor;sensor failure;resource consumption;data-centric information routing;analytical model;game theory;intelligent sensor model;rational player;N-player routing game;communication link establishment;optimal routing architecture;Nash equilibrium;optimal path computing;NP-hard problem;data-aggregation;game-theoretic metric;path weakness;qualitative performance measure;energy-constrained routing algorithm;payoff maximization;Routing;Intelligent networks;Intelligent sensors;Sensor phenomena and characterization;Game theory;Energy efficiency;Computer science;Power generation economics;Distributed decision making;Analytical models},
doi={10.1109/INFCOM.2003.1208719},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208720,
author={R. L. Cruz and A. V. Santhanam},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Optimal routing, link scheduling and power control in multihop wireless networks},
year={2003},
volume={1},
number={},
pages={702-711 vol.1},
abstract={In this paper, we study the problem of joint routing, link scheduling and power control to support high data rates for broadband wireless multihop networks. We first address the problem of finding an optimal link scheduling and power control policy that minimizes the total average transmission power in the wireless multihop network, subject to given constraints regarding the minimum average data rate per link, as well as peak transmission power constraints per node. Multiaccess signal interference is explicitly modeled. We use a duality approach whereby, as a byproduct of finding the optimal policy, we find the sensitivity of the minimal total average power with respect to the average data rate for each link. Since the minimal total average power is a convex function of the required minimum average data rates, shortest path algorithms with the link weights set to the link sensitivities can be used to guide the search for a globally optimum routing. We present a few simple examples that show our algorithm can find policies that support data rates that are not possible with conventional approaches. Moreover, we find that optimum allocations do not necessarily route traffic over minimum energy paths.},
keywords={telecommunication control;scheduling;broadband networks;radio links;telecommunication network routing;power control;optimal network routing;network link scheduling;network power control;multihop wireless network;broadband wireless multihop network;average transmission power;transmission power constraint;multiaccess signal interference;duality approach;minimal total average power sensitivity;average data rate;shortest path algorithm;link weight;minimum energy path;Routing;Power control;Intelligent networks;Spread spectrum communication;Wireless networks;Processor scheduling;Transmitters;Interference constraints;Frequency;Femtocell networks},
doi={10.1109/INFCOM.2003.1208720},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208721,
author={S. K. Kasera and Ramachandran Ramjee and S. Thuel and X. Wang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Congestion control policies for IP-based CDMA radio access networks},
year={2003},
volume={1},
number={},
pages={712-722 vol.1},
abstract={As CDMA-based cellular networks mature, the current point-to-point links used in connecting base stations to network controllers will evolve to an IP-based radio access network (RAN) for reasons of lower cost due to statistical multiplexing gains, better scalability and reliability, and the projected growth in data applications. In this paper, we study the impact of congestion in a best-effort IP RAN on CDMA cellular voice networks. We propose and evaluate three congestion control mechanisms, admission control, diversity control, and router control, to maximize network capacity while maintaining good voice quality. We first propose two new enhancements to CDMA call admission control that consider a unified view of both IP RAN and air interface resources. Next, we introduce a novel technique called diversity control that exploits the soft-handoff feature of CDMA networks and drops selected frames belonging to multiple soft-handoff legs to gracefully degrade voice quality during congestion. Finally, we study the impact of router control where an active queue management technique is used to reduce delay and minimize correlated losses. Using simulations of a large mobile network, we show that the three different control mechanisms can help gracefully manage 10-40% congestion overload in the IP RAN.},
keywords={telecommunication congestion control;multiplexing;code division multiple access;radio access networks;cellular radio;radio links;Internet telephony;telecommunication network routing;queueing theory;computer network management;IP networks;congestion control policy;IP-based CDMA radio access network;point-to-point link;base station connection;network controller;statistical multiplexing gain;network reliability;data application;cellular voice network;admission control;diversity control;router control;network capacity;voice quality;CDMA call admission control;air interface resource;CDMA network soft-handoff feature;frame selection;active queue management technique;correlated loss minimization;mobile network;congestion overload;Radio control;Multiaccess communication;Radio access networks;Land mobile radio cellular systems;Joining processes;Base stations;Costs;Scalability;Cellular networks;Admission control},
doi={10.1109/INFCOM.2003.1208721},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208722,
author={F. Baccelli and B. Blaszczyszyn and F. Tournois},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Downlink admission/congestion control and maximal load in CDMA networks},
year={2003},
volume={1},
number={},
pages={723-733 vol.1},
abstract={This paper is focused on the influence of geometry on the combination of intercell and intracell interferences in the downlink of large CDMA networks. We use an exact representation of the geometry of the downlink channels to define scalable admission and congestion control schemes, namely schemes that allow each base station to decide independently of the others what set of voice users to serve and/or what bit rates to offer to elastic traffic users competing for bandwidth. We then study the load of these schemes when the size of the network tends to infinity using stochastic geometry tools. By load, we mean here the distribution of the number of voice users that each base station can serve and that of the bit rate offered to each elastic traffic user.},
keywords={telecommunication congestion control;radiofrequency interference;code division multiple access;cellular radio;downlink admission control;congestion control;CDMA network maximal load;intercell combination;intracell interference combination;downlink channel geometry;base station;voice user;bit rate;elastic traffic user;stochastic geometry tool;Downlink;Multiaccess communication;Geometry;Base stations;Bit rate;Interference;Communication system traffic control;Bandwidth;H infinity control;Stochastic processes},
doi={10.1109/INFCOM.2003.1208722},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208723,
author={X. Wang},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={An FDD wideband CDMA MAC protocol for wireless multimedia networks},
year={2003},
volume={1},
number={},
pages={734-744 vol.1},
abstract={A medium access control (MAC) protocol is developed for wireless multimedia networks based on frequency division duplex (FDD) wideband code division multiple access (CDMA). In this protocol, the received power levels of simultaneously transmitting users are controlled by a minimum-power allocation algorithm such that the heterogeneous bit error rates (BERs) of multimedia traffic are guaranteed. With minimum-power allocation, a multimedia wideband CDMA generalized processor sharing (GPS) scheduling scheme is proposed. It provides fair queueing to multimedia traffic with different QoS constraints. It also takes into account the limited number of code channels for each user and the variable system capacity due to interference experienced by users in a CDMA network. The admission of real-time connections is determined by a new effective bandwidth connection admission control (CAC) algorithm in which the minimum-power allocation is also considered. Simulation results show that the new MAC protocol guarantees QoS requirements of both real-time and nonreal-time traffic in an FDD wideband CDMA network.},
keywords={code division multiple access;telecommunication congestion control;error statistics;processor scheduling;multimedia communication;frequency division multiplexing;broadband networks;access protocols;radio networks;queueing theory;quality of service;FDD wideband CDMA network;MAC protocol;wireless multimedia network;medium access control;frequency division duplex wideband code division multiple access;received power level;transmitting user;minimum-power allocation algorithm;heterogeneous bit error rate;BER;multimedia wideband CDMA generalized processor sharing scheduling scheme;multimedia traffic queueing;QoS constraint;code channel;variable system capacity;user interference;real-time connection;effective bandwidth connection admission control algorithm;QoS requirement;real-time traffic;nonreal-time traffic;Wideband;Multiaccess communication;Media Access Protocol;Wireless application protocol;Access protocols;Communication system traffic control;Traffic control;Frequency conversion;Bit error rate;Global Positioning System},
doi={10.1109/INFCOM.2003.1208723},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208724,
author={M. J. Neely and E. Modiano and C. E. Rohrs},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Dynamic power allocation and routing for time varying wireless networks},
year={2003},
volume={1},
number={},
pages={745-755 vol.1},
abstract={We consider dynamic routing and power allocation for a wireless network with time varying channels. The network consists of power constrained nodes which transmit over wireless links with adaptive transmission rates. Packets randomly enter the system at each node and wait in output queues to be transmitted through the network to their destinations. We establish the capacity region of all rate matrices (/spl lambda//sub ij/) that the system can stably support - where (/spl lambda//sub ij/) represents the rate of traffic originating at node i and destined for node j. A joint routing and power allocation policy is developed which stabilizes the system and provides bounded average delay guarantees whenever the input rates are within this capacity region. Such performance holds for general arrival and channel state processes, even if these processes are unknown to the network controller. We then apply this control algorithm to an ad-hoc wireless network where channel variations are due to user mobility, and compare its performance with the Grossglauser-Tse (2001) relay model.},
keywords={time-varying channels;telecommunication network routing;ad hoc networks;mobile radio;telecommunication control;radio links;power control;dynamic power allocation;dynamic routing;time varying wireless network;time varying channel;power constrained node;wireless link;adaptive transmission rate;packet transmission;network queue;network capacity region;node traffic rate;system stability;network average delay;arrival state process;channel state process;network controller;ad-hoc wireless network control algorithm;channel variation;user mobility;Grossglauser-Tse relay model;Routing;Wireless networks;World Wide Web;Communication system control;Telecommunication traffic;Traffic control;Delay;Relays;Data communication;Communication cables},
doi={10.1109/INFCOM.2003.1208724},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208725,
author={A. Pattavina and G. L. Tesei},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Modelling the blocking behavior of multicast Clos networks},
year={2003},
volume={1},
number={},
pages={756-763 vol.1},
abstract={This paper considers three-stage switching networks able to support multicast traffic, i.e. connections in which one inlet is connected to more than one output at the same time. The nonblocking conditions for this network are studied under the assumption of absence of any optimized routing of the connections inside the structure (the so-called strict-sense nonblocking networks). An analytical model is developed here that provides not only the nonblocking conditions of three-stage multicast networks, but also the evaluation of the blocking probability when such conditions are not satisfied. Unlike previous well-known approaches, our model takes into account the correlation between occupancy events in links belonging to different interstage patterns. The results being found also provide a more stringent condition of network nonblocking for multicast traffic which disproves some of the claimed results recently published in the technical literature.},
keywords={multistage interconnection networks;telecommunication traffic;multicast communication;modelling;multicast Clos network blocking behavior;three-stage switching network;multicast traffic;multicast connection;network nonblocking condition;strict-sense nonblocking network;blocking probability;interstage link;Analytical models;Telecommunication traffic;Traffic control;Unicast;Communication switching;Routing;Joining processes;Data communication;Parallel processing;Multicast communication},
doi={10.1109/INFCOM.2003.1208725},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208726,
author={M. Andrews and M. Vojnovic},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Scheduling reserved traffic in input-queued switches: new delay bounds via probabilistic techniques},
year={2003},
volume={1},
number={},
pages={764-774 vol.1},
abstract={We consider the problem of providing delay bounds to reserved traffic in high-speed input-queued switches. We assume that the matrix of bandwidth demands is known and we use the now standard approach of decomposing this matrix into a convex combination of permutation matrices. Our problem therefore reduces to the problem of constructing a schedule for these permutation matrices. In this paper we derive delay bounds for four algorithms that are based on probabilistic techniques. For each algorithm we first place tokens randomly in continuous time for each permutation matrix. If the nth token that appears corresponds to permutation matrix M/sub k/ then we schedule matrix M/sub k/ in the nth time slot. The algorithms differ in how the random token processes are defined. For two of the algorithms we are able to perform a derandomization so as to obtain deterministic schedules. We show through numerical computation that in many situations the resulting delay bounds are smaller than the previously best-known delay bounds of Chang, Chen, and Huang (1999).},
keywords={queueing theory;delays;telecommunication traffic;matrix decomposition;telecommunication switching;randomised algorithms;probability;scheduling;deterministic algorithms;reserved traffic scheduling;high-speed input-queued switch;delay bound;probabilistic technique;bandwidth demand matrix;matrix decomposition;permutation matrice convex combination;matrix schedule;time slot;random token process;derandomization;deterministic schedule;numerical computation;decomposition-based schedule;Switches;Delay;Processor scheduling;Matrix decomposition;Bandwidth;Stability;Telecommunication traffic;Traffic control;Multiprotocol label switching;Scheduling algorithm},
doi={10.1109/INFCOM.2003.1208726},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208727,
author={H. J. Chao and K. -. Deng and Z. Jing},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={A petabit photonic packet switch (P/sup 3/S)},
year={2003},
volume={1},
number={},
pages={775-785 vol.1},
abstract={This paper presents a new petabit photonic packet switch (P/sup 3/S) architecture that is highly scalable both in dimension and capacity while maintaining high system performances. Using a new multidimensional photonic multiplexing scheme that includes space, time, wavelength, and subcarrier domains, we propose a photonic switch fabric based on a 3-stage Clos network to provide scalable large-dimension photonic interconnections with nanosecond reconfiguration speed. Packet buffering is implemented electronically at the input and output port controllers, allowing the central photonic switch fabric to transport high-speed optical signals without electrical-to-optical conversion. Optical time division multiplexing (OTDM) technology further scales port speed beyond electronic speed up to 160 Gbits/s to minimize the fiber connections. To solve output contention, we propose a new arbitration scheme, called frame-based exhaustive matching (FEM), using extended frames to aggregate cells from different incoming lines. The extended frame relaxes the stringent arbitration time constraint at a 160 Gbit/s port speed. Based on the FEM scheme in the proposed architecture, a 6400 /spl times/ 6400 switch with a total capacity of 1.024 petabit/s can be achieved with throughput close to 100% under various traffic conditions.},
keywords={photonic switching systems;packet switching;multistage interconnection networks;optical interconnections;petabit photonic packet switch architecture;system dimension;system capacity;system performance;multidimensional photonic multiplexing scheme;space domain;time domain;wavelength domain;subcarrier domain;photonic switch fabric;3-stage Clos network;photonic interconnection;nanosecond reconfiguration speed;packet buffering;input-output port controller;high-speed optical signal;optical time division multiplexing technology;port speed;fiber connection minimization;arbitration scheme;frame-based exhaustive matching;frame extension;incoming line;stringent arbitration time constraint;traffic condition;1.024 Pbit/s;160 Gbit/s;Packet switching;Optical buffering;Optical packet switching;Optical switches;Fabrics;High speed optical techniques;Optical interconnections;Multidimensional systems;WDM networks;Centralized control},
doi={10.1109/INFCOM.2003.1208727},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{1208728,
author={Suman Das and Harish Viswanathan and G. Rittenhouse},
booktitle={IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No.03CH37428)},
title={Dynamic load balancing through coordinated scheduling in packet data systems},
year={2003},
volume={1},
number={},
pages={786-796 vol.1},
abstract={Third generation code-division multiple access (CDMA) systems propose to provide packet data service through a high speed shared channel with intelligent and fast scheduling at the base-stations. In the current approach base-stations schedule independently of other base-stations. We consider scheduling schemes in which scheduling decisions are made jointly for a cluster of cells thereby enhancing performance through interference avoidance and dynamic load balancing. We consider algorithms that assume complete knowledge of the channel quality information from each of the base-stations to the terminals at the centralized scheduler as well as a two-tier scheduling strategy that assumes only the knowledge of the long term channel conditions at the centralized scheduler. We demonstrate that in the case of asymmetric traffic distribution, where load imbalance is most pronounced, significant throughput gains can be obtained while the gains in the symmetric case are modest. Since the load balancing is achieved through centralized scheduling, our scheme can adapt to time-varying traffic patterns dynamically.},
keywords={resource allocation;scheduling;cellular radio;telecommunication traffic;code division multiple access;packet radio networks;3G mobile communication;dynamic load balancing;coordinated scheduling;packet data system;third generation code-division multiple access system;CDMA system;high speed shared channel;base-station;scheduling decision;cell cluster;interference avoidance;channel quality information;centralized scheduler;two-tier scheduling strategy;time-varying traffic pattern;Load management;Dynamic scheduling;Data systems;Multiaccess communication;Telecommunication traffic;Time division multiple access;Frequency;Interference;Scheduling algorithm;Clustering algorithms},
doi={10.1109/INFCOM.2003.1208728},
ISSN={0743-166X},
month={March},}

