{u'doi': u'10.1109/INFOCOM.2018.8486356', u'author': u'S. Ji and T. Du and Z. Hong and T. Wang and R. Beyah', u'title': u'Quantifying Graph Anonymity, Utility, and De-anonymity', 'ENTRYTYPE': u'inproceedings', u'abstract': u"In this paper, we study the correlation of graph da-ta's anonymity, utility, and de-anonymity. Our main contributions include four perspectives. First, to the best of our knowledge, we conduct the first Anonymity-Utility-De-anonymity (AUD) correlation quantification for graph data and obtain close-forms for such correlation under both a preliminary mathematical model and a general data model. Second, we integrate our AUD quantification to SecGraph [31], a recently published Secure Graph data sharing/publishing system, and extend it to Sec-Graph+. Compared to SecGraph, SecGraph+ is an improved and enhanced uniform and open-source system for comprehensively studying graph anonymization, de-anonymization, and utility evaluation. Third, based on our AUD quantification, we evaluate the anonymity, utility, and de-anonymity of 12 real world graph datasets which are generated from various computer systems and services. The results show that the achievable anonymity/de-anonymity depends on multiple factors, e.g., the preserved data utility, the quality of the employed auxiliary data. Finally, we apply our AUD quantification to evaluate the performance of state-of-the-art anonymization and de-anonymization techniques. Interestingly, we find that there is still significant space to improve state-of-the-art de-anonymization attacks. We also explicitly and quantitatively demonstrate such possible improvement space.", u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'1736-1744', u'year': u'2018', u'keywords': u'data privacy;graph theory;security of data;Graph Anonymity;Anonymity-Utility-De-anonymity correlation quantification;AUD quantification;graph anonymization;utility evaluation;data model;data utility;auxiliary data;SecGraph;Secure Graph data sharing/publishing system;Sec-Graph+;Correlation;Data models;Erbium;Measurement;Electronic mail;Conferences;Mathematical model', 'ID': u'8486356', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2018.8486356', u'author': u'S. Ji and T. Du and Z. Hong and T. Wang and R. Beyah', u'title': u'Quantifying Graph Anonymity, Utility, and De-anonymity', 'ENTRYTYPE': u'inproceedings', u'abstract': u"In this paper, we study the correlation of graph da-ta's anonymity, utility, and de-anonymity. Our main contributions include four perspectives. First, to the best of our knowledge, we conduct the first Anonymity-Utility-De-anonymity (AUD) correlation quantification for graph data and obtain close-forms for such correlation under both a preliminary mathematical model and a general data model. Second, we integrate our AUD quantification to SecGraph [31], a recently published Secure Graph data sharing/publishing system, and extend it to Sec-Graph+. Compared to SecGraph, SecGraph+ is an improved and enhanced uniform and open-source system for comprehensively studying graph anonymization, de-anonymization, and utility evaluation. Third, based on our AUD quantification, we evaluate the anonymity, utility, and de-anonymity of 12 real world graph datasets which are generated from various computer systems and services. The results show that the achievable anonymity/de-anonymity depends on multiple factors, e.g., the preserved data utility, the quality of the employed auxiliary data. Finally, we apply our AUD quantification to evaluate the performance of state-of-the-art anonymization and de-anonymization techniques. Interestingly, we find that there is still significant space to improve state-of-the-art de-anonymization attacks. We also explicitly and quantitatively demonstrate such possible improvement space.", u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'1736-1744', u'year': u'2018', u'keywords': u'data privacy;graph theory;security of data;Graph Anonymity;Anonymity-Utility-De-anonymity correlation quantification;AUD quantification;graph anonymization;utility evaluation;data model;data utility;auxiliary data;SecGraph;Secure Graph data sharing/publishing system;Sec-Graph+;Correlation;Data models;Erbium;Measurement;Electronic mail;Conferences;Mathematical model', 'ID': u'8486356', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057191', u'author': u'H. Dai and B. Liu and H. Yuan and P. Crowley and J. Lu', u'title': u'Analysis of tandem PIT and CS with non-zero download delay', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Collapsed forwarding has long been used in cache systems to reduce the load on servers by aggregating requests for the same content. Named Data Networking (NDN) as a future Internet architecture incorporates this technique through a data structure called Pending Interest Table (PIT). The request aggregation feature suggests that PIT can be viewed as a nonreset time-to-live (TTL) based cache. The Content Store (CS) is a content cache placed in front of the PIT on the NDN forwarding path, so they make up a tandem cache network. To investigate the metrics of interest in this network, like the hit probability for the PIT and the CS, the expected PIT size, non-zero download delay (non-ZDD) should be taken into consideration. Caching policies usually assume zero download delay (ZDD), i.e., request and object arrive simultaneously, and numerous analytical methods have been proposed to study the ZDD caching policies. In this paper, after dissecting the LRU policy, we for the first time propose two LRU variants considering non-ZDD by defining separate operations for the request and object arrivals. When CS adopts the proposed LRU variants, the analysis of the CS-PIT network can still take advantage of the existing models, so the metrics of interest can be computed. Especially, the distribution for the \u201cinter-miss\u201d time of this network can be derived, which has not been achieved by prior works. Finally, the analytical results are verified through simulations.', u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'cache storage;data structures;Internet;future Internet architecture;data structure;Pending Interest Table;request aggregation feature;Content Store;content cache;NDN forwarding path;tandem cache network;nonzero download delay;nonZDD;zero download delay;ZDD caching policies;LRU policy;LRU variants;CS-PIT network;cache systems;Named Data Networking;nonreset time-to-live cache;TTL based cache;inter-miss time;Delays;Computational modeling;Random variables;Conferences;Data structures;Analytical models', 'ID': u'8057191', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057191', u'author': u'H. Dai and B. Liu and H. Yuan and P. Crowley and J. Lu', u'title': u'Analysis of tandem PIT and CS with non-zero download delay', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Collapsed forwarding has long been used in cache systems to reduce the load on servers by aggregating requests for the same content. Named Data Networking (NDN) as a future Internet architecture incorporates this technique through a data structure called Pending Interest Table (PIT). The request aggregation feature suggests that PIT can be viewed as a nonreset time-to-live (TTL) based cache. The Content Store (CS) is a content cache placed in front of the PIT on the NDN forwarding path, so they make up a tandem cache network. To investigate the metrics of interest in this network, like the hit probability for the PIT and the CS, the expected PIT size, non-zero download delay (non-ZDD) should be taken into consideration. Caching policies usually assume zero download delay (ZDD), i.e., request and object arrive simultaneously, and numerous analytical methods have been proposed to study the ZDD caching policies. In this paper, after dissecting the LRU policy, we for the first time propose two LRU variants considering non-ZDD by defining separate operations for the request and object arrivals. When CS adopts the proposed LRU variants, the analysis of the CS-PIT network can still take advantage of the existing models, so the metrics of interest can be computed. Especially, the distribution for the \u201cinter-miss\u201d time of this network can be derived, which has not been achieved by prior works. Finally, the analytical results are verified through simulations.', u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'cache storage;data structures;Internet;future Internet architecture;data structure;Pending Interest Table;request aggregation feature;Content Store;content cache;NDN forwarding path;tandem cache network;nonzero download delay;nonZDD;zero download delay;ZDD caching policies;LRU policy;LRU variants;CS-PIT network;cache systems;Named Data Networking;nonreset time-to-live cache;TTL based cache;inter-miss time;Delays;Computational modeling;Random variables;Conferences;Data structures;Analytical models', 'ID': u'8057191', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057168', u'author': u'B. Samanta and A. De and N. Ganguly', u'title': u'STRM: A sister tweet reinforcement process for modeling hashtag popularity', 'ENTRYTYPE': u'inproceedings', u'abstract': u"With social media platform such as Twitter becoming the de facto destination for users' views and opinions, it is of great importance to forecast an information outbreak. In Twitter, tweets are often annotated with hashtags to help its users to quickly extract their contents. The existing approaches for modeling the dynamics of tweet-messages are usually limited to individual or simple aggregates of tweets rather than the underlying hashtags. In this paper, we develop, STRM, a novel point process driven model that considers the effect of cross-tweet impact in hashtag popularity. STRM, by assuming hashtag to be a heterogeneous collection of tweet-chains. Through extensive experimentation, we find that our algorithm - STRM, shows consistent performance boosts with six diverse real datasets against several strong baselines. Moreover surprisingly, it also offers significant accuracy gains in popularity-prediction for individual tweets as compared with the existing paradigms.", u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'information retrieval;social networking (online);cross-tweet impact;tweet-chains;popularity-prediction;STRM process;tweet-messages;information outbreak;Twitter;social media platform;hashtag popularity;sister tweet reinforcement process;Twitter;Tagging;Computational modeling;Predictive models;Data models;Proposals;History', 'ID': u'8057168', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFOCOM.2017.8057168', u'author': u'B. Samanta and A. De and N. Ganguly', u'title': u'STRM: A sister tweet reinforcement process for modeling hashtag popularity', 'ENTRYTYPE': u'inproceedings', u'abstract': u"With social media platform such as Twitter becoming the de facto destination for users' views and opinions, it is of great importance to forecast an information outbreak. In Twitter, tweets are often annotated with hashtags to help its users to quickly extract their contents. The existing approaches for modeling the dynamics of tweet-messages are usually limited to individual or simple aggregates of tweets rather than the underlying hashtags. In this paper, we develop, STRM, a novel point process driven model that considers the effect of cross-tweet impact in hashtag popularity. STRM, by assuming hashtag to be a heterogeneous collection of tweet-chains. Through extensive experimentation, we find that our algorithm - STRM, shows consistent performance boosts with six diverse real datasets against several strong baselines. Moreover surprisingly, it also offers significant accuracy gains in popularity-prediction for individual tweets as compared with the existing paradigms.", u'issn': '', u'number': '', u'month': u'May', u'volume': '', u'pages': u'1-9', u'year': u'2017', u'keywords': u'information retrieval;social networking (online);cross-tweet impact;tweet-chains;popularity-prediction;STRM process;tweet-messages;information outbreak;Twitter;social media platform;hashtag popularity;sister tweet reinforcement process;Twitter;Tagging;Computational modeling;Predictive models;Data models;Proposals;History', 'ID': u'8057168', u'booktitle': u'IEEE INFOCOM 2017 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFCOM.2004.1354624', u'author': '', u'title': u'[Blank page]', 'ENTRYTYPE': u'inproceedings', u'abstract': u'This page or pages intentionally left blank.', u'issn': u'0743-166X', u'number': '', u'month': u'March', u'volume': u'3', u'pages': u'2174-2174', u'year': u'2004', u'keywords': '', 'ID': u'1354624', u'booktitle': u'IEEE INFOCOM 2004'}
{u'doi': u'10.1109/INFOCOM.2016.7524381', u'author': u'S. Li and J. Xu and M. van der Schaar and W. Li', u'title': u'Popularity-driven content caching', 'ENTRYTYPE': u'inproceedings', u'abstract': u'This paper presents a novel cache replacement method - Popularity-Driven Content Caching (PopCaching). PopCaching learns the popularity of content and uses it to determine which content it should store and which it should evict from the cache. Popularity is learned in an online fashion, requires no training phase and hence, it is more responsive to continuously changing trends of content popularity. We prove that the learning regret of PopCaching (i.e., the gap between the hit rate achieved by PopCaching and that by the optimal caching policy with hindsight) is sublinear in the number of content requests. Therefore, PopCaching converges fast and asymptotically achieves the optimal cache hit rate. We further demonstrate the effectiveness of PopCaching by applying it to a movie.douban.com dataset that contains over 38 million requests. Our results show significant cache hit rate lift compared to existing algorithms, and the improvements can exceed 40% when the cache capacity is limited. In addition, PopCaching has low complexity.', u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'1-9', u'year': u'2016', u'keywords': u'learning (artificial intelligence);social networking (online);popularity driven content caching;PopCaching;cache replacement method;online fashion;content popularity;cache hit rate;movie.douban.com;Databases;Context;Forecasting;Training;Streaming media;Servers;Algorithm design and analysis', 'ID': u'7524381', u'booktitle': u'IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications'}
{u'doi': u'10.1109/INFCOM.2001.916635', u'author': u'E. Cohen and H. Kaplan', u'title': u'Refreshment policies for Web content caches', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Web content caches are often placed between end-users and origin servers as a mean to reduce server load, network usage, and ultimately, user-perceived latency. Cached objects typically have associated expiration times, after which they are considered stale and must be validated with a remote server (origin or another cache) before they can be sent to a client. A considerable fraction of cache hits involve stale copies that turned out to be current. These validations of current objects have small message size, but nonetheless, often induce latency comparable to full-fledged cache misses. Thus, the functionality of caches as a latency-reducing mechanism highly depends not only on content availability but also on its freshness. We propose policies for caches to preactively validate selected objects as they become stale, and thus allow for more client requests to be processed locally. Our policies operate within the existing protocols and exploit natural properties of request patterns such as frequency and recency. We evaluated and compared different policies using trace-based simulations.', u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': u'3', u'pages': u'1398-1406 vol.3', u'year': u'2001', u'keywords': u'Internet;cache storage;client-server systems;refreshment policies;Web content caches;expiration times;cache hits;stale copies;message size;latency;cache misses;functionality;latency-reducing mechanism;content availability;freshness;protocols;request patterns;frequency;recency;trace-based simulations;Network servers;Delay;Costs;Bandwidth;Cache storage;Web server;Prefetching;Protocols;Frequency;Web and internet services', 'ID': u'916635', u'booktitle': u'Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)'}
{u'doi': u'10.1109/INFOCOM.2018.8485860', u'author': u'K. Ji and G. Quan and J. Tan', u'title': u'Asymptotic Miss Ratio of LRU Caching with Consistent Hashing', 'ENTRYTYPE': u'inproceedings', u'abstract': u'To efficiently scale data caching infrastructure to support emerging big data applications, many caching systems rely on consistent hashing to group a large number of servers to form a cooperative cluster. These servers are organized together according to a random hash function. They jointly provide a unified but distributed hash table to serve swift and voluminous data item requests. Different from the single least-recently-used (LRU) server that has already been extensively studied, theoretically characterizing a cluster that consists of multiple LRU servers remains yet to be explored. These servers are not simply added together; the random hashing complicates the behavior. To this end, we derive the asymptotic miss ratio of data item requests on a LRU cluster with consistent hashing. We show that these individual cache spaces on different servers can be effectively viewed as if they could be pooled together to form a single virtual LRU cache space parametrized by an appropriate cache size. This equivalence can be established rigorously under the condition that the cache sizes of the individual servers are large. For typical data caching systems this condition is common. Our theoretical framework provides a convenient abstraction that can directly apply the results from the simpler single LRU cache to the more complex LRU cluster with consistent hashing.', u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'450-458', u'year': u'2018', u'keywords': u'Big Data;cache storage;file organisation;file servers;asymptotic miss ratio;LRU caching;consistent hashing;data caching infrastructure;big data applications;random hash function;swift data item requests;voluminous data item requests;multiple LRU servers;random hashing;individual cache spaces;single virtual LRU cache space;appropriate cache size;cache sizes;individual servers;typical data caching systems;simpler single LRU cache;complex LRU cluster;distributed hash table;Servers;Distributed databases;Partitioning algorithms;Conferences;Clustering algorithms;Random variables;Electronic mail', 'ID': u'8485860', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
