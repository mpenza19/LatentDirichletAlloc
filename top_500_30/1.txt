{u'doi': u'10.1109/INFCOM.2013.6566967', u'author': u'M. Malboubi and C. Vu and C. Chuah and P. Sharma', u'title': u'Decentralizing network inference problems with Multiple-Description Fusion Estimation (MDFE)', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Two forms of network inference (or tomography) problems have been studied rigorously: (a) traffic matrix estimation or completion based on link-level traffic measurements, and (b) link-level loss or delay inference based on end-to-end measurements. These problems are often posed as underdetermined linear inverse (UDLI) problems and solved in a centralized manner, where all the measurements are collected at a central node, which then applies a variety of inference techniques to estimate the attributes of interest. This paper proposes a novel framework for decentralizing these large-scale UDLI network inference problems by intelligently partitioning it into smaller sub-problems and solving them independently and in parallel. The resulting estimates, referred to as multiple descriptions, can then be fused together to compute the global estimate. We apply this Multiple Description and Fusion Estimation (MDFE) framework to three classical problems: traffic matrix estimation, traffic matrix completion, and loss inference. Using real topologies and traces, we demonstrate how MDFE can speed up computation time while maintaining (even improving) the estimation accuracy and how it enhances robustness against noise and failures. We also show that our MDFE framework is compatible with a variety of existing inference techniques used to solve the UDLI problems.', u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': '', u'pages': u'1699-1707', u'year': u'2013', u'keywords': u'delays;inference mechanisms;Internet;matrix algebra;telecommunication traffic;decentralizing network inference problem;multiple-description fusion estimation;MDFE;link-level traffic measurements;link-level loss;delay inference;end-to-end measurement;under-determined linear inverse;UDLI network inference problem;traffic matrix estimation;traffic matrix completion;MDFE framework;inference technique;Internet;Estimation;Partitioning algorithms;Accuracy;Loss measurement;Robustness;Complexity theory;Clustering algorithms', 'ID': u'6566967', u'booktitle': u'2013 Proceedings IEEE INFOCOM'}
{u'doi': u'10.1109/INFCOM.2011.5935054', u'author': u'M. Lee and M. Hajjat and R. R. Kompella and S. Rao', u'title': u'RelSamp: Preserving application structure in sampled flow measurements', 'ENTRYTYPE': u'inproceedings', u'abstract': u'The Internet has significantly evolved in the number and variety of applications. Network operators need mechanisms to constantly monitor and study these applications. Given modern applications routinely consist of several flows, potentially to many different destinations, existing measurement approaches such as Sampled NetFlow sample only a few flows per application session. To address this issue, in this paper, we introduce RelSamp architecture that implements the notion of related sampling where flows that are part of the same application session are given higher probability. In our evaluation using real traces, we show that RelSamp achieves 5-10x more flows per application session compared to Sampled NetFlow for the same effective number of sampled packets. We also show that behavioral and statistical classification approaches such as BLINC, SVM and C4.5 achieve up to 50% better classification accuracy compared to Sampled NetFlow, while not breaking existing management tasks such as volume estimation.', u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': '', u'pages': u'2354-2362', u'year': u'2011', u'keywords': u'Internet;statistical analysis;RelSamp;application structure;sampled flow measurements;Internet;sampled NetFlow;statistical classification;Accuracy;IP networks;Internet;Monitoring;Estimation;Random variables;Inspection', 'ID': u'5935054', u'booktitle': u'2011 Proceedings IEEE INFOCOM'}
{u'doi': u'10.1109/INFOCOM.2015.7218672', u'author': u'F. Xiao and C. Sha and L. Chen and L. Sun and R. Wang', u'title': u'Noise-tolerant localization from incomplete range measurements for wireless sensor networks', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Accurate and sufficient range measurements are essential for range-based localization in wireless sensor networks. However, noise and data missing are inevitable in distance ranging, which may degrade localization accuracy drastically. Existing localization approaches often degrade in terms of accuracy in the co-existence of incomplete and corrupted range measurements. To address this challenge, a noise-tolerant localization algorithm called NLIRM is presented. By utilizing the natural low rank property of Euclidean distance matrix, the reconstruction of partially sampled and noisy distance matrix is formulated as a norm-regularized matrix completion problem, where Gaussian noises and outliers are smoothed by Frobenius-norm and L<sub>1</sub> norm regularization, respectively. As far as we are aware of, this is the first scheme that can recover the missing range measurements and explicitly sift Gaussian noise and outlier simultaneously. Simulation results demonstrate that, compared with traditional algorithms, NLIRM achieves better localization performance under the same experiment setting. In addition, our algorithm provides an accurate prediction of outlier positions, which is the prerequisite for malfunction diagnosis in WSN.', u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': '', u'pages': u'2794-2802', u'year': u'2015', u'keywords': u'Gaussian noise;signal reconstruction;wireless sensor networks;Gaussian noises;norm-regularized matrix completion problem;noisy distance matrix;Euclidean distance matrix;natural low rank property;wireless sensor networks;incomplete range measurements;noise-tolerant localization;Noise;Wireless sensor networks;Distance measurement;Noise measurement;Sparse matrices;Algorithm design and analysis;Matrix decomposition', 'ID': u'7218672', u'booktitle': u'2015 IEEE Conference on Computer Communications (INFOCOM)'}
{u'doi': u'10.1109/INFOCOM.2008.13', u'author': u'J. Cao and A. Chen and T. Bu', u'title': u'A Quasi-Likelihood Approach for Accurate Traffic Matrix Estimation in a High Speed Network', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Knowing the traffic matrix, i.e., packet/byte counts between pairs of nodes in a network, is important for network management. The main challenges for accurate traffic matrix estimation in a high speed network are the computation and memory limitations. In this paper, we propose a novel algorithm for traffic matrix estimation that can yield accurate estimates whereas uses small memory and per packet update overhead. Our algorithm constructs a compact probabilistic traffic digest at each network node, and derives a Quasi Maximum Likelihood Estimate (Quasi-MLE) of the traffic matrix by correlating the traffic digests received at a central location. Our new approach is highly efficient, requiring no prior knowledge of the exact packet size distributions. We derive accurate approximation of the relative error distribution of our estimate. For an origin- destination (OD) pair (o,d), we show that by using an array of size M for each traffic digest at o and d, the relative estimation standard error is O(M<sup>-1/2</sup>(sigma<sub>o</sub> <sub>+</sub>sigma<sub>d</sub>)<sup>1/2</sup>), where sigma<sub>o</sub>,sigma<sub>d</sub> are the noise-to-signal ratios, defined as the ratios of non-OD packet/byte counts to OD packet/byte counts at the origin and destination. This is superior to the state-of-the-art algorithms, especially for large sigma<sub>o</sub> and sigma<sub>d</sub>, where the estimation is more challenging. We further demonstrate the effectiveness of our approach using both model and real Internet trace-driven simulations.', u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': '', u'pages': u'21-25', u'year': u'2008', u'keywords': u'approximation theory;computational complexity;matrix algebra;maximum likelihood estimation;probability;telecommunication network management;telecommunication traffic;probabilistic traffic matrix estimation;quasi maximum likelihood estimation;high speed network management;approximation theory;Telecommunication traffic;High-speed networks;Yield estimation;Computer network management;Computer networks;Maximum likelihood estimation;Estimation error;Signal to noise ratio;State estimation;Internet', 'ID': u'4509608', u'booktitle': u'IEEE INFOCOM 2008 - The 27th Conference on Computer Communications'}
{u'doi': u'10.1109/INFCOM.1999.749287', u'author': u'S. B. Moon and P. Skelly and D. Towsley', u'title': u'Estimation and removal of clock skew from network delay measurements', 'ENTRYTYPE': u'inproceedings', u'abstract': u'Packet delay and loss traces are frequently used by network engineers, as well as network applications, to analyze network performance. The clocks on the end-systems used to measure the delays, however, are not always synchronized, and this lack of synchronization reduces the accuracy of these measurements. Therefore, estimating and removing relative skews and offsets from delay measurements between sender and receiver clocks are critical to the accurate assessment and analysis of network performance. We introduce a linear programming-based algorithm to estimate the clock skew in network delay measurements and compare it with three other algorithms. We show that our algorithm has a time complexity of O(N), leaves the delay after the skew removal positive, and is robust in the sense that the error margin of the skew estimate is independent of the magnitude of the skew. We use traces of real Internet delay measurements to assess the algorithm, and compare its performance to that of three other algorithms. Furthermore, we show through simulation that our algorithm is unbiased, and that the sample variance of the skew estimate is better (smaller) than existing algorithms.', u'issn': u'0743-166X', u'number': '', u'month': u'March', u'volume': u'1', u'pages': u'227-234 vol.1', u'year': u'1999', u'keywords': u'Internet;delay estimation;time measurement;clocks;packet switching;performance evaluation;computational complexity;linear programming;synchronisation;network delay measurements;clock skew removal;clock skew estimation;network applications;network performance;packet delay;packet traces;receiver clock;sender clock;linear programming-based algorithm;time complexity;error margin;real Internet delay measurements;simulation;unbiased algorithm;sample variance;synchronization;Delay estimation;Clocks;Delay effects;Internet;Frequency synchronization;Frequency measurement;Loss measurement;Computer science;Application software;Performance analysis', 'ID': u'749287', u'booktitle': u"IEEE INFOCOM '99. Conference on Computer Communications. Proceedings. Eighteenth Annual Joint Conference of the IEEE Computer and Communications Societies. The Future is Now (Cat. No.99CH36320)"}
{u'doi': u'10.1109/INFOCOM.2018.8486306', u'author': u'H. Shao and S. Yao and Y. Zhao and C. Zhang and J. Han and L. Kaplan and L. Su and T. Abdelzaher', u'title': u'A Constrained Maximum Likelihood Estimator for Unguided Social Sensing', 'ENTRYTYPE': u'inproceedings', u'abstract': u'This paper develops a constrained expectation maximization algorithm (CEM) that improves the accuracy of truth estimation in unguided social sensing applications. Unguided social sensing refers to the act of leveraging naturally occurring observations on social media as \u201csensor measurements\u201d, when the sources post at will and not in response to specific sensing campaigns or surveys. A key challenge in social sensing, in general, lies in estimating the veracity of reported observations, when the sources reporting these observations are of unknown reliability and their observations themselves cannot be readily verified. This problem is known as fact-finding. Unsupervised solutions have been proposed to the fact-finding problem that explore notions of internal data consistency in order to estimate observation veracity. This paper observes that unguided social sensing gives rise to a new (and very simple) constraint that dramatically reduces the space of feasible fact-finding solutions, hence significantly improving the quality of fact-finding results. The constraint relies on a simple approximate test of source independence, applicable to unguided sensing, and incorporates information about the number of independent sources of an observation to constrain the posterior estimate of its probability of correctness. Two different approaches are developed to test the independence of sources for purposes of applying this constraint, leading to two flavors of the CEM algorithm, we call CEM and CEM-Jaccard. We show using both simulation and real data sets collected from Twitter that by forcing the algorithm to converge to a solution in which the constraint is satisfied, the quality of solutions is significantly improved.', u'issn': '', u'number': '', u'month': u'April', u'volume': '', u'pages': u'2429-2437', u'year': u'2018', u'keywords': u'data mining;expectation-maximisation algorithm;information resources;sensor fusion;social networking (online);fact-finding problem;constrained maximum likelihood estimator;constrained expectation maximization algorithm;truth estimation;unguided social sensing applications;social media;sensor measurements;data consistency;CEM algorithm;CEM-Jaccard;information fusion;truth discovery;Sensors;Silicon;Reliability;Twitter;Estimation;Conferences;social networks;truth discovery;constrained expectation maximization (CEM);estimation accuracy', 'ID': u'8486306', u'booktitle': u'IEEE INFOCOM 2018 - IEEE Conference on Computer Communications'}
{u'doi': u'10.1109/INFCOM.2010.5461918', u'author': u'D. Ghita and H. Nguyen and M. Kurant and K. Argyraki and P. Thiran', u'title': u'Netscope: Practical Network Loss Tomography', 'ENTRYTYPE': u'inproceedings', u'abstract': u'We present Netscope, a tomographic technique that infers the loss rates of network links from unicast end-to-end measurements. Netscope uses a novel combination of first- and second-order moments of end-to-end measurements to identify and characterize the links that cannot be (accurately) characterized through existing practical tomographic techniques. Using both analytical and experimental tools, we show that Netscope enables scalable, accurate link-loss inference: in a simulation scenario involving 4000 links, 20% of them lossy, Netscope correctly identifies 94% of the lossy links with a false positive rate of 16%-a significant improvement over the existing alternatives. Netscope is robust in the sense that it requires no parameter tuning, moreover its advantage over the alternatives widens when the number of lossy links increases. We also validate Netscope\'s performance on an "Internet tomographer" that we deployed on an overlay of 400 PlanetLab nodes.', u'issn': u'0743-166X', u'number': '', u'month': u'March', u'volume': '', u'pages': u'1-9', u'year': u'2010', u'keywords': u'Internet;Netscope;network loss tomography technique;unicast end-to-end measurements;network links;link-loss inference;Internet tomographer;PlanetLab nodes;Tomography;Extraterrestrial measurements;Internet;Loss measurement;Routing;Inference algorithms;Analytical models;Robustness;Vectors;Delay estimation', 'ID': u'5461918', u'booktitle': u'2010 Proceedings IEEE INFOCOM'}
{u'doi': u'10.1109/INFOCOM.2015.7218633', u'author': u'K. Xie and L. Wang and X. Wang and G. Xie and G. Zhang and D. Xie and J. Wen', u'title': u'Sequential and adaptive sampling for matrix completion in network monitoring systems', 'ENTRYTYPE': u'inproceedings', u'abstract': u'End-to-end network monitoring is essential to ensure transmission quality for Internet applications. However, in large-scale networks, full-mesh measurement of network performance between all transmission pairs is infeasible. As a newly emerging sparsity representation technique, matrix completion allows the recovery of a low-rank matrix using only a small number of random samples. Existing schemes often fix the number of samples assuming the rank of the matrix is known, while the data features thus the matrix rank vary over time. In this paper, we propose to exploit the matrix completion techniques to derive the end-to-end network performance among all node pairs by only measuring a small subset of end-to-end paths. To address the challenge of rank change in the practical system, we propose a sequential and information-based adaptive sampling scheme, along with a novel sampling stopping condition. Our scheme is based only on the data observed without relying on the reconstruction method or the knowledge on the sparsity of unknown data. We have performed extensive simulations based on real-world trace data, and the results demonstrate that our scheme can significantly reduce the measurement cost while ensuring high accuracy in obtaining the whole network performance data.', u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': '', u'pages': u'2443-2451', u'year': u'2015', u'keywords': u'matrix algebra;signal sampling;wireless mesh networks;end-to-end network monitoring system performance;large-scale network full-mesh measurement;low-rank matrix completion technique;sequential sampling scheme;information-based adaptive sampling scheme;sampling stopping condition;Monitoring;Sparse matrices;Matrix decomposition;Computers;Accuracy;Conferences;Internet;Matrix Completion;Round-Trip Time Measurement;Sampling Stopping Condition', 'ID': u'7218633', u'booktitle': u'2015 IEEE Conference on Computer Communications (INFOCOM)'}
{u'doi': u'10.1109/INFOCOM.2015.7218646', u'author': u'G. Einziger and B. Fellman and Y. Kassner', u'title': u'Independent counter estimation buckets', 'ENTRYTYPE': u'inproceedings', u'abstract': u"Measurement capabilities are essential for a variety of network applications, such as load balancing, routing, fairness and intrusion detection. These capabilities require large counter arrays in order to monitor the traffic of all network flows. While commodity SRAM memories are capable of operating at line speed, they are too small to accommodate large counter arrays. Previous works suggested estimators, which trade precision for reduced space. However, in order to accurately estimate the largest counter, these methods compromise the accuracy of the rest of the counters. In this work we present a closed form representation of the optimal estimation function. We then introduce Independent Counter Estimation Buckets (ICE-Buckets), a novel algorithm that improves estimation accuracy for all counters. This is achieved by separating the flows to buckets and configuring the optimal estimation function according to each bucket's counter scale. We prove an improved upper bound on the relative error and demonstrate an accuracy improvement of up to 57 times on real Internet packet traces.", u'issn': u'0743-166X', u'number': '', u'month': u'April', u'volume': '', u'pages': u'2560-2568', u'year': u'2015', u'keywords': u'estimation theory;independent counter estimation buckets;closed form representation;optimal estimation function;Radiation detectors;Estimation;Accuracy;Random access memory;Conferences;Computers;Monitoring', 'ID': u'7218646', u'booktitle': u'2015 IEEE Conference on Computer Communications (INFOCOM)'}
{u'doi': u'10.1109/INFCOM.2000.832579', u'author': u'A. Vidacs and J. T. Virtamo', u'title': u'Parameter estimation of geometrically sampled fractional Brownian traffic', 'ENTRYTYPE': u'inproceedings', u'abstract': u"The parameter estimation of a traffic model based on the fractional Brownian motion (FBM) is studied. The model has three parameters: the mean rate m, variance parameter a and the Hurst parameter H. Explicit expressions for the maximum likelihood (ML) estimates m/spl circ/ and a/spl circ/ in terms of H are given, as well as the expression for the log likelihood function from which the estimate H/spl circ/ is obtained as the maximizing argument. A geometric sequence of sampling points, t/sub i/=/spl alpha//sup i/, is introduced, which fits neatly into the self-similar property of the process and also reduces the number of samples needed to cover several time scales. It is shown that by a proper 'descaling' the traffic process is stationary on this grid leading to a Toeplitz-type covariance matrix. Approximations for the inverted covariance matrix and its determinant are introduced. The accuracy of the estimations is studied by simulations. Comparisons with estimates obtained with linear sampling and with the wavelet-based A-V estimator show that the geometrical sampling indeed improves the accuracy of the estimate H/spl circ/ with a given number of samples.", u'issn': u'0743-166X', u'number': '', u'month': u'March', u'volume': u'3', u'pages': u'1791-1796 vol.3', u'year': u'2000', u'keywords': u'maximum likelihood estimation;Brownian motion;telecommunication traffic;fractals;sequences;approximation theory;Toeplitz matrices;covariance matrices;matrix inversion;determinants;sampling methods;parameter estimation;geometrically sampled traffic;fractional Brownian motion;Hurst parameter;maximum likelihood estimates;ML estimates;log likelihood function;geometric sequence;self-similar property;descaling;Toeplitz-type covariance matrix;approximations;inverted covariance matrix;determinant;simulations;Parameter estimation;Traffic control;Sampling methods;Maximum likelihood estimation;Covariance matrix;Telecommunication traffic;High-speed networks;Telematics;Brownian motion;Time measurement', 'ID': u'832579', u'booktitle': u'Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)'}
